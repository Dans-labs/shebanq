{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
    "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETCBC in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exports the ETCBC database to an R data frame.\n",
    "The nodes are exported as rows, they correspond to the objects.\n",
    "The edges corresponding to the etcbc features *mother*, *functional_parent*, *distributional_parent* are\n",
    "exported as columns. For each row, such a column indicates the target of a corresponding outgoing edge.\n",
    "In the ETCBC data objects have at most one outgoing edge for each type of edge. The target is identified by its object identifier, which is in the ``oid`` column.\n",
    "\n",
    "Extra data such as lexicon (including frequency and rank features), phonetic transcription, and ketiv-qere is also included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the file \n",
    "``etcbc4b.rds``\n",
    "in the \n",
    "[laf-fabric-data github repository](https://github.com/ETCBC/laf-fabric-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.7\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, collections\n",
    "\n",
    "\n",
    "from laf.fabric import LafFabric\n",
    "import etcbc\n",
    "\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2016-01-27T18-59-08\n",
      "  1.15s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/hinr/__log__hinr.txt\n",
      "  1.15s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX para FOR TASK hinr AT 2016-01-28T06-40-56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('etcbc4', ['db.maxmonad', 'db.minmonad', 'db.monads', 'db.oid', 'db.otype', 'ft.code', 'ft.det', 'ft.dist', 'ft.dist_unit', 'ft.domain', 'ft.function', 'ft.g_cons', 'ft.g_cons_utf8', 'ft.g_lex', 'ft.g_lex_utf8', 'ft.g_nme', 'ft.g_nme_utf8', 'ft.g_pfm', 'ft.g_pfm_utf8', 'ft.g_prs', 'ft.g_prs_utf8', 'ft.g_uvf', 'ft.g_uvf_utf8', 'ft.g_vbe', 'ft.g_vbe_utf8', 'ft.g_vbs', 'ft.g_vbs_utf8', 'ft.g_word', 'ft.g_word_utf8', 'ft.gn', 'ft.is_root', 'ft.kind', 'ft.language', 'ft.lex', 'ft.lex_utf8', 'ft.ls', 'ft.mother_object_type', 'ft.nme', 'ft.nu', 'ft.number', 'ft.pdp', 'ft.pfm', 'ft.prs', 'ft.ps', 'ft.rela', 'ft.sp', 'ft.st', 'ft.tab', 'ft.trailer_utf8', 'ft.txt', 'ft.typ', 'ft.uvf', 'ft.vbe', 'ft.vbs', 'ft.vs', 'ft.vt', 'px.instruction', 'px.number_in_ch', 'px.pargr', 'sft.book', 'sft.chapter', 'sft.label', 'sft.verse'])]\n"
     ]
    }
   ],
   "source": [
    "API = fabric.load('etcbc4b', 'para', 'hinr', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "''',\"\"),\n",
    "    \"primary\": False,\n",
    "})\n",
    "print(API['F_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instruction number_in_ch pargr'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_features = [x.split('.', 1)[1] for x in API['F_all'][0][1] if x.split('.', 1)[0] == 'px']\n",
    "p_feature_str = ' '.join(p_features)\n",
    "p_feature_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2016-01-27T18-59-08\n",
      "  0.21s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX para FOR TASK hinr AT 2016-01-28T06-42-11\n"
     ]
    }
   ],
   "source": [
    "API = fabric.load_again({\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": (p_feature_str,\"\"),\n",
    "    \"primary\": False,\n",
    "})\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5.02s Collecting R data for paragraphs\n",
      "  5.46s  100000 nodes read\n",
      "  5.81s  200000 nodes read\n",
      "  6.18s  300000 nodes read\n",
      "  6.53s  400000 nodes read\n",
      "  6.86s  500000 nodes read\n",
      "  7.20s  600000 nodes read\n",
      "  7.56s  700000 nodes read\n",
      "  7.90s  800000 nodes read\n",
      "  8.23s  900000 nodes read\n",
      "  8.54s 1000000 nodes read\n",
      "  8.88s 1100000 nodes read\n",
      "  9.21s 1200000 nodes read\n",
      "  9.86s 1300000 nodes read\n",
      "    10s 1400000 nodes read\n",
      "    10s 1436858 nodes read and done\n"
     ]
    }
   ],
   "source": [
    "msg(\"Collecting R data for paragraphs\")\n",
    "chunk_size = 100000\n",
    "i = 0\n",
    "s = 0\n",
    "p_data = {}\n",
    "for n in NN():\n",
    "    p_values = []\n",
    "    p_data[n] = tuple(F.item[x].v(n) for x in p_features)\n",
    "    i += 1\n",
    "    s += 1\n",
    "    if s == chunk_size:\n",
    "        s = 0\n",
    "        msg('{:>7} nodes read'.format(i))\n",
    "msg('{:>7} nodes read and done'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2016-01-27T19-01-17\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK hinr AT 2016-01-28T06-42-26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('etcbc4', ['db.maxmonad', 'db.minmonad', 'db.monads', 'db.oid', 'db.otype', 'ft.code', 'ft.det', 'ft.dist', 'ft.dist_unit', 'ft.domain', 'ft.function', 'ft.g_cons', 'ft.g_cons_utf8', 'ft.g_lex', 'ft.g_lex_utf8', 'ft.g_nme', 'ft.g_nme_utf8', 'ft.g_pfm', 'ft.g_pfm_utf8', 'ft.g_prs', 'ft.g_prs_utf8', 'ft.g_uvf', 'ft.g_uvf_utf8', 'ft.g_vbe', 'ft.g_vbe_utf8', 'ft.g_vbs', 'ft.g_vbs_utf8', 'ft.g_word', 'ft.g_word_utf8', 'ft.gn', 'ft.is_root', 'ft.kind', 'ft.language', 'ft.lex', 'ft.lex_utf8', 'ft.ls', 'ft.mother_object_type', 'ft.nme', 'ft.nu', 'ft.number', 'ft.pdp', 'ft.pfm', 'ft.prs', 'ft.ps', 'ft.rela', 'ft.sp', 'ft.st', 'ft.tab', 'ft.trailer_utf8', 'ft.txt', 'ft.typ', 'ft.uvf', 'ft.vbe', 'ft.vbs', 'ft.vs', 'ft.vt', 'kq.g_qere_utf8', 'kq.qtrailer_utf8', 'lex.entry', 'lex.entry_heb', 'lex.entryid', 'lex.freq_lex', 'lex.freq_occ', 'lex.g_entry', 'lex.g_entry_heb', 'lex.gloss', 'lex.id', 'lex.lan', 'lex.nametype', 'lex.pos', 'lex.rank_lex', 'lex.rank_occ', 'lex.root', 'lex.subpos', 'ph.phono', 'ph.phono_sep', 'sft.book', 'sft.chapter', 'sft.label', 'sft.verse'])]\n",
      "[('etcbc4', ['ft.distributional_parent', 'ft.functional_parent', 'ft.mother']), ('laf', [('', 'x'), ('', 'y')])]\n"
     ]
    }
   ],
   "source": [
    "API = fabric.load('etcbc4b', 'lexicon', 'hinr', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "''',\"\"),\n",
    "    \"primary\": False,\n",
    "})\n",
    "\n",
    "print(API['F_all'])\n",
    "print(API['FE_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distributional_parent functional_parent mother'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = [x.split('.', 1)[1] for x in API['F_all'][0][1]]\n",
    "all_feature_str = ' '.join(all_features)\n",
    "alle_features = [x.split('.', 1)[1] for x in API['FE_all'][0][1]]\n",
    "alle_feature_str = ' '.join(alle_features)\n",
    "alle_feature_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2016-01-27T19-01-17\n",
      "    25s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK hinr AT 2016-01-28T06-43-08\n"
     ]
    }
   ],
   "source": [
    "API = fabric.load_again({\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": (all_feature_str,alle_feature_str),\n",
    "    \"primary\": False,\n",
    "})\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4.98s Writing R data\n",
      "    14s  100000 nodes written\n",
      "    25s  200000 nodes written\n",
      "    34s  300000 nodes written\n",
      "    43s  400000 nodes written\n",
      "    52s  500000 nodes written\n",
      " 1m 02s  600000 nodes written\n",
      " 1m 11s  700000 nodes written\n",
      " 1m 23s  800000 nodes written\n",
      " 1m 35s  900000 nodes written\n",
      " 1m 45s 1000000 nodes written\n",
      " 1m 55s 1100000 nodes written\n",
      " 2m 06s 1200000 nodes written\n",
      " 2m 18s 1300000 nodes written\n",
      " 2m 33s 1400000 nodes written\n",
      " 2m 37s 1436858 nodes written and done\n"
     ]
    }
   ],
   "source": [
    "msg(\"Writing R data\")\n",
    "hr = open('/Users/dirk/SURFdrive/laf-fabric-data/r/etcbc4b.txt', 'w')\n",
    "use_features = all_features\n",
    "usee_features = alle_features\n",
    "# use_features = ['oid'] + all_features[60:77]\n",
    "hr.write('{}\\t{}\\t{}\\n'.format(\n",
    "    '\\t'.join(use_features),\n",
    "    '\\t'.join(p_features),\n",
    "    '\\t'.join(usee_features),\n",
    "))\n",
    "chunk_size = 100000\n",
    "i = 0\n",
    "s = 0\n",
    "for n in NN():\n",
    "    all_values = [F.item[x].v(n) for x in use_features]\n",
    "    p_values = p_data[n]\n",
    "    alle_values = [F.oid.v((list(C.item[x].v(n)) or [-1])[0]) for x in usee_features]\n",
    "    hr.write('{}\\t{}\\t{}\\n'.format(\n",
    "        ('\\t'.join(x or '' for x in all_values)).replace('\\n',''),\n",
    "        ('\\t'.join(x or '' for x in p_values)).replace('\\n',''),\n",
    "        ('\\t'.join(x or '' for x in alle_values)).replace('\\n',''),\n",
    "    ))\n",
    "    i += 1\n",
    "    s += 1\n",
    "    if s == chunk_size:\n",
    "        s = 0\n",
    "        msg('{:>7} nodes written'.format(i))\n",
    "hr.close()\n",
    "msg('{:>7} nodes written and done'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R export is ready now, but it is a bit large.\n",
    "We can get a much leaner file by using R to load this file and save it in .rds format.\n",
    "\n",
    "If your installation is not such that you can run R in a notebook based on a python kernel (as I am experiencing right now due to problems with the python module `rpy2`), switch to the Hebrew_In_RR notebook in this same directory to \n",
    "carry out the R cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data in R and save it in compact .rds format.\n",
    "\n",
    "Note that we have to ignore quotes and comment signs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cell magic `%%R` not found.\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "etcbc = read.table(\n",
    "    '/Users/dirk/SURFdrive/laf-fabric-data/r/etcbc4b.txt', \n",
    "    sep=\"\\t\", \n",
    "    header=TRUE, \n",
    "    comment.char=\"\",\n",
    "    quote=\"\",\n",
    "    as.is = TRUE,\n",
    ")\n",
    "dim(etcbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "saveRDS(\n",
    "    object=etcbc, \n",
    "    file='/Users/dirk/SURFdrive/laf-fabric-data/r/etcbc4b.rds'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 645384\r\n",
      "-rw-r--r--  1 dirk  staff    50M Jan 28 09:39 etcbc4b.rds\r\n",
      "-rw-r--r--  1 dirk  staff   265M Jan 28 07:45 etcbc4b.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /Users/dirk/SURFdrive/laf-fabric-data/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check how fast this loads. (Half the time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1436858      82\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "etcbc = readRDS(\n",
    "    file='/Users/dirk/SURFdrive/laf-fabric-data/r/etcbc4b.rds'\n",
    ")\n",
    "dim(etcbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy it to the github directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp '/Users/dirk/SURFdrive/laf-fabric-data/r/etcbc4b.rds' '/Users/dirk/SURFdrive/current/demos/github/laf-fabric-data/etcbc4b.rds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
