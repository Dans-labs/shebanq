{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-small.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/DANS-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-small.png\"/></a>\n",
    "<a href=\"https://www.academic-bible.com/en/online-bibles/biblia-hebraica-stuttgartensia-bhs/read-the-bible-text/\" target=\"_blank\"><img align=\"right\" src=\"files/images/DBG-small.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbal valence\n",
    "\n",
    "*Verbal valence* is a kind of signature of a verb, not unlike overloading in programming languages.\n",
    "The meaning of a verb depends on the number and kind of its complements, i.e. the linguistic entities that act as arguments for the semantic function of the verb.\n",
    "\n",
    "We will use a set of flowcharts to specify and compute the sense of a verb in specific contexts depending on the verbal valence. The flowcharts have been composed by Janet Dyk. Although they are not difficult to understand, it takes a good deal of ingenuity to apply them in all the real world situations that we encounter in our corpus.\n",
    "\n",
    "\n",
    "# Authors\n",
    "\n",
    "This notebook is being written by [Dirk Roorda](dirk.roorda@dans.knaw.nl) following the ideas of \n",
    "[Janet Dyk](j.w.dyk@vu.nl). Janet's ideas have been published in various ways, see the references below.\n",
    "They can be summarized as a set of flowcharts. Each flowchart describes set of rules how to choose between\n",
    "the senses of a specific verb based on the constituents in each context where it occurs.\n",
    "The role of Dirk is to turn those ideas into a working program based on the ETCBC data.\n",
    "\n",
    "# About\n",
    "\n",
    "This is an [Jupyter](http://jupyter.org) notebook. It contains a working program to carry out the computations\n",
    "that we need for making use of verbal valence patterns.\n",
    "You can download this notebook and run it on your computer, provided you have\n",
    "[LAF-Fabric](http://laf-fabric.readthedocs.org/en/latest/texts/welcome.html) installed.\n",
    "\n",
    "There is not only code in this notebook, but also extensive documentation, and a description how to view\n",
    "the results on \n",
    "[SHEBANQ](https://shebanq.ancient-data.org) as a set of *Notes*.\n",
    "See the end of the notebook for precise links.\n",
    "\n",
    "# Status\n",
    "\n",
    "**Last modified: 2016-11-15**\n",
    "\n",
    "This notebook is not yet finished. \n",
    "It turns out that the ETCBC data at present does not contain all bits and pieces that are needed to follow\n",
    "the rules in Janet's flowcharts. It is difficult to find all direct objects, especially implied ones.\n",
    "And there are many cases where the database encodes a phrase as a complement, where the flowchart expects it to be a direct object.\n",
    "\n",
    "We have set up a workflow for correcting and enriching the ETCBC data. See the\n",
    "[corr_enrich notebook](corr_enrich.ipynb).\n",
    "There we take care that all relevant phrases get there proper *function*\n",
    "labels. And we analyse those phrases and assign new properties to them, based on certain heuristics.\n",
    "\n",
    "This flowchart notebook takes those new properties as input for determining the valencies of verbs.\n",
    " \n",
    "# More about flowcharts\n",
    "\n",
    "Here is an original flowchart by Janet, the one for NTN (*give*).\n",
    "\n",
    "<img src=\"images/FlowChartNTN-orig.pdf\"/>\n",
    "\n",
    "In order to run the flowcharts, preliminary work has to be done. \n",
    "We have to \n",
    "\n",
    "* identify direct objects;\n",
    "* divide them into principal and secundary ones if there are multiple;\n",
    "* identify complements;\n",
    "* divide them into locatives, indirect objects, and other complements;\n",
    "* detect relativa and offer them as potential direct objects;\n",
    "* detect phrases starting with MN (*from*) and offer them as potential direct objects.\n",
    "\n",
    "These are exactly the things that we outsource to the \n",
    "[corr_enrich notebook](corr_enrich.ipynb).\n",
    "\n",
    "\n",
    "# Generic flowchart\n",
    "\n",
    "The generic flowchart rules can be read off this diagram.\n",
    "\n",
    "<img src=\"images/Valence/Valence.001.jpeg\"/>\n",
    "\n",
    "In fact, this part of the flowchart requires the most programming effort.\n",
    "\n",
    "# Specific flowcharts\n",
    "\n",
    "Using the generic flowchart, we state the rules for individual verbs, which can be expressed as simple\n",
    "multiple choice lists. Far below in this notebook, these rules will be applied to all clauses.\n",
    "\n",
    "As an example, this is a simplified flowchart for NTN in diagram form as we will implement it below.\n",
    "\n",
    "<img src=\"images/Valence/Valence.002.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowchart logic\n",
    "\n",
    "Here is the bare logic of the flow charts for the individual verbs.\n",
    "\n",
    "The ``senses`` data structure is a dictionary keyed by verb lexemes. \n",
    "For each verb it is keyed by *sense labels*, which is a code for the presence and nature of direct objects and  complements that are present in the context.\n",
    "\n",
    "These are the possible sense labels.\n",
    "\n",
    "The **object** column may contain:\n",
    "\n",
    "* in case there is a principal direct object and other objects or object-like constituents,\n",
    "  the first letter indicates that kind of non-principal object\n",
    "  * `n` phrase[type=NP] or phrase[type=PP] and starts with >T\n",
    "  * `l` phrase starting with L (but not indirect object or benefactive)\n",
    "  * `k` phrase starting with K\n",
    "  * `i` clause starting with L and having an infinitive as predicate, \n",
    "    but not coded as `rela=Objc`\n",
    "* in case there is a single direct object:\n",
    "  * `d` (maybe in the shape of a phrase or a clause)\n",
    "* in case of no objects:\n",
    "  * `-`\n",
    "\n",
    "The **complement** column may contain:\n",
    "\n",
    "* `i` indirect object\n",
    "* `b` adjunct benefactive\n",
    "* `p` locative, there is a fine distinction within these cases dependent on preposition\n",
    "* `c` other complement\n",
    "* `-` no complement present\n",
    "* `.` presence of complement not relevant\n",
    "\n",
    "object|complement\n",
    "------|----------\n",
    "`-`|`-`\n",
    "`-`|`c`\n",
    "`-`|`i`\n",
    "`-`|`b`\n",
    "`-`|`p`\n",
    "`d`|`-`\n",
    "`d`|`c`\n",
    "`d`|`i`\n",
    "`d`|`b`\n",
    "`d`|`p`\n",
    "`n`|`.`\n",
    "`l`|`.`\n",
    "`k`|`.`\n",
    "`i`|`.`\n",
    "\n",
    "Behind each sense label there is information about the meaning of the verb in such a context.\n",
    "The meaning consists of 2 or 3 pieces of information.\n",
    "\n",
    "The important part is the second one, the *sense template*, which consist of a gloss augmented with placeholders for the direct objecs and complements.\n",
    "\n",
    "* `{verb}` the verb occurrence in question\n",
    "* `{pdos}` principal direct objects (phrase)\n",
    "* `{kdos}` K-objects (phrase)\n",
    "* `{ldos}` L-objects (phrase)\n",
    "* `{ndos}` direct objects (phrase) (none of the above)\n",
    "* `{idos}` infinitive construct (clause) objects\n",
    "* `{cdos}` direct objects (clause) (none of the above)\n",
    "* `{inds}` indirect objects\n",
    "* `{bens}` benefactive adjuncts\n",
    "* `{locs}` locatives\n",
    "* `{cpls}` complements, not marked as either indirect object or locative\n",
    "\n",
    "In case there are multiple entities, the algorithm returns them chunked as phrases/clauses.\n",
    "\n",
    "Apart from the template, there is also a *status* and an optional *account*. \n",
    "\n",
    "The status is ``!`` in normal cases, ``?`` in dubious cases, and ``-`` in erroneous cases.\n",
    "In SHEBANQ these statuses are translated into colors of the notes (blue/orange/red).\n",
    "\n",
    "The account contains information about the grounds of which the algorithm has arrived at its conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "senses_spec = '''\n",
    "<FH\n",
    "--:!: act; take action\n",
    "-i:?: act; take action for {inds} :: {inds} taken as benefactive adjunct\n",
    "-b:!: act; take action (for the benefit of) {bens}\n",
    "-p:?: act; take action at {locs} :: {locs} taken as locative adjunct\n",
    "-c:?: do; make; perform; observe {cpls} :: {cpls} taken as direct object\n",
    "d-:!: do; make; perform; observe {dos}\n",
    "di:?: do; make; perform; observe {dos} for {inds} :: {inds} taken as benefactive adjunct\n",
    "db:!: do; make; perform; observe {dos} (for the benefit of) {bens}\n",
    "dp:?: do; make; perform; observe {dos} at {locs} :: {locs} taken as locative adjunct\n",
    "dc:?: make {dos} to be {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:-: !not encountered!\n",
    "\n",
    "BR>\n",
    "--:-: !not encountered!\n",
    "-i:?: create for {inds} :: {inds} taken as benefactive adjunct\n",
    "-b:!: create (for the benefit of) {bens}\n",
    "-p:?: create at {locs} :: {locs} taken as locative adjunct\n",
    "-c:?: create {cpls} :: {cpls} taken as direct object\n",
    "d-:!: create {dos}\n",
    "di:?: create {dos} for {inds} :: {inds} taken as benefactive adjunct\n",
    "db:!: create {dos} (for the benefit of) {bens}\n",
    "dp:?: create {dos} at {locs} :: {locs} taken as locative adjunct\n",
    "dc:?: create {dos} to be {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: create {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:-: !not encountered!\n",
    "k.:-: !not encountered!\n",
    "i.:-: !not encountered!\n",
    "\n",
    "CJT\n",
    "--:-: !not encountered!\n",
    "-i:-: !not encountered!\n",
    "-b:!: install (for the benefit of) {bens}\n",
    "-p:-: !not encountered!\n",
    "-c:?: install; set up; put in place {cpls} :: {cpls} taken as direct object\n",
    "d-:!: install; set up; put in place {dos}\n",
    "di:?: place {dos} for the benefit of {inds} :: {inds} taken as benefactive adjunct\n",
    "db:!: place {dos} (for the benefit of) {bens}\n",
    "dp:!: place {dos} {locs}\n",
    "dc:?: make {dos} to be {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: !specific significance!\n",
    "\n",
    "DBQ\n",
    "--:-: !not encountered!\n",
    "-i:?: cling; cleave; adhere to {inds} :: {inds} taken as locative\n",
    "-b:-: !not encountered!\n",
    "-p:!: cling; cleave; adhere after/to {locs}\n",
    "-c:?: cling; cleave; adhere to {cpls} :: {cpls} taken as locative\n",
    "d-:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "di:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "db:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "dp:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "dc:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: !specific significance!\n",
    "\n",
    "FJM\n",
    "--:!: prepare; put in place; institute\n",
    "-i:?: prepare; put in place; for {inds} :: {inds} taken as benefactive adjunct\n",
    "-b:!: prepare; put in place; (for the benefit of) {bens}\n",
    "-p:!: place {locs}\n",
    "-c:?: prepare; put in place; institute {pdos} :: {cpls} taken as extra direct object besides {pdos}\n",
    "d-:!: prepare; put in place; institute {dos}\n",
    "di:?: prepare; put in place; institute {dos} for {inds} :: {inds} taken as benefactive adjunct\n",
    "db:!: prepare; put in place; institute {dos} (for the benefit of) {bens}\n",
    "dp:!: put; place {dos} {locs}\n",
    "dc:?: make {dos} (to be) {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: set {pdos} to {cdos}\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: be determined to do {idos}\n",
    "\n",
    "NTN\n",
    "--:!: (act of) producing; yielding; giving (in itself)\n",
    "-i:!: produce for; yield for; give to {inds}\n",
    "-b:-: !not encountered!\n",
    "-p:-: !not encountered!\n",
    "-c:?: produce; yield; give {cpls} :: {cpls} taken as extra direct object besides {pdos}\n",
    "d-:!: produce; yield; give {dos}\n",
    "di:!: give {dos} to {inds}\n",
    "db:-: !not encountered!\n",
    "dp:!: place {dos} {locs}\n",
    "dc:?: make {dos} (to be (as)/to become/to do) {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:!: allow {pdos} to do {idos}\n",
    "\n",
    "QR>\n",
    "--:!: shout; call; invoke\n",
    "-i:!: call; summon {inds}\n",
    "-b:-: !not encountered!\n",
    "-p:?: call at {locs} :: {locs} taken as locative adjunct.\n",
    "-c:?: call {cpls} (content) :: {cpls} taken as direct object\n",
    "d-:!: call; summon {dos} (content or addressee)\n",
    "di:!: summon {dos} for {inds}\n",
    "db:-: !not encountered!\n",
    "dp:!: call out {dos} before {locs}\n",
    "dc:?: call {dos} (to be named) {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: call {pdos} (to be named) {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: call {pdos} (to be named) {ldos}\n",
    "k.:!: call {pdos} (to be named) according to {kdos}\n",
    "i.:?: !specific significance!\n",
    "\n",
    "ZQN\n",
    "--:!: be old\n",
    "-i:?: be old for {inds} :: {inds} taken as benefactive adjunct\n",
    "-b:!: be old (for the benefit of) {bens}\n",
    "-p:?: be old in {locs} :: {locs} taken as locative adjunct\n",
    "-c:?: be old ... {cpls} :: {cpls} taken as adjunct\n",
    "d-:-: !not encountered!\n",
    "di:-: !not encountered!\n",
    "di:-: !not encountered!\n",
    "db:-: !not encountered!\n",
    "dc:-: !not encountered!\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: !specific significance!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "See the results on SHEBANQ.\n",
    "\n",
    "The complete set of results is in the note set \n",
    "[valence](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxlbmNl&tp=txt_tb1).\n",
    "You can find it on the Notes page in SHEBANQ:\n",
    "\n",
    "<img src=\"images/valnotes.png\"/>\n",
    "\n",
    "By checking the other note sets you *mute* them, so they do not show up among the lines.\n",
    "\n",
    "In order to see a note set, click on its name. You then go to pages with all verses that have a note of this set attached. \n",
    "\n",
    "<img src=\"images/notesview.png\"/>\n",
    "\n",
    "In order to see the actual notes, click the comment cloud icons. If you click the upper left one, notes are fetched for all verses on the page.\n",
    "\n",
    "<img src=\"images/withnotes.png\"/>\n",
    "\n",
    "You can also export the notes as csv, or view them in a chart.\n",
    "\n",
    "The *valence* set has the following subsets:\n",
    "\n",
    "* Unresolved results: [val_nb](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfbmI_&tp=txt_tb1);\n",
    "* Uncertain results: [val_wrn](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfd3Ju&tp=txt_tb1);\n",
    "* Erroneous results: [val_err](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfZXJy&tp=txt_tb1).\n",
    "\n",
    "So if you follow the *valence* link you see them all, but you can also focus on the problematic cases.\n",
    "\n",
    "And if you are logged in, you can add remarks in free text. Just start typing in one of the new note boxes.\n",
    "Hint: use the keyword **val_note** for your manual notes to valence, then other users can see all relevant information about valence together.\n",
    "\n",
    "By clicking on the status symbol you can cycle through different display styles and colors for your note.\n",
    "Do not forget to save when you are done!\n",
    "\n",
    "See also the SHEBANQ help on notes:\n",
    "[general](https://shebanq.ancient-data.org/help#notes)\n",
    "[notes view](https://shebanq.ancient-data.org/help#notes_style)\n",
    "[working with notes](https://shebanq.ancient-data.org/help#working_with_notes)\n",
    "\n",
    "If you have a solid contribution to make, e.g. the outcome of an algorithm, consider\n",
    "[bulk uploading notes](https://shebanq.ancient-data.org/help#bulk_uploading_notes).\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "(Janet Dyk, Reinoud Oosting and Oliver Glanz, 2014) \n",
    "Analysing Valence Patterns in Biblical Hebrew: Theoretical Questions and Analytic Frameworks.\n",
    "*J. of Northwest Semitic Languages, vol. 40 (2014), no. 1, pp. 43-62*.\n",
    "[pdf abstract](http://academic.sun.ac.za/jnsl/Volumes/JNSL%2040%201%20abstracts%20and%20bookreview.pdf)\n",
    "[pdf fulltext (author's copy with deviant page numbering)](https://shebanq.ancient-data.org/static/docs/methods/2014_Dyk_jnsl.pdf)\n",
    "\n",
    "(Janet Dyk 2014)\n",
    "Deportation or Forgiveness in Hosea 1.6? Verb Valence Patterns and Translation Proposals.\n",
    "*The Bible Translator 2014, Vol. 65(3) 235–279*.\n",
    "[pdf](http://tbt.sagepub.com/content/65/3/235.full.pdf?ijkey=VK2CEHvVrvSGA5B&keytype=finite)\n",
    "\n",
    "(Janet Dyk 014)\n",
    "Traces of Valence Shift in Classical Hebrew.\n",
    "In: *Discourse, Dialogue, and Debate in the Bible: Essays in Honour of Frank Polak*.\n",
    "Ed. Athalya Brenner-Idan.\n",
    "*Sheffield Pheonix Press, 48–65*.\n",
    "[book behind pay-wall](http://www.sheffieldphoenix.com/showbook.asp?bkid=273)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.8.3\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: etcbc4b: UP TO DATE\n",
      "  0.01s USING main: etcbc4b DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.01s DETAIL: COMPILING a: complements: UP TO DATE\n",
      "  0.01s USING annox: complements DATA COMPILED AT: 2016-11-16T08-07-40\n",
      "  0.01s DETAIL: COMPILING a: lexicon: UP TO DATE\n",
      "  0.01s USING annox: lexicon DATA COMPILED AT: 2016-07-08T14-32-54\n",
      "  0.02s DETAIL: load main: G.node_anchor_min\n",
      "  0.11s DETAIL: load main: G.node_anchor_max\n",
      "  0.20s DETAIL: load main: G.node_sort\n",
      "  0.25s DETAIL: load main: G.node_sort_inv\n",
      "  0.67s DETAIL: load main: G.edges_from\n",
      "  0.74s DETAIL: load main: G.edges_to\n",
      "  0.81s DETAIL: load main: F.etcbc4_db_monads [node] \n",
      "  1.57s DETAIL: load main: F.etcbc4_db_oid [node] \n",
      "  2.39s DETAIL: load main: F.etcbc4_db_otype [node] \n",
      "  3.08s DETAIL: load main: F.etcbc4_ft_det [node] \n",
      "  3.30s DETAIL: load main: F.etcbc4_ft_g_word_utf8 [node] \n",
      "  3.64s DETAIL: load main: F.etcbc4_ft_lex [node] \n",
      "  3.82s DETAIL: load main: F.etcbc4_ft_ls [node] \n",
      "  4.02s DETAIL: load main: F.etcbc4_ft_number [node] \n",
      "  4.47s DETAIL: load main: F.etcbc4_ft_pdp [node] \n",
      "  4.66s DETAIL: load main: F.etcbc4_ft_prs [node] \n",
      "  4.86s DETAIL: load main: F.etcbc4_ft_rela [node] \n",
      "  5.20s DETAIL: load main: F.etcbc4_ft_sp [node] \n",
      "  5.38s DETAIL: load main: F.etcbc4_ft_trailer_utf8 [node] \n",
      "  5.51s DETAIL: load main: F.etcbc4_ft_typ [node] \n",
      "  5.94s DETAIL: load main: F.etcbc4_ft_uvf [node] \n",
      "  6.13s DETAIL: load main: F.etcbc4_ft_vs [node] \n",
      "  6.32s DETAIL: load main: F.etcbc4_ft_vt [node] \n",
      "  6.51s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  6.52s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  6.54s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  6.58s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  6.59s DETAIL: load main: F.etcbc4_ft_mother [e] \n",
      "  6.64s DETAIL: load main: C.etcbc4_ft_mother -> \n",
      "  6.81s DETAIL: load main: C.etcbc4_ft_mother <- \n",
      "  6.95s DETAIL: load annox lexicon: F.etcbc4_lex_gloss [node] \n",
      "  7.18s DETAIL: load annox lexicon: F.etcbc4_lex_nametype [node] \n",
      "  7.32s DETAIL: load annox complements: F.JanetDyk_ft_f_correction [node] \n",
      "  7.36s DETAIL: load annox complements: F.JanetDyk_ft_function [node] \n",
      "  7.40s DETAIL: load annox complements: F.JanetDyk_ft_grammatical [node] \n",
      "  7.44s DETAIL: load annox complements: F.JanetDyk_ft_lexical [node] \n",
      "  7.46s DETAIL: load annox complements: F.JanetDyk_ft_original [node] \n",
      "  7.48s DETAIL: load annox complements: F.JanetDyk_ft_predication [node] \n",
      "  7.52s DETAIL: load annox complements: F.JanetDyk_ft_s_manual [node] \n",
      "  7.55s DETAIL: load annox complements: F.JanetDyk_ft_semantic [node] \n",
      "  7.58s DETAIL: load annox complements: F.JanetDyk_ft_valence [node] \n",
      "  7.62s LOGFILE=/Users/dirk/laf/laf-fabric-output/etcbc4b/valence/__log__valence.txt\n",
      "  7.74s INFO: LOADING PREPARED data: please wait ... \n",
      "  7.74s prep prep: G.node_sort\n",
      "  7.79s prep prep: G.node_sort_inv\n",
      "  8.43s prep prep: L.node_up\n",
      "    12s prep prep: L.node_down\n",
      "    17s prep prep: V.verses\n",
      "    17s prep prep: V.books_la\n",
      "    17s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    21s INFO: LOADED PREPARED data\n",
      "    21s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon, complements FOR TASK valence AT 2016-11-16T08-10-00\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "API = fabric.load('etcbc{}'.format(version), 'lexicon,complements', 'valence', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        oid otype monads\n",
    "        JanetDyk:ft.function rela typ\n",
    "        g_word_utf8 trailer_utf8\n",
    "        lex prs uvf sp pdp ls vs vt nametype det gloss\n",
    "        book chapter verse label number\n",
    "        s_manual f_correction\n",
    "        valence predication grammatical original lexical semantic\n",
    "    ''',\n",
    "    '''\n",
    "        mother\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "home_dir = os.path.expanduser('~').replace('\\\\', '/')\n",
    "base_dir = '{}/Dropbox/SYNVAR'.format(home_dir)\n",
    "result_dir = '{}/results'.format(base_dir)\n",
    "result_v_dir = '{}/by_verb'.format(result_dir)\n",
    "os.makedirs(result_v_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators\n",
    "\n",
    "Here we specify by what features we recognize key constituents.\n",
    "We use predominantly features that come from the correction/enrichment workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pf ... : predication feature\n",
    "# gf_... : grammatical feature\n",
    "# vf_... : valence feature\n",
    "# sf_... : lexical feature\n",
    "# of_... : original feature\n",
    "\n",
    "pf_predicate = {\n",
    "    'regular',\n",
    "}\n",
    "gf_direct_object = {\n",
    "    'principal_direct_object',\n",
    "    'NP_direct_object',\n",
    "    'direct_object',\n",
    "    'L_object',\n",
    "    'K_object',\n",
    "    'infinitve_object,'\n",
    "}\n",
    "gf_indirect_object = {\n",
    "    'indirect_object',\n",
    "}\n",
    "gf_complement = {\n",
    "    '*',\n",
    "}\n",
    "sf_locative = {\n",
    "    'location',\n",
    "}\n",
    "sf_benefactive ={\n",
    "    'benefactive',\n",
    "}\n",
    "vf_locative = {\n",
    "    'complement',\n",
    "    'adjunct',\n",
    "}\n",
    "\n",
    "verbal_stems = set('''\n",
    "    qal\n",
    "'''.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronominal suffixes\n",
    "We collect the information to determine how to render pronominal suffixes on words. \n",
    "On verbs, they must be rendered *accusatively*, like `see him`.\n",
    "But on nouns, they must be rendered *genitively*, like `hand my`.\n",
    "So we make an inventory of part of speech types and the pronominal suffixes that occur on them.\n",
    "On that basis we make the translation dictionaries `pronominal suffix` and `switch_prs`.\n",
    "\n",
    "Finally, we define a function `get_prs_info` that for each word delivers the pronominal suffix info and gloss,\n",
    "if there is any, and else `(None, None)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjv  H   :    16\n",
      "adjv  HM  :    10\n",
      "adjv  J   :    25\n",
      "adjv  K   :    35\n",
      "adjv  K=  :     3\n",
      "adjv  KM  :     7\n",
      "adjv  M   :     8\n",
      "adjv  MW  :     1\n",
      "adjv  NW  :     5\n",
      "adjv  W   :    59\n",
      "adjv  absent :  9323\n",
      "advb  n/a :  4550\n",
      "art   n/a : 30380\n",
      "conj  n/a : 62723\n",
      "inrg  K   :     1\n",
      "inrg  M   :     2\n",
      "inrg  W   :     5\n",
      "inrg  absent :  1277\n",
      "intj  K   :    13\n",
      "intj  K=  :     7\n",
      "intj  KM  :     2\n",
      "intj  M   :    37\n",
      "intj  NJ  :   181\n",
      "intj  NW  :     8\n",
      "intj  W   :     3\n",
      "intj  absent :  1634\n",
      "nega  n/a :  6053\n",
      "nmpr  n/a : 33083\n",
      "prde  n/a :  2660\n",
      "prep  H   :  1019\n",
      "prep  H=  :    36\n",
      "prep  HJ  :    13\n",
      "prep  HM  :  1499\n",
      "prep  HN  :    74\n",
      "prep  HW  :   174\n",
      "prep  HWN :    19\n",
      "prep  J   :  1853\n",
      "prep  K   :  1634\n",
      "prep  K=  :   353\n",
      "prep  KM  :  1181\n",
      "prep  KN  :     2\n",
      "prep  KWN :     1\n",
      "prep  M   :   684\n",
      "prep  MW  :    68\n",
      "prep  N   :     3\n",
      "prep  N>  :     4\n",
      "prep  NJ  :   105\n",
      "prep  NW  :   539\n",
      "prep  W   :  3247\n",
      "prep  absent : 60765\n",
      "prin  n/a :  1021\n",
      "prps  n/a :  5011\n",
      "subs  H   :  1633\n",
      "subs  H=  :   108\n",
      "subs  HJ  :    58\n",
      "subs  HM  :  1417\n",
      "subs  HN  :   114\n",
      "subs  HW  :   340\n",
      "subs  HWN :    32\n",
      "subs  J   :  4332\n",
      "subs  K   :  4362\n",
      "subs  K=  :   744\n",
      "subs  KM  :  1335\n",
      "subs  KN  :    16\n",
      "subs  KWN :     7\n",
      "subs  M   :  1919\n",
      "subs  MW  :    25\n",
      "subs  N   :    29\n",
      "subs  N>  :     3\n",
      "subs  NJ  :    19\n",
      "subs  NW  :   809\n",
      "subs  W   :  7653\n",
      "subs  absent : 96518\n",
      "verb  H   :   682\n",
      "verb  H=  :    17\n",
      "verb  HJ  :     6\n",
      "verb  HM  :   121\n",
      "verb  HN  :     4\n",
      "verb  HW  :  1097\n",
      "verb  J   :   356\n",
      "verb  K   :  1089\n",
      "verb  K=  :   201\n",
      "verb  KM  :   132\n",
      "verb  KN  :     1\n",
      "verb  KWN :     2\n",
      "verb  M   :  1288\n",
      "verb  MW  :    23\n",
      "verb  N   :    15\n",
      "verb  N>  :     3\n",
      "verb  NJ  :  1016\n",
      "verb  NW  :   274\n",
      "verb  W   :   938\n",
      "verb  absent : 66414\n"
     ]
    }
   ],
   "source": [
    "prss = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "for w in F.otype.s('word'):\n",
    "    prss[F.sp.v(w)][F.prs.v(w)] += 1\n",
    "for sp in sorted(prss):\n",
    "    for prs in sorted(prss[sp]):\n",
    "        print('{:<5} {:<3} : {:>5}'.format(sp, prs, prss[sp][prs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pronominal_suffix = {\n",
    "    'accusative': {\n",
    "        'W': ('p3-sg-m', 'him'),\n",
    "        'K': ('p2-sg-m', 'you:m'),\n",
    "        'J': ('p1-sg-', 'me'),\n",
    "        'M': ('p3-pl-m', 'them:mm'),\n",
    "        'H': ('p3-sg-f', 'her'),\n",
    "        'HM': ('p3-pl-m', 'them:mm'),\n",
    "        'KM': ('p2-pl-m', 'you:mm'),\n",
    "        'NW': ('p1-pl-', 'us'),\n",
    "        'HW': ('p3-sg-m', 'him'),\n",
    "        'NJ': ('p1-sg-', 'me'),\n",
    "        'K=': ('p2-sg-f', 'you:f'),\n",
    "        'HN': ('p3-pl-f', 'them:ff'),\n",
    "        'MW': ('p3-pl-m', 'them:mm'),\n",
    "        'N': ('p3-pl-f', 'them:ff'),\n",
    "        'KN': ('p2-pl-f', 'you:ff'),\n",
    "    },\n",
    "    'genitive' : {\n",
    "        'W': ('p3-sg-m', 'his'),\n",
    "        'K': ('p2-sg-m', 'yor:m'),\n",
    "        'J': ('p1-sg-', 'my'),\n",
    "        'M': ('p3-pl-m', 'their:mm'),\n",
    "        'H': ('p3-sg-f', 'her'),\n",
    "        'HM': ('p3-pl-m', 'their:mm'),\n",
    "        'KM': ('p2-pl-m', 'your:mm'),\n",
    "        'NW': ('p1-pl-', 'our'),\n",
    "        'HW': ('p3-sg-m', 'his'),\n",
    "        'NJ': ('p1-sg-', 'my'),\n",
    "        'K=': ('p2-sg-f', 'your:f'),\n",
    "        'HN': ('p3-pl-f', 'their:ff'),\n",
    "        'MW': ('p3-pl-m', 'their:mm'),\n",
    "        'N': ('p3-pl-f', 'their:ff'),\n",
    "        'KN': ('p2-pl-f', 'your:ff'),        \n",
    "    }\n",
    "}\n",
    "switch_prs = dict(\n",
    "    subs = 'genitive',\n",
    "    verb = 'accusative',\n",
    "    prep = 'accusative',\n",
    "    conj = None,\n",
    "    nmpr = None,\n",
    "    art = None,\n",
    "    adjv = 'genitive',\n",
    "    nega = None,\n",
    "    prps = None,\n",
    "    advb = None,\n",
    "    prde = None,\n",
    "    intj = 'accusative',\n",
    "    inrg = 'genitive',\n",
    "    prin = None,\n",
    ")\n",
    "\n",
    "def get_prs_info(w):\n",
    "    sp = F.sp.v(w)\n",
    "    prs = F.prs.v(w)\n",
    "    switch = switch_prs[sp]\n",
    "    return pronominal_suffix.get(switch, {}).get(prs, (None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2.22s ZQN   : Missing sense label: dp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.22s Senses for 8 verbs:\n",
      "\t<FH\n",
      "\tBR>\n",
      "\tCJT\n",
      "\tDBQ\n",
      "\tFJM\n",
      "\tNTN\n",
      "\tQR>\n",
      "\tZQN\n"
     ]
    }
   ],
   "source": [
    "slabels = '''\n",
    "--\n",
    "-c\n",
    "-i\n",
    "-b\n",
    "-p\n",
    "d-\n",
    "dc\n",
    "di\n",
    "db\n",
    "dp\n",
    "n.\n",
    "c.\n",
    "l.\n",
    "k.\n",
    "i.\n",
    "'''.strip().split()\n",
    "\n",
    "senses = {}\n",
    "senses_blocks = senses_spec.strip().split('\\n\\n')\n",
    "for b in senses_blocks:\n",
    "    lines = b.split('\\n')\n",
    "    verb = lines[0]\n",
    "    sense_parts = [l.split(':', 2) for l in lines[1:]]\n",
    "    senses[verb] = dict(\n",
    "        (x[0].strip(), (x[1].strip(), [y.strip() for y in x[2].strip().split('::')])) for x in sense_parts\n",
    "    )\n",
    "    for slabel in slabels:\n",
    "        if slabel not in senses[verb]:\n",
    "            msg('{:<6}: Missing sense label: {}'.format(verb, slabel))\n",
    "    for slabel in sorted(senses[verb]):\n",
    "        if slabel not in slabels:\n",
    "            msg('{:<6}: Unknown sense label: {}'.format(verb, slabel))\n",
    "inf('Senses for {} verbs:\\n\\t{}'.format(len(senses), '\\n\\t'.join(sorted(senses))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a verb-clause index\n",
    "\n",
    "We generate an index which gives for each verb lexeme a list of clauses that have that lexeme as the main verb.\n",
    "In the index we store the clause node together with the word node(s) that carries the main verb(s).\n",
    "\n",
    "Clauses may have multiple verbs. In many cases it is a copula plus an other verb.\n",
    "In those cases, we are interested in the other verb, so we exclude copulas.\n",
    "\n",
    "Yet, there are also sentences with more than one main verb.\n",
    "In those cases, we treat both verbs separately as main verb of one and the same clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2.23s Making the verb-clause index\n",
      "  3.80s Done (6042 clauses with a flowchart verb)\n"
     ]
    }
   ],
   "source": [
    "msg('Making the verb-clause index')\n",
    "occs = collections.defaultdict(list)   # dictionary of all verb occurrence nodes per verb lexeme\n",
    "verb_clause = collections.defaultdict(list)    # dictionary of all verb occurrence nodes per clause node\n",
    "clause_verb = collections.OrderedDict() # idem but for the occurrences of selected verbs\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    if F.sp.v(w) != 'verb': continue\n",
    "    lex = F.lex.v(w).rstrip('[')\n",
    "    if lex not in senses: continue   \n",
    "    pf = F.predication.v(L.u('phrase', w))\n",
    "    if pf in pf_predicate:\n",
    "        cn = L.u('clause', w)\n",
    "        clause_verb.setdefault(cn, []).append(w)\n",
    "        verb_clause[lex].append((cn, w))\n",
    "msg('Done ({} clauses with a flowchart verb)'.format(len(clause_verb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Indirect) Objects, Locatives, Benefactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3.85s Finding key constituents\n",
      "  4.01s Done\n"
     ]
    }
   ],
   "source": [
    "msg('Finding key constituents')\n",
    "constituents = collections.defaultdict(lambda: collections.defaultdict(set))\n",
    "ckinds = '''\n",
    "    dos pdos ndos kdos ldos idos cdos inds locs cpls bens\n",
    "'''.strip().split()\n",
    "\n",
    "# go through all relevant clauses and collect all types of direct objects\n",
    "for c in clause_verb:\n",
    "    these_constituents = collections.defaultdict(set)\n",
    "    # phrase like constituents\n",
    "    for p in L.d('phrase', c):\n",
    "        gf = F.grammatical.v(p)\n",
    "        of = F.original.v(p)\n",
    "        sf = F.semantic.v(p)\n",
    "        vf = F.valence.v(p)\n",
    "        ckind = None\n",
    "        if gf in gf_direct_object:\n",
    "            if gf =='principal_direct_object':\n",
    "                ckind = 'pdos'\n",
    "            elif gf == 'NP_direct_object':\n",
    "                ckind = 'ndos'\n",
    "            elif gf == 'L_object':\n",
    "                ckind = 'ldos'\n",
    "            elif gf == 'K_object':\n",
    "                ckind = 'kdos'\n",
    "            else:\n",
    "                ckind = 'dos'\n",
    "        elif gf in gf_indirect_object:\n",
    "            ckind = 'inds'\n",
    "        elif  sf and sf in sf_benefactive:\n",
    "            ckind = 'bens'\n",
    "        elif sf in sf_locative and vf in vf_locative:\n",
    "            ckind = 'locs'\n",
    "        elif gf in gf_complement:\n",
    "            ckind = 'cpls'\n",
    "        if ckind: these_constituents[ckind].add(p)\n",
    "\n",
    "    # clause like constituents: only look for object clauses dependent on this clause\n",
    "    for ac in L.d('clause', L.u('sentence', c)):\n",
    "        dep = list(C.mother.v(ac))\n",
    "        if len(dep) and dep[0] == c:\n",
    "            gf = F.grammatical.v(ac)\n",
    "            ckind = None\n",
    "            if gf in gf_direct_object:\n",
    "                if gf == 'direct_object':\n",
    "                    ckind = 'cdos'\n",
    "                elif gf == 'infinitive_object':\n",
    "                    ckind = 'idos'\n",
    "            if ckind: these_constituents[ckind].add(ac)\n",
    "    \n",
    "    for ckind in these_constituents:\n",
    "        constituents[c][ckind] |= these_constituents[ckind]\n",
    "\n",
    "msg('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE 431892=clause (Adju-InfC)\n",
      "CLAUSE: L#WM LKM #>RJT B>RY \n",
      "VERSE\n",
      "Genesis 45:7\tWJ#LXNJ >LHJM LPNJKM L#WM LKM #>RJT B>RY WLHXJWT LKM LPLJVH GDLH00\n",
      "GLOSS and send god(s) to face to put to rest in the earth and to be alive to to escape great\n",
      "\n",
      "PHRASES\n",
      "\n",
      "621178 (Pred-InfC) L#WM  \"to put\"\n",
      "valence = core; grammatical = NA; lexical = ; semantic = \n",
      "\n",
      "621179 (Adju-InfC) LKM  \"to\"\n",
      "valence = adjunct; grammatical = NA; lexical = ; semantic = benefactive\n",
      "\n",
      "621180 (Objc-InfC) #>RJT  \"rest\"\n",
      "valence = complement; grammatical = direct_object; lexical = ; semantic = \n",
      "\n",
      "621181 (Cmpl-InfC) B>RY  \"in the earth\"\n",
      "valence = complement; grammatical = *; lexical = location; semantic = location\n",
      "\n",
      "SUBCLAUSES\n",
      "\n",
      "621181 (Coor-InfC) WLHXJWT LKM LPLJVH GDLH00\n",
      " \"and to be alive to to escape great\"\n",
      "valence = NA; grammatical = ; lexical = ; semantic = \n",
      "\n",
      "CONSTITUENTS\n",
      "dos : 621180\n",
      "pdos: \n",
      "ndos: \n",
      "kdos: \n",
      "ldos: \n",
      "idos: \n",
      "cdos: \n",
      "inds: \n",
      "locs: 621181\n",
      "cpls: \n",
      "bens: 621179\n",
      "================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testcases = (\n",
    "#    426954,\n",
    "#    427653,\n",
    "#    428419,\n",
    "#    429411,\n",
    "#    429500,\n",
    "#    429861,\n",
    "#    431694,\n",
    "    431892,\n",
    ")\n",
    "\n",
    "def showcase(n):\n",
    "    otype = F.otype.v(n)\n",
    "    print('''CASE {}={} ({}-{})\\nCLAUSE: {}\\nVERSE\\n{}GLOSS {}\\n'''.format(\n",
    "        n, otype, F.rela.v(n), F.typ.v(n),\n",
    "        T.words(L.d('word', n), fmt='ec'), \n",
    "        T.text(\n",
    "            book=F.book.v(L.u('book', n)), \n",
    "            chapter=int(F.chapter.v(L.u('chapter', n))),\n",
    "            verse=int(F.verse.v(L.u('verse', n))), \n",
    "            fmt='ec', lang='la',\n",
    "        ),\n",
    "        ' '.join(F.gloss.v(w) for w in L.d('word', L.u('verse', n)))\n",
    "    ))\n",
    "    print('PHRASES\\n')\n",
    "    for p in L.d('phrase', n):\n",
    "        print('''{} ({}-{}) {} \"{}\"'''.format(\n",
    "            p, F.function.v(p), F.typ.v(n),\n",
    "            T.words(L.d('word', p), fmt='ec'),\n",
    "            ' '.join(F.gloss.v(w) for w in L.d('word', p)),\n",
    "        ))\n",
    "        print('valence = {}; grammatical = {}; lexical = {}; semantic = {}\\n'.format(\n",
    "            F.valence.v(p),\n",
    "            F.grammatical.v(p),\n",
    "            F.lexical.v(p),\n",
    "            F.semantic.v(p),\n",
    "        ))\n",
    "    print('SUBCLAUSES\\n')\n",
    "    for ac in L.d('clause', L.u('sentence', n)):\n",
    "        dep = list(C.mother.v(ac))\n",
    "        if not(len(dep) and dep[0] == n): continue\n",
    "        print('''{} ({}-{}) {} \"{}\"'''.format(\n",
    "            p, F.rela.v(ac), F.typ.v(ac),\n",
    "            T.words(L.d('word', ac), fmt='ec'),\n",
    "            ' '.join(F.gloss.v(w) for w in L.d('word', ac)),\n",
    "        ))\n",
    "        print('valence = {}; grammatical = {}; lexical = {}; semantic = {}\\n'.format(\n",
    "            F.valence.v(ac),\n",
    "            F.grammatical.v(ac),\n",
    "            F.lexical.v(ac),\n",
    "            F.semantic.v(ac),\n",
    "        ))\n",
    "\n",
    "    print('CONSTITUENTS')\n",
    "    for ckind in ckinds:\n",
    "        print('{:<4}: {}'.format(ckind, ','.join(str(x) for x in sorted(constituents[n][ckind]))))\n",
    "    print('================\\n')\n",
    "\n",
    "for n in (testcases): showcase(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2719 clauses with  1 dos        constituents\n",
      " 2174 clauses with  0 dos        constituents\n",
      " 2719 clauses with  a dos        constituents\n",
      " 1113 clauses with  1 pdos       constituents\n",
      " 3780 clauses with  0 pdos       constituents\n",
      " 1113 clauses with  a pdos       constituents\n",
      "  403 clauses with  1 ndos       constituents\n",
      " 4490 clauses with  0 ndos       constituents\n",
      "  403 clauses with  a ndos       constituents\n",
      "   60 clauses with  1 kdos       constituents\n",
      " 4833 clauses with  0 kdos       constituents\n",
      "   60 clauses with  a kdos       constituents\n",
      "   19 clauses with  2 ldos       constituents\n",
      "  685 clauses with  1 ldos       constituents\n",
      " 4189 clauses with  0 ldos       constituents\n",
      "  704 clauses with  a ldos       constituents\n",
      " 4893 clauses with  0 idos       constituents\n",
      "    0 clauses with  a idos       constituents\n",
      "    1 clauses with  2 cdos       constituents\n",
      "  153 clauses with  1 cdos       constituents\n",
      " 4739 clauses with  0 cdos       constituents\n",
      "  154 clauses with  a cdos       constituents\n",
      "    3 clauses with  2 inds       constituents\n",
      "  717 clauses with  1 inds       constituents\n",
      " 4173 clauses with  0 inds       constituents\n",
      "  720 clauses with  a inds       constituents\n",
      "    5 clauses with  3 locs       constituents\n",
      "   27 clauses with  2 locs       constituents\n",
      " 1052 clauses with  1 locs       constituents\n",
      " 3809 clauses with  0 locs       constituents\n",
      " 1084 clauses with  a locs       constituents\n",
      "    8 clauses with  2 cpls       constituents\n",
      "  379 clauses with  1 cpls       constituents\n",
      " 4506 clauses with  0 cpls       constituents\n",
      "  387 clauses with  a cpls       constituents\n",
      "   22 clauses with  1 bens       constituents\n",
      " 4871 clauses with  0 bens       constituents\n",
      "   22 clauses with  a bens       constituents\n",
      " 6042 clauses with  a flowchart verb\n"
     ]
    }
   ],
   "source": [
    "# Counting constituents\n",
    "\n",
    "constituents_count = collections.defaultdict(collections.Counter)\n",
    "\n",
    "for c in constituents:\n",
    "    for ckind in ckinds:\n",
    "        n = len(constituents[c][ckind])\n",
    "        constituents_count[ckind][n] += 1\n",
    "\n",
    "for ckind in ckinds:\n",
    "    total = 0\n",
    "    for (count, n) in sorted(constituents_count[ckind].items(), key=lambda y: -y[0]):\n",
    "        if count: total += n\n",
    "        inf('{:>5} clauses with {:>2} {:<10} constituents'.format(n, count, ckind), withtime=False)\n",
    "    inf('{:>5} clauses with {:>2} {:<10} constituents'.format(total, 'a', ckind), withtime=False)\n",
    "inf('{:>5} clauses with {:>2} flowchart verb'.format(len(clause_verb), 'a'), withtime=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying the flowchart\n",
    "\n",
    "We can now apply the flowchart in a straightforward manner.\n",
    "\n",
    "We output the results as a stand-alone comma separated file, with these columns as specified in the code below.\n",
    "This file can be used to import into a spreadsheet and check results.\n",
    "\n",
    "We also provide a comma separated file that can be imported directly into SHEBANQ as a set of notes, so that the reader can check results within SHEBANQ. This has the benefit that the full context is available, and also data view can be called up easily to inspect the coding situation for each particular instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "status_rep = {\n",
    "    '*': 'note',\n",
    "    '!': 'good',\n",
    "    '?': 'warning',\n",
    "    '-': 'error',\n",
    "}\n",
    "stat_rep = {\n",
    "    '*': 'NB',\n",
    "    '!': '',\n",
    "    '?': 'wrn',\n",
    "    '-': 'err',\n",
    "}\n",
    "\n",
    "gloss_hacks = {\n",
    "    'XQ/': 'law/precept',\n",
    "}\n",
    "\n",
    "def reptext(label, ckind, v, phrases, num=False, txt=False, gloss=False, textformat='ec'): \n",
    "    if phrases == None: return ''\n",
    "    label_rep = '{}='.format(label) if label else ''\n",
    "    phrases_rep = []\n",
    "    for p in sorted(phrases, key=NK):\n",
    "        ptext = '[{}|'.format(F.number.v(p) if num else '[')\n",
    "        if txt:\n",
    "            ptext += T.words(L.d('word', p), fmt=textformat).replace('\\n', '.')\n",
    "        if gloss:\n",
    "            words = L.d('word', p)\n",
    "            if ckind == 'ldos' and F.lex.v(words[0]) == 'L': words = words[1:]\n",
    "\n",
    "            wtexts = []\n",
    "            for w in words:\n",
    "                g = gloss_hacks.get(F.lex.v(w), F.gloss.v(w)).replace('<object marker>','&')\n",
    "                if F.lex.v(w) == 'BJN/' and F.pdp.v(w) == 'prep': g = 'between'\n",
    "                prs_g = get_prs_info(w)[1]\n",
    "                uvf = F.uvf.v(w)\n",
    "                wtext = ''\n",
    "                if uvf == 'H': ptext += 'toward '\n",
    "                wtext += g if w != v else '' # we do not have to put in the gloss of the verb in question\n",
    "                wtext += ('~'+prs_g) if prs_g != None else ''\n",
    "                wtexts.append(wtext)\n",
    "            ptext += ' '.join(wtexts)\n",
    "        ptext += ']'\n",
    "        phrases_rep.append(ptext)\n",
    "    return ' '.join(phrases_rep)\n",
    "\n",
    "debug_messages = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "\n",
    "def flowchart(v, lex, verb, consts):\n",
    "    consts = deepcopy(consts)\n",
    "    sense_label = None\n",
    "    n_ = collections.defaultdict(lambda: 0)\n",
    "    for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "    char1 = None\n",
    "    char2 = None\n",
    "    # determine char 1 of the sense label\n",
    "    if n_['pdos'] > 0:\n",
    "        if n_['ndos'] > 0: char1 = 'n'\n",
    "        elif n_['cdos'] > 0: char1 = 'c'\n",
    "        elif n_['ldos'] > 0: char1 = 'l'\n",
    "        elif n_['kdos'] > 0: char1 = 'k'\n",
    "        elif n_['idos'] > 0: char1 = 'i'\n",
    "        else:\n",
    "        # in trouble: if there is a principal direct object, there should be an other object as well\n",
    "        # and the other one should be an NP, object clause, L_object, K_object, or I_object\n",
    "        # If this happens, it is probably the result of manual correction\n",
    "        # We warn, and remedy\n",
    "            msg_rep = '; '.join('{} {}'.format(n_[ckind], ckind) for ckind in ckinds)\n",
    "            if n_['dos'] > 0:\n",
    "                # there is an other object (dos should only be used if there is a single object)\n",
    "                # we'll put the dos in the ndos (which was empty)\n",
    "                # This could be caused by a manual enrichment sheet that has been generated \n",
    "                # before the concept of NP_direct_object had been introduced\n",
    "                char1 = 'n'\n",
    "                consts['ndos'] = consts['dos']\n",
    "                debug_messages[lex]['pdos with dos'].append('{}: {}'.format(T.passage(v), msg_rep))\n",
    "            else:\n",
    "                # there is not another object, we treat this as a single object, so as a dos\n",
    "                char1 = 'd'\n",
    "                consts['dos'] = consts['pdos']\n",
    "                debug_messages[lex]['lonely pdos'].append('{}: {}'.format(T.passage(v), msg_rep))\n",
    "    else:\n",
    "        if n_['cdos'] > 0:\n",
    "        # in the case of a single object, the clause objects act as ordinary objects\n",
    "            char1 = 'd'\n",
    "            consts['dos'] |= consts['cdos']\n",
    "        if n_['ndos'] > 0:\n",
    "        # in the case of a single object, the np_objects act as ordinary objects\n",
    "            char1 = 'd'\n",
    "            consts['dos'] |= consts['ndos']\n",
    "\n",
    "    n_ = collections.defaultdict(lambda: 0)\n",
    "    for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "\n",
    "    if n_['pdos'] == 0 and n_['dos'] > 0:\n",
    "        char1 = 'd'\n",
    "    if n_['pdos'] == 0 and n_['dos'] == 0:\n",
    "        char1 = '-'\n",
    "\n",
    "    # determine char 2 of the sense label\n",
    "    if char1 in 'nclki':\n",
    "        char2 = '.'\n",
    "    else:\n",
    "        if n_['inds'] > 0:\n",
    "            char2 = 'i'\n",
    "        elif n_['bens'] > 0:\n",
    "            char2 = 'b'\n",
    "        elif n_['locs'] > 0:\n",
    "            char2 = 'p'\n",
    "        elif n_['cpls'] > 0:\n",
    "            char2 = 'c'\n",
    "        else:\n",
    "            char2 = '-'\n",
    "\n",
    "    sense_label = char1+char2\n",
    "    \n",
    "    sinfo = senses.\\\n",
    "        get(lex, {lex: {'': ('-', 'no senses given for {}'.format(lex))}}).\\\n",
    "        get(sense_label, ('-', 'no sense {} given for {}'.format(sense_label, lex)))\n",
    "    status = sinfo[0]\n",
    "    sense_fmt = sinfo[1][0]\n",
    "    action_fmt = sinfo[1][1] if len(sinfo[1]) >= 2 else ''\n",
    "    action_stat = sinfo[1][2] if len(sinfo) >= 3 else status\n",
    "\n",
    "    verb_rep = reptext('', '', v, verb, num=True, gloss=True)\n",
    "    consts_rep = dict((ckind, reptext('', ckind, v, consts[ckind], num=True, gloss=True)) for ckind in consts)\n",
    "        \n",
    "    sense_txt = sense_fmt.format(verb=verb_rep, **consts_rep)\n",
    "    action_txt = action_fmt.format(verb=verb_rep, **consts_rep)\n",
    "\n",
    "    return (sense_label, status, sense_txt, action_txt, action_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields = ('''\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    sentence#\n",
    "    clause#\n",
    "    lex\n",
    "    status\n",
    "    sense_label\n",
    "    sense\n",
    "    action_status\n",
    "    action\n",
    "    '''+(''.join('\\n\\t#{}'.format(ckind) for ckind in ckinds))+'''\n",
    "    text\n",
    "''').strip().split()\n",
    "\n",
    "sfields = '''\n",
    "    version\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    clause_atom\n",
    "    is_shared\n",
    "    is_published\n",
    "    status\n",
    "    keywords\n",
    "    ntext\n",
    "'''.strip().split()\n",
    "\n",
    "fields_fmt = ('{};' * (len(fields) - 1)) + '{}\\n' \n",
    "sfields_fmt = ('{}\\t' * (len(sfields) - 1)) + '{}\\n' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the flowchart\n",
    "\n",
    "The next cell finally performs all the flowchart computations for all verbs in all contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4.76s Applying the flowchart\n",
      "  4.76s No verb ZQN in enriched corpus\n",
      "  6.22s No verb DBQ in enriched corpus\n",
      "  7.65s Done\n",
      "QR>\n",
      "\tlonely pdos\n",
      "\t\tNumbers 24:10: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJudges 6:32: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tIsaiah 61:2: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 11:6: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 34:8: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tRuth 4:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tLamentations 1:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls; 0 bens\n",
      "\t\tEzra 8:21: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "FJM\n",
      "\tlonely pdos\n",
      "\t\tGenesis 4:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 1 bens\n",
      "\t\tGenesis 30:41: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 2 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 9:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tDeuteronomy 12:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tDeuteronomy 22:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\t1_Samuel 8:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\t2_Samuel 13:33: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls; 0 bens\n",
      "\t\t1_Kings 2:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls; 0 bens\n",
      "\t\t2_Kings 12:18: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 7:30: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 32:34: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 42:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 42:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJeremiah 44:12: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tEzekiel 21:24: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tEzekiel 21:25: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tEzekiel 21:27: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tEzekiel 21:27: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tEzekiel 24:7: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls; 0 bens\n",
      "\t\tEzekiel 30:21: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tAND 4 more\n",
      "\tpdos with dos\n",
      "\t\tGenesis 28:11: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 28:18: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 28:22: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "NTN\n",
      "\tlonely pdos\n",
      "\t\tGenesis 1:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 15:7: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 15:10: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 20:6: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 28:4: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 2 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 28:20: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 31:7: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 3:19: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 5:21: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 12:23: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 16:8: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 22:6: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 22:9: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 24:12: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 30:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 36:1: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 39:25: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 3 locs; 1 cpls; 0 bens\n",
      "\t\tExodus 39:31: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls; 0 bens\n",
      "\t\tExodus 40:30: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tLeviticus 10:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 1 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tAND 70 more\n",
      "BR>\n",
      "\tlonely pdos\n",
      "\t\tIsaiah 54:16: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "CJT\n",
      "\tlonely pdos\n",
      "\t\tExodus 23:1: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tPsalms 17:11: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tPsalms 73:28: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "<FH\n",
      "\tlonely pdos\n",
      "\t\tGenesis 34:7: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tGenesis 34:14: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 14:11: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 27:3: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 28:3: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 28:4: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 28:42: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 36:18: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 36:33: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tExodus 39:1: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tLeviticus 18:4: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tLeviticus 26:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tNumbers 15:3: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tNumbers 15:13: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tDeuteronomy 6:24: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tDeuteronomy 22:21: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls; 0 bens\n",
      "\t\tDeuteronomy 28:58: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJoshua 22:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJoshua 22:24: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tJudges 11:27: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls; 0 bens\n",
      "\t\tAND 29 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 5725 clauses with flowchart\n",
      "action     notes: 504\n",
      "valence    notes: 5725\n",
      "Total      notes: 6229\n",
      "All lexemes with flowchart specification\n",
      "     Status   good   : 5140 clauses\n",
      "     Status   error  :   81 clauses\n",
      "     Status   warning:  504 clauses\n",
      "     All status      : 5725 clauses\n",
      "     Sense    --     : 1219 clauses\n",
      "     Sense    -c     :  106 clauses\n",
      "     Sense    -i     :  268 clauses\n",
      "     Sense    -b     :    1 clauses\n",
      "     Sense    -p     :  214 clauses\n",
      "     Sense    d-     : 1704 clauses\n",
      "     Sense    dc     :  202 clauses\n",
      "     Sense    di     :  383 clauses\n",
      "     Sense    db     :   15 clauses\n",
      "     Sense    dp     :  691 clauses\n",
      "     Sense    n.     :  403 clauses\n",
      "     Sense    c.     :   12 clauses\n",
      "     Sense    l.     :  450 clauses\n",
      "     Sense    k.     :   57 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      : 5725 clauses\n",
      " \n",
      "<FH\n",
      "     Status   good   : 2345 clauses\n",
      "     Status   error  :    3 clauses\n",
      "     Status   warning:  120 clauses\n",
      "     All status      : 2468 clauses\n",
      "     Sense    --     :  916 clauses\n",
      "     Sense    -c     :    4 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :   49 clauses\n",
      "     Sense    d-     : 1278 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    1 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :   66 clauses\n",
      "     Sense    n.     :  127 clauses\n",
      "     Sense    c.     :    3 clauses\n",
      "     Sense    l.     :   19 clauses\n",
      "     Sense    k.     :    5 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      : 2468 clauses\n",
      " \n",
      "BR>\n",
      "     Status   good   :   29 clauses\n",
      "     Status   error  :    4 clauses\n",
      "     Status   warning:    3 clauses\n",
      "     All status      :   36 clauses\n",
      "     Sense    --     :    4 clauses\n",
      "     Sense    -c     :    0 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :    0 clauses\n",
      "     Sense    d-     :   24 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    0 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :    3 clauses\n",
      "     Sense    n.     :    5 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :   36 clauses\n",
      " \n",
      "CJT\n",
      "     Status   good   :   57 clauses\n",
      "     Status   error  :    6 clauses\n",
      "     Status   warning:   19 clauses\n",
      "     All status      :   82 clauses\n",
      "     Sense    --     :    3 clauses\n",
      "     Sense    -c     :    7 clauses\n",
      "     Sense    -i     :    1 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :    2 clauses\n",
      "     Sense    d-     :   10 clauses\n",
      "     Sense    dc     :    9 clauses\n",
      "     Sense    di     :    3 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :   20 clauses\n",
      "     Sense    n.     :   12 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :   10 clauses\n",
      "     Sense    k.     :    5 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :   82 clauses\n",
      " \n",
      "DBQ\n",
      "     All status      :    0 clauses\n",
      "     Sense    --     :    0 clauses\n",
      "     Sense    -c     :    0 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :    0 clauses\n",
      "     Sense    d-     :    0 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    0 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :    0 clauses\n",
      "     Sense    n.     :    0 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :    0 clauses\n",
      " \n",
      "FJM\n",
      "     Status   good   :  492 clauses\n",
      "     Status   error  :    3 clauses\n",
      "     Status   warning:   82 clauses\n",
      "     All status      :  577 clauses\n",
      "     Sense    --     :   12 clauses\n",
      "     Sense    -c     :   22 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -b     :    1 clauses\n",
      "     Sense    -p     :   39 clauses\n",
      "     Sense    d-     :   66 clauses\n",
      "     Sense    dc     :   51 clauses\n",
      "     Sense    di     :    9 clauses\n",
      "     Sense    db     :   15 clauses\n",
      "     Sense    dp     :  204 clauses\n",
      "     Sense    n.     :   68 clauses\n",
      "     Sense    c.     :    3 clauses\n",
      "     Sense    l.     :   60 clauses\n",
      "     Sense    k.     :   27 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :  577 clauses\n",
      " \n",
      "NTN\n",
      "     Status   good   : 1660 clauses\n",
      "     Status   error  :   65 clauses\n",
      "     Status   warning:  185 clauses\n",
      "     All status      : 1910 clauses\n",
      "     Sense    --     :  134 clauses\n",
      "     Sense    -c     :   51 clauses\n",
      "     Sense    -i     :  158 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :   59 clauses\n",
      "     Sense    d-     :  220 clauses\n",
      "     Sense    dc     :  134 clauses\n",
      "     Sense    di     :  332 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :  372 clauses\n",
      "     Sense    n.     :   93 clauses\n",
      "     Sense    c.     :    6 clauses\n",
      "     Sense    l.     :  332 clauses\n",
      "     Sense    k.     :   19 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      : 1910 clauses\n",
      " \n",
      "QR>\n",
      "     Status   good   :  557 clauses\n",
      "     Status   warning:   95 clauses\n",
      "     All status      :  652 clauses\n",
      "     Sense    --     :  150 clauses\n",
      "     Sense    -c     :   22 clauses\n",
      "     Sense    -i     :  109 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :   65 clauses\n",
      "     Sense    d-     :  106 clauses\n",
      "     Sense    dc     :    8 clauses\n",
      "     Sense    di     :   38 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :   26 clauses\n",
      "     Sense    n.     :   98 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :   29 clauses\n",
      "     Sense    k.     :    1 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :  652 clauses\n",
      " \n",
      "ZQN\n",
      "     All status      :    0 clauses\n",
      "     Sense    --     :    0 clauses\n",
      "     Sense    -c     :    0 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -b     :    0 clauses\n",
      "     Sense    -p     :    0 clauses\n",
      "     Sense    d-     :    0 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    0 clauses\n",
      "     Sense    db     :    0 clauses\n",
      "     Sense    dp     :    0 clauses\n",
      "     Sense    n.     :    0 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :    0 clauses\n",
      " \n"
     ]
    }
   ],
   "source": [
    "msg('Applying the flowchart')\n",
    "\n",
    "outcome_sta = collections.Counter()\n",
    "outcome_lab = collections.Counter()\n",
    "outcome_sta_l = collections.defaultdict(lambda: collections.Counter())\n",
    "outcome_lab_l = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "# we want an overview of the flowchart decisions per lexeme\n",
    "# Per lexeme, per sense_label we store the clauses\n",
    "\n",
    "decisions = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
    "\n",
    "of = open('{}/{}'.format(result_dir, 'valence_results.csv'), 'w')\n",
    "ofs = open('{}/{}'.format(result_dir, 'valence_notes.csv'), 'w')\n",
    "of.write('{}\\n'.format(';'.join(fields)))\n",
    "ofs.write('{}\\n'.format('\\t'.join(sfields)))\n",
    "\n",
    "note_keyword_base = 'valence'\n",
    "\n",
    "nnotes = collections.Counter()\n",
    "\n",
    "for lex in verb_clause:\n",
    "    if lex not in senses:\n",
    "        msg('No flowchart definition for verb {}'.format(lex))\n",
    "for lex in senses:\n",
    "    this_of = open('{}/{}.csv'.format(result_v_dir, lex), 'w')\n",
    "    if lex not in verb_clause:\n",
    "        msg('No verb {} in enriched corpus'.format(lex))\n",
    "        continue\n",
    "    for (c,v) in verb_clause[lex]:\n",
    "        if F.vs.v(v) not in verbal_stems: continue\n",
    "    \n",
    "        book = F.book.v(L.u('book', v))\n",
    "        chapter = F.chapter.v(L.u('chapter', v))\n",
    "        verse = F.verse.v(L.u('verse', v))\n",
    "        sentence_n = F.number.v(L.u('sentence', v))\n",
    "        clause_n = F.number.v(c)\n",
    "        clause_atom_n = F.number.v(L.u('clause_atom', v))\n",
    "        \n",
    "        verb = [L.u('phrase', v)]\n",
    "        consts = constituents[c]\n",
    "        n_ = collections.defaultdict(lambda: 0)\n",
    "        for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "        \n",
    "        (sense_label, status, sense_txt, action_txt, action_stat) = flowchart(v, lex, verb, consts)\n",
    "        \n",
    "        outcome_sta[status] += 1\n",
    "        outcome_sta_l[lex][status] += 1\n",
    "        outcome_lab[sense_label] += 1\n",
    "        outcome_lab_l[lex][sense_label] += 1\n",
    "        decisions[lex][sense_label][c] = '{} :: {}'.format(sense_txt, action_txt)\n",
    "        text = reptext('', '', v, L.d('phrase', c), num=True, txt=True)\n",
    "\n",
    "        txt = fields_fmt.format(\n",
    "            book,\n",
    "            chapter,\n",
    "            verse,\n",
    "            sentence_n,\n",
    "            clause_n,\n",
    "            '\"'+lex+'\"',\n",
    "            stat_rep[status],\n",
    "            '\"<'+sense_label+'>\"',\n",
    "            '\"'+sense_txt+'\"',\n",
    "            action_stat,\n",
    "            '\"'+action_txt+'\"',\n",
    "            *(n_[ckind] for ckind in ckinds),\n",
    "            '\"'+text+'\"',\n",
    "        )\n",
    "        of.write(txt)\n",
    "        this_of.write(txt)\n",
    "        ofs.write(sfields_fmt.format(\n",
    "            version,\n",
    "            book,\n",
    "            chapter,\n",
    "            verse,\n",
    "            clause_atom_n,\n",
    "            'T',\n",
    "            '',\n",
    "            status,\n",
    "            note_keyword_base+(' val_{}'.format(stat_rep[status]) if status != '!' else ''),\n",
    "            '_{sl}_ [{nm}|{vb}] {st}'.format(\n",
    "                nm=F.number.v(L.u('phrase', v)),\n",
    "                vb=F.g_word_utf8.v(v),\n",
    "                st=sense_txt,\n",
    "                sl=sense_label,\n",
    "            ),\n",
    "        ))\n",
    "        nnotes[note_keyword_base] += 1\n",
    "        if action_txt != '':\n",
    "            ofs.write(sfields_fmt.format(\n",
    "                version,\n",
    "                book,\n",
    "                chapter,\n",
    "                verse,\n",
    "                clause_atom_n,\n",
    "                'T',\n",
    "                '',\n",
    "                action_stat,\n",
    "                note_keyword_base+(' val_{}'.format(stat_rep[status]) if status != '!' else ''),\n",
    "                action_txt,\n",
    "            ))\n",
    "            nnotes['action'] += 1\n",
    "    this_of.close()\n",
    "            \n",
    "of.close()\n",
    "ofs.close()\n",
    "msg('Done')\n",
    "\n",
    "show_limit = 20\n",
    "for lex in debug_messages:\n",
    "    msg(lex, withtime=False)\n",
    "    for kind in debug_messages[lex]:\n",
    "        msg('\\t{}'.format(kind), withtime=False)\n",
    "        messages = debug_messages[lex][kind]\n",
    "        lm = len(messages)\n",
    "        msg('\\t\\t{}{}'.format(\n",
    "            '\\n\\t\\t'.join(messages[0:show_limit]),\n",
    "            '' if lm <= show_limit else '\\n\\t\\tAND {} more'.format(lm-show_limit),\n",
    "        ), withtime=False)\n",
    "\n",
    "inf('Computed {} clauses with flowchart'.format(sum(outcome_sta.values())), withtime=False)\n",
    "ntot = 0\n",
    "for (lab, n) in sorted(nnotes.items(), key=lambda x: x[0]):\n",
    "    ntot += n\n",
    "    print('{:<10} notes: {}'.format(lab, n))\n",
    "print('{:<10} notes: {}'.format('Total', ntot))\n",
    "\n",
    "for lex in [''] + sorted(senses):\n",
    "    print('All lexemes with flowchart specification' if lex == '' else lex)\n",
    "    src_sta = outcome_sta if lex == '' else outcome_sta_l.get(lex, collections.defaultdict(lambda: 0))\n",
    "    src_lab = outcome_lab if lex == '' else outcome_lab_l.get(lex, collections.defaultdict(lambda: 0))\n",
    "    tot = 0\n",
    "    for (x, n) in src_sta.items():\n",
    "        tot += n\n",
    "        print('     Status   {:<7}: {:>4} clauses'.format(status_rep[x], n))\n",
    "    print('     All status      : {:>4} clauses'.format(tot))\n",
    "    tot = 0\n",
    "    for x in slabels:\n",
    "        n = src_lab[x]\n",
    "        tot += n\n",
    "        print('     Sense    {:<7}: {:>4} clauses'.format(x, n))\n",
    "    print('     All senses      : {:>4} clauses'.format(tot))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_decision(verbs=None, labels=None, books=None): # show all clauses that have a verb in verbs and a sense label in labels\n",
    "    results = []\n",
    "    for verb in decisions:\n",
    "        if verbs != None and verb not in verbs: continue\n",
    "        for label in decisions[verb]:\n",
    "            if labels != None and label not in labels: continue\n",
    "            for (c, stxt) in sorted(decisions[verb][label].items()):\n",
    "                book = T.book_name(L.u('book', c))\n",
    "                if books != None and book not in books: continue\n",
    "                sentence_words = L.d('word', L.u('sentence', c))\n",
    "                results.append('{:<7} {:<12} {:<5} {:<2} {}\\n\\t{}\\n\\t{}\\n'.format(\n",
    "                    c,\n",
    "                    T.passage(c),\n",
    "                    verb,\n",
    "                    label,\n",
    "                    stxt,\n",
    "                    T.words(sentence_words, fmt='ec'),\n",
    "                    ' '.join(F.gloss.v(w) for w in sentence_words),\n",
    "                ).replace('<', '&lt;'))\n",
    "    print('\\n'.join(sorted(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467292  Isaiah 3:7   FJM   n. make [2|~me] to be [3|chief people] :: \n",
      "\tL> T#JMNJ QYJN &lt;M00\n",
      "\n",
      "\tnot put chief people\n",
      "\n",
      "467455  Isaiah 5:20  FJM   l. make [2|darkness] to become [3|light] :: \n",
      "\tHWJ H>MRJM LR&lt; WLVWB #MJM X#K L>WR W>WR LX#K #MJM MR LMTWQ WMTWQ LMR00\n",
      "\n",
      "\talas the say to the evil and to the good put darkness to light and light to darkness put bitter to sweet and sweet to bitter\n",
      "\n",
      "467457  Isaiah 5:20  FJM   l. make [2|bitter] to become [3|sweet] :: \n",
      "\tHWJ H>MRJM LR&lt; WLVWB #MJM X#K L>WR W>WR LX#K #MJM MR LMTWQ WMTWQ LMR00\n",
      "\n",
      "\talas the say to the evil and to the good put darkness to light and light to darkness put bitter to sweet and sweet to bitter\n",
      "\n",
      "467854  Isaiah 10:6  FJM   n. make [2|to ~him] to be [3|trampled land] :: \n",
      "\tW&lt;L&&lt;M &lt;BRTJ >YWNW L#LL #LL WLBZ BZ WL#WMW MRMS KXMR XWYWT00\n",
      "\n",
      "\tand upon people anger command to plunder plunder and to spoil spoiling and to put trampled land as clay outside\n",
      "\n",
      "468058  Isaiah 13:9  FJM   l. make [2|the earth] to become [3|destruction] :: \n",
      "\tHNH JWM&JHWH B> >KZRJ W&lt;BRH WXRWN >P L#WM H>RY L#MH \n",
      "\tbehold day YHWH come cruel and anger and anger nose to put the earth to destruction\n",
      "\n",
      "468160  Isaiah 14:17 FJM   k. make [2|world] to be as [3|as the desert] :: \n",
      "\t#M TBL KMDBR \n",
      "\tput world as the desert\n",
      "\n",
      "468181  Isaiah 14:23 FJM   l. make [2|~her] to become [3|possession hedgehog] :: \n",
      "\tW#MTJH LMWR# QPD W>GMJ&MJM \n",
      "\tand put to possession hedgehog and reedy pool water\n",
      "\n",
      "468545  Isaiah 21:4  FJM   l. make [1|& breeze desire~my] to become [4|trembling] :: \n",
      "\t>T N#P X#QJ #M LJ LXRDH00\n",
      "\n",
      "\t&lt;object marker> breeze desire put to to trembling\n",
      "\n",
      "468746  Isaiah 23:13 FJM   l. make [1|~her] to become [2|decay] :: \n",
      "\t#MH LMPLH00\n",
      "\n",
      "\tput to decay\n",
      "\n",
      "468866  Isaiah 25:2  FJM   l. make [5|town fortified] to become [4|the heap] :: \n",
      "\tKJ #MT M&lt;JR LGL QRJH BYWRH LMPLH >RMWN ZRJM M&lt;JR \n",
      "\tthat put from town to the heap town fortified to decay dwelling tower strange from town\n",
      "\n",
      "469019  Isaiah 27:9  FJM   k. make [2|whole stone altar] to be as [3|as stone chalk shatter] :: \n",
      "\tB#WMW KL&>BNJ MZBX K>BNJ&GR MNPYWT L>&JQMW >#RJM WXMNJM00\n",
      "\n",
      "\tin put whole stone altar as stone chalk shatter not arise asherah and incense-stand\n",
      "\n",
      "469106  Isaiah 28:15 FJM   n. make [3|lie] to be [4|refuge~our] :: \n",
      "\tKJ #MNW KZB MXSNW \n",
      "\tthat put lie refuge\n",
      "\n",
      "469112  Isaiah 28:17 FJM   l. make [3|justice] to become [4|line] :: \n",
      "\tW#MTJ M#PV LQW WYDQH LM#QLT \n",
      "\tand put justice to line and justice to leveller\n",
      "\n",
      "469151  Isaiah 28:25 FJM   n. make [3|wheat] to be [4|&lt;animal>] :: \n",
      "\tW#M XVH #WRH W#&lt;RH NSMN WKSMT GBLTW00\n",
      "\n",
      "\tand put wheat &lt;animal> and barley &lt;uncertain> and spelt boundary\n",
      "\n",
      "469974  Isaiah 37:29 FJM   dp put; place [3|thorn~my] [4|in nose~yor:m] :: \n",
      "\tW#MTJ XXJ B>PK WMTGJ B#PTJK \n",
      "\tand put thorn in nose and bridle in lip\n",
      "\n",
      "470344  Isaiah 41:15 FJM   l. make [2|~you:f] to become [3|threshing-sledge threshing instrument new lord, baal double-edged] :: \n",
      "\tHNH #MTJK LMWRG XRWY XD# B&lt;L PJPJWT \n",
      "\tbehold put to threshing-sledge threshing instrument new lord, baal double-edged\n",
      "\n",
      "470347  Isaiah 41:15 FJM   k. make [2|hill] to be as [3|as the chaff] :: \n",
      "\tWGB&lt;WT KMY T#JM00\n",
      "\n",
      "\tand hill as the chaff put\n",
      "\n",
      "470362  Isaiah 41:18 FJM   l. make [2|desert] to become [3|reedy pool water] :: \n",
      "\t>#JM MDBR L>GM&MJM W>RY YJH LMWY>J MJM00\n",
      "\n",
      "\tput desert to reedy pool water and earth dry country to issue water\n",
      "\n",
      "470365  Isaiah 41:19 FJM   dp put; place [3|juniper box tree and cypress] [2|in the desert] :: \n",
      "\t>#JM B&lt;RBH BRW# TDHR WT>#WR JXDW00\n",
      "\n",
      "\tput in the desert juniper box tree and cypress together\n",
      "\n",
      "470368  Isaiah 41:20 FJM   -- prepare; put in place; institute :: \n",
      "\tWJ#JMW \n",
      "\tand put\n",
      "\n",
      "470382  Isaiah 41:22 FJM   d- prepare; put in place; institute [3|heart~our] :: \n",
      "\tWN#JMH LBNW \n",
      "\tand put heart\n",
      "\n",
      "470439  Isaiah 42:4  FJM   dp put; place [4|justice] [3|in the earth] :: \n",
      "\t&lt;D&J#JM B>RY M#PV \n",
      "\tunto put in the earth justice\n",
      "\n",
      "470472  Isaiah 42:12 FJM   db prepare; put in place; institute [3|weight] (for the benefit of) [2|to YHWH] :: \n",
      "\tJ#JMW LJHWH KBWD \n",
      "\tput to YHWH weight\n",
      "\n",
      "470487  Isaiah 42:15 FJM   l. make [3|stream] to become [4|the coast, island] :: \n",
      "\tW#MTJ NHRWT L>JJM \n",
      "\tand put stream to the coast, island\n",
      "\n",
      "470493  Isaiah 42:16 FJM   l. make [2|dark place] to become [4|the light] :: \n",
      "\t>#JM MX#K LPNJHM L>WR WM&lt;Q#JM LMJ#WR \n",
      "\tput dark place to face to the light and rugged country to fairness\n",
      "\n",
      "470543  Isaiah 42:25 FJM   -c prepare; put in place; institute  :: [4|upon heart] taken as extra direct object besides \n",
      "\tWL>&J#JM &lt;L&LB00\n",
      "\n",
      "\tand not put upon heart\n",
      "\n",
      "470635  Isaiah 43:19 FJM   dp put; place [4|way] [3|in the desert] :: \n",
      "\t>P >#JM BMDBR DRK BJ#MWN NHRWT00\n",
      "\n",
      "\teven put in the desert way in wilderness stream\n",
      "\n",
      "470696  Isaiah 44:7  FJM   d- prepare; put in place; institute [2|people eternity] :: \n",
      "\tWJ&lt;RKH LJ M#WMJ &lt;M&&lt;WLM \n",
      "\tand arrange to from put people eternity\n",
      "\n",
      "471068  Isaiah 47:6  FJM   d- prepare; put in place; institute [4|compassion] :: \n",
      "\tL>&#MT LHM RXMJM \n",
      "\tnot put to compassion\n",
      "\n",
      "471072  Isaiah 47:7  FJM   dc make [4|these] (to be) [5|upon heart~your:f] :: [5|upon heart~your:f] taken as extra direct object besides [4|these]\n",
      "\t&lt;D L>&#MT >LH &lt;L&LBK \n",
      "\tunto not put these upon heart\n",
      "\n",
      "471242  Isaiah 49:2  FJM   k. make [3|mouth~my] to be as [4|as dagger sharp] :: \n",
      "\tWJ#M PJ KXRB XDH \n",
      "\tand put mouth as dagger sharp\n",
      "\n",
      "471244  Isaiah 49:2  FJM   l. make [2|~me] to become [3|arrow purge] :: \n",
      "\tWJ#JMNJ LXY BRWR \n",
      "\tand put to arrow purge\n",
      "\n",
      "471295  Isaiah 49:11 FJM   l. make [3|whole mountain~my] to become [4|the way] :: \n",
      "\tW#MTJ KL&HRJ LDRK \n",
      "\tand put whole mountain to the way\n",
      "\n",
      "471383  Isaiah 50:2  FJM   n. make [2|stream] to be [3|desert] :: \n",
      "\t>#JM NHRWT MDBR \n",
      "\tput stream desert\n",
      "\n",
      "471387  Isaiah 50:3  FJM   n. make [2|sack] to be [4|covering~their:mm] :: \n",
      "\tW#Q >#JM KSWTM00\n",
      "\n",
      "\tand sack put covering\n",
      "\n",
      "471402  Isaiah 50:7  FJM   k. make [3|face~my] to be as [4|as the flint] :: \n",
      "\t&lt;L&KN #MTJ PNJ KXLMJ# \n",
      "\tupon thus put face as the flint\n",
      "\n",
      "471444  Isaiah 51:3  FJM   k. make [3|desert~her] to be as [4|as Eden] :: \n",
      "\tWJ#M MDBRH K&lt;DN W&lt;RBTH KGN&JHWH \n",
      "\tand put desert as Eden and desert as garden YHWH\n",
      "\n",
      "471485  Isaiah 51:10 FJM   n. make [3|depths sea] to be [4|way] :: \n",
      "\tHLW> >T&HJ> HMXRBT JM MJ THWM RBH H#MH M&lt;MQJ&JM DRK L&lt;BR G>WLJM00\n",
      "\n",
      "\t&lt;interrogative> not you she the be dry sea water primeval ocean much the put depths sea way to pass redeem\n",
      "\n",
      "471515  Isaiah 51:16 FJM   dp put; place [3|word~my] [4|in mouth~yor:m] :: \n",
      "\tW>#JM DBRJ BPJK \n",
      "\tand put word in mouth\n",
      "\n",
      "471551  Isaiah 51:23 FJM   dp put; place [2|~her] [3|in hand grieve~you:f] :: \n",
      "\tW#MTJH BJD&MWGJK >#R&>MRW LNP#K \n",
      "\tand put in hand grieve &lt;relative> say to soul\n",
      "\n",
      "471555  Isaiah 51:23 FJM   k. make [4|back~your:f] to be as [3|as the earth] :: \n",
      "\tWT#JMJ K>RY GWK WKXWY L&lt;BRJM00\n",
      "\n",
      "\tand put as the earth back and as the outside to the pass\n",
      "\n",
      "471677  Isaiah 53:10 FJM   n. make [3|guilt] to be [4|soul~his] :: \n",
      "\t>M&T#JM >#M NP#W \n",
      "\tif put guilt soul\n",
      "\n",
      "471742  Isaiah 54:12 FJM   n. make [3|ruby] to be [4|sun~your:f] :: \n",
      "\tW#MTJ KDKD #M#TJK W#&lt;RJK L>BNJ >QDX WKL&GBWLK L>BNJ&XPY00\n",
      "\n",
      "\tand put ruby sun and gate to stone beryl and whole boundary to stone pleasure\n",
      "\n",
      "471905  Isaiah 57:1  FJM   -c prepare; put in place; institute  :: [2|upon heart] taken as extra direct object besides \n",
      "\tW>JN >J# #M &lt;L&LB \n",
      "\tand &lt;NEG> man put upon heart\n",
      "\n",
      "471928  Isaiah 57:7  FJM   dp put; place [3|couch~your:f] [1|upon mountain high and lift] :: \n",
      "\t&lt;L HR&GBH WN#> #MT M#KBK \n",
      "\tupon mountain high and lift put couch\n",
      "\n",
      "471931  Isaiah 57:8  FJM   dp put; place [4|remembrance~your:f] [2|after the door and the door-post] :: \n",
      "\tW>XR HDLT WHMZWZH #MT ZKRWNK \n",
      "\tand after the door and the door-post put remembrance\n",
      "\n",
      "471951  Isaiah 57:11 FJM   -c prepare; put in place; institute  :: [3|upon heart~your:f] taken as extra direct object besides \n",
      "\tL>&#MT &lt;L&LBK \n",
      "\tnot put upon heart\n",
      "\n",
      "472183  Isaiah 59:21 FJM   -p place [3|in mouth~yor:m] :: \n",
      "\tRWXJ >#R &lt;LJK WDBRJ >#R&#MTJ BPJK L>&JMW#W MPJK WMPJ ZR&lt;K WMPJ ZR&lt; ZR&lt;K M&lt;TH W&lt;D&&lt;WLM00\n",
      "\n",
      "\twind &lt;relative> upon and word &lt;relative> put in mouth not depart from mouth and from mouth seed and from mouth seed seed from now and unto eternity\n",
      "\n",
      "472243  Isaiah 60:15 FJM   d- prepare; put in place; institute [2|~you:f] :: \n",
      "\tTXT HJWTK &lt;ZWBH W#NW>H W>JN &lt;WBR W#MTJK LG>WN &lt;WLM M#W# DWR WDWR00\n",
      "\n",
      "\tunder part be leave and hate and &lt;NEG> pass and put to height eternity joy generation and generation\n",
      "\n",
      "472252  Isaiah 60:17 FJM   n. make [3|commission~your:f] to be [4|peace] :: \n",
      "\tW#MTJ PQDTK #LWM WNG#JK YDQH00\n",
      "\n",
      "\tand put commission peace and drive justice\n",
      "\n",
      "472284  Isaiah 61:3  FJM   -- prepare; put in place; institute :: \n",
      "\t#LXNJ LXB# LN#BRJ&LB LQR> L#BWJM DRWR WL>SWRJM PQX&QWX00\n",
      "LQR> #NT&RYWN LJHWH WJWM NQM L>LHJNW LNXM KL&>BLJM00\n",
      "L#WM L>BLJ YJWN LTT LHM P>R TXT >PR #MN ##WN TXT >BL M&lt;VH THLH TXT RWX KHH \n",
      "\tsend to saddle to break heart to call to take captive release and to bind opening to call year pleasure to YHWH and day vengeance to god(s) to repent, console whole mourning to put to mourning Zion to give to headdress under part dust oil rejoicing under part mourning rites wrap praise under part wind dim\n",
      "\n",
      "472356  Isaiah 62:7  FJM   n. make [4|& Jerusalem] to be [5|praise in the earth] :: \n",
      "\tW&lt;D&J#JM >T&JRW#LM THLH B>RY00\n",
      "\n",
      "\tand unto put &lt;object marker> Jerusalem praise in the earth\n",
      "\n",
      "472435  Isaiah 63:11 FJM   dp put; place [4|& wind holiness~his] [3|in interior~his] :: \n",
      "\t>JH H#M BQRBW >T&RWX QD#W00\n",
      "MWLJK LJMJN M#H ZRW&lt; TP>RTW BWQ&lt; MJM MPNJHM L&lt;#WT LW #M &lt;WLM00\n",
      "MWLJKM BTHMWT \n",
      "\twhere the put in interior &lt;object marker> wind holiness walk to right-hand side Moses arm splendour split water from face to make to name eternity walk in the primeval ocean\n",
      "\n",
      "472737  Isaiah 66:19 FJM   dp put; place [4|sign] [3|in~them:mm] :: \n",
      "\tW#MTJ BHM >WT \n",
      "\tand put in sign\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_decision(verbs={'FJM'}, books={'Isaiah'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
