{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-small.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/DANS-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-small.png\"/></a>\n",
    "<a href=\"https://www.academic-bible.com/en/online-bibles/biblia-hebraica-stuttgartensia-bhs/read-the-bible-text/\" target=\"_blank\"><img align=\"right\" src=\"files/images/DBG-small.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbal valence\n",
    "\n",
    "*Verbal valence* is a kind of signature of a verb, not unlike overloading in programming languages.\n",
    "The meaning of a verb depends on the number and kind of its complements, i.e. the linguistic entities that act as arguments for the semantic function of the verb.\n",
    "\n",
    "We will use a set of flowcharts to specify and compute the sense of a verb in specific contexts depending on the verbal valence. The flowcharts have been composed by Janet Dyk. Although they are not difficult to understand, it takes a good deal of ingenuity to apply them in all the real world situations that we encounter in our corpus.\n",
    "\n",
    "\n",
    "# Authors\n",
    "\n",
    "This notebook is being written by [Dirk Roorda](dirk.roorda@dans.knaw.nl) following the ideas of \n",
    "[Janet Dyk](j.w.dyk@vu.nl). Janet's ideas have been published in various ways, see the references below.\n",
    "They can be summarized as a set of flowcharts. Each flowchart describes set of rules how to choose between\n",
    "the senses of a specific verb based on the constituents in each context where it occurs.\n",
    "The role of Dirk is to turn those ideas into a working program based on the ETCBC data.\n",
    "\n",
    "# About\n",
    "\n",
    "This is an [Jupyter](http://jupyter.org) notebook. It contains a working program to carry out the computations\n",
    "that we need for making use of verbal valence patterns.\n",
    "You can download this notebook and run it on your computer, provided you have\n",
    "[LAF-Fabric](http://laf-fabric.readthedocs.org/en/latest/texts/welcome.html) installed.\n",
    "\n",
    "There is not only code in this notebook, but also extensive documentation, and a description how to view\n",
    "the results on \n",
    "[SHEBANQ](https://shebanq.ancient-data.org) as a set of *Notes*.\n",
    "See the end of the notebook for precise links.\n",
    "\n",
    "# Status\n",
    "\n",
    "**Last modified: 2016-07-07**\n",
    "\n",
    "This notebook is not yet finished. \n",
    "It turns out that the ETCBC data at present does not contain all bits and pieces that are needed to follow\n",
    "the rules in Janet's flowcharts. It is difficult to find all direct objects, especially implied ones.\n",
    "And there are many cases where the database encodes a phrase as a complement, where the flowchart expects it to be a direct object.\n",
    "\n",
    "We have set up a workflow for correcting and enriching the ETCBC data. See the\n",
    "[corr_enrich notebook](corr_enrich.ipynb).\n",
    "There we take care that all relevant phrases get there proper *function*\n",
    "labels. And we analyse those phrases and assign new properties to them, based on certain heuristics.\n",
    "\n",
    "This flowchart notebook takes those new properties as input for determining the valencies of verbs.\n",
    " \n",
    "# More about flowcharts\n",
    "\n",
    "Here is an original flowchart by Janet, the one for NTN (*give*).\n",
    "\n",
    "<img src=\"images/FlowChartNTN-orig.pdf\"/>\n",
    "\n",
    "In order to run the flowcharts, preliminary work has to be done. \n",
    "We have to \n",
    "\n",
    "* identify direct objects;\n",
    "* divide them into principal and secundary ones if there are multiple;\n",
    "* identify complements;\n",
    "* divide them into locatives, indirect objects, and other complements;\n",
    "* detect relativa and offer them as potential direct objects;\n",
    "* detect phrases starting with MN (*from*) and offer them as potential direct objects.\n",
    "\n",
    "These are exactly the things that we outsource to the \n",
    "[corr_enrich notebook](corr_enrich.ipynb).\n",
    "\n",
    "\n",
    "# Generic flowchart\n",
    "\n",
    "The generic flowchart rules can be read off this diagram.\n",
    "\n",
    "<img src=\"images/Valence-Generic.pdf\"/>\n",
    "\n",
    "In fact, this part of the flowchart requires the most programming effort.\n",
    "\n",
    "# Specific flowcharts\n",
    "\n",
    "Using the generic flowchart, we state the rules for individual verbs, which can be expressed as simple\n",
    "multiple choice lists. Far below in this notebook, these rules will be applied to all clauses.\n",
    "\n",
    "As an example, this is a simplified flowchart for NTN in diagram form as we will implement it below.\n",
    "\n",
    "<img src=\"images/Valence-NTN.pdf\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowchart logic\n",
    "\n",
    "Here is the bare logic of the flow charts for the individual verbs.\n",
    "\n",
    "The ``senses`` data structure is a dictionary keyed by verb lexemes. \n",
    "For each verb it is keyed by *sense labels*, which is a code for the presence and nature of direct objects and  complements that are present in the context.\n",
    "\n",
    "These are the possible sense labels.\n",
    "\n",
    "The **object** column may contain:\n",
    "\n",
    "* `n` phrase[type=NP] or phrase[type=PP] and starts with >T\n",
    "* `l` phrase starting with L (but not indirect object or benefactive)\n",
    "* `k` phrase starting with K\n",
    "* `i` clause starting with L and having an infinitive as predicate, but not coded as `rela=Objc`\n",
    "* `-` no object present\n",
    "\n",
    "The **complement** column may contain:\n",
    "\n",
    "* `i` indirect object or adjunct benefactive\n",
    "* `p` locative, fine distinction within these cases dependent on preposition\n",
    "* `c` other complement\n",
    "* `-` no complement present\n",
    "* `.` presence of complement not relevant\n",
    "\n",
    "object|complement\n",
    "------|----------\n",
    "`-`|`-`\n",
    "`-`|`c`\n",
    "`-`|`i`\n",
    "`-`|`p`\n",
    "`d`|`-`\n",
    "`d`|`c`\n",
    "`d`|`i`\n",
    "`d`|`p`\n",
    "`n`|`.`\n",
    "`l`|`.`\n",
    "`k`|`.`\n",
    "`i`|`.`\n",
    "\n",
    "Behind each sense label there is information about the meaning of the verb in such a context.\n",
    "The meaning consists of 2 or 3 pieces of information.\n",
    "\n",
    "The important part is the second one, the *sense template*, which consist of a gloss augmented with placeholders for the direct objecs and complements.\n",
    "\n",
    "* `{verb}` the verb occurrence in question\n",
    "* `{pdos}` principal direct objects (phrase)\n",
    "* `{kdos}` K-objects (phrase)\n",
    "* `{ldos}` L-objects (phrase)\n",
    "* `{ndos}` direct objects (phrase) (none of the above)\n",
    "* `{idos}` infinitive construct (clause) objects\n",
    "* `{cdos}` direct objects (clause) (none of the above)\n",
    "* `{inds}` indirect objects\n",
    "* `{locs}` locatives\n",
    "* `{cpls}` complements, not marked as either indirect object or locative\n",
    "\n",
    "In case there are multiple entities, the algorithm returns them chunked as phrases/clauses.\n",
    "\n",
    "Apart from the template, there is also a *status* and an optional *account*. \n",
    "\n",
    "The status is ``!`` in normal cases, ``?`` in dubious cases, and ``-`` in erroneous cases.\n",
    "In SHEBANQ these statuses are translated into colors of the notes (blue/orange/red).\n",
    "\n",
    "The account contains information about the grounds of which the algorithm has arrived at its conclusions.\n",
    "\n",
    "A typical case is ``NTN[`` sense ``0c``. This verbs prefers indirect objects and not locatives.\n",
    "So when the context has a complement that fails to be classified beforehand as either locative or indirect object, this is the moment that we finally decide it is an indirect object after all.\n",
    "But this is risky, so we give it status ``?`` and we tell the user that we have decided to change ``C`` into ``I`` for this complement.\n",
    "\n",
    "Likewise, sense ``0l`` is not expected to occur. When we encounter it, we conclude that our heuristic for choosing between ``L`` and ``I`` has failed here, and we overrule that decision and change ``L`` to ``I``.\n",
    "We tell the user that here we have encountered an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "senses_spec = '''\n",
    "<FH\n",
    "--:!: act; take action\n",
    "-i:?: act; take action for {inds} :: {inds} taken as benefactive adjunct\n",
    "-p:?: act; take action at {locs} :: {locs} taken as locative adjunct\n",
    "-c:?: do; make; perform; observe {cpls} :: {cpls} taken as direct object\n",
    "d-:!: do; make; perform; observe {dos}\n",
    "di:?: do; make; perform; observe {dos} for {inds} :: {inds} taken as benefactive adjunct\n",
    "dp:?: do; make; perform; observe {dos} at {locs} :: {locs} taken as locative adjunct\n",
    "dc:?: make {dos} to be {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:-: !not encountered!\n",
    "\n",
    "BR>\n",
    "--:-: !not encountered!\n",
    "-i:?: create for {inds} :: {inds} taken as benefactive adjunct\n",
    "-p:?: create at {locs} :: {locs} taken as locative adjunct\n",
    "-c:?: create {cpls} :: {cpls} taken as direct object\n",
    "d-:!: create {dos}\n",
    "di:?: create {dos} for {inds} :: {inds} taken as benefactive adjunct\n",
    "dp:?: create {dos} at {locs} :: {locs} taken as locative adjunct\n",
    "dc:?: create {dos} to be {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: create {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:-: !not encountered!\n",
    "k.:-: !not encountered!\n",
    "i.:-: !not encountered!\n",
    "\n",
    "CJT\n",
    "--:-: !not encountered!\n",
    "-i:-: !not encountered!\n",
    "-p:-: !not encountered!\n",
    "-c:?: install; set up; put in place {cpls} :: {cpls} taken as direct object\n",
    "d-:!: install; set up; put in place {dos}\n",
    "di:?: place {dos} for the benefit of {inds} :: {inds} taken as benefactive adjunct\n",
    "dp:!: place {dos} {locs}\n",
    "dc:?: make {dos} to be {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: !specific significance!\n",
    "\n",
    "DBQ\n",
    "--:-: !not encountered!\n",
    "-i:?: cling; cleave; adhere to {inds} :: {inds} taken as locative\n",
    "-p:!: cling; cleave; adhere after/to {locs}\n",
    "-c:?: cling; cleave; adhere to {cpls} :: {cpls} taken as locative\n",
    "d-:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "di:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "dp:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "dc:-: !not encountered! :: Should {verb} be hiphil? :: ?\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: !specific significance!\n",
    "\n",
    "FJM\n",
    "--:!: prepare; put in place; institute\n",
    "-i:?: prepare; put in place; for {inds} :: {inds} taken as benefactive adjunct\n",
    "-p:!: put in place {locs}\n",
    "-c:?: prepare; put in place; institute {pdos} :: {cpls} taken as extra direct object besides {pdos}\n",
    "d-:!: prepare; put in place; institute {dos}\n",
    "di:?: prepare; put in place; institute {dos} for {inds} :: {inds} taken as benefactive adjunct\n",
    "dp:!: put; place {dos} {locs}\n",
    "dc:?: make {dos} (to be) {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: set {pdos} to {cdos}\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: be determined to do {idos}\n",
    "\n",
    "NTN\n",
    "--:!: (act of) producing; yielding; giving (in itself)\n",
    "-i:!: produce for; yield for; give to {inds}\n",
    "-p:-: !not encountered!\n",
    "-c:?: produce; yield; give {cpls} :: {cpls} taken as extra direct object besides {pdos}\n",
    "d-:!: produce; yield; give {dos}\n",
    "di:!: give {dos} to {inds}\n",
    "dp:!: place {dos} {locs}\n",
    "dc:?: make {dos} (to be (as)/to become/to do) {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:!: allow {pdos} to do {idos}\n",
    "\n",
    "QR>\n",
    "--:!: shout; call; invoke\n",
    "-i:!: call; summon {inds}\n",
    "-p:?: call at {locs} :: {locs} taken as locative adjunct.\n",
    "-c:?: call {cpls} (content) :: {cpls} taken as direct object\n",
    "d-:!: call; summon {dos} (content or addressee)\n",
    "di:!: summon {dos} for {inds}\n",
    "dp:!: call out {dos} before {locs}\n",
    "dc:?: call {dos} (to be named) {cpls} :: {cpls} taken as extra direct object besides {dos}\n",
    "n.:!: call {pdos} (to be named) {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: call {pdos} (to be named) {ldos}\n",
    "k.:!: call {pdos} (to be named) according to {kdos}\n",
    "i.:?: !specific significance!\n",
    "\n",
    "ZQN\n",
    "--:!: be old\n",
    "-i:?: be old for {inds} :: {inds} taken as benefactive adjunct\n",
    "-p:?: be old in {locs} :: {locs} taken as locative adjunct\n",
    "-c:?: be old ... {cpls} :: {cpls} taken as adjunct\n",
    "d-:-: !not encountered!\n",
    "di:-: !not encountered!\n",
    "dp:-: !not encountered!\n",
    "dc:-: !not encountered!\n",
    "n.:!: make {pdos} to be {ndos}\n",
    "c.:-: !not defined principal={pdos}, secundary(clause)={cdos}!\n",
    "l.:!: make {pdos} to become {ldos}\n",
    "k.:!: make {pdos} to be as {kdos}\n",
    "i.:?: !specific significance!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "See the results on SHEBANQ.\n",
    "\n",
    "The complete set of results is in the note set \n",
    "[valence](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxlbmNl&tp=txt_tb1).\n",
    "You can find it on the Notes page in SHEBANQ:\n",
    "\n",
    "<img src=\"images/valnotes.png\"/>\n",
    "\n",
    "By checking the other note sets you *mute* them, so they do not show up among the lines.\n",
    "\n",
    "In order to see a note set, click on its name. You then go to pages with all verses that have a note of this set attached. \n",
    "\n",
    "<img src=\"images/notesview.png\"/>\n",
    "\n",
    "In order to see the actual notes, click the comment cloud icons. If you click the upper left one, notes are fetched for all verses on the page.\n",
    "\n",
    "<img src=\"images/withnotes.png\"/>\n",
    "\n",
    "You can also export the notes as csv, or view them in a chart.\n",
    "\n",
    "The *valence* set has the following subsets:\n",
    "\n",
    "* Unresolved results: [val_nb](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfbmI_&tp=txt_tb1);\n",
    "* Uncertain results: [val_wrn](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfd3Ju&tp=txt_tb1);\n",
    "* Erroneous results: [val_err](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfZXJy&tp=txt_tb1);\n",
    "* Promotion candidates [val_prom](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxfcHJvbQ__&tp=txt_tb1)\n",
    "\n",
    "So if you follow the *valence* link you see them all, but you can also focus on the problematic cases.\n",
    "\n",
    "And if you are logged in, you can add remarks in free text. Just start typing in one of the new note boxes.\n",
    "Hint: use the keyword **val_note** for your manual notes to valence, then other users can see all relevant information about valence together.\n",
    "\n",
    "By clicking on the status symbol you can cycle through different display styles and colors for your note.\n",
    "Do not forget to save when you are done!\n",
    "\n",
    "See also the SHEBANQ help on notes:\n",
    "[general](https://shebanq.ancient-data.org/help#notes)\n",
    "[notes view](https://shebanq.ancient-data.org/help#notes_style)\n",
    "[working with notes](https://shebanq.ancient-data.org/help#working_with_notes)\n",
    "\n",
    "If you have a solid contribution to make, e.g. the outcome of an algorithm, consider\n",
    "[bulk uploading notes](https://shebanq.ancient-data.org/help#bulk_uploading_notes).\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "(Janet Dyk, Reinoud Oosting and Oliver Glanz, 2014) \n",
    "Analysing Valence Patterns in Biblical Hebrew: Theoretical Questions and Analytic Frameworks.\n",
    "*J. of Northwest Semitic Languages, vol. 40 (2014), no. 1, pp. 43-62*.\n",
    "[pdf abstract](http://academic.sun.ac.za/jnsl/Volumes/JNSL%2040%201%20abstracts%20and%20bookreview.pdf)\n",
    "[pdf fulltext (author's copy with deviant page numbering)](https://shebanq.ancient-data.org/static/docs/methods/2014_Dyk_jnsl.pdf)\n",
    "\n",
    "(Janet Dyk 2014)\n",
    "Deportation or Forgiveness in Hosea 1.6? Verb Valence Patterns and Translation Proposals.\n",
    "*The Bible Translator 2014, Vol. 65(3) 235–279*.\n",
    "[pdf](http://tbt.sagepub.com/content/65/3/235.full.pdf?ijkey=VK2CEHvVrvSGA5B&keytype=finite)\n",
    "\n",
    "(Janet Dyk 014)\n",
    "Traces of Valence Shift in Classical Hebrew.\n",
    "In: *Discourse, Dialogue, and Debate in the Bible: Essays in Honour of Frank Polak*.\n",
    "Ed. Athalya Brenner-Idan.\n",
    "*Sheffield Pheonix Press, 48–65*.\n",
    "[book behind pay-wall](http://www.sheffieldphoenix.com/showbook.asp?bkid=273)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.8.3\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import collections\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.01s DETAIL: COMPILING m: etcbc4b: UP TO DATE\n",
      "  0.01s USING main: etcbc4b DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.01s DETAIL: COMPILING a: complements: UP TO DATE\n",
      "  0.01s USING annox: complements DATA COMPILED AT: 2016-11-14T15-26-18\n",
      "  0.01s DETAIL: COMPILING a: lexicon: UP TO DATE\n",
      "  0.02s USING annox: lexicon DATA COMPILED AT: 2016-07-08T14-32-54\n",
      "  0.03s DETAIL: load main: G.node_anchor_min\n",
      "  0.12s DETAIL: load main: G.node_anchor_max\n",
      "  0.18s DETAIL: load main: G.node_sort\n",
      "  0.23s DETAIL: load main: G.node_sort_inv\n",
      "  0.62s DETAIL: load main: G.edges_from\n",
      "  0.68s DETAIL: load main: G.edges_to\n",
      "  0.74s DETAIL: load main: F.etcbc4_db_monads [node] \n",
      "  1.40s DETAIL: load main: F.etcbc4_db_oid [node] \n",
      "  2.05s DETAIL: load main: F.etcbc4_db_otype [node] \n",
      "  2.67s DETAIL: load main: F.etcbc4_ft_det [node] \n",
      "  2.87s DETAIL: load main: F.etcbc4_ft_g_word_utf8 [node] \n",
      "  3.13s DETAIL: load main: F.etcbc4_ft_lex [node] \n",
      "  3.30s DETAIL: load main: F.etcbc4_ft_ls [node] \n",
      "  3.48s DETAIL: load main: F.etcbc4_ft_number [node] \n",
      "  3.89s DETAIL: load main: F.etcbc4_ft_prs [node] \n",
      "  4.06s DETAIL: load main: F.etcbc4_ft_rela [node] \n",
      "  4.36s DETAIL: load main: F.etcbc4_ft_sp [node] \n",
      "  4.53s DETAIL: load main: F.etcbc4_ft_trailer_utf8 [node] \n",
      "  4.65s DETAIL: load main: F.etcbc4_ft_typ [node] \n",
      "  4.93s DETAIL: load main: F.etcbc4_ft_uvf [node] \n",
      "  5.10s DETAIL: load main: F.etcbc4_ft_vs [node] \n",
      "  5.25s DETAIL: load main: F.etcbc4_ft_vt [node] \n",
      "  5.42s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  5.43s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  5.44s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  5.46s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  5.47s DETAIL: load main: F.etcbc4_ft_mother [e] \n",
      "  5.52s DETAIL: load main: C.etcbc4_ft_mother -> \n",
      "  5.64s DETAIL: load main: C.etcbc4_ft_mother <- \n",
      "  5.75s DETAIL: load annox lexicon: F.etcbc4_lex_gloss [node] \n",
      "  5.94s DETAIL: load annox lexicon: F.etcbc4_lex_nametype [node] \n",
      "  6.03s DETAIL: load annox complements: F.JanetDyk_ft_f_correction [node] \n",
      "  6.06s DETAIL: load annox complements: F.JanetDyk_ft_function [node] \n",
      "  6.08s DETAIL: load annox complements: F.JanetDyk_ft_grammatical [node] \n",
      "  6.11s DETAIL: load annox complements: F.JanetDyk_ft_lexical [node] \n",
      "  6.13s DETAIL: load annox complements: F.JanetDyk_ft_original [node] \n",
      "  6.14s DETAIL: load annox complements: F.JanetDyk_ft_predication [node] \n",
      "  6.16s DETAIL: load annox complements: F.JanetDyk_ft_s_manual [node] \n",
      "  6.19s DETAIL: load annox complements: F.JanetDyk_ft_semantic [node] \n",
      "  6.21s DETAIL: load annox complements: F.JanetDyk_ft_valence [node] \n",
      "  6.23s LOGFILE=/Users/dirk/laf/laf-fabric-output/etcbc4b/valence/__log__valence.txt\n",
      "  6.32s INFO: LOADING PREPARED data: please wait ... \n",
      "  6.32s prep prep: G.node_sort\n",
      "  6.36s prep prep: G.node_sort_inv\n",
      "  6.80s prep prep: L.node_up\n",
      "  9.71s prep prep: L.node_down\n",
      "    15s prep prep: V.verses\n",
      "    15s prep prep: V.books_la\n",
      "    15s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    18s INFO: LOADED PREPARED data\n",
      "    18s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon, complements FOR TASK valence AT 2016-11-14T15-27-11\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "API = fabric.load('etcbc{}'.format(version), 'lexicon,complements', 'valence', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        oid otype monads\n",
    "        JanetDyk:ft.function rela typ\n",
    "        g_word_utf8 trailer_utf8\n",
    "        lex prs uvf sp ls vs vt nametype det gloss\n",
    "        book chapter verse label number\n",
    "        s_manual f_correction\n",
    "        valence predication grammatical original lexical semantic\n",
    "    ''',\n",
    "    '''\n",
    "        mother\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "home_dir = os.path.expanduser('~').replace('\\\\', '/')\n",
    "base_dir = '{}/Dropbox/SYNVAR'.format(home_dir)\n",
    "result_dir = '{}/results'.format(base_dir)\n",
    "result_v_dir = '{}/by_verb'.format(result_dir)\n",
    "os.makedirs(result_v_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators\n",
    "\n",
    "Here we specify by what features we recognize key constituents.\n",
    "We use predominantly features that come from the correction/enrichment workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pf ... : predication feature\n",
    "# gf_... : grammatical feature\n",
    "# vf_... : valence feature\n",
    "# sf_... : lexical feature\n",
    "# of_... : original feature\n",
    "\n",
    "pf_predicate = {\n",
    "    'regular',\n",
    "}\n",
    "gf_direct_object = {\n",
    "    'principal_direct_object',\n",
    "    'NP_direct_object',\n",
    "    'direct_object',\n",
    "    'L_object',\n",
    "    'K_object',\n",
    "    'infinitve_object,'\n",
    "}\n",
    "gf_indirect_object = {\n",
    "    'indirect_object',\n",
    "}\n",
    "gf_complement = {\n",
    "    '*',\n",
    "}\n",
    "sf_locative = {\n",
    "    'location',\n",
    "}\n",
    "vf_locative = {\n",
    "    'complement',\n",
    "    'adjunct',\n",
    "}\n",
    "\n",
    "verbal_stems = set('''\n",
    "    qal\n",
    "'''.strip().split())\n",
    "\n",
    "pronominal_suffix = {\n",
    "    'W': ('p3-sg-m', 'him'),\n",
    "    'K': ('p2-sg-m', 'you:m'),\n",
    "    'J': ('p1-sg-', 'me'),\n",
    "    'M': ('p3-pl-m', 'them:mm'),\n",
    "    'H': ('p3-sg-f', 'her'),\n",
    "    'HM': ('p3-pl-m', 'them:mm'),\n",
    "    'KM': ('p2-pl-m', 'you:mm'),\n",
    "    'NW': ('p1-pl-', 'us'),\n",
    "    'HW': ('p3-sg-m', 'him'),\n",
    "    'NJ': ('p1-sg-', 'me'),\n",
    "    'K=': ('p2-sg-f', 'you:f'),\n",
    "    'HN': ('p3-pl-f', 'them:ff'),\n",
    "    'MW': ('p3-pl-m', 'them:mm'),\n",
    "    'N': ('p3-pl-f', 'them:ff'),\n",
    "    'KN': ('p2-pl-f', 'you:ff'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06s Senses for 8 verbs:\n",
      "\t<FH\n",
      "\tBR>\n",
      "\tCJT\n",
      "\tDBQ\n",
      "\tFJM\n",
      "\tNTN\n",
      "\tQR>\n",
      "\tZQN\n"
     ]
    }
   ],
   "source": [
    "slabels = '''\n",
    "--\n",
    "-c\n",
    "-i\n",
    "-p\n",
    "d-\n",
    "dc\n",
    "di\n",
    "dp\n",
    "n.\n",
    "c.\n",
    "l.\n",
    "k.\n",
    "i.\n",
    "'''.strip().split()\n",
    "\n",
    "senses = {}\n",
    "senses_blocks = senses_spec.strip().split('\\n\\n')\n",
    "for b in senses_blocks:\n",
    "    lines = b.split('\\n')\n",
    "    verb = lines[0]\n",
    "    sense_parts = [l.split(':', 2) for l in lines[1:]]\n",
    "    senses[verb] = dict(\n",
    "        (x[0].strip(), (x[1].strip(), [y.strip() for y in x[2].strip().split('::')])) for x in sense_parts\n",
    "    )\n",
    "    for slabel in slabels:\n",
    "        if slabel not in senses[verb]:\n",
    "            msg('{:<6}: Missing sense label: {}'.format(verb, slabel))\n",
    "    for slabel in sorted(senses[verb]):\n",
    "        if slabel not in slabels:\n",
    "            msg('{:<6}: Unknown sense label: {}'.format(verb, slabel))\n",
    "inf('Senses for {} verbs:\\n\\t{}'.format(len(senses), '\\n\\t'.join(sorted(senses))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a verb-clause index\n",
    "\n",
    "We generate an index which gives for each verb lexeme a list of clauses that have that lexeme as the main verb.\n",
    "In the index we store the clause node together with the word node(s) that carries the main verb(s).\n",
    "\n",
    "Clauses may have multiple verbs. In many cases it is a copula plus an other verb.\n",
    "In those cases, we are interested in the other verb, so we exclude copulas.\n",
    "\n",
    "Yet, there are also sentences with more than one main verb.\n",
    "In those cases, we treat both verbs separately as main verb of one and the same clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.08s Making the verb-clause index\n",
      "  1.77s Done (6042 clauses with a flowchart verb)\n"
     ]
    }
   ],
   "source": [
    "msg('Making the verb-clause index')\n",
    "occs = collections.defaultdict(list)   # dictionary of all verb occurrence nodes per verb lexeme\n",
    "verb_clause = collections.defaultdict(list)    # dictionary of all verb occurrence nodes per clause node\n",
    "clause_verb = collections.OrderedDict() # idem but for the occurrences of selected verbs\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    if F.sp.v(w) != 'verb': continue\n",
    "    lex = F.lex.v(w).rstrip('[')\n",
    "    if lex not in senses: continue   \n",
    "    pf = F.predication.v(L.u('phrase', w))\n",
    "    if pf in pf_predicate:\n",
    "        cn = L.u('clause', w)\n",
    "        clause_verb.setdefault(cn, []).append(w)\n",
    "        verb_clause[lex].append((cn, w))\n",
    "msg('Done ({} clauses with a flowchart verb)'.format(len(clause_verb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Indirect) Objects, Locatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1.83s Finding key constituents\n",
      "  2.00s Done\n"
     ]
    }
   ],
   "source": [
    "msg('Finding key constituents')\n",
    "constituents = collections.defaultdict(lambda: collections.defaultdict(set))\n",
    "ckinds = '''\n",
    "    dos pdos ndos kdos ldos idos cdos inds locs cpls\n",
    "'''.strip().split()\n",
    "\n",
    "# go through all relevant clauses and collect all types of direct objects\n",
    "for c in clause_verb:\n",
    "    these_constituents = collections.defaultdict(set)\n",
    "    # phrase like constituents\n",
    "    for p in L.d('phrase', c):\n",
    "        gf = F.grammatical.v(p)\n",
    "        of = F.original.v(p)\n",
    "        sf = F.semantic.v(p)\n",
    "        vf = F.valence.v(p)\n",
    "        ckind = None\n",
    "        if gf in gf_direct_object:\n",
    "            if gf =='principal_direct_object':\n",
    "                ckind = 'pdos'\n",
    "            elif gf == 'NP_direct_object':\n",
    "                ckind = 'ndos'\n",
    "            elif gf == 'L_object':\n",
    "                ckind = 'ldos'\n",
    "            elif gf == 'K_object':\n",
    "                ckind = 'kdos'\n",
    "            else:\n",
    "                ckind = 'dos'\n",
    "        elif gf in gf_indirect_object:\n",
    "            ckind = 'inds'\n",
    "        elif sf in sf_locative and vf in vf_locative:\n",
    "            ckind = 'locs'\n",
    "        elif gf in gf_complement:\n",
    "            ckind = 'cpls'\n",
    "        if ckind: these_constituents[ckind].add(p)\n",
    "\n",
    "    # clause like constituents: only look for object clauses dependent on this clause\n",
    "    for ac in L.d('clause', L.u('sentence', c)):\n",
    "        dep = list(C.mother.v(ac))\n",
    "        if len(dep) and dep[0] == c:\n",
    "            gf = F.grammatical.v(ac)\n",
    "            ckind = None\n",
    "            if gf in gf_direct_object:\n",
    "                if gf == 'direct_object':\n",
    "                    ckind = 'cdos'\n",
    "                elif gf == 'infinitive_object':\n",
    "                    ckind = 'idos'\n",
    "            if ckind: these_constituents[ckind].add(ac)\n",
    "    \n",
    "    for ckind in these_constituents:\n",
    "        constituents[c][ckind] |= these_constituents[ckind]\n",
    "\n",
    "msg('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647761=phrase (Adju-PP) LK Numeri 6:26\tJ#> JHWH PNJW >LJK WJ#M LK #LWM00\n",
      "\n",
      "valence = adjunct; grammatical = NA; lexical = ; semantic = benefactive\n",
      "\n",
      "constituents: defaultdict(<class 'set'>, {})\n",
      "=====\n",
      "\n",
      "440568=clause (NA-WYq0) WJ#M LK #LWM00\n",
      "Numeri 6:26\tJ#> JHWH PNJW >LJK WJ#M LK #LWM00\n",
      "\n",
      "valence = None; grammatical = None; lexical = None; semantic = None\n",
      "\n",
      "constituents: defaultdict(<class 'set'>, {'dos': {647762}})\n",
      "=====\n",
      "\n",
      "448456=clause (NA-ZIm0) #JM&LK M>XRJH00\n",
      "Josua 8:2\tW<#JT L<J WLMLKH K>#R <#JT LJRJXW WLMLKH RQ&#LLH WBHMTH TBZW LKM #JM&LK >RB L<JR M>XRJH00\n",
      "\n",
      "valence = None; grammatical = None; lexical = None; semantic = None\n",
      "\n",
      "constituents: defaultdict(<class 'set'>, {'locs': {671522}, 'cdos': {448457}})\n",
      "=====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testp = 647761\n",
    "testc = 440568\n",
    "testx = 448456\n",
    "\n",
    "def showcase(n):\n",
    "    otype = F.otype.v(n)\n",
    "    att1 = F.function.v(n) if otype == 'phrase' else F.rela.v(n)\n",
    "    att2 = F.typ.v(n)\n",
    "    print('''{}={} ({}-{}) {}{}'''.format(\n",
    "        n, otype, att1, att2,\n",
    "        T.words(L.d('word', n), fmt='ec'), \n",
    "        T.text(\n",
    "            book=F.book.v(L.u('book', n)), \n",
    "            chapter=int(F.chapter.v(L.u('chapter', n))),\n",
    "            verse=int(F.verse.v(L.u('verse', n))), \n",
    "            fmt='ec', lang='la',\n",
    "        ),\n",
    "    ))\n",
    "    print('valence = {}; grammatical = {}; lexical = {}; semantic = {}\\n'.format(\n",
    "        F.valence.v(n),\n",
    "        F.grammatical.v(n),\n",
    "        F.lexical.v(n),\n",
    "        F.semantic.v(n),\n",
    "    ))\n",
    "    print('constituents: {}\\n=====\\n'.format(constituents[n]))\n",
    "\n",
    "for n in (testp, testc, testx): showcase(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 clauses with  2 dos        constituents\n",
      " 3447 clauses with  1 dos        constituents\n",
      " 1443 clauses with  0 dos        constituents\n",
      " 3449 clauses with  a dos        constituents\n",
      "  542 clauses with  1 pdos       constituents\n",
      " 4350 clauses with  0 pdos       constituents\n",
      "  542 clauses with  a pdos       constituents\n",
      "  336 clauses with  1 ndos       constituents\n",
      " 4556 clauses with  0 ndos       constituents\n",
      "  336 clauses with  a ndos       constituents\n",
      "   33 clauses with  1 kdos       constituents\n",
      " 4859 clauses with  0 kdos       constituents\n",
      "   33 clauses with  a kdos       constituents\n",
      "   19 clauses with  2 ldos       constituents\n",
      "  617 clauses with  1 ldos       constituents\n",
      " 4256 clauses with  0 ldos       constituents\n",
      "  636 clauses with  a ldos       constituents\n",
      " 4892 clauses with  0 idos       constituents\n",
      "    0 clauses with  a idos       constituents\n",
      "    1 clauses with  2 cdos       constituents\n",
      "  153 clauses with  1 cdos       constituents\n",
      " 4738 clauses with  0 cdos       constituents\n",
      "  154 clauses with  a cdos       constituents\n",
      "    3 clauses with  2 inds       constituents\n",
      "  717 clauses with  1 inds       constituents\n",
      " 4172 clauses with  0 inds       constituents\n",
      "  720 clauses with  a inds       constituents\n",
      "    5 clauses with  3 locs       constituents\n",
      "   27 clauses with  2 locs       constituents\n",
      " 1043 clauses with  1 locs       constituents\n",
      " 3817 clauses with  0 locs       constituents\n",
      " 1075 clauses with  a locs       constituents\n",
      "    8 clauses with  2 cpls       constituents\n",
      "  388 clauses with  1 cpls       constituents\n",
      " 4496 clauses with  0 cpls       constituents\n",
      "  396 clauses with  a cpls       constituents\n",
      " 6042 clauses with  a flowchart verb\n"
     ]
    }
   ],
   "source": [
    "# Counting constituents\n",
    "\n",
    "constituents_count = collections.defaultdict(collections.Counter)\n",
    "\n",
    "for c in constituents:\n",
    "    for ckind in ckinds:\n",
    "        n = len(constituents[c][ckind])\n",
    "        constituents_count[ckind][n] += 1\n",
    "\n",
    "for ckind in ckinds:\n",
    "    total = 0\n",
    "    for (count, n) in sorted(constituents_count[ckind].items(), key=lambda y: -y[0]):\n",
    "        if count: total += n\n",
    "        inf('{:>5} clauses with {:>2} {:<10} constituents'.format(n, count, ckind), withtime=False)\n",
    "    inf('{:>5} clauses with {:>2} {:<10} constituents'.format(total, 'a', ckind), withtime=False)\n",
    "inf('{:>5} clauses with {:>2} flowchart verb'.format(len(clause_verb), 'a'), withtime=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying the flowchart\n",
    "\n",
    "We can now apply the flowchart in a straightforward manner.\n",
    "\n",
    "We output the results as a stand-alone comma separated file, with these columns as specified in the code below.\n",
    "This file can be used to import into a spreadsheet and check results.\n",
    "\n",
    "We also provide a comma separated file that can be imported directly into SHEBANQ as a set of notes, so that the reader can check results within SHEBANQ. This has the benefit that the full context is available, and also data view can be called up easily to inspect the coding situation for each particular instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_rep = {\n",
    "    '*': 'note',\n",
    "    '!': 'good',\n",
    "    '?': 'warning',\n",
    "    '-': 'error',\n",
    "}\n",
    "stat_rep = {\n",
    "    '*': 'NB',\n",
    "    '!': '',\n",
    "    '?': 'wrn',\n",
    "    '-': 'err',\n",
    "}\n",
    "\n",
    "def reptext(label, phrases, num=False, txt=False, gloss=False, textformat='ec'): \n",
    "    if phrases == None: return ''\n",
    "    label_rep = '{}='.format(label) if label else ''\n",
    "    phrases_rep = []\n",
    "    for p in sorted(phrases, key=NK):\n",
    "        ptext = '[{}|'.format(F.number.v(p) if num else '[')\n",
    "        if txt:\n",
    "            ptext += T.words(L.d('word', p), fmt=textformat).replace('\\n', '.')\n",
    "        if gloss:\n",
    "            wtexts = []\n",
    "            for w in L.d('word',p ):\n",
    "                g = F.gloss.v(w).replace('<object marker>','&')\n",
    "                prs = F.prs.v(w)\n",
    "                prs_g = pronominal_suffix.get(prs, (None, None))[1]\n",
    "                uvf = F.uvf.v(w)\n",
    "                wtext = ''\n",
    "                if uvf == 'H': ptext += 'toward '\n",
    "                wtext += g\n",
    "                wtext += ('~'+prs_g) if prs_g != None else ''\n",
    "                wtexts.append(wtext)\n",
    "            ptext += ' '.join(wtexts)\n",
    "        ptext += ']'\n",
    "        phrases_rep.append(ptext)\n",
    "    return ' '.join(phrases_rep)\n",
    "\n",
    "debug_messages = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "\n",
    "def flowchart(v, lex, verb, consts):\n",
    "    sense_label = None\n",
    "    n_ = collections.defaultdict(lambda: 0)\n",
    "    for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "    char1 = None\n",
    "    char2 = None\n",
    "    # determine char 1 of the sense label\n",
    "    if n_['pdos'] > 0:\n",
    "        if n_['ndos'] > 0: char1 = 'n'\n",
    "        elif n_['cdos'] > 0: char1 = 'c'\n",
    "        elif n_['ldos'] > 0: char1 = 'l'\n",
    "        elif n_['kdos'] > 0: char1 = 'k'\n",
    "        elif n_['idos'] > 0: char1 = 'i'\n",
    "        else:\n",
    "        # in trouble: if there is a principal direct object, there should be an other object as well\n",
    "        # and the other one should be an NP, object clause, L_object, K_object, or I_object\n",
    "        # If this happens, it is probably the result of manual correction\n",
    "        # We warn, and remedy\n",
    "            msg_rep = '; '.join('{} {}'.format(n_[ckind], ckind) for ckind in ckinds)\n",
    "            if n_['dos'] > 0:\n",
    "                # there is an other object (dos should only be used if there is a single object)\n",
    "                # we'll put the dos in the ndos (which was empty)\n",
    "                # This could be caused by a manual enrichment sheet that has been generated \n",
    "                # before the concept of NP_direct_object had been introduced\n",
    "                char1 = 'n'\n",
    "                consts['ndos'] |= consts['dos']\n",
    "                debug_messages[lex]['pdos with dos'].append('{}: {}'.format(T.passage(v), msg_rep))\n",
    "            else:\n",
    "                # there is not another object, we treat this as a single object, so as a dos\n",
    "                char1 = 'd'\n",
    "                consts['dos'] |= consts['pdos']\n",
    "                debug_messages[lex]['lonely pdos'].append('{}: {}'.format(T.passage(v), msg_rep))\n",
    "    else:\n",
    "        if n_['cdos'] > 0:\n",
    "        # in the case of a single object, the clause objects act as ordinary objects\n",
    "            char1 = 'd'\n",
    "            consts['dos'] |= consts['cdos']\n",
    "        if n_['ndos'] > 0:\n",
    "        # in the case of a single object, the np_objects act as ordinary objects\n",
    "            char1 = 'd'\n",
    "            consts['dos'] |= consts['ndos']\n",
    "\n",
    "    n_ = collections.defaultdict(lambda: 0)\n",
    "    for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "\n",
    "    if n_['pdos'] == 0 and n_['dos'] > 0:\n",
    "        char1 = 'd'\n",
    "    if n_['pdos'] == 0 and n_['dos'] == 0:\n",
    "        char1 = '-'\n",
    "\n",
    "    # determine char 2 of the sense label\n",
    "    if char1 in 'nclki':\n",
    "        char2 = '.'\n",
    "    else:\n",
    "        if n_['inds'] > 0:\n",
    "            char2 = 'i'\n",
    "        elif n_['locs'] > 0:\n",
    "            char2 = 'p'\n",
    "        elif n_['cpls'] > 0:\n",
    "            char2 = 'c'\n",
    "        else:\n",
    "            char2 = '-'\n",
    "\n",
    "    sense_label = char1+char2\n",
    "    \n",
    "    sinfo = senses.\\\n",
    "        get(lex, {lex: {'': ('-', 'no senses given for {}'.format(lex))}}).\\\n",
    "        get(sense_label, ('-', 'no sense {} given for {}'.format(sense_label, lex)))\n",
    "    status = sinfo[0]\n",
    "    sense_fmt = sinfo[1][0]\n",
    "    action_fmt = sinfo[1][1] if len(sinfo[1]) >= 2 else ''\n",
    "    action_stat = sinfo[1][2] if len(sinfo) >= 3 else status\n",
    "\n",
    "    verb_rep = reptext('', verb, num=True, gloss=True)\n",
    "    consts_rep = dict((ckind, reptext('', consts[ckind], num=True, gloss=True)) for ckind in consts)\n",
    "        \n",
    "    sense_txt = sense_fmt.format(verb=verb_rep, **consts_rep)\n",
    "    action_txt = action_fmt.format(verb=verb_rep, **consts_rep)\n",
    "\n",
    "    return (sense_label, status, sense_txt, action_txt, action_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = ('''\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    sentence#\n",
    "    clause#\n",
    "    lex\n",
    "    status\n",
    "    sense_label\n",
    "    sense\n",
    "    action_status\n",
    "    action\n",
    "    '''+(''.join('\\n\\t#{}'.format(ckind) for ckind in ckinds))+'''\n",
    "    text\n",
    "''').strip().split()\n",
    "\n",
    "sfields = '''\n",
    "    version\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    clause_atom\n",
    "    is_shared\n",
    "    is_published\n",
    "    status\n",
    "    keywords\n",
    "    ntext\n",
    "'''.strip().split()\n",
    "\n",
    "fields_fmt = ('{};' * (len(fields) - 1)) + '{}\\n' \n",
    "sfields_fmt = ('{}\\t' * (len(sfields) - 1)) + '{}\\n' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the flowchart\n",
    "\n",
    "The next cell finally performs all the flowchart computations for all verbs in all contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30m 43s Applying the flowchart\n",
      "30m 43s No verb ZQN in enriched corpus\n",
      "30m 44s No verb DBQ in enriched corpus\n",
      "30m 45s Done\n",
      "FJM\n",
      "\tlonely pdos\n",
      "\t\tGenesis 4:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 30:41: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 2 locs; 0 cpls\n",
      "\t\tGenesis 45:7: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tExodus 1:11: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tExodus 9:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tDeuteronomy 12:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tDeuteronomy 22:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\t1_Samuel 8:5: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\t1_Samuel 8:12: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\t2_Samuel 7:23: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\t2_Samuel 13:33: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls\n",
      "\t\t1_Kings 2:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls\n",
      "\t\t2_Kings 12:18: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tJeremiah 7:30: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tJeremiah 32:34: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tJeremiah 42:15: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tJeremiah 42:17: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tJeremiah 44:11: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tJeremiah 44:12: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tEzekiel 21:24: 0 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tAND 12 more\n",
      "\tpdos with dos\n",
      "\t\tGenesis 13:16: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 21:13: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 21:18: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 27:37: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 28:18: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 32:13: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 45:8: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 45:9: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 46:3: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tGenesis 47:6: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tGenesis 47:26: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tGenesis 48:20: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tExodus 2:14: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 1 cpls\n",
      "\t\tExodus 14:21: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tExodus 28:12: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 1 locs; 0 cpls\n",
      "\t\tExodus 40:5: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tExodus 40:28: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tLeviticus 24:6: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 2 locs; 0 cpls\n",
      "\t\tDeuteronomy 10:22: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tDeuteronomy 32:46: 1 dos; 1 pdos; 0 ndos; 0 kdos; 0 ldos; 0 idos; 0 cdos; 0 inds; 0 locs; 0 cpls\n",
      "\t\tAND 166 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 5725 clauses with flowchart\n",
      "action     notes: 516\n",
      "valence    notes: 5725\n",
      "Total      notes: 6241\n",
      "All lexemes with flowchart specification\n",
      "     Status   good   : 5129 clauses\n",
      "     Status   warning:  516 clauses\n",
      "     Status   error  :   80 clauses\n",
      "     All status      : 5725 clauses\n",
      "     Sense    --     : 1218 clauses\n",
      "     Sense    -c     :  107 clauses\n",
      "     Sense    -i     :  268 clauses\n",
      "     Sense    -p     :  213 clauses\n",
      "     Sense    d-     : 2070 clauses\n",
      "     Sense    dc     :  212 clauses\n",
      "     Sense    di     :  405 clauses\n",
      "     Sense    dp     :  699 clauses\n",
      "     Sense    n.     :  521 clauses\n",
      "     Sense    c.     :   12 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      : 5725 clauses\n",
      " \n",
      "<FH\n",
      "     Status   good   : 2344 clauses\n",
      "     Status   warning:  121 clauses\n",
      "     Status   error  :    3 clauses\n",
      "     All status      : 2468 clauses\n",
      "     Sense    --     :  916 clauses\n",
      "     Sense    -c     :    4 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -p     :   49 clauses\n",
      "     Sense    d-     : 1301 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    1 clauses\n",
      "     Sense    dp     :   67 clauses\n",
      "     Sense    n.     :  127 clauses\n",
      "     Sense    c.     :    3 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      : 2468 clauses\n",
      " \n",
      "BR>\n",
      "     Status   warning:    3 clauses\n",
      "     Status   good   :   29 clauses\n",
      "     Status   error  :    4 clauses\n",
      "     All status      :   36 clauses\n",
      "     Sense    --     :    4 clauses\n",
      "     Sense    -c     :    0 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -p     :    0 clauses\n",
      "     Sense    d-     :   24 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    0 clauses\n",
      "     Sense    dp     :    3 clauses\n",
      "     Sense    n.     :    5 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :   36 clauses\n",
      " \n",
      "CJT\n",
      "     Status   good   :   56 clauses\n",
      "     Status   warning:   20 clauses\n",
      "     Status   error  :    6 clauses\n",
      "     All status      :   82 clauses\n",
      "     Sense    --     :    3 clauses\n",
      "     Sense    -c     :    7 clauses\n",
      "     Sense    -i     :    1 clauses\n",
      "     Sense    -p     :    2 clauses\n",
      "     Sense    d-     :   24 clauses\n",
      "     Sense    dc     :   10 clauses\n",
      "     Sense    di     :    3 clauses\n",
      "     Sense    dp     :   20 clauses\n",
      "     Sense    n.     :   12 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :   82 clauses\n",
      " \n",
      "DBQ\n",
      "     All status      :    0 clauses\n",
      "     Sense    --     :    0 clauses\n",
      "     Sense    -c     :    0 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -p     :    0 clauses\n",
      "     Sense    d-     :    0 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    0 clauses\n",
      "     Sense    dp     :    0 clauses\n",
      "     Sense    n.     :    0 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :    0 clauses\n",
      " \n",
      "FJM\n",
      "     Status   good   :  492 clauses\n",
      "     Status   warning:   82 clauses\n",
      "     Status   error  :    3 clauses\n",
      "     All status      :  577 clauses\n",
      "     Sense    --     :   11 clauses\n",
      "     Sense    -c     :   22 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -p     :   39 clauses\n",
      "     Sense    d-     :   62 clauses\n",
      "     Sense    dc     :   51 clauses\n",
      "     Sense    di     :    9 clauses\n",
      "     Sense    dp     :  194 clauses\n",
      "     Sense    n.     :  186 clauses\n",
      "     Sense    c.     :    3 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :  577 clauses\n",
      " \n",
      "NTN\n",
      "     Status   good   : 1651 clauses\n",
      "     Status   warning:  195 clauses\n",
      "     Status   error  :   64 clauses\n",
      "     All status      : 1910 clauses\n",
      "     Sense    --     :  134 clauses\n",
      "     Sense    -c     :   52 clauses\n",
      "     Sense    -i     :  158 clauses\n",
      "     Sense    -p     :   58 clauses\n",
      "     Sense    d-     :  524 clauses\n",
      "     Sense    dc     :  143 clauses\n",
      "     Sense    di     :  354 clauses\n",
      "     Sense    dp     :  388 clauses\n",
      "     Sense    n.     :   93 clauses\n",
      "     Sense    c.     :    6 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      : 1910 clauses\n",
      " \n",
      "QR>\n",
      "     Status   good   :  557 clauses\n",
      "     Status   warning:   95 clauses\n",
      "     All status      :  652 clauses\n",
      "     Sense    --     :  150 clauses\n",
      "     Sense    -c     :   22 clauses\n",
      "     Sense    -i     :  109 clauses\n",
      "     Sense    -p     :   65 clauses\n",
      "     Sense    d-     :  135 clauses\n",
      "     Sense    dc     :    8 clauses\n",
      "     Sense    di     :   38 clauses\n",
      "     Sense    dp     :   27 clauses\n",
      "     Sense    n.     :   98 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :  652 clauses\n",
      " \n",
      "ZQN\n",
      "     All status      :    0 clauses\n",
      "     Sense    --     :    0 clauses\n",
      "     Sense    -c     :    0 clauses\n",
      "     Sense    -i     :    0 clauses\n",
      "     Sense    -p     :    0 clauses\n",
      "     Sense    d-     :    0 clauses\n",
      "     Sense    dc     :    0 clauses\n",
      "     Sense    di     :    0 clauses\n",
      "     Sense    dp     :    0 clauses\n",
      "     Sense    n.     :    0 clauses\n",
      "     Sense    c.     :    0 clauses\n",
      "     Sense    l.     :    0 clauses\n",
      "     Sense    k.     :    0 clauses\n",
      "     Sense    i.     :    0 clauses\n",
      "     All senses      :    0 clauses\n",
      " \n"
     ]
    }
   ],
   "source": [
    "msg('Applying the flowchart')\n",
    "\n",
    "outcome_sta = collections.Counter()\n",
    "outcome_lab = collections.Counter()\n",
    "outcome_sta_l = collections.defaultdict(lambda: collections.Counter())\n",
    "outcome_lab_l = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "# we want an overview of the flowchart decisions per lexeme\n",
    "# Per lexeme, per sense_label we store the clauses\n",
    "\n",
    "decisions = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
    "\n",
    "of = open('{}/{}'.format(result_dir, 'valence_results.csv'), 'w')\n",
    "ofs = open('{}/{}'.format(result_dir, 'valence_notes.csv'), 'w')\n",
    "of.write('{}\\n'.format(';'.join(fields)))\n",
    "ofs.write('{}\\n'.format('\\t'.join(sfields)))\n",
    "\n",
    "note_keyword_base = 'valence'\n",
    "\n",
    "nnotes = collections.Counter()\n",
    "\n",
    "for lex in verb_clause:\n",
    "    if lex not in senses:\n",
    "        msg('No flowchart definition for verb {}'.format(lex))\n",
    "for lex in senses:\n",
    "    this_of = open('{}/{}.csv'.format(result_v_dir, lex), 'w')\n",
    "    if lex not in verb_clause:\n",
    "        msg('No verb {} in enriched corpus'.format(lex))\n",
    "        continue\n",
    "    for (c,v) in verb_clause[lex]:\n",
    "        if F.vs.v(v) not in verbal_stems: continue\n",
    "    \n",
    "        book = F.book.v(L.u('book', v))\n",
    "        chapter = F.chapter.v(L.u('chapter', v))\n",
    "        verse = F.verse.v(L.u('verse', v))\n",
    "        sentence_n = F.number.v(L.u('sentence', v))\n",
    "        clause_n = F.number.v(c)\n",
    "        clause_atom_n = F.number.v(L.u('clause_atom', v))\n",
    "        \n",
    "        verb = [L.u('phrase', v)]\n",
    "        consts = constituents[c]\n",
    "        n_ = collections.defaultdict(lambda: 0)\n",
    "        for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "        \n",
    "        (sense_label, status, sense_txt, action_txt, action_stat) = flowchart(v, lex, verb, consts)\n",
    "        \n",
    "        outcome_sta[status] += 1\n",
    "        outcome_sta_l[lex][status] += 1\n",
    "        outcome_lab[sense_label] += 1\n",
    "        outcome_lab_l[lex][sense_label] += 1\n",
    "        decisions[lex][sense_label][c] = '{} :: {}'.format(sense_txt, action_txt)\n",
    "        text = reptext('', L.d('phrase', c), num=True, txt=True)\n",
    "\n",
    "        txt = fields_fmt.format(\n",
    "            book,\n",
    "            chapter,\n",
    "            verse,\n",
    "            sentence_n,\n",
    "            clause_n,\n",
    "            '\"'+lex+'\"',\n",
    "            stat_rep[status],\n",
    "            '\"<'+sense_label+'>\"',\n",
    "            '\"'+sense_txt+'\"',\n",
    "            action_stat,\n",
    "            '\"'+action_txt+'\"',\n",
    "            *(n_[ckind] for ckind in ckinds),\n",
    "            '\"'+text+'\"',\n",
    "        )\n",
    "        of.write(txt)\n",
    "        this_of.write(txt)\n",
    "        ofs.write(sfields_fmt.format(\n",
    "            version,\n",
    "            book,\n",
    "            chapter,\n",
    "            verse,\n",
    "            clause_atom_n,\n",
    "            'T',\n",
    "            '',\n",
    "            status,\n",
    "            note_keyword_base+(' val_{}'.format(stat_rep[status]) if status != '!' else ''),\n",
    "            '_{sl}_ [{nm}|{vb}] {st}'.format(\n",
    "                nm=F.number.v(L.u('phrase', v)),\n",
    "                vb=F.g_word_utf8.v(v),\n",
    "                st=sense_txt,\n",
    "                sl=sense_label,\n",
    "            ),\n",
    "        ))\n",
    "        nnotes[note_keyword_base] += 1\n",
    "        if action_txt != '':\n",
    "            ofs.write(sfields_fmt.format(\n",
    "                version,\n",
    "                book,\n",
    "                chapter,\n",
    "                verse,\n",
    "                clause_atom_n,\n",
    "                'T',\n",
    "                '',\n",
    "                action_stat,\n",
    "                note_keyword_base+(' val_{}'.format(stat_rep[status]) if status != '!' else ''),\n",
    "                action_txt,\n",
    "            ))\n",
    "            nnotes['action'] += 1\n",
    "    this_of.close()\n",
    "            \n",
    "of.close()\n",
    "ofs.close()\n",
    "msg('Done')\n",
    "\n",
    "show_limit = 20\n",
    "for lex in debug_messages:\n",
    "    msg(lex, withtime=False)\n",
    "    for kind in debug_messages[lex]:\n",
    "        msg('\\t{}'.format(kind), withtime=False)\n",
    "        messages = debug_messages[lex][kind]\n",
    "        lm = len(messages)\n",
    "        msg('\\t\\t{}{}'.format(\n",
    "            '\\n\\t\\t'.join(messages[0:show_limit]),\n",
    "            '' if lm <= show_limit else '\\n\\t\\tAND {} more'.format(lm-show_limit),\n",
    "        ), withtime=False)\n",
    "\n",
    "inf('Computed {} clauses with flowchart'.format(sum(outcome_sta.values())), withtime=False)\n",
    "ntot = 0\n",
    "for (lab, n) in sorted(nnotes.items(), key=lambda x: x[0]):\n",
    "    ntot += n\n",
    "    print('{:<10} notes: {}'.format(lab, n))\n",
    "print('{:<10} notes: {}'.format('Total', ntot))\n",
    "\n",
    "for lex in [''] + sorted(senses):\n",
    "    print('All lexemes with flowchart specification' if lex == '' else lex)\n",
    "    src_sta = outcome_sta if lex == '' else outcome_sta_l.get(lex, collections.defaultdict(lambda: 0))\n",
    "    src_lab = outcome_lab if lex == '' else outcome_lab_l.get(lex, collections.defaultdict(lambda: 0))\n",
    "    tot = 0\n",
    "    for (x, n) in src_sta.items():\n",
    "        tot += n\n",
    "        print('     Status   {:<7}: {:>4} clauses'.format(status_rep[x], n))\n",
    "    print('     All status      : {:>4} clauses'.format(tot))\n",
    "    tot = 0\n",
    "    for x in slabels:\n",
    "        n = src_lab[x]\n",
    "        tot += n\n",
    "        print('     Sense    {:<7}: {:>4} clauses'.format(x, n))\n",
    "    print('     All senses      : {:>4} clauses'.format(tot))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_decision(verbs, labels): # show all clauses that have a verb in verbs and a sense label in labels\n",
    "    for verb in decisions:\n",
    "        if verb not in verbs: continue\n",
    "        for label in decisions[verb]:\n",
    "            if label not in labels: continue\n",
    "            for (c, stxt) in sorted(decisions[verb][label].items()):\n",
    "                sentence_words = L.d('word', L.u('sentence', c))\n",
    "                print('{:<7} {:<12} {:<5} {:<2} {}\\n\\t{}\\n\\t{}\\n'.format(\n",
    "                    c,\n",
    "                    T.passage(c),\n",
    "                    verb,\n",
    "                    label,\n",
    "                    stxt,\n",
    "                    T.words(sentence_words, fmt='ec'),\n",
    "                    ' '.join(F.gloss.v(w) for w in sentence_words),\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435546  Exodus 28:37 FJM   dc make [3|&~him] (to be) [4|upon cord purple wool] :: [4|upon cord purple wool] taken as extra direct object besides [3|&~him]\n",
      "\tW#MT >TW <L&PTJL TKLT \n",
      "\tand put <object marker> upon cord purple wool\n",
      "\n",
      "448816  Joshua 10:24 FJM   dc make [2|& foot~you:mm] (to be) [3|upon neck the king the these] :: [3|upon neck the king the these] taken as extra direct object besides [2|& foot~you:mm]\n",
      "\t#JMW >T&RGLJKM <L&YW>RJ HMLKJM H>LH \n",
      "\tput <object marker> foot upon neck the king the these\n",
      "\n",
      "448818  Joshua 10:24 FJM   dc make [3|& foot~them:mm] (to be) [4|upon neck~them:mm] :: [4|upon neck~them:mm] taken as extra direct object besides [3|& foot~them:mm]\n",
      "\tWJ#JMW >T&RGLJHM <L&YW>RJHM00\n",
      "\n",
      "\tand put <object marker> foot upon neck\n",
      "\n",
      "448837  Joshua 10:27 FJM   dc make [3|stone great] (to be) [4|upon mouth the cave] :: [4|upon mouth the cave] taken as extra direct object besides [3|stone great]\n",
      "\tWJ#MW >BNJM GDLWT <L&PJ HM<RH <D&<YM HJWM HZH00\n",
      "\n",
      "\tand put stone great upon mouth the cave unto bone the day the this\n",
      "\n",
      "449937  Joshua 24:7  FJM   dc make [3|darkness] (to be) [4|interval~you:mm and interval the Egyptian] :: [4|interval~you:mm and interval the Egyptian] taken as extra direct object besides [3|darkness]\n",
      "\tWJ#M M>PL BJNJKM WBJN HMYRJM \n",
      "\tand put darkness interval and interval the Egyptian\n",
      "\n",
      "451492  Judges 11:11 FJM   dc make [4|&~him] (to be) [5|upon~them:mm] [6|to head and to chief] :: [5|upon~them:mm] [6|to head and to chief] taken as extra direct object besides [4|&~him]\n",
      "\tWJ#JMW H<M >WTW <LJHM LR># WLQYJN \n",
      "\tand put the people <object marker> upon to head and to chief\n",
      "\n",
      "452363  Judges 18:19 FJM   dc make [2|hand~you:m] (to be) [3|upon mouth~you:m] :: [3|upon mouth~you:m] taken as extra direct object besides [2|hand~you:m]\n",
      "\t#JM&JDK <L&PJK \n",
      "\tput hand upon mouth\n",
      "\n",
      "453531  1_Samuel 6:11 FJM   dc make [3|& ark YHWH and & the saddle-bag and & jerboa the gold and & image tumours~them:mm] (to be) [4|to the chariot] :: [4|to the chariot] taken as extra direct object besides [3|& ark YHWH and & the saddle-bag and & jerboa the gold and & image tumours~them:mm]\n",
      "\tWJ#MW >T&>RWN JHWH >L&H<GLH W>T H>RGZ W>T <KBRJ HZHB W>T YLMJ VXRJHM00\n",
      "\n",
      "\tand put <object marker> ark YHWH to the chariot and <object marker> the saddle-bag and <object marker> jerboa the gold and <object marker> image tumours\n",
      "\n",
      "453867  1_Samuel 9:23 FJM   dc make [2|&~her] (to be) [3|with~you:m] :: [3|with~you:m] taken as extra direct object besides [2|&~her]\n",
      "\t#JM >TH <MK00\n",
      "\n",
      "\tput <object marker> with\n",
      "\n",
      "453999  1_Samuel 10:19 FJM   dc make [2|king] (to be) [4|upon~us] :: [4|upon~us] taken as extra direct object besides [2|king]\n",
      "\tKJ&MLK T#JM <LJNW \n",
      "\tthat king put upon\n",
      "\n",
      "455167  1_Samuel 18:5 FJM   dc make [2|put~him] (to be) [4|upon man the war] :: [4|upon man the war] taken as extra direct object besides [2|put~him]\n",
      "\tWJ#MHW #>WL <L >N#J HMLXMH \n",
      "\tand put Saul upon man the war\n",
      "\n",
      "458324  2_Samuel 13:19 FJM   dc make [3|hand~her] (to be) [4|upon head~her] :: [4|upon head~her] taken as extra direct object besides [3|hand~her]\n",
      "\tWT#M JDH <L&R>#H \n",
      "\tand put hand upon head\n",
      "\n",
      "458401  2_Samuel 13:33 FJM   dc make [5|word] (to be) [4|to heart~him] :: [4|to heart~him] taken as extra direct object besides [5|word]\n",
      "\t>L&J#M >DNJ HMLK >L&LBW DBR L>MR \n",
      "\tnot put lord the king to heart word to say\n",
      "\n",
      "458469  2_Samuel 14:7 FJM   dc make [3|name and rest] (to be) [4|upon face the soil] :: [4|upon face the soil] taken as extra direct object besides [3|name and rest]\n",
      "\tWKBW >T&GXLTJ >#R N#>RH LBLTJ #JM&L>J#J #M W#>RJT <L&PNJ H>DMH00\n",
      "\n",
      "\tand go out <object marker> glow <relative> remain to failure put to man name and rest upon face the soil\n",
      "\n",
      "459065  2_Samuel 18:1 FJM   dc make [4|chief thousand and chief hundred] (to be) [3|upon~them:mm] :: [3|upon~them:mm] taken as extra direct object besides [4|chief thousand and chief hundred]\n",
      "\tWJ#M <LJHM #RJ >LPJM W#RJ M>WT00\n",
      "\n",
      "\tand put upon chief thousand and chief hundred\n",
      "\n",
      "460387  1_Kings 2:15 FJM   dc make [5|face~them:mm] (to be) [2|upon~me] :: [2|upon~me] taken as extra direct object besides [5|face~them:mm]\n",
      "\t>T JD<T KJ&LJ HJTH HMLWKH W<LJ #MW KL&J#R>L PNJHM LMLK \n",
      "\tyou know that to be the kingship and upon put whole Israel face to be king\n",
      "\n",
      "462889  1_Kings 18:42 FJM   dc make [3|face~him] (to be) [4|interval knee~him] :: [4|interval knee~him] taken as extra direct object besides [3|face~him]\n",
      "\tWJ#M PNJW BJN BRKJW00\n",
      "\n",
      "\tand put face interval knee\n",
      "\n",
      "463442  1_Kings 21:27 FJM   dc make [3|sack] (to be) [4|upon flesh~him] :: [4|upon flesh~him] taken as extra direct object besides [3|sack]\n",
      "\tWJ#M&#Q <L&B#RW \n",
      "\tand put sack upon flesh\n",
      "\n",
      "464246  2_Kings 4:29 FJM   dc make [3|support~me] (to be) [4|upon face the boy] :: [4|upon face the boy] taken as extra direct object besides [3|support~me]\n",
      "\tW#MT M#<NTJ <L&PNJ HN<R00\n",
      "\n",
      "\tand put support upon face the boy\n",
      "\n",
      "464254  2_Kings 4:31 FJM   dc make [3|& the support] (to be) [4|upon face the boy] :: [4|upon face the boy] taken as extra direct object besides [3|& the support]\n",
      "\tWJ#M >T&HM#<NT <L&PNJ HN<R \n",
      "\tand put <object marker> the support upon face the boy\n",
      "\n",
      "464270  2_Kings 4:34 FJM   dc make [3|mouth~him] (to be) [4|upon mouth~him] :: [4|upon mouth~him] taken as extra direct object besides [3|mouth~him]\n",
      "\tWJ#M PJW <L&PJW W<JNJW <L&<JNJW WKPJW <L&KPJW \n",
      "\tand put mouth upon mouth and eye upon eye and palm upon palm\n",
      "\n",
      "465611  2_Kings 13:16 FJM   dc make [4|hand~him] (to be) [5|upon hand the king] :: [5|upon hand the king] taken as extra direct object besides [4|hand~him]\n",
      "\tWJ#M >LJ#< JDJW <L&JDJ HMLK00\n",
      "\n",
      "\tand put Elisha hand upon hand the king\n",
      "\n",
      "466183  2_Kings 18:14 FJM   dc make [5|three hundred disk silver and three disk gold] (to be) [4|upon Hizkiah king Judah] :: [4|upon Hizkiah king Judah] taken as extra direct object besides [5|three hundred disk silver and three disk gold]\n",
      "\tWJ#M MLK&>#WR <L&XZQJH MLK&JHWDH #L# M>WT KKR&KSP W#L#JM KKR ZHB00\n",
      "\n",
      "\tand put king Asshur upon Hizkiah king Judah three hundred disk silver and three disk gold\n",
      "\n",
      "471072  Isaiah 47:7  FJM   dc make [4|these] (to be) [5|upon heart~you:f] :: [5|upon heart~you:f] taken as extra direct object besides [4|these]\n",
      "\t<D L>&#MT >LH <L&LBK \n",
      "\tunto not put these upon heart\n",
      "\n",
      "474261  Jeremiah 13:1 FJM   dc make [2|put~him] (to be) [3|upon hips~you:m] :: [3|upon hips~you:m] taken as extra direct object besides [2|put~him]\n",
      "\tW#MTW <L&MTNJK \n",
      "\tand put upon hips\n",
      "\n",
      "475497  Jeremiah 24:6 FJM   dc make [3|eye~me] (to be) [4|upon~them:mm] :: [4|upon~them:mm] taken as extra direct object besides [3|eye~me]\n",
      "\tW#MTJ <JNJ <LJHM LVWBH \n",
      "\tand put eye upon to what is good\n",
      "\n",
      "477236  Jeremiah 39:12 FJM   dc make [2|eye~you:m] (to be) [4|upon~him] :: [4|upon~him] taken as extra direct object besides [2|eye~you:m]\n",
      "\tW<JNJK #JM <LJW \n",
      "\tand eye put upon\n",
      "\n",
      "477286  Jeremiah 40:4 FJM   dc make [3|& eye~me] (to be) [4|upon~you:m] :: [4|upon~you:m] taken as extra direct object besides [3|& eye~me]\n",
      "\tW>#JM >T&<JNJ <LJK \n",
      "\tand put <object marker> eye upon\n",
      "\n",
      "477588  Jeremiah 43:10 FJM   dc make [3|seat~him] (to be) [4|from top to the stone the these] :: [4|from top to the stone the these] taken as extra direct object besides [3|seat~him]\n",
      "\tW#MTJ KS>W MM<L L>BNJM H>LH >#R VMNTJ \n",
      "\tand put seat from top to the stone the these <relative> hide\n",
      "\n",
      "479236  Ezekiel 4:4  FJM   dc make [3|& sin house Israel] (to be) [4|upon~him] :: [4|upon~him] taken as extra direct object besides [3|& sin house Israel]\n",
      "\tW#MT >T&<WN BJT&J#R>L <LJW \n",
      "\tand put <object marker> sin house Israel upon\n",
      "\n",
      "480182  Ezekiel 14:4 FJM   dc make [2|stumbling block sin~him] (to be) [4|straightness face~him] :: [4|straightness face~him] taken as extra direct object besides [2|stumbling block sin~him]\n",
      "\t>J# >J# MBJT J#R>L >#R J<LH >T&GLWLJW >L&LBW WMK#WL <WNW J#JM NKX PNJW \n",
      "\tman man from house Israel <relative> ascend <object marker> idols to heart and stumbling block sin put straightness face\n",
      "\n",
      "480197  Ezekiel 14:7 FJM   dc make [2|stumbling block sin~him] (to be) [4|straightness face~him] :: [4|straightness face~him] taken as extra direct object besides [2|stumbling block sin~him]\n",
      "\tKJ >J# >J# MBJT J#R>L WMHGR >#R&JGWR BJ#R>L WJNZR M>XRJ WJ<L GLWLJW >L&LBW WMK#WL <WNW J#JM NKX PNJW >NJ JHWH N<NH&LW BJ00\n",
      "\n",
      "\tthat man man from house Israel and from the sojourner <relative> dwell in Israel and dedicate from after and ascend idols to heart and stumbling block sin put straightness face i YHWH answer to in\n",
      "\n",
      "481595  Ezekiel 23:41 FJM   dc make [2|smoke of sacrifice~me and oil~me] (to be) [4|upon~her] :: [4|upon~her] taken as extra direct object besides [2|smoke of sacrifice~me and oil~me]\n",
      "\tWQVRTJ W#MNJ #MT <LJH00\n",
      "\n",
      "\tand smoke of sacrifice and oil put upon\n",
      "\n",
      "481651  Ezekiel 24:7 FJM   dc make [2|put~him] (to be) [1|upon surface rock] :: [1|upon surface rock] taken as extra direct object besides [2|put~him]\n",
      "\t<L&YXJX SL< #MTHW LH<LWT XMH LNQM NQM \n",
      "\tupon surface rock put to ascend heat to avenge vengeance\n",
      "\n",
      "486152  Amos 9:4     FJM   dc make [3|eye~me] (to be) [4|upon~them:mm] :: [4|upon~them:mm] taken as extra direct object besides [3|eye~me]\n",
      "\tW#MTJ <JNJ <LJHM LR<H WL> LVWBH00\n",
      "\n",
      "\tand put eye upon to evil and not to what is good\n",
      "\n",
      "486224  Obadiah 1:4  FJM   dc make [5|nest~you:m] (to be) [3|interval star] :: [3|interval star] taken as extra direct object besides [5|nest~you:m]\n",
      "\tW>M&BJN KWKBJM #JM QNK \n",
      "\tand if interval star put nest\n",
      "\n",
      "486778  Micah 4:14   FJM   dc make [1|siege] (to be) [3|upon~us] :: [3|upon~us] taken as extra direct object besides [1|siege]\n",
      "\tMYWR #M <LJNW \n",
      "\tsiege put upon\n",
      "\n",
      "486970  Micah 7:16   FJM   dc make [2|hand] (to be) [3|upon mouth] :: [3|upon mouth] taken as extra direct object besides [2|hand]\n",
      "\tJ#JMW JD <L&PH \n",
      "\tput hand upon mouth\n",
      "\n",
      "488036  Zechariah 3:5 FJM   dc make [2|turban pure] (to be) [3|upon head~him] :: [3|upon head~him] taken as extra direct object besides [2|turban pure]\n",
      "\tJ#JMW YNJP VHWR <L&R>#W \n",
      "\tput turban pure upon head\n",
      "\n",
      "488037  Zechariah 3:5 FJM   dc make [3|the turban the pure] (to be) [4|upon head~him] :: [4|upon head~him] taken as extra direct object besides [3|the turban the pure]\n",
      "\tWJ#JMW HYNJP HVHWR <L&R>#W \n",
      "\tand put the turban the pure upon head\n",
      "\n",
      "494688  Psalms 109:5 FJM   dc make [4|evil] (to be) [3|upon~me] :: [3|upon~me] taken as extra direct object besides [4|evil]\n",
      "\tWJ#JMW <LJ R<H TXT VWBH W#N>H TXT >HBTJ00\n",
      "\n",
      "\tand put upon evil under part what is good and hatred under part love\n",
      "\n",
      "496429  Job 1:8      FJM   dc make [3|heart~you:m] (to be) [4|upon servant~me Job] :: [4|upon servant~me Job] taken as extra direct object besides [3|heart~you:m]\n",
      "\tH#MT LBK <L&<BDJ >JWB \n",
      "\t<interrogative> put heart upon servant Job\n",
      "\n",
      "496515  Job 2:3      FJM   dc make [3|heart~you:m] (to be) [4|to servant~me Job] :: [4|to servant~me Job] taken as extra direct object besides [3|heart~you:m]\n",
      "\tH#MT LBK >L&<BDJ >JWB \n",
      "\t<interrogative> put heart to servant Job\n",
      "\n",
      "496718  Job 5:8      FJM   dc make [4|cause~me] (to be) [2|to god(s)] :: [2|to god(s)] taken as extra direct object besides [4|cause~me]\n",
      "\tW>L&>LHJM >#JM DBRTJ00\n",
      "<#H GDLWT W>JN XQR NPL>WT <D&>JN MSPR00\n",
      "HNTN MVR <L&PNJ&>RY W#LX MJM <L&PNJ XWYWT00\n",
      "L#WM #PLJM LMRWM WQDRJM #GBW J#<00\n",
      "MPR MX#BWT <RWMJM LKD XKMJM B<RMM \n",
      "\tand to god(s) put cause make great and <NEG> exploration be miraculous unto <NEG> number the give rain upon face earth and send water upon face outside to put low to high place and be dark be high help break thought shrewd seize wise in be cunning\n",
      "\n",
      "496888  Job 7:12     FJM   dc make [4|guard] (to be) [3|upon~me] :: [3|upon~me] taken as extra direct object besides [4|guard]\n",
      "\tKJ&T#JM <LJ M#MR00\n",
      "\n",
      "\tthat put upon guard\n",
      "\n",
      "497669  Job 19:8     FJM   dc make [3|darkness] (to be) [2|upon path~me] :: [2|upon path~me] taken as extra direct object besides [3|darkness]\n",
      "\tW<L NTJBWTJ X#K J#JM00\n",
      "\n",
      "\tand upon path darkness put\n",
      "\n",
      "497811  Job 21:5     FJM   dc make [3|hand] (to be) [4|upon mouth] :: [4|upon mouth] taken as extra direct object besides [3|hand]\n",
      "\tW#JMW JD <L&PH00\n",
      "\n",
      "\tand put hand upon mouth\n",
      "\n",
      "498726  Job 34:23    FJM   dc make [5|duration] (to be) [3|upon man] :: [3|upon man] taken as extra direct object besides [5|duration]\n",
      "\tKJ L> <L&>J# J#JM <WD LHLK >L&>L BM#PV00\n",
      "\n",
      "\tthat not upon man put duration to walk to god in the justice\n",
      "\n",
      "499145  Job 40:4     FJM   dc make [1|hand~me] (to be) [3|to mouth~me] :: [3|to mouth~me] taken as extra direct object besides [1|hand~me]\n",
      "\tJDJ #MTJ LMW&PJ00\n",
      "\n",
      "\thand put to mouth\n",
      "\n",
      "499209  Job 40:32    FJM   dc make [3|palm~you:m] (to be) [2|upon~him] :: [2|upon~him] taken as extra direct object besides [3|palm~you:m]\n",
      "\t#JM&<LJW KPK \n",
      "\tput upon palm\n",
      "\n",
      "501985  Ruth 3:3     FJM   dc make [3|mantle~you:f] (to be) [4|upon~you:f] :: [4|upon~you:f] taken as extra direct object besides [3|mantle~you:f]\n",
      "\tW#MT #MLTJK <LJK \n",
      "\tand put mantle upon\n",
      "\n",
      "502534  Song_of_songs 6:12 FJM   dc make [2|put~me] (to be) [3|chariot people willing] :: [3|chariot people willing] taken as extra direct object besides [2|put~me]\n",
      "\tNP#J #MTNJ MRKBWT <MJ&NDJB00\n",
      "\n",
      "\tsoul put chariot people willing\n",
      "\n",
      "504333  Esther 3:1   FJM   dc make [3|& seat~him] (to be) [4|from upon whole the chief] :: [4|from upon whole the chief] taken as extra direct object besides [3|& seat~him]\n",
      "\tWJ#M >T&KS>W M<L KL&H#RJM >#R >TW00\n",
      "\n",
      "\tand put <object marker> seat from upon whole the chief <relative> together with\n",
      "\n",
      "504926  Daniel 1:8   FJM   dc make [2|<relative> not pollute in table the king and in wine drinking~him] (to be) [4|upon heart~him] :: [4|upon heart~him] taken as extra direct object besides [2|<relative> not pollute in table the king and in wine drinking~him]\n",
      "\tWJ#M DNJ>L <L&LBW >#R L>&JTG>L BPTBG HMLK WBJJN M#TJW \n",
      "\tand put Daniel upon heart <relative> not pollute in table the king and in wine drinking\n",
      "\n",
      "509690  1_Chronicles 11:25 FJM   dc make [2|put~him] (to be) [4|upon subject~him] :: [4|upon subject~him] taken as extra direct object besides [2|put~him]\n",
      "\tWJ#JMHW DWJD <L&M#M<TW00\n",
      "\n",
      "\tand put David upon subject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_decision({'FJM'}, {'dc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
