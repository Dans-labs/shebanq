{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
    "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ketiv - Qere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.4\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from IPython.display import display, HTML, FileLinks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "from etcbc.lib import Transcription\n",
    "from etcbc.extra import ExtraData\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create annotations from px file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.01s DETAIL: load main: G.node_anchor_min\n",
      "  0.15s DETAIL: load main: G.node_anchor_max\n",
      "  0.28s DETAIL: load main: G.node_sort\n",
      "  0.41s DETAIL: load main: G.node_sort_inv\n",
      "  1.02s DETAIL: load main: G.edges_from\n",
      "  1.18s DETAIL: load main: G.edges_to\n",
      "  1.36s DETAIL: load main: F.etcbc4_db_otype [node] \n",
      "  2.58s DETAIL: load main: F.etcbc4_ft_g_cons [node] \n",
      "  2.86s DETAIL: load main: F.etcbc4_ft_g_word [node] \n",
      "  3.22s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  3.25s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/ketivqere/__log__ketivqere.txt\n",
      "  3.25s DETAIL: prep prep: G.node_sort\n",
      "  3.38s DETAIL: prep prep: G.node_sort_inv\n",
      "  4.06s DETAIL: prep prep: L.node_up\n",
      "  8.65s DETAIL: prep prep: L.node_down\n",
      "    16s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: load main: F.etcbc4_ft_number [node] \n",
      "  0.80s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  0.82s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  0.84s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  0.86s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK ketivqere AT 2015-09-30T06-38-10\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK ketivqere AT 2015-09-30T06-38-10\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "etcbc_source = 'etcbc{}'.format(version)\n",
    "API=fabric.load(etcbc_source, '--', 'ketivqere', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype label\n",
    "        g_word g_cons\n",
    "    ''',\n",
    "    '''\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a verse index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2.62s Making mappings between verse labels in KQ and verse nodes in LAF\n",
      "  4.32s 23213 verses\n"
     ]
    }
   ],
   "source": [
    "msg(\"Making mappings between verse labels in KQ and verse nodes in LAF\")\n",
    "vlab2vnode = {}\n",
    "for vs in F.otype.s('verse'):\n",
    "    lab = F.label.v(vs)\n",
    "    vlab2vnode[lab] = vs\n",
    "msg(\"{} verses\".format(len(vlab2vnode)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to read kq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_kq(kq_file):\n",
    "    msg(\"Reading Ketiv-Qere data\")\n",
    "\n",
    "    info = collections.defaultdict(lambda: [])\n",
    "    not_found = set()\n",
    "    missing = collections.defaultdict(lambda: [])\n",
    "    missed = collections.defaultdict(lambda: [])\n",
    "\n",
    "    error_limit = 10\n",
    "\n",
    "    kq_handle = open(kq_file)\n",
    "\n",
    "    ln = 0\n",
    "    can = 0\n",
    "    cur_label = None\n",
    "    for line in kq_handle:\n",
    "        ln += 1\n",
    "        can += 1\n",
    "        vlab = line[0:10]\n",
    "        fields = line.rstrip('\\n')[10:].split()\n",
    "        (ketiv, qere) = fields[0:2]\n",
    "        (qtrim, qtrailer) = Transcription.suffix_and_finales(qere)\n",
    "        vnode = vlab2vnode.get(vlab, None)\n",
    "        if vnode == None:\n",
    "            not_found.add(vlab)\n",
    "            continue\n",
    "        info[vnode].append((ketiv, qtrim, qtrailer))        \n",
    "    kq_handle.close()\n",
    "    msg(\"Read {} ketiv-qere annotations\".format(ln))\n",
    "\n",
    "    data = []\n",
    "    for vnode in info:\n",
    "        wlookup = collections.defaultdict(lambda: [])\n",
    "        wvisited = collections.defaultdict(lambda: -1)\n",
    "        wnodes = L.d('word', vnode)\n",
    "        for w in wnodes:\n",
    "            gw = F.g_word.v(w)\n",
    "            if '*' in gw:\n",
    "                gw = F.g_cons.v(w)\n",
    "                if gw == '': gw = '.'\n",
    "                wlookup[gw].append(w)\n",
    "        for (ketiv, qere, qtrailer) in info[vnode]:\n",
    "            wvisited[ketiv] += 1\n",
    "            windex = wvisited[ketiv]\n",
    "            ws = wlookup.get(ketiv, None)\n",
    "            if ws == None or windex > len(ws) - 1:\n",
    "                missing[vnode].append((windex, ketiv, qere))\n",
    "                continue\n",
    "            w = ws[windex]\n",
    "            data.append((w, ketiv, qere, qtrailer))\n",
    "        for ketiv in wlookup:\n",
    "            if ketiv not in wvisited or len(wlookup[ketiv]) - 1 > wvisited[ketiv]:\n",
    "                missed[vnode].append((len(wlookup[ketiv]) - (wvisited.get(ketiv, -1) + 1), ketiv))\n",
    "    msg(\"Parsed {} ketiv-qere annotations\".format(len(data)))\n",
    "\n",
    "    if not_found:\n",
    "        msg(\"Could not find {} verses: {}\".format(len(not_found), sorted(not_found)))\n",
    "    else:\n",
    "        msg(\"All verses entries found in index\")\n",
    "    if missing:\n",
    "        msg(\"Could not locate ketivs in the text: {} verses\".format(len(missing)))\n",
    "        e = 0\n",
    "        for vnode in sorted(missing):\n",
    "            if e > error_limit: break\n",
    "            vlab = F.label.v(vnode)\n",
    "            for (windex, ketiv, qere) in missing[vnode]:\n",
    "                e += 1\n",
    "                if e > error_limit: break\n",
    "                print('NOT IN TEXT: {:<10} {:<20} #{} {}'.format(vlab, ketiv, windex, qere))\n",
    "    else:\n",
    "        msg(\"All ketivs found in the text\")\n",
    "    if missed:\n",
    "        msg(\"Could not lookup qeres in the data: {} verses\".format(len(missing)))\n",
    "        e = 0\n",
    "        for vnode in sorted(missed):\n",
    "            if e > error_limit: break\n",
    "            vlab = F.label.v(vnode)\n",
    "            for (windex, ketiv) in missed[vnode]:\n",
    "                e += 1\n",
    "                if e > error_limit: break\n",
    "                print('NOT IN DATA: {:<10} {:<20} #{}'.format(vlab, ketiv, windex))\n",
    "    else:\n",
    "        msg(\"All ketivs found in the data\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the kq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9.41s Reading Ketiv-Qere data\n",
      "  9.45s Read 1892 ketiv-qere annotations\n",
      "  9.51s Parsed 1892 ketiv-qere annotations\n",
      "  9.51s All verses entries found in index\n",
      "  9.52s All ketivs found in the text\n",
      "  9.52s All ketivs found in the data\n"
     ]
    }
   ],
   "source": [
    "infile_name = '{}/{}/{}.{}'.format(API['data_dir'], 'kq', 'kq', etcbc_source)\n",
    "data = read_kq(infile_name)\n",
    "outf = outfile('kq.tsv')\n",
    "for (w, ketiv, qere, qtrailer) in sorted(data):\n",
    "    outf.write('{}\\t{}\\t{}\\t{}\\n'.format(str(w), ketiv, qere, qtrailer.replace('\\n', '\\\\n')))\n",
    "outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kq = ExtraData(API)\n",
    "kq.deliver_annots('kq/kq.{}'.format(etcbc_source), 'lexicon', 'kq', read_kq, (\n",
    "        ('etcbc4', 'kq', 'qere'),\n",
    "        ('etcbc4', 'px', 'qtrailer'),\n",
    "    ),\n",
    "    {'title': 'Ketiv Qere', 'date': '2015'},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
