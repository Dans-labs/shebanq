{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQL testing\n",
    "\n",
    "This notebook is for performance testing of MQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "MQL queries are performed by the Emdros software, which is written in C++.\n",
    "\n",
    "We use the Python bindings (SWIG) to steer the Emdros engine.\n",
    "\n",
    "These Python bindings need Python2.\n",
    "\n",
    "In order to have a Python2 kernel in Jupyter under an Anaconda installation that is based on Python3, I had to perform the following sequence:\n",
    "\n",
    "    conda create -n py27 python=2.7\n",
    "    source activate py27\n",
    "    conda install notebook ipykernel\n",
    "    sudo ipython kernel install\n",
    "    source deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem queries\n",
    "\n",
    "MQL queries may easily deliver billions of results. \n",
    "Usually, it is not the intention of the user to get that many results.\n",
    "Most of the time, it is caused by limited experience with the MQL language.\n",
    "\n",
    "Here is an example query (see also \n",
    "[this query on SHEBANQ](https://shebanq.ancient-data.org/hebrew/query?version=4b&id=1119)\n",
    "):\n",
    "\n",
    "    select all objects where\n",
    "        [word focus lex = 'R>CJT/']\n",
    "        ..\n",
    "        [word]\n",
    "        ..\n",
    "        [word lex = 'BR>[']\n",
    "\n",
    "The problem is that every combination of three words in the 425000 words in the Bible of which the first and third meet the indicated requirements counts as a result.\n",
    "So, if we have say 10 candidates for the first word in Genesis, and 10 candidates for the second in Chronicles, then we have 100 combinations. And every such combination has at least 300000 words in between, so we get 30 million results.\n",
    "\n",
    "This kind of problem can be remedied by putting the word blocks in a container, e.g.\n",
    "\n",
    "    select all objects where\n",
    "        [chapter\n",
    "            [word focus lex = 'R>CJT/']\n",
    "            ..\n",
    "            [word]\n",
    "            ..\n",
    "            [word lex = 'BR>[']\n",
    "        ]\n",
    "        \n",
    "and most of the time this corresponds better with the intention of the query writer.\n",
    "Instead of a wild multiplication of search results, we have a more or less linear behaviour of the amount of search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance testing\n",
    "\n",
    "We are going to conduct several experiments with the \"bad\" query above, just to collect some statistics.\n",
    "\n",
    "The resulting insights have been applied in the ``mql.py`` module in the SHEBANQ web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, time, collections\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from operator import add\n",
    "\n",
    "sys.path.append('/opt/emdros/lib/emdros')\n",
    "sys.path.append('/Users/dirk/SURFdrive/current/demos/github/shebanq/modules')\n",
    "import EmdrosPy\n",
    "from get_db_config import config, emdros_versions\n",
    "\n",
    "db='shebanq_etcbc'\n",
    "\n",
    "OLD_EMDROS_VERSIONS = set(emdros_versions[0:-1])\n",
    "EMDROS_VERSION = emdros_versions[-1]\n",
    "\n",
    "timestamp = None\n",
    "\n",
    "def _reset():\n",
    "    global timestamp\n",
    "    timestamp = time.time()\n",
    "\n",
    "def _elapsed():\n",
    "    interval = time.time() - timestamp\n",
    "    if interval < 10: return \"{: 2.2f}s\".format(interval)\n",
    "    interval = int(round(interval))\n",
    "    if interval < 60: return \"{:>2d}s\".format(interval)\n",
    "    if interval < 3600: return \"{:>2d}m {:>02d}s\".format(interval // 60, interval % 60)\n",
    "    return \"{:>2d}h {:>02d}m {:>02d}s\".format(interval // 3600, (interval % 3600) // 60, interval % 60)\n",
    "\n",
    "def msg(msg, newline=True, withtime=True):\n",
    "    timed_msg = \"{:>7} \".format(_elapsed()) if withtime else ''\n",
    "    timed_msg += msg\n",
    "    if newline: timed_msg += \"\\n\"\n",
    "    sys.stderr.write(timed_msg)\n",
    "    sys.stderr.flush()\n",
    "\n",
    "def Msg(txt, newline=True, withtime=True):\n",
    "    _reset()\n",
    "    msg(txt, newline=newline, withtime=withtime)\n",
    "\n",
    "def sanitize(query, msgs):\n",
    "    comps = query.split('/*')\n",
    "    lastcomp = comps[-1]\n",
    "    if len(comps) > 1 and lastcomp.find('*/') == -1:\n",
    "        result = query + '*/'\n",
    "    else:\n",
    "        result = query\n",
    "    if 'focus' not in query.lower():\n",
    "        msgs.append(('note', 'no FOCUS in your query!'))\n",
    "    return result + \"\\nGO\\n\"\n",
    "\n",
    "def to_monadsets(setstr):\n",
    "    elems = setstr[2:-2].strip()\n",
    "    if elems == '': return []\n",
    "    comps = elems.split(',')\n",
    "    return [[int(y) for y in x.lstrip().split('-')] if '-' in x else [int(x), int(x)] for x in comps]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test queries\n",
    "\n",
    "We will test with the above \"bad\" query.\n",
    "We will also use test versions that restrict the results to certain initial stretches of the total text, say 100,000 words, 200,000 and 300,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_tpl = '''\n",
    "select all objects {} where\n",
    "    [word focus lex = 'R>CJT/']\n",
    "    ..\n",
    "    [word]\n",
    "    ..\n",
    "    [word lex = 'BR>[']\n",
    "'''\n",
    "\n",
    "queries = collections.OrderedDict((\n",
    "    ('r10', query_tpl.format('in {1-100000}')),\n",
    "    ('r20', query_tpl.format('in {1-200000}')),\n",
    "    ('r25', query_tpl.format('in {1-250000}')),\n",
    "    ('all', query_tpl.format('')),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQL results: the Sheaf\n",
    "\n",
    "The sheaf is a sophisticted data structure that stores the results of an MQL query.\n",
    "In general, the results of one and the same MQL query share a considerable amount of information. The sheaf fully utilizes and reflects this data sharing.\n",
    "\n",
    "The flip side is, that in order to get the concrete results, we have to recursively walk this data structure and construct results.\n",
    "\n",
    "Even when we start counting the results, we have to make this walk, and this can be rather costly.\n",
    "\n",
    "The sheaf is a C++ datastructure, delivered by the Emdros software.\n",
    "\n",
    "In our case, with this concrete problem query, the sheaf has ~130,000,000 results.\n",
    "It takes Emdros roughly 5 minutes to build it up. There is very little sql time involved, the bulk of the time is C processing.\n",
    "\n",
    "We hit a performance penalty when we use a scripting language to walk this structure.\n",
    "Even if we use fast and efficient Python constructs such as iterators and generators, it takes much more time than it took Emdros to create the sheaf.\n",
    "\n",
    "It turns out that it takes nearly half an hour to just count the number of results.\n",
    "\n",
    "That is a pity, since the delivering of the results that SHEBANQ needs, goes much faster.\n",
    "SHEBANQ does not need the list of results, but the set of monads that occur in a result.\n",
    "\n",
    "Emdros has an API function to deliver exactly this, so we can the big monad set with C speed. \n",
    "And this is never bigger than the set of all monads, which has a size of 425000.\n",
    "\n",
    "So the mere counting of results causes a 3 fold increase in waiting time.\n",
    "\n",
    "We have to do something about it.\n",
    "\n",
    "## Optimizing the Python code\n",
    "\n",
    "It turns out that using the generator idiom and not the for-loop-idiom does not help here.\n",
    "Problably the performance hit is in SWIG, which maps slick C++-data structures to Python data structures all the time. We cannot change that machinery.\n",
    "\n",
    "## Constraining the sheaf\n",
    "\n",
    "When we are counting, we can decide to stop counting as soon as we have reached a certain number of results. This will dramatically cut down the counting effort, at the expense of not being able to count the number of results of offending queries.\n",
    "\n",
    "We opt for a limit that is slightly larger than the number of words in the bible, and we hope that this will not constrain people. We believe that offending queries are mostly a result of unlucky attempts to formalize a problem into an MQL query.\n",
    "If that is true, it is better to be able to notify the user and not to waste valuable server time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITER_LIMIT = 500000\n",
    "\n",
    "class LimitError(Exception):\n",
    "    def __init__(self, message, cause=None):\n",
    "        Exception.__init__(self, message)\n",
    "\n",
    "def elements_of(xiter):\n",
    "    i = 0\n",
    "    while xiter.hasNext():\n",
    "        i += 1\n",
    "        if i > ITER_LIMIT:\n",
    "            raise LimitError('')\n",
    "            break\n",
    "        yield xiter.current()\n",
    "        xiter.next()\n",
    "        \n",
    "limits = (\n",
    "    100000,\n",
    "    500000,\n",
    "    1000000,\n",
    "    1000000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For loop idiom and Generator idiom\n",
    "\n",
    "In the for loop idiom we use straightforward code based on for loops.\n",
    "\n",
    "In the Generator idiom we use generators and the function ``reduce``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sheaf_results_f(sheaf):\n",
    "    sh_iter = sheaf.const_iterator()\n",
    "    n = 0\n",
    "    while sh_iter.hasNext():\n",
    "        straw = sh_iter.current()\n",
    "        n += straw_results_f(straw)\n",
    "        if n > ITER_LIMIT:\n",
    "            raise LimitError('')\n",
    "        sh_iter.next()\n",
    "    return n\n",
    "\n",
    "def straw_results_f(straw):\n",
    "    n = 1\n",
    "    st_iter = straw.const_iterator()\n",
    "    while st_iter.hasNext():\n",
    "        mo = st_iter.current()\n",
    "        if not mo.sheafIsEmpty():\n",
    "            sheaf = mo.getSheaf()\n",
    "            n *= sheaf_results_f(sheaf)\n",
    "            if n > ITER_LIMIT:\n",
    "                raise LimitError('')\n",
    "        st_iter.next()\n",
    "    return n\n",
    "\n",
    "def sheaf_results_g(sheaf):\n",
    "    try:\n",
    "        n = reduce(\n",
    "            lambda x,y: add(x, straw_results_g(y)), \n",
    "            elements_of(sheaf.const_iterator()), \n",
    "            0,\n",
    "        ) \n",
    "    except LimitError as e:\n",
    "        n = ITER_LIMIT\n",
    "        raise LimitError('')\n",
    "    return n\n",
    "\n",
    "def straw_results_g(straw):\n",
    "    try:\n",
    "        n = reduce(\n",
    "            lambda x,y: mul(x, sheaf_results_g(y.getSheaf()) if not y.sheafIsEmpty() else 1),\n",
    "            elements_of(straw.const_iterator()),\n",
    "            1,\n",
    "        ) \n",
    "    except LimitError as e:\n",
    "        n = ITER_LIMIT\n",
    "        raise LimitError('')\n",
    "    return n\n",
    "\n",
    "idioms = dict(\n",
    "    f=(sheaf_results_f, straw_results_f),\n",
    "    g=(sheaf_results_g, straw_results_g),\n",
    "\n",
    ")\n",
    "\n",
    "idiom_names = dict(\n",
    "    f='For',\n",
    "    g='Gen',\n",
    ")\n",
    "\n",
    "def set_idiom(i):\n",
    "    global sheaf_results\n",
    "    global straw_results\n",
    "    (sheaf_results, straw_results) = idioms[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common code\n",
    "\n",
    "Here is code used by both idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sheaf(vr, query):\n",
    "    env = EmdrosPy.EmdrosEnv(EmdrosPy.kOKConsole, EmdrosPy.kCSUTF8, config['shebanq_host'], config['shebanq_user'], config['shebanq_passwd'], db+vr, EmdrosPy.kMySQL)\n",
    "    compiler_result = False\n",
    "    msgs = []\n",
    "\n",
    "    msg('{:<10}: fetching the sheaf'.format('C++'))\n",
    "    good = env.executeString(sanitize(query, msgs) , compiler_result, False, False)[1]\n",
    "    sheaf = env.getSheaf() if good and env.isSheaf else None\n",
    "    msg('{:<10}: fetching done{}'.format('C++', ' NO SHEAF!' if sheaf == None else ''))\n",
    "    # we only need the sheaf, but if we do not return the env, it will be garbage collected\n",
    "    # and then we get a segmentation fault\n",
    "    return (env, sheaf)\n",
    "\n",
    "def get_ms(sheaf):                \n",
    "    msg('{:<10}: making monadsets'.format('Python'))\n",
    "    ms = to_monadsets(sheaf.getSOM(True).toString())\n",
    "    msg('{:<10}: returning {} monadsets'.format('Python', len(ms)))\n",
    "    return ms\n",
    "\n",
    "def get_n(sheaf):\n",
    "    msg('{:<10}: computing number of results'.format('SWIG'))\n",
    "    limit_exceeded = False\n",
    "    try:\n",
    "        n = sheaf_results(sheaf)\n",
    "    except LimitError as e:\n",
    "        n = ITER_LIMIT\n",
    "        limit_exceeded = True\n",
    "    msg('{:<10}: {} results{})'.format('SWIG', n, 'exceeded' if limit_exceeded else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Here we show the results of executing various options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_version = '4'\n",
    "\n",
    "def do_all():\n",
    "    global ITER_LIMIT\n",
    "    for q in queries:\n",
    "        Msg('QUERY {}'.format(q))\n",
    "        query = queries[q]\n",
    "        (env, sheaf) = get_sheaf(data_version, query)\n",
    "        if sheaf == None: continue\n",
    "        ms = get_ms(sheaf)\n",
    "        for lm in limits:\n",
    "            Msg('LIMIT {}'.format(lm))\n",
    "            ITER_LIMIT = lm\n",
    "            for i in idioms:\n",
    "                Msg('IDIOM {}'.format(idiom_names[i]))\n",
    "                set_idiom(i)\n",
    "                get_n(sheaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s QUERY r10\n",
      "  0.01s C++       : fetching the sheaf\n",
      "  4.16s C++       : fetching done\n",
      "  4.17s Python    : making monadsets\n",
      "  4.28s Python    : returning 11 monadsets\n",
      "  0.00s LIMIT 100000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.12s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.11s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s LIMIT 500000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  5.85s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  4.73s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s LIMIT 1000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "    11s SWIG      : 942880 results)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  9.33s SWIG      : 942880 results)\n",
      "  0.00s LIMIT 1000000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "    11s SWIG      : 942880 results)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  9.86s SWIG      : 942880 results)\n",
      "  0.00s QUERY r20\n",
      "  0.00s C++       : fetching the sheaf\n",
      "  9.12s C++       : fetching done\n",
      "  9.68s Python    : making monadsets\n",
      "  9.82s Python    : returning 11 monadsets\n",
      "  0.00s LIMIT 100000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.19s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  0.98s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s LIMIT 500000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  6.13s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  4.98s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s LIMIT 1000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "    11s SWIG      : 942880 results)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  9.01s SWIG      : 942880 results)\n",
      "  0.00s LIMIT 1000000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "    11s SWIG      : 942880 results)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  9.05s SWIG      : 942880 results)\n",
      "  0.00s QUERY r25\n",
      "  0.00s C++       : fetching the sheaf\n",
      " 2m 39s C++       : fetching done\n",
      " 2m 40s Python    : making monadsets\n",
      " 3m 01s Python    : returning 21 monadsets\n",
      "  0.00s LIMIT 100000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.34s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.35s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s LIMIT 500000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  6.02s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  4.99s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s LIMIT 1000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "    12s SWIG      : 1000000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  9.42s SWIG      : 1000000 resultsexceeded)\n",
      "  0.00s LIMIT 1000000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "12m 45s SWIG      : 63247779 results)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "10m 40s SWIG      : 63247779 results)\n",
      "  0.00s QUERY all\n",
      "  0.00s C++       : fetching the sheaf\n",
      " 5m 41s C++       : fetching done\n",
      " 7m 06s Python    : making monadsets\n",
      " 8m 44s Python    : returning 47 monadsets\n",
      "  0.00s LIMIT 100000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.67s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  1.13s SWIG      : 100000 resultsexceeded)\n",
      "  0.00s LIMIT 500000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "  7.68s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "  5.38s SWIG      : 500000 resultsexceeded)\n",
      "  0.00s LIMIT 1000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "    14s SWIG      : 1000000 resultsexceeded)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n",
      "    11s SWIG      : 1000000 resultsexceeded)\n",
      "  0.00s LIMIT 1000000000\n",
      "  0.00s IDIOM Gen\n",
      "  0.00s SWIG      : computing number of results\n",
      "28m 04s SWIG      : 131181928 results)\n",
      "  0.00s IDIOM For\n",
      "  0.00s SWIG      : computing number of results\n"
     ]
    }
   ],
   "source": [
    "do_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
