{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
    "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phono annotations\n",
    "\n",
    "We collect the output of the phono notebook.\n",
    "It has generated phonetic transcriptions for all the words.\n",
    "\n",
    "Every line in the output file is a tab-separated list of node number, phonetic transcription, and trailer material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.3\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: http://shebanq-doc.readthedocs.org/en/latest/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "from etcbc.extra import ExtraData\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create annotations from lexicon file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: clear main: F.etcbc4_db_otype [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_ft_number [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_sft_book [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_sft_chapter [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_sft_verse [node] \n",
      "  0.02s DETAIL: clear prep: G.node_sort\n",
      "  0.02s DETAIL: clear prep: G.node_sort_inv\n",
      "  0.02s DETAIL: clear prep: L.node_up\n",
      "  0.02s DETAIL: clear prep: L.node_down\n",
      "  0.02s DETAIL: load main: X. [node]  -> \n",
      "  2.11s DETAIL: load main: X. [node]  <- \n",
      "  3.58s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK phono AT 2015-09-24T14-27-42\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "etcbc_source = 'etcbc{}'.format(version)\n",
    "API=fabric.load(etcbc_source, '--', 'phono', {\n",
    "    \"xmlids\": {\"node\": True, \"edge\": False},\n",
    "    \"features\": ('', ''),\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the phonetic data\n",
    "\n",
    "First we read the lexicon, and perform some internal consistency checks, e.g. whether there are duplicate lexical entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_fname = 'wordph{}.txt'.format(version)\n",
    "word_file = infile(word_fname)\n",
    "for line in word_file:\n",
    "    (node, wordph, sep) = line[0:-1].split('\\t')\n",
    "    if sep == '+': continue\n",
    "word_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 6m 37s Writing annotation file ...\n",
      " 6m 59s Done\n"
     ]
    }
   ],
   "source": [
    "ph_annot = ExtraData(API)\n",
    "\n",
    "msg(\"Writing annotation file ...\")\n",
    "ph_annot.deliver_annots('lexicon/lex_data', 'lexicon', 'lex', get_lex, (\n",
    "        ('etcbc4', 'lex', 'id'),\n",
    "        ('etcbc4', 'lex', 'lan'),\n",
    "        ('etcbc4', 'lex', 'entryid'),\n",
    "        ('etcbc4', 'lex', 'entry'),\n",
    "        ('etcbc4', 'lex', 'entry_heb'),\n",
    "        ('etcbc4', 'lex', 'g_entry'),\n",
    "        ('etcbc4', 'lex', 'g_entry_heb'),\n",
    "        ('etcbc4', 'lex', 'root'),\n",
    "        ('etcbc4', 'lex', 'pos'),\n",
    "        ('etcbc4', 'lex', 'nametype'),\n",
    "        ('etcbc4', 'lex', 'subpos'),\n",
    "        ('etcbc4', 'lex', 'gloss'),\n",
    "    ),\n",
    "    {'title': 'Lexicon lookups', 'date': '2015'},\n",
    ")\n",
    "msg(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking: loading the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-05-04T13-46-20\n",
      "  0.00s BEGIN COMPILE a: lexicon\n",
      "  0.00s DETAIL: load main: X. [node]  -> \n",
      "  1.27s DETAIL: load main: X. [e]  -> \n",
      "  3.28s DETAIL: load main: G.node_anchor_min\n",
      "  3.34s DETAIL: load main: G.node_anchor_max\n",
      "  3.40s DETAIL: load main: G.node_sort\n",
      "  3.45s DETAIL: load main: G.node_sort_inv\n",
      "  3.94s DETAIL: load main: G.edges_from\n",
      "  4.01s DETAIL: load main: G.edges_to\n",
      "  4.09s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-data/etcbc4b/bin/A/lexicon/__log__compile__.txt\n",
      "  4.09s PARSING ANNOTATION FILES\n",
      "  4.10s INFO: parsing lex.xml\n",
      " 1m 15s INFO: END PARSING\n",
      "         0 good   regions  and     0 faulty ones\n",
      "         0 linked nodes    and     0 unlinked ones\n",
      "         0 good   edges    and     0 faulty ones\n",
      "    426567 good   annots   and     0 faulty ones\n",
      "   5118804 good   features and     0 faulty ones\n",
      "    426567 distinct xml identifiers\n",
      "\n",
      " 1m 15s MODELING RESULT FILES\n",
      " 1m 15s INFO: CONNECTIVITY\n",
      " 1m 15s WRITING RESULT FILES for a\n",
      " 1m 15s DETAIL: write annox: F.etcbc4_lex_entry [node] \n",
      " 1m 15s DETAIL: write annox: F.etcbc4_lex_entry_heb [node] \n",
      " 1m 16s DETAIL: write annox: F.etcbc4_lex_entryid [node] \n",
      " 1m 16s DETAIL: write annox: F.etcbc4_lex_g_entry [node] \n",
      " 1m 17s DETAIL: write annox: F.etcbc4_lex_g_entry_heb [node] \n",
      " 1m 17s DETAIL: write annox: F.etcbc4_lex_gloss [node] \n",
      " 1m 18s DETAIL: write annox: F.etcbc4_lex_id [node] \n",
      " 1m 18s DETAIL: write annox: F.etcbc4_lex_lan [node] \n",
      " 1m 19s DETAIL: write annox: F.etcbc4_lex_nametype [node] \n",
      " 1m 19s DETAIL: write annox: F.etcbc4_lex_pos [node] \n",
      " 1m 19s DETAIL: write annox: F.etcbc4_lex_root [node] \n",
      " 1m 20s DETAIL: write annox: F.etcbc4_lex_subpos [node] \n",
      " 1m 20s END   COMPILE a: lexicon\n",
      " 1m 20s INFO: USING DATA COMPILED AT: 2015-05-04T14-07-34\n",
      " 1m 20s DETAIL: keep main: G.node_anchor_min\n",
      " 1m 20s DETAIL: keep main: G.node_anchor_max\n",
      " 1m 20s DETAIL: keep main: G.node_sort\n",
      " 1m 20s DETAIL: keep main: G.node_sort_inv\n",
      " 1m 20s DETAIL: keep main: G.edges_from\n",
      " 1m 20s DETAIL: keep main: G.edges_to\n",
      " 1m 20s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      " 1m 20s DETAIL: keep main: F.etcbc4_ft_g_word [node] \n",
      " 1m 20s DETAIL: keep main: F.etcbc4_ft_g_word_utf8 [node] \n",
      " 1m 20s DETAIL: keep main: F.etcbc4_ft_lex [node] \n",
      " 1m 20s DETAIL: clear main: X. [node]  -> \n",
      " 1m 20s DETAIL: clear main: X. [node]  <- \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_db_oid [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_g_lex [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_g_lex_utf8 [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_gn [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_language [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_lex_utf8 [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_ls [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_nu [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_ps [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_sp [node] \n",
      " 1m 20s DETAIL: clear main: F.etcbc4_ft_st [node] \n",
      " 1m 20s DETAIL: load main: F.etcbc4_ft_g_cons_utf8 [node] \n",
      " 1m 20s DETAIL: load main: F.etcbc4_lex_g_entry [node] \n",
      " 1m 20s DETAIL: load main: F.etcbc4_lex_gloss [node] \n",
      " 1m 20s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      " 1m 20s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      " 1m 20s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      " 1m 20s DETAIL: load annox: F.etcbc4_db_otype [node] \n",
      " 1m 20s DETAIL: load annox: F.etcbc4_ft_g_cons_utf8 [node] \n",
      " 1m 20s DETAIL: load annox: F.etcbc4_ft_g_word [node] \n",
      " 1m 20s DETAIL: load annox: F.etcbc4_ft_g_word_utf8 [node] \n",
      " 1m 20s DETAIL: load annox: F.etcbc4_ft_lex [node] \n",
      " 1m 20s DETAIL: load annox: F.etcbc4_lex_g_entry [node] \n",
      " 1m 21s DETAIL: load annox: F.etcbc4_lex_gloss [node] \n",
      " 1m 21s DETAIL: load annox: F.etcbc4_sft_book [node] \n",
      " 1m 21s DETAIL: load annox: F.etcbc4_sft_chapter [node] \n",
      " 1m 21s DETAIL: load annox: F.etcbc4_sft_verse [node] \n",
      " 1m 21s DETAIL: prep prep: G.node_sort\n",
      " 1m 21s DETAIL: prep prep: G.node_sort_inv\n",
      " 1m 22s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK gloss AT 2015-05-04T14-07-36\n"
     ]
    }
   ],
   "source": [
    "API=fabric.load(etcbc_source, 'lexicon', 'gloss', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype\n",
    "        book chapter verse\n",
    "        g_cons_utf8 g_word_utf8 g_word lex g_entry gloss\n",
    "    ''',\n",
    "    '''\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "}, verbose='DETAIL',compile_annox=True)\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
