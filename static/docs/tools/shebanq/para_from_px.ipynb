{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
    "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragraphs from the px files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.4\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "from etcbc.extra import ExtraData\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create annotations from px file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'etcbc'\n",
    "if 'version' not in locals(): version = '4b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.00s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: keep main: F.etcbc4_ft_number [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_sft_book [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_sft_chapter [node] \n",
      "  0.01s DETAIL: clear main: F.etcbc4_sft_verse [node] \n",
      "  0.01s DETAIL: load main: X. [node]  -> \n",
      "  1.54s DETAIL: load main: X. [node]  <- \n",
      "  2.49s DETAIL: load main: F.etcbc4_db_monads [node] \n",
      "  3.32s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  3.35s DETAIL: keep prep: G.node_sort\n",
      "  3.35s DETAIL: keep prep: G.node_sort_inv\n",
      "  3.35s DETAIL: keep prep: L.node_up\n",
      "  3.35s DETAIL: keep prep: L.node_down\n",
      "  3.35s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: keep main: F.etcbc4_ft_number [node] \n",
      "  0.01s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  0.03s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  0.05s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  0.06s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK shebanq AT 2015-10-15T21-14-06\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK shebanq AT 2015-10-15T21-14-06\n"
     ]
    }
   ],
   "source": [
    "API=fabric.load(source+version, '--', 'shebanq', {\n",
    "    \"xmlids\": {\"node\": True, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype monads number label\n",
    "    ''',\n",
    "    '''\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to read px data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_px(px_file):\n",
    "    msg(\"Making mappings between clause atoms in PX and nodes in LAF\")\n",
    "    ca_labn2id = {}\n",
    "    ca_id2labn = {}\n",
    "    for n in NN():\n",
    "        otype = F.otype.v(n)\n",
    "        if otype == 'verse':\n",
    "            cur_label = F.label.v(n)\n",
    "        elif otype == 'chapter':\n",
    "            cur_subtract += cur_chapter_cas\n",
    "            cur_chapter_cas = 0\n",
    "        elif otype == 'book':\n",
    "            cur_subtract = 0\n",
    "            cur_chapter_cas = 0\n",
    "        elif otype == 'clause_atom':\n",
    "            cur_chapter_cas += 1\n",
    "            nm = int(F.number.v(n)) - cur_subtract\n",
    "            ca_labn2id[(cur_label, nm)] = n\n",
    "            ca_id2labn[n] = (cur_label, nm)\n",
    "    msg(\"End making mappings: {}={} clauses\".format(len(ca_labn2id), len(ca_id2labn)))\n",
    "\n",
    "    data = []\n",
    "    not_found = set()\n",
    "    px_handle = open(px_file)\n",
    "    ln = 0\n",
    "    can = 0\n",
    "    featurescan = re.compile(r'0 0 (..) [0-9]+ LineNr\\s*([0-9]+).*?Pargr:\\s*([0-9.]+)')\n",
    "    cur_label = None\n",
    "    data = []\n",
    "    for line in px_handle:\n",
    "        ln += 1\n",
    "        if line.strip()[0] != '*':\n",
    "            cur_label = line[0:10]\n",
    "            continue\n",
    "        can += 1\n",
    "        features = featurescan.findall(line)\n",
    "        if len(features) == 0:\n",
    "            msg(\"Warning: line {}: no instruction, LineNr, Pargr found\".format(ln))\n",
    "        elif len(features) > 1:\n",
    "            msg(\"Warning: line {}: multiple instruction, LineNr, Pargr found\".format(ln))\n",
    "        else:\n",
    "            feature = features[0]\n",
    "            the_ins = feature[0]\n",
    "            the_n = feature[1]\n",
    "            the_para = feature[2]\n",
    "            labn = (cur_label, int(the_n))\n",
    "            if labn not in ca_labn2id:\n",
    "                not_found.add(labn)\n",
    "                continue\n",
    "            data.append((ca_labn2id[labn], the_ins, the_n, the_para))\n",
    "    px_handle.close()\n",
    "    msg(\"Read {} paragraph annotations\".format(len(data)))\n",
    "    if not_found:\n",
    "        msg(\"Could not find {} label/line entries in index: {}\".format(len(not_found), sorted({lab for lab in not_found})))\n",
    "    else:\n",
    "        msg(\"All label/line entries found in index\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the px data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 4m 18s Making mappings between clause atoms in PX and nodes in LAF\n",
      " 4m 20s End making mappings: 90315=90315 clauses\n",
      " 4m 21s Read 90274 paragraph annotations\n",
      " 4m 21s Could not find 43 label/line entries in index: [(' IKON07,30', 115), (' IKON07,31', 121), (' IKON07,32', 124), (' IKON07,33', 127), (' IKON07,34', 129), (' IKON07,35', 133), (' IKON07,36', 135), (' IKON07,37', 137), (' IKON07,38', 141), (' IKON07,39', 145), (' IKON07,40', 149), (' IKON07,41', 154), (' IKON07,42', 158), (' IKON07,43', 159), (' IKON07,44', 160), (' IKON07,45', 164), (' IKON07,46', 165), (' IKON07,47', 167), (' IKON07,48', 172), (' IKON07,49', 177), (' IKON07,50', 179), (' IKON07,51', 183), (' JER 32,24', 103), (' JER 32,25', 108), (' JER 32,26', 110), (' JER 32,27', 112), (' JER 32,28', 115), (' JER 32,29', 123), (' JER 32,30', 128), (' JER 32,31', 132), (' JER 32,32', 136), (' JER 32,33', 143), (' JER 32,34', 146), (' JER 32,35', 153), (' JER 32,36', 157), (' JER 32,37', 161), (' JER 32,38', 163), (' JER 32,39', 166), (' JER 32,40', 171), (' JER 32,41', 174), (' JER 32,42', 178), (' JER 32,43', 182), (' JER 32,44', 189)]\n"
     ]
    }
   ],
   "source": [
    "px = ExtraData(API)\n",
    "px.deliver_annots(\n",
    "    'para', \n",
    "    {'title': 'Paragraph numbers', 'date': '2015'},\n",
    "    [\n",
    "        ('px/px_data.{}'.format(source+version), 'px', read_px, (\n",
    "            ('etcbc4', 'px', 'instruction'),\n",
    "            ('etcbc4', 'px', 'number_in_ch'),\n",
    "            ('etcbc4', 'px', 'pargr'),\n",
    "        )),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking: loading the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-05-04T14-11-41\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.02s DETAIL: keep main: G.edges_to\n",
      "  0.02s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.02s DETAIL: keep main: F.etcbc4_ft_number [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_sft_book [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_sft_chapter [node] \n",
      "  0.02s DETAIL: clear main: F.etcbc4_sft_verse [node] \n",
      "  0.02s DETAIL: load main: F.etcbc4_db_oid [node] \n",
      "  0.87s DETAIL: load main: F.etcbc4_px_instruction [node] \n",
      "  0.87s DETAIL: load main: F.etcbc4_px_number_in_ch [node] \n",
      "  0.87s DETAIL: load main: F.etcbc4_px_pargr [node] \n",
      "  0.87s DETAIL: load main: F.etcbc4_sft_label [node] \n",
      "  0.90s DETAIL: load annox: F.etcbc4_db_oid [node] \n",
      "  0.90s DETAIL: load annox: F.etcbc4_db_otype [node] \n",
      "  0.90s DETAIL: load annox: F.etcbc4_ft_number [node] \n",
      "  0.90s DETAIL: load annox: F.etcbc4_px_instruction [node] \n",
      "  0.96s DETAIL: load annox: F.etcbc4_px_number_in_ch [node] \n",
      "  1.01s DETAIL: load annox: F.etcbc4_px_pargr [node] \n",
      "  1.05s DETAIL: load annox: F.etcbc4_sft_label [node] \n",
      "  1.05s DETAIL: keep prep: G.node_sort\n",
      "  1.05s DETAIL: keep prep: G.node_sort_inv\n",
      "  1.05s DETAIL: keep prep: L.node_up\n",
      "  1.05s DETAIL: keep prep: L.node_down\n",
      "  1.05s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-05-04T14-11-41\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: keep main: F.etcbc4_ft_number [node] \n",
      "  0.01s DETAIL: keep annox: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: keep annox: F.etcbc4_ft_number [node] \n",
      "  0.01s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  0.03s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  0.05s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  0.06s DETAIL: load annox: F.etcbc4_sft_book [node] \n",
      "  0.06s DETAIL: load annox: F.etcbc4_sft_chapter [node] \n",
      "  0.06s DETAIL: load annox: F.etcbc4_sft_verse [node] \n",
      "  0.06s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX px FOR TASK shebanq AT 2015-10-15T21-19-01\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX px FOR TASK shebanq AT 2015-10-15T21-19-01\n"
     ]
    }
   ],
   "source": [
    "API=fabric.load(source+version, 'px', 'shebanq', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        oid otype number label\n",
    "        instruction number_in_ch pargr\n",
    "    ''',\n",
    "    '''\n",
    "    '''),\n",
    "    \"prepare\": prepare,\n",
    "}, verbose='DETAIL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating MQL\n",
    "\n",
    "We generate an text file with the new feature data which we will insert\n",
    "properly in the existing MQL dump of the ETCBC database.\n",
    "\n",
    "The text file is structured as follows:\n",
    "\n",
    "It consists of tab delimited lines, with a header line:\n",
    "\n",
    "    object_type feature_name1 feature_name2 ...\n",
    "\n",
    "followed by lines with the same number of fields.\n",
    "The first field is the object id, the subsequent fields are the values of the corresponding features for that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 clause atoms\n",
      "20000 clause atoms\n",
      "30000 clause atoms\n",
      "40000 clause atoms\n",
      "50000 clause atoms\n",
      "60000 clause atoms\n",
      "70000 clause atoms\n",
      "80000 clause atoms\n",
      "90000 clause atoms\n",
      "90315 clause atoms\n"
     ]
    }
   ],
   "source": [
    "pm = outfile('pargr_data.mql')\n",
    "pm.write('{}\\t{}\\n'.format('clause_atom', 'pargr'))\n",
    "chunk = 10000\n",
    "nc = 0\n",
    "ic = 0\n",
    "for c in F.otype.s('clause_atom'):\n",
    "    nc += 1\n",
    "    ic += 1\n",
    "    if ic == chunk: \n",
    "        ic = 0\n",
    "        print('{:>5} clause atoms'.format(nc))\n",
    "    pm.write('{}\\t{}\\n'.format(F.oid.v(c), F.pargr.v(c) or ''))\n",
    "print('{:>5} clause atoms'.format(nc))\n",
    "pm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting all objects that got new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2m 16s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GEN 01,01: instruction = 1; .N; para = 1\n",
      " GEN 01,02: instruction = 2; ..; para = 1\n",
      " GEN 01,02: instruction = 3; ..; para = 1\n",
      " GEN 01,02: instruction = 4; ..; para = 1\n",
      " GEN 01,03: instruction = 5; .#; para = 1.1\n",
      " GEN 01,03: instruction = 6; .q; para = 1.1.1\n",
      " GEN 01,03: instruction = 7; .#; para = 1.1.2\n",
      " GEN 01,04: instruction = 8; .#; para = 1.1.3\n",
      " GEN 01,04: instruction = 9; ..; para = 1.1.3\n",
      " GEN 01,04: instruction = 10; .#; para = 1.1.4\n",
      " GEN 01,05: instruction = 11; .#; para = 1.1.5\n",
      " GEN 01,05: instruction = 12; ..; para = 1.1.5\n",
      " GEN 01,05: instruction = 13; .#; para = 1.1.5.1\n",
      " GEN 01,05: instruction = 14; .#; para = 1.1.5.2\n",
      " GEN 01,05: instruction = 15; ..; para = 1.1.5.2\n",
      " GEN 01,06: instruction = 16; .#; para = 1.2\n",
      " GEN 01,06: instruction = 17; .q; para = 1.2.1\n",
      " GEN 01,06: instruction = 18; ..; para = 1.2.1\n",
      " GEN 01,07: instruction = 19; .#; para = 1.2.2\n",
      " GEN 01,07: instruction = 20; ..; para = 1.2.2\n",
      " GEN 01,07: instruction = 21; .e; para = 1.2.2\n",
      " GEN 01,07: instruction = 22; d.; para = 1.2.2\n",
      " GEN 01,07: instruction = 23; ..; para = 1.2.2\n",
      " GEN 01,07: instruction = 24; ..; para = 1.2.2\n",
      " GEN 01,08: instruction = 25; .#; para = 1.2.2.1\n",
      " GEN 01,08: instruction = 26; .#; para = 1.2.2.1.1\n"
     ]
    }
   ],
   "source": [
    "pfile = 'paras.txt'\n",
    "ph = outfile(pfile)\n",
    "cur_label = None\n",
    "for n in NN():\n",
    "    otype = F.otype.v(n)\n",
    "    if otype == 'verse':\n",
    "        cur_label = F.label.v(n)\n",
    "    elif otype == 'clause_atom':\n",
    "        nm = F.number_in_ch.v(n)\n",
    "        if nm:\n",
    "            ph.write(\"{}: instruction = {}; {}; para = {}\\n\".format(cur_label, nm, F.instruction.v(n), F.pargr.v(n)))\n",
    "ph.close()\n",
    "\n",
    "i = 0\n",
    "inf = infile(pfile)\n",
    "for line in inf:\n",
    "    i += 1\n",
    "    if i > 26: break\n",
    "    print(line.rstrip('\\n'))\n",
    "inf.close()\n",
    "    \n",
    "msg(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
