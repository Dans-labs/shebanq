{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
    "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows you how to use LAF-Fabric for exciting data processing on the Hebrew Bible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "You need hardware, an operating system, additional software, LAF-Fabric itself and ETCBC data.\n",
    "\n",
    "Here is a summary to get it all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get it all!\n",
    "\n",
    "1. Download and install [Anaconda](), choose a python3 based version for your platform.\n",
    "\n",
    "1. get the data\n",
    "    \n",
    "    cd ~\n",
    "    git clone .../ETCBC/laf-fabric-data\n",
    "    \n",
    "1. get laf-fabric\n",
    "    \n",
    "    cd ~\n",
    "    git clone .../ETCBC/laf-fabric\n",
    "    cd laf-fabric-dist/laf-fabric-*\n",
    "    python3 setup.py\n",
    "\n",
    "Skip the next two steps if this is your first acquaintance with LAF-Fabric.\n",
    "\n",
    "1. Install databases\n",
    "\n",
    "    sudo apt-get install mysql-server\n",
    "    sudo apt-get install sqlite3\n",
    "    \n",
    "1. Download [Emdros](). Build and install it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware\n",
    "\n",
    "You need a computer with enough RAM (at least 8GB). It can be a laptop, or a virtual machine inside a laptop.\n",
    "That virtual machine needs at least 4GB of RAM, but make it 6GB. If your VM has a 64-bit architecture, you need to allocate 12 GB.\n",
    "\n",
    "Personally, I feel most comfortable with running LAF-Fabric natively, not in a VM, because then everything integrates much better with the rest of your work.\n",
    "\n",
    "## Operating system\n",
    "\n",
    "Preferably, the computer understand unix-like commands and has a *terminal* utility, also known as *command line* in the Windows world. That means that Mac OS X is OK and Linux is OK, and Windows is doable with extra care.\n",
    "\n",
    "Working with LAF-Fabric breathes a culture of terminal commands, it involves git, bash, and the installation instructions are given in unix lingo. \n",
    "\n",
    "If you are on Windows, use unix-like tools that have been ported to Windows, such as Git-Bash, Cygwin, or other stuff.\n",
    "It is possible to get LAF-Fabric up and running on Windows, without these unix tools, but you need the expertise to translate the unix way of working into a Windows way of working.\n",
    "\n",
    "## Additional software\n",
    "\n",
    "What you need in this chapter are programming languages and databases and other utilities.\n",
    "\n",
    "### Python and friends\n",
    "\n",
    "Python is not only a programming language but also an ecosystem of packages that are very helpful in data processing.\n",
    "It comes in versions 2 and 3. Version 3 has proper UNICODE handling. LAF-Fabric is based on version 3.\n",
    "\n",
    "You can run a python program by issuing a command on the terminal. \n",
    "But you can also run a python script interactively on the terminal.\n",
    "Even better, you can run python in a rich interface in the browser, where you can document your code in a rich way.\n",
    "This is the *notebook* concept. What you are reading now is part of a notebook.\n",
    "The technology that makes this possible is called **Jupyter** (formerly **IPython**).\n",
    "In order to install Python and Jupyter and all they need in one go, download **Anaconda** and install it.\n",
    "\n",
    "### MySQL, SQLite3\n",
    "\n",
    "Relational databases may not be the hype nowadays, they have lost nothing of their usefulness. Make sure that you have either sqlite3 or mysql on your system, or both.\n",
    "\n",
    "### Emdros\n",
    "\n",
    "Emdros implements the concept of a text database, where text is modelled as things that come in an order and that can be nested  The things can be given features that describe their properties, and things can be connected by relationships. Having done that, Emdros supports a query language in which your queries are structural templates with fixed and variable properties. The result are all possible ways by which the variable parts can be filled from the data in the database.\n",
    "\n",
    "Most data processing in LAF-Fabric does not need Emdros, because LAF-Fabric offers its own way of retrieving information from a graph database. Nevertheless, LAF-Fabric has an API for MQL queries, so that you can run them programmatically, and process their results. You can combine results of multiple queries and compare results with other ways of querying the data.\n",
    "\n",
    "If you plan to do this, you also have to install Emdros.\n",
    "\n",
    "## LAF-Fabric\n",
    "\n",
    "LAF-Fabric is a python package, with two sub packages: **laf** and **etcbc**. \n",
    "The **laf** package offers an API for working efficiently with LAF data, i.e. data in Linguistic Annotation Framework. It does so by compiling a LAF resource (which is a set of bulky XML files) into fast-loading data structures for Python.\n",
    "Where as the LAF resource takes 10 minutes to parse, before you can do useful work with it, the compiled data loads in a matter of seconds. LAF-Fabric loads and unloads data according to your request.\n",
    "\n",
    "In order to get it, you can clone it from Github, after which you have to perform an installation step to incorporate the package into your python environment.\n",
    "\n",
    "## ETCBC data\n",
    "\n",
    "The Hebrew Bible as encoded by the ETCBC contains the text of the Biblia Hebraica Stuttgartensia plus linguistic features provided by the Eep Talstra Centre for Bible and Computer.\n",
    "\n",
    "This data has been curated and archived at DANS/EASY, in several versions: 3, 4, and 4b.\n",
    "Versions 4 and 4b contain the curated data in LAF, but also in other convenient formats.\n",
    "The compiled data of the latest version is in a Github repository, and this is the recommended way to quickly get up and running with LAF-Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work\n",
    "\n",
    "Now we can get to work.\n",
    "\n",
    "We import some modules, among which **laf** and **etcbc** from the LAF-fabric package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.5\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import collections\n",
    "\n",
    "from laf.fabric import LafFabric\n",
    "import etcbc\n",
    "from etcbc.preprocess import prepare\n",
    "\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the hyperlinks above:\n",
    "\n",
    "1. to the documentation of the LAF-Fabric API. This tells you what the software can do.\n",
    "2. to the feature documentation. This tells you what information has been encoded in the data and how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose your source and features\n",
    "\n",
    "LAF-Fabric is a generic tool for LAF resources. We have to specify a data source.\n",
    "In our case, that is a sub-directory of the **laf-fabric-data** directory.\n",
    "\n",
    "Our data is in **etcbc4b**. We call **etcbc** the source, and **4b** the version.\n",
    "\n",
    "We also give our task a name, in this case **tutorial**.\n",
    "The task name will become a sub-directory of **laf-fabric-output**.\n",
    "There are handy commands to read and write files in this directory.\n",
    "\n",
    "Below, in the call of **fabric.load** you see an argument '--'.\n",
    "This is nothing, but it could have been a package with extra annotations.\n",
    "If you specify such a package, its annotations will be merged with the annotations in the main resource.\n",
    "\n",
    "This is a convenient way to enrich the base data with extra information, or to override erroneous annotations with correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'etcbc'\n",
    "version = '4b'\n",
    "task = 'tutorial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to specify the data *features* that we want to use.\n",
    "We declare just a bare minimum; later on we add more as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.01s DETAIL: load main: G.node_anchor_min\n",
      "  0.12s DETAIL: load main: G.node_anchor_max\n",
      "  0.22s DETAIL: load main: G.node_sort\n",
      "  0.31s DETAIL: load main: G.node_sort_inv\n",
      "  0.75s DETAIL: load main: G.edges_from\n",
      "  0.87s DETAIL: load main: G.edges_to\n",
      "  1.00s DETAIL: load main: F.etcbc4_db_otype [node] \n",
      "  1.70s DETAIL: load main: F.etcbc4_ft_gn [node] \n",
      "  1.85s DETAIL: load main: F.etcbc4_ft_sp [node] \n",
      "  2.04s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/tutorial/__log__tutorial.txt\n",
      "  2.04s DETAIL: prep prep: G.node_sort\n",
      "  2.14s DETAIL: prep prep: G.node_sort_inv\n",
      "  2.61s DETAIL: prep prep: L.node_up\n",
      "  5.56s DETAIL: prep prep: L.node_down\n",
      "    11s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s DETAIL: COMPILING m: UP TO DATE\n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  0.00s DETAIL: COMPILING a: UP TO DATE\n",
      "  0.01s DETAIL: keep main: G.node_anchor_min\n",
      "  0.01s DETAIL: keep main: G.node_anchor_max\n",
      "  0.01s DETAIL: keep main: G.node_sort\n",
      "  0.01s DETAIL: keep main: G.node_sort_inv\n",
      "  0.01s DETAIL: keep main: G.edges_from\n",
      "  0.01s DETAIL: keep main: G.edges_to\n",
      "  0.01s DETAIL: keep main: F.etcbc4_db_otype [node] \n",
      "  0.01s DETAIL: load main: F.etcbc4_ft_number [node] \n",
      "  0.65s DETAIL: load main: F.etcbc4_sft_book [node] \n",
      "  0.67s DETAIL: load main: F.etcbc4_sft_chapter [node] \n",
      "  0.69s DETAIL: load main: F.etcbc4_sft_verse [node] \n",
      "  0.71s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK tutorial AT 2015-11-20T13-47-09\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK tutorial AT 2015-11-20T13-47-09\n"
     ]
    }
   ],
   "source": [
    "API = fabric.load(source+version, '--', task, {\n",
    "    'xmlids': {'node': False, 'edge': False},\n",
    "    'features': ('''\n",
    "        otype sp gn\n",
    "''',''),\n",
    "    'prepare': prepare,\n",
    "}, verbose='DETAIL')\n",
    "\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Let's go computing\n",
    "\n",
    "We are now in an excellent position to explore the data.\n",
    "We shall assume very little knowledge about what is in the data.\n",
    "We are going to discover it.\n",
    "\n",
    "## Counting\n",
    "\n",
    "So, the data is a graph with nodes and edges. How many nodes? We are going to walk through them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1m 34s Counting nodes\n",
      " 1m 34s There are 1436858 nodes\n"
     ]
    }
   ],
   "source": [
    "msg('Counting nodes')\n",
    "\n",
    "n_nodes = 0\n",
    "for n in NN(): n_nodes += 1\n",
    "    \n",
    "msg('There are {} nodes'.format(n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``msg`` is part of LAF-Fabric. It gives a progress message with the elapsed time since the API was loaded. You see that counting 1.4 million nodes is a breeze.\n",
    "\n",
    "## Finer counting\n",
    "\n",
    "The nodes corresponds with *types* of data.\n",
    "The feature ``otype`` tells what type a node has.\n",
    "Lets get those types and count how many nodes each type has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 4m 27s Counting node types\n",
      " 4m 29s There are 12 node types:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbook           :    39 nodes\n",
      "\tchapter        :   929 nodes\n",
      "\tclause         : 88011 nodes\n",
      "\tclause_atom    : 90554 nodes\n",
      "\thalf_verse     : 45180 nodes\n",
      "\tphrase         : 253161 nodes\n",
      "\tphrase_atom    : 267499 nodes\n",
      "\tsentence       : 63586 nodes\n",
      "\tsentence_atom  : 64354 nodes\n",
      "\tsubphrase      : 113764 nodes\n",
      "\tverse          : 23213 nodes\n",
      "\tword           : 426568 nodes\n"
     ]
    }
   ],
   "source": [
    "msg('Counting node types')\n",
    "\n",
    "node_types = collections.Counter()\n",
    "\n",
    "for n in NN(): node_types[F.otype.v(n)] += 1\n",
    "\n",
    "msg('There are {} node types:'.format(len(node_types)))\n",
    "for nt in sorted(node_types):\n",
    "    print('\\t{:<15}: {:>5} nodes'.format(nt, node_types[nt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our corpus has 436568 words.\n",
    "\n",
    "# Gender in Hebrew\n",
    "\n",
    "The Hebrew language has two genders: ``m`` (masculine) and ``f`` (feminine).\n",
    "Any specific words either has one of these genders, or it is unknown or irrelevant what gender it has.\n",
    "\n",
    "Let us count the proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 5m 55s Counting genders\n",
      " 5m 57s These are the values that the feature gn can take: NA, unknown, m, f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNA             : 180149 nodes\n",
      "\tf              : 36712 nodes\n",
      "\tm              : 164183 nodes\n",
      "\tunknown        : 45524 nodes\n"
     ]
    }
   ],
   "source": [
    "msg('Counting genders')\n",
    "\n",
    "genders = collections.Counter()\n",
    "\n",
    "for w in F.otype.s('word'): genders[F.gn.v(w)] += 1\n",
    "\n",
    "msg('These are the values that the feature gn can take: {}'.format(', '.join(genders)))\n",
    "for gn in sorted(genders):\n",
    "    print('\\t{:<15}: {:>5} nodes'.format(gn, genders[gn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now make an overview of the proportion between positively masculine words and positively feminine words per book in the Hebrew Bible. Most feminine books on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 6m 49s Ranking books on gender ratio\n",
      " 6m 50s Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruth            m/f = 1.4\n",
      "Canticum        m/f = 1.8\n",
      "Ezechiel        m/f = 2.8\n",
      "Esther          m/f = 3.1\n",
      "Nahum           m/f = 3.2\n",
      "Threni          m/f = 3.3\n",
      "Proverbia       m/f = 3.4\n",
      "Micha           m/f = 3.4\n",
      "Leviticus       m/f = 3.4\n",
      "Zephania        m/f = 3.7\n",
      "Genesis         m/f = 4.0\n",
      "Daniel          m/f = 4.0\n",
      "Numeri          m/f = 4.1\n",
      "Amos            m/f = 4.2\n",
      "Jesaia          m/f = 4.2\n",
      "Sacharia        m/f = 4.2\n",
      "Jona            m/f = 4.3\n",
      "Jeremia         m/f = 4.3\n",
      "Iob             m/f = 4.4\n",
      "Exodus          m/f = 4.7\n",
      "Judices         m/f = 4.7\n",
      "Hosea           m/f = 4.7\n",
      "Psalmi          m/f = 4.9\n",
      "Nehemia         m/f = 5.0\n",
      "Joel            m/f = 5.1\n",
      "Josua           m/f = 5.2\n",
      "Reges_I         m/f = 5.3\n",
      "Chronica_II     m/f = 5.3\n",
      "Habakuk         m/f = 5.4\n",
      "Esra            m/f = 5.4\n",
      "Deuteronomium   m/f = 5.4\n",
      "Ecclesiastes    m/f = 5.5\n",
      "Maleachi        m/f = 6.0\n",
      "Reges_II        m/f = 6.0\n",
      "Samuel_I        m/f = 6.1\n",
      "Samuel_II       m/f = 6.2\n",
      "Chronica_I      m/f = 7.4\n",
      "Obadia          m/f = 7.7\n",
      "Haggai          m/f = 8.0\n"
     ]
    }
   ],
   "source": [
    "msg ('Ranking books on gender ratio')\n",
    "\n",
    "book_genders = collections.defaultdict(lambda: collections.Counter())\n",
    "real_genders = {'m', 'f'}\n",
    "\n",
    "current_book = None\n",
    "for n in NN():\n",
    "    ntype = F.otype.v(n)\n",
    "    if ntype == 'book': current_book = F.book.v(n)\n",
    "    elif ntype == 'word': \n",
    "        gn = F.gn.v(n)\n",
    "        if gn in real_genders: book_genders[current_book][gn] += 1\n",
    "            \n",
    "book_ratios = dict((book, book_genders[book]['m'] / book_genders[book]['f']) for book in book_genders)\n",
    "msg('Done')\n",
    "\n",
    "for (book, ratio) in sorted(book_ratios.items(), key=lambda x: (x[1], x[0])):\n",
    "    print('{:<15} m/f = {:.2}'.format(book, ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
