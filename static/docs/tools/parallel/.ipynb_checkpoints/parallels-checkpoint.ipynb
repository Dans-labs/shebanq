{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"https://www.academic-bible.com/en/online-bibles/biblia-hebraica-stuttgartensia-bhs/read-the-bible-text/\" target=\"_blank\"><img align=\"right\" src=\"files/images/DBG-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"50%\" src=\"files/images/parallel.png\"/>\n",
    "\n",
    "# Parallel Passages in the MT\n",
    "\n",
    "We want to make a list of **all** parallel passages in the Masoretic Text (MT) of the Hebrew Bible.\n",
    "\n",
    "Here is a quote that triggered Dirk to write this notebook:\n",
    "\n",
    "> Finally, the Old Testament Parallels module in Accordance is a helpful resource that enables the researcher to examine 435 sets of parallel texts, or in some cases very similar wording in different texts, in both the MT and translation, but the large number of sets of texts in this database should not fool one to think it is complete or even nearly complete for all parallel writings in the Hebrew Bible.\n",
    "\n",
    "Robert Rezetko and Ian Young.\n",
    "    Historical linguistics & Biblical Hebrew. Steps Toward an Integrated Approach.\n",
    "    *Ancient Near East Monographs, Number9*. SBL Press Atlanta. 2014. \n",
    "    [PDF Open access available](https://www.google.nl/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0CCgQFjAB&url=http%3A%2F%2Fwww.sbl-site.org%2Fassets%2Fpdfs%2Fpubs%2F9781628370461_OA.pdf&ei=2QSdVf-vAYSGzAPArJeYCg&usg=AFQjCNFA3TymYlsebQ0MwXq2FmJCSHNUtg&sig2=LaXuAC5k3V7fSXC6ZVx05w&bvm=bv.96952980,d.bGQ)\n",
    "\n",
    "It is a pity that we cannot compare our results with the Accordance resource mentioned above, since that resource has not been published in an accessible manner. We also do not have the information how this resource has been constructed on the basis of the raw data. In contrast with that, we present our results in a completely reproducible manner. This notebook itself can serve as the method of replication, provided you have obtained the necessary resources. See [SHEBANQ sources](https://shebanq.ancient-data.org/sources), which are all Open Access.\n",
    "\n",
    "The notion of *parallel passage* is not a simple, straightforward one.\n",
    "There are parallels on the basis of lexical content in the passages on the one hand, \n",
    "but on the other hand there are also correspondences in certain syntactical structures, \n",
    "or even in similarities in text structure.\n",
    "\n",
    "In this notebook we do select a straightforward notion of parallel, based on lexical content only.\n",
    "We investigate two measures of similarity, one that ignores word order completely, and one that takes word order into account.\n",
    "\n",
    "Two kinds of short-comings of this approach must be mentioned:\n",
    "\n",
    "1. We will not find parallels based on non-lexical criteria (unless they are also lexical parallels)\n",
    "1. We will find too many parallels: certain short sentences (and he said), or formula like passages (and the word of God came to Moses) occur so often that they have a more subtle bearing on whether there is a common text history.\n",
    "\n",
    "For a more full treatment of parallel passages, see\n",
    "\n",
    "Wido Th. van Peursen and Eep Talstra.\n",
    "  Computer-Assisted Analysis of Parallel Texts in the Bible - \n",
    "  The Case of 2 Kings xviii-xix and its Parallels in Isaiah and Chronicles.\n",
    "  Vetus Testamentum</i> 57, pp. 45-72.\n",
    "  2007, Brill, Leiden.\n",
    "  \n",
    "Note that our method fails to identify any parallels with Chronica_II 32. Van Peursen and Talstra state about this chapter and 2 Kings 18: \n",
    "\n",
    "> These chapters differ so much, that it is sometimes impossible to establish which verses should be considered parallel.\n",
    "\n",
    "In this notebook we produce a set of *cliques*, a clique being a set of passages that are *quite* similar, based on lexical information.\n",
    "\n",
    "\n",
    "# Authors\n",
    "\n",
    "[Dirk Roorda](mailto:dirk.roorda@dans.knaw.nl) while discussing ideas with \n",
    "[Martijn Naaijer](mailto:m.naaijer@vu.nl). \n",
    "\n",
    "# Status\n",
    "\n",
    "**Last modified: 2016-02-21** Added 18 experiments based on chapter chunks.\n",
    "\n",
    "144 experiments have been carried out, of which 9 with promising results.\n",
    "All results can be easily inspected, just by clicking in your browser.\n",
    "One of the experiments has been chosen as the basis for\n",
    "[crossref](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnxjcm9zc3JlZg__&tp=txt_tb1&nget=v)\n",
    "annotations in SHEBANQ.\n",
    "\n",
    "# Results\n",
    "\n",
    "Click in a green cell to see interesting results. The numbers in the cell indicate\n",
    "\n",
    "* the number of passages that have a variant elsewhere\n",
    "* the number of *cliques* they form (cliques are sets of similar passages)\n",
    "* the number of passages in the biggest clique\n",
    "\n",
    "Below the results is an account of the method that we used, followed by the actual code to produce these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "<table>\n",
       "<tr><td class=\"mis\">no results available</td></tr>\n",
       "<tr><td class=\"rec\">promising results: recommended</td></tr>\n",
       "<tr><td class=\"dep\">messy results: deprecated</td></tr>\n",
       "<tr><td class=\"dub\">mixed quality: take care</td></tr>\n",
       "<tr><td class=\"out\">method deprecated</td></tr>\n",
       "<tr><td class=\"nor\">unassessed quality: inspection needed</td></tr>\n",
       "</table>\n",
       "\n",
       "<table>\n",
       "<tr><th>chunk type</th><th>chunk size</th><th>similarity method</th><th>100</th><th>95</th><th>90</th><th>85</th><th>80</th><th>75</th><th>70</th><th>65</th><th>60</th><th>55</th><th>50</th><th>45</th><th>40</th><th>35</th><th>30</th></tr>\n",
       "<tr><td>fixed</td><td>100</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S100.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">18</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S90.html\"><span class=\"cl\">9</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">37</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S85.html\"><span class=\"cl\">18</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">64</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S80.html\"><span class=\"cl\">30</span></a><br/>\n",
       "    <span class=\"mx\">6</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">87</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S75.html\"><span class=\"cl\">40</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">113</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S70.html\"><span class=\"cl\">52</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">154</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S65.html\"><span class=\"cl\">70</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">208</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S60.html\"><span class=\"cl\">94</span></a><br/>\n",
       "    <span class=\"mx\">10</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">309</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S55.html\"><span class=\"cl\">138</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">473</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S50.html\"><span class=\"cl\">189</span></a><br/>\n",
       "    <span class=\"mx\">14</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>100</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">39</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S90.html\"><span class=\"cl\">19</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">59</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S85.html\"><span class=\"cl\">29</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">85</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S80.html\"><span class=\"cl\">41</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">122</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S75.html\"><span class=\"cl\">56</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">189</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S70.html\"><span class=\"cl\">88</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">287</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S65.html\"><span class=\"cl\">132</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">535</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S60.html\"><span class=\"cl\">214</span></a><br/>\n",
       "    <span class=\"mx\">31</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>50</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">24</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S90.html\"><span class=\"cl\">12</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">57</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S85.html\"><span class=\"cl\">26</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">114</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S80.html\"><span class=\"cl\">52</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">186</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S75.html\"><span class=\"cl\">85</span></a><br/>\n",
       "    <span class=\"mx\">8</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">271</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S70.html\"><span class=\"cl\">124</span></a><br/>\n",
       "    <span class=\"mx\">10</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">385</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S65.html\"><span class=\"cl\">176</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">535</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S60.html\"><span class=\"cl\">235</span></a><br/>\n",
       "    <span class=\"mx\">15</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">748</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S55.html\"><span class=\"cl\">315</span></a><br/>\n",
       "    <span class=\"mx\">20</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1187</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S50.html\"><span class=\"cl\">465</span></a><br/>\n",
       "    <span class=\"mx\">47</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>50</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">12</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S95.html\"><span class=\"cl\">6</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">53</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S90.html\"><span class=\"cl\">25</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">119</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S85.html\"><span class=\"cl\">53</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">196</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S80.html\"><span class=\"cl\">89</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">301</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S75.html\"><span class=\"cl\">135</span></a><br/>\n",
       "    <span class=\"mx\">19</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">464</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S70.html\"><span class=\"cl\">205</span></a><br/>\n",
       "    <span class=\"mx\">20</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">761</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S65.html\"><span class=\"cl\">312</span></a><br/>\n",
       "    <span class=\"mx\">28</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1888</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S60.html\"><span class=\"cl\">552</span></a><br/>\n",
       "    <span class=\"mx\">112</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>20</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">28</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S100.html\"><span class=\"cl\">14</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">28</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S95.html\"><span class=\"cl\">14</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">105</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S90.html\"><span class=\"cl\">46</span></a><br/>\n",
       "    <span class=\"mx\">8</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">174</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S85.html\"><span class=\"cl\">72</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">326</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S80.html\"><span class=\"cl\">143</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">528</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S75.html\"><span class=\"cl\">227</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">762</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S70.html\"><span class=\"cl\">331</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1058</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S65.html\"><span class=\"cl\">452</span></a><br/>\n",
       "    <span class=\"mx\">13</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1830</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S60.html\"><span class=\"cl\">733</span></a><br/>\n",
       "    <span class=\"mx\">29</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2787</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S55.html\"><span class=\"cl\">979</span></a><br/>\n",
       "    <span class=\"mx\">154</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4913</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S50.html\"><span class=\"cl\">1203</span></a><br/>\n",
       "    <span class=\"mx\">1573</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>20</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">6</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S100.html\"><span class=\"cl\">3</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">47</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S95.html\"><span class=\"cl\">22</span></a><br/>\n",
       "    <span class=\"mx\">4</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">149</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S90.html\"><span class=\"cl\">61</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">311</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S85.html\"><span class=\"cl\">136</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">682</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S80.html\"><span class=\"cl\">299</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1137</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S75.html\"><span class=\"cl\">470</span></a><br/>\n",
       "    <span class=\"mx\">27</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2217</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S70.html\"><span class=\"cl\">838</span></a><br/>\n",
       "    <span class=\"mx\">52</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">5971</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S65.html\"><span class=\"cl\">1223</span></a><br/>\n",
       "    <span class=\"mx\">2709</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">17656</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S60.html\"><span class=\"cl\">152</span></a><br/>\n",
       "    <span class=\"mx\">17329</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>10</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">448</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S100.html\"><span class=\"cl\">209</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">448</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S95.html\"><span class=\"cl\">209</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">482</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S90.html\"><span class=\"cl\">220</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1114</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S85.html\"><span class=\"cl\">493</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1536</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S80.html\"><span class=\"cl\">628</span></a><br/>\n",
       "    <span class=\"mx\">36</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2754</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S75.html\"><span class=\"cl\">1094</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4020</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S70.html\"><span class=\"cl\">1474</span></a><br/>\n",
       "    <span class=\"mx\">163</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">5785</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S65.html\"><span class=\"cl\">1850</span></a><br/>\n",
       "    <span class=\"mx\">702</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">10211</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S60.html\"><span class=\"cl\">2210</span></a><br/>\n",
       "    <span class=\"mx\">4141</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">14100</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S55.html\"><span class=\"cl\">2018</span></a><br/>\n",
       "    <span class=\"mx\">9047</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">23054</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S50.html\"><span class=\"cl\">1455</span></a><br/>\n",
       "    <span class=\"mx\">19638</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>fixed</td><td>10</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">239</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S100.html\"><span class=\"cl\">114</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">379</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S95.html\"><span class=\"cl\">182</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">905</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S90.html\"><span class=\"cl\">399</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1917</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S85.html\"><span class=\"cl\">791</span></a><br/>\n",
       "    <span class=\"mx\">71</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">3850</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S80.html\"><span class=\"cl\">1418</span></a><br/>\n",
       "    <span class=\"mx\">137</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">8552</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S75.html\"><span class=\"cl\">2342</span></a><br/>\n",
       "    <span class=\"mx\">1980</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">20382</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S70.html\"><span class=\"cl\">1926</span></a><br/>\n",
       "    <span class=\"mx\">15724</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">37700</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S65.html\"><span class=\"cl\">223</span></a><br/>\n",
       "    <span class=\"mx\">37234</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">42450</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S60.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">42448</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>chapter</td><td>SET</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S95.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S90.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S85.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S80.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">14</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S75.html\"><span class=\"cl\">7</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">20</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S70.html\"><span class=\"cl\">10</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">24</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S65.html\"><span class=\"cl\">12</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">34</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S60.html\"><span class=\"cl\">17</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">44</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S55.html\"><span class=\"cl\">22</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">56</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S50.html\"><span class=\"cl\">28</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">80</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S45.html\"><span class=\"cl\">39</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">142</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S40.html\"><span class=\"cl\">62</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">302</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S35.html\"><span class=\"cl\">53</span></a><br/>\n",
       "    <span class=\"mx\">61</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">571</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_SET_M30_S30.html\"><span class=\"cl\">28</span></a><br/>\n",
       "    <span class=\"mx\">496</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>chapter</td><td>LCS</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S95.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S90.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S85.html\"><span class=\"cl\">6</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">18</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S80.html\"><span class=\"cl\">9</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">26</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S75.html\"><span class=\"cl\">13</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">38</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S70.html\"><span class=\"cl\">19</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">44</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S65.html\"><span class=\"cl\">22</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">52</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S60.html\"><span class=\"cl\">26</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">102</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_chapter_LCS_M55_S55.html\"><span class=\"cl\">49</span></a><br/>\n",
       "    <span class=\"mx\">4</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>verse</td><td>SET</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">993</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S100.html\"><span class=\"cl\">388</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">1029</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S95.html\"><span class=\"cl\">406</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1286</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S90.html\"><span class=\"cl\">526</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1573</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S85.html\"><span class=\"cl\">651</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">1958</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S80.html\"><span class=\"cl\">800</span></a><br/>\n",
       "    <span class=\"mx\">154</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2359</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S75.html\"><span class=\"cl\">961</span></a><br/>\n",
       "    <span class=\"mx\">156</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2720</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S70.html\"><span class=\"cl\">1094</span></a><br/>\n",
       "    <span class=\"mx\">166</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3139</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S65.html\"><span class=\"cl\">1235</span></a><br/>\n",
       "    <span class=\"mx\">172</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3877</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S60.html\"><span class=\"cl\">1439</span></a><br/>\n",
       "    <span class=\"mx\">202</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">4735</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S55.html\"><span class=\"cl\">1638</span></a><br/>\n",
       "    <span class=\"mx\">388</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">6711</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S50.html\"><span class=\"cl\">1850</span></a><br/>\n",
       "    <span class=\"mx\">1476</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>verse</td><td>LCS</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">793</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S100.html\"><span class=\"cl\">295</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1235</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S95.html\"><span class=\"cl\">504</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1754</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S90.html\"><span class=\"cl\">724</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2296</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S85.html\"><span class=\"cl\">938</span></a><br/>\n",
       "    <span class=\"mx\">160</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2925</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S80.html\"><span class=\"cl\">1141</span></a><br/>\n",
       "    <span class=\"mx\">174</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3685</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S75.html\"><span class=\"cl\">1340</span></a><br/>\n",
       "    <span class=\"mx\">190</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">4958</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S70.html\"><span class=\"cl\">1644</span></a><br/>\n",
       "    <span class=\"mx\">257</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">9046</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S65.html\"><span class=\"cl\">1821</span></a><br/>\n",
       "    <span class=\"mx\">4221</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">18941</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S60.html\"><span class=\"cl\">380</span></a><br/>\n",
       "    <span class=\"mx\">18073</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>half_verse</td><td>SET</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4327</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S100.html\"><span class=\"cl\">1725</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4333</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S95.html\"><span class=\"cl\">1728</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4618</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S90.html\"><span class=\"cl\">1863</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">5145</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S85.html\"><span class=\"cl\">2072</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">6422</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S80.html\"><span class=\"cl\">2474</span></a><br/>\n",
       "    <span class=\"mx\">195</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">8265</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S75.html\"><span class=\"cl\">2888</span></a><br/>\n",
       "    <span class=\"mx\">536</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">9388</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S70.html\"><span class=\"cl\">3193</span></a><br/>\n",
       "    <span class=\"mx\">681</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12162</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S65.html\"><span class=\"cl\">3342</span></a><br/>\n",
       "    <span class=\"mx\">2842</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">16476</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S60.html\"><span class=\"cl\">3424</span></a><br/>\n",
       "    <span class=\"mx\">6915</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">19519</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S55.html\"><span class=\"cl\">3184</span></a><br/>\n",
       "    <span class=\"mx\">10993</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">28990</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S50.html\"><span class=\"cl\">2031</span></a><br/>\n",
       "    <span class=\"mx\">24008</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>half_verse</td><td>LCS</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">3799</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S100.html\"><span class=\"cl\">1514</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4342</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S95.html\"><span class=\"cl\">1771</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">5776</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S90.html\"><span class=\"cl\">2336</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">7970</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S85.html\"><span class=\"cl\">2983</span></a><br/>\n",
       "    <span class=\"mx\">189</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12504</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S80.html\"><span class=\"cl\">3540</span></a><br/>\n",
       "    <span class=\"mx\">2364</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">19148</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S75.html\"><span class=\"cl\">3084</span></a><br/>\n",
       "    <span class=\"mx\">11090</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">28472</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S70.html\"><span class=\"cl\">1894</span></a><br/>\n",
       "    <span class=\"mx\">23864</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">38180</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S65.html\"><span class=\"cl\">665</span></a><br/>\n",
       "    <span class=\"mx\">36649</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">44011</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S60.html\"><span class=\"cl\">89</span></a><br/>\n",
       "    <span class=\"mx\">43822</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>sentence</td><td>SET</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19028</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S100.html\"><span class=\"cl\">4325</span></a><br/>\n",
       "    <span class=\"mx\">1056</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19036</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S95.html\"><span class=\"cl\">4329</span></a><br/>\n",
       "    <span class=\"mx\">1056</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19208</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S90.html\"><span class=\"cl\">4404</span></a><br/>\n",
       "    <span class=\"mx\">1056</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19771</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S85.html\"><span class=\"cl\">4606</span></a><br/>\n",
       "    <span class=\"mx\">1056</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">22063</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S80.html\"><span class=\"cl\">5066</span></a><br/>\n",
       "    <span class=\"mx\">1056</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">25724</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S75.html\"><span class=\"cl\">4993</span></a><br/>\n",
       "    <span class=\"mx\">4853</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">26880</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S70.html\"><span class=\"cl\">5222</span></a><br/>\n",
       "    <span class=\"mx\">5232</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">33378</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S65.html\"><span class=\"cl\">4111</span></a><br/>\n",
       "    <span class=\"mx\">17433</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">38807</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S60.html\"><span class=\"cl\">3753</span></a><br/>\n",
       "    <span class=\"mx\">24074</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">41835</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S55.html\"><span class=\"cl\">3505</span></a><br/>\n",
       "    <span class=\"mx\">28077</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">53117</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S50.html\"><span class=\"cl\">1174</span></a><br/>\n",
       "    <span class=\"mx\">50174</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "<tr><td>object</td><td>sentence</td><td>LCS</td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">17532</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S100.html\"><span class=\"cl\">3981</span></a><br/>\n",
       "    <span class=\"mx\">1054</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">18079</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S95.html\"><span class=\"cl\">4215</span></a><br/>\n",
       "    <span class=\"mx\">1054</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">21246</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S90.html\"><span class=\"cl\">4993</span></a><br/>\n",
       "    <span class=\"mx\">1054</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">26473</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S85.html\"><span class=\"cl\">4853</span></a><br/>\n",
       "    <span class=\"mx\">7321</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">35626</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S80.html\"><span class=\"cl\">3470</span></a><br/>\n",
       "    <span class=\"mx\">25548</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">44307</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S75.html\"><span class=\"cl\">2293</span></a><br/>\n",
       "    <span class=\"mx\">38261</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">52535</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S70.html\"><span class=\"cl\">1197</span></a><br/>\n",
       "    <span class=\"mx\">49324</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">58863</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S65.html\"><span class=\"cl\">460</span></a><br/>\n",
       "    <span class=\"mx\">57763</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">62379</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S60.html\"><span class=\"cl\">105</span></a><br/>\n",
       "    <span class=\"mx\">62134</span>\n",
       "    </td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td><td class=\"mis\">&nbsp;</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell after all other cells\n",
    "HTML(other_exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and results\n",
    "\n",
    "We have conducted 144 experiments, all corresponding to a specific choice of parameters.\n",
    "Every experiment is an attempt to identify variants and collect them in *cliques*.\n",
    "\n",
    "The table gives an overview of the experiments conducted.\n",
    "\n",
    "Every *row* corresponds to a particular way of chunking and a method of measuring the similarity.\n",
    "\n",
    "There are *columns* for each similarity *threshold* that we have tried.\n",
    "The idea is that chunks are similar if their similarity is above the threshold.\n",
    "\n",
    "The outcomes of one experiment have been added to SHEBANQ as the note set\n",
    "[crossref](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnxjcm9zc3JlZg__&tp=txt_tb1&nget=v).\n",
    "The experiment chosen for this is currently\n",
    "\n",
    "* *chunking*: **object verse**\n",
    "* *similarity method*: **SET**\n",
    "* *similarity threshold*: **65**\n",
    "\n",
    "\n",
    "## Assessing the outcomes\n",
    "\n",
    "Not all experiments lead to useful results.\n",
    "We have indicated the value of a result by a color coding, based on objective characteristics,\n",
    "such as the number of passages, the number of cliques, the size of the greatest clique, and the way of chunking.\n",
    "These numbers are shown in the cells.\n",
    "\n",
    "If you click on the hyperlink in the cell, you are taken to a page that gives you\n",
    "all the details of the results:\n",
    "\n",
    "1. A link to a file with all *cliques* (which are the sets of similar passages)\n",
    "1. A list of links to chapter-by-chapter diff files (for cliques with just two members), and only for\n",
    "   experiments with outcomes that are labeled as *promising* or *unassessed quality* or *mixed results*.\n",
    "\n",
    "To get into the variants quickly, inspect the list (2) and click through \n",
    "to see the actual variant material in chapter context.\n",
    "\n",
    "Not all variants occur here, so continue with (1) to see the remaining cliques.\n",
    "\n",
    "Sometimes in (2) a chapter diff file does not indicate clearly the relevant common part of both chapters.\n",
    "In that case you have to consult the big list (1)\n",
    "\n",
    "All these results can be downloaded from the\n",
    "[SHEBANQ github repo](https://github.com/ETCBC/shebanq/tree/master/static/docs/tools/parallel/files)\n",
    "After downloading the whole directory, open ``experiments.html`` in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This is an IPython notebook. \n",
    "It contains a working program to carry out the computations needed to obtain the results reported here.\n",
    "\n",
    "You can download this notebook and run it on your computer, provided you have\n",
    "[LAF-Fabric](http://laf-fabric.readthedocs.org/en/latest/texts/welcome.html) installed.\n",
    "An easy way to do that is describe [here](laf-fabric.readthedocs.org/texts/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method description\n",
    "\n",
    "Here we discuss the method we used to arrive at a list of parallel passages \n",
    "in the Masoretic Text (MT) of the Hebrew Bible.\n",
    "\n",
    "## Similarity\n",
    "\n",
    "We have to find passages in the MT that are *similar*.\n",
    "Therefore we *chunk* the text in some way, and then compute the similarities between pairs of chunks.\n",
    "\n",
    "There are many ways to define and compute similarity between texts.\n",
    "Here, we have tried two methods ``SET`` and ``LCS``.\n",
    "Both methods define similarity as the fraction of common material with respect to the total material.\n",
    "\n",
    "### SET\n",
    "\n",
    "The ``SET`` method reduces textual chunks to *sets* of *lexemes*.\n",
    "This method abstracts from the order and number of occurrences of words in chunks.\n",
    "\n",
    "We use as measure for the similarity of chunks $C_1$ and $C_2$ (taken as sets):\n",
    "\n",
    "$$ s_{\\rm set}(C_1, C_2) = {\\vert C_1 \\cap C_2\\vert \\over \\vert C_1 \\cup C_2 \\vert} $$\n",
    "\n",
    "where $\\vert X \\vert$ is the number of elements in set $X$.\n",
    "\n",
    "### LCS\n",
    "\n",
    "The ``LCS`` method is less reductive: chunks are *strings* of *lexemes*, \n",
    "so the order and number of occurrences of words is retained.\n",
    "\n",
    "We use as measure for the similarity of chunks $C_1$ and $C_2$ (taken as strings):\n",
    "\n",
    "$$ s_{\\rm lcs}(C_1, C_2) = {\\vert {\\rm LCS}(C_1,C_2)\\vert \\over \\vert C_1\\vert + \\vert C_2 \\vert - \n",
    "\\vert {\\rm LCS}(C_1,C_2)\\vert} $$\n",
    "\n",
    "where ${\\rm LCS}(C_1, C_2)$ is the\n",
    "[longest common subsequence](https://en.wikipedia.org/wiki/Longest_common_subsequence_problem)\n",
    "of $C_1$ and $C_2$ and\n",
    "$\\vert X\\vert$ is the length of sequence $X$.\n",
    "\n",
    "It remains to be seen whether we need the extra sophistication of ``LCS``.\n",
    "The risk is that ``LCS`` could fail to spot related passages when there is a large amount of transposition going on.\n",
    "The results should have the last word. \n",
    "\n",
    "We need to compute the LCS efficiently, and for this we used the python ``Levenshtein`` module:\n",
    "\n",
    "``pip install python-Levenshtein``\n",
    "\n",
    "whose documentation is\n",
    "[here](http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html).\n",
    "\n",
    "## Performance\n",
    "\n",
    "Similarity computation is the part where the heavy lifting occurs.\n",
    "It is basically quadratic in the number of chunks, so if you have verses as chunks (~ 23,000),\n",
    "you need to do ~ 270,000,000 similarity computations, and if you use sentences (~ 64,000), \n",
    "you need to do ~ 2,000,000,000 ones!\n",
    "The computation of a single similarity should be *really* fast.\n",
    "\n",
    "Besides that, we use two ways to economize:\n",
    "\n",
    "* after having computed a matrix for a specific set of parameter values, we save the matrix to disk;\n",
    "  new runs can load the matrix from disk in a matter of seconds;\n",
    "* we do not store low similarity values in the matrix, low being < ``MATRIX_THRESHOLD``.\n",
    "\n",
    "The ``LCS`` method is more complicated.\n",
    "We have tried the ``ratio`` method from the ``difflib`` package that is present in the standard python distribution.\n",
    "This is unbearably slow for our purposes.\n",
    "The ``ratio`` method in the ``Levenshtein`` package is much quicker.\n",
    "\n",
    "See the table for an indication of the amount of work to create the similarity matrix\n",
    "and the performance per similarity method.\n",
    "\n",
    "The *matrix threshold* is the lower bound of similarities that are stored in the matrix.\n",
    "If a pair of chunks has a lower similarity, no entry will be made in the matrix.\n",
    "\n",
    "The computing has been done on a Macbook Air (11\", mid 2012, 1.7 GHz Intel Core i5, 8GB RAM).\n",
    "\n",
    "|chunk type |chunk size|similarity method|matrix threshold|# of comparisons|size of matrix (KB)|computing time (min)|\n",
    "|:----------|---------:|----------------:|---------------:|---------------:|------------------:|-------------------:|\n",
    "|fixed      |100       |LCS              |60              |       9,003,646|                  7|                  ? |\n",
    "|fixed      |100       |SET              |50              |       9,003,646|                  7|                  ? |\n",
    "|fixed      |50        |LCS              |60              |      36,197,286|                 37|                  ? |\n",
    "|fixed      |50        |SET              |50              |      36,197,286|                 18|                  ? |\n",
    "|fixed      |20        |LCS              |60              |     227,068,705|              2,400|                  ? |\n",
    "|fixed      |20        |SET              |50              |     227,068,705|                113|                  ? |\n",
    "|fixed      |10        |LCS              |60              |     909,020,841|             59,000|                  ? |\n",
    "|fixed      |10        |SET              |50              |     909,020,841|              1,800|                  ? |\n",
    "|object     |verse     |LCS              |60              |     269,410,078|              2,300|                  31|\n",
    "|object     |verse     |SET              |50              |     269,410,078|                509|                  14|\n",
    "|object     |half_verse|LCS              |60              |   1,016,396,241|             40,000|                  50|\n",
    "|object     |half_verse|SET              |50              |   1,016,396,241|              3,600|                  41|\n",
    "|object     |sentence  |LCS              |60              |   2,055,975,750|            212,000|                  68|\n",
    "|object     |sentence  |SET              |50              |   2,055,975,750|             82,000|                  63|\n",
    "\n",
    "\n",
    "## Chunking\n",
    "\n",
    "There are several ways to chunk the text:\n",
    "\n",
    "* fixed chunks of approximately ``CHUNK_SIZE`` words\n",
    "* by object, such as verse, sentence and even chapter\n",
    "\n",
    "After chunking, we prepare the chunks for similarity measuring.\n",
    "\n",
    "### Observations\n",
    "\n",
    "#### Fixed chunking\n",
    "Fixed chunking is unnatural, but if the chunk size is small, it can yield fair results.\n",
    "The results are somewhat difficult to inspect, because they generally do not respect constituent boundaries.\n",
    "It is to be expected that fixed chunks in variant passages will be mutually *out of phase*, \n",
    "meaning that the chunks involved in these passages are not aligned with each other.\n",
    "So they will have a lower similarity than they could have if they were aligned.\n",
    "This is a source of artificial noise in the outcome and/or missed cases.\n",
    "\n",
    "If the chunking respects \"natural\" boundaries in the text, there is far less misalignment.\n",
    "\n",
    "#### Object chunking\n",
    "We can also chunk by object, such as verse, half_verse or sentence.\n",
    "\n",
    "Chunking by *verse* is very much like chunking in fixed chunks of size 20, performance-wise.\n",
    "\n",
    "Chunking by *half_verse* is comparable to fixed chunks of size 10.\n",
    "\n",
    "Chunking by *sentence* will generate an enormous amount of\n",
    "false positives, because there are very many very short sentences (down to 1-word) in the text.\n",
    "Besides that, the performance overhead is huge.\n",
    "\n",
    "The *half_verses* seem to be a very interesting candidate. \n",
    "They are smaller than verses, but there are less *degenerate cases* compared to with sentences. \n",
    "From the table above it can be read that half verses require only half as many similarity computations as sentences.\n",
    "\n",
    "\n",
    "## Preparing\n",
    "\n",
    "We prepare the chunks for the application of the chosen method of similarity computation (``SET`` or ``LCS``).\n",
    "\n",
    "In both cases we reduce the text to a sequence of transliterated consonantal *lexemes* without disambiguation.\n",
    "In fact, we go one step further: we remove the consonants (alef, wav, yod) that are often silent.\n",
    "\n",
    "For ``SET``, we represent each chunk as the set of its reduced lexemes.\n",
    "\n",
    "For ``LCS``, we represent each chunk as the string obtained by joining its reduced lexemes separated by white spaces.\n",
    "\n",
    "## Cliques\n",
    "\n",
    "After having computed a sufficient part of the similarity matrix, we set a value for ``SIMILARITY_THRESHOLD``.\n",
    "All pairs of chunks having at least that similarity are deemed *interesting*.\n",
    "\n",
    "We organize the members of such pairs in *cliques*, groups of chunks of which each member is \n",
    "similar (*similarity* > ``SIMILARITY_THRESHOLD``) to at least one other member.\n",
    "\n",
    "We start with no cliques and walk through the pairs whose similarity is above ``SIMILARITY_THRESHOLD``, \n",
    "and try to put each member into a clique.\n",
    "\n",
    "If there is not yet a clique, we make the member in question into a new singleton clique.\n",
    "\n",
    "If there are cliques, we find the cliques that have a member similar to the member in question.\n",
    "If we find several, we merge them all into one clique.\n",
    "\n",
    "If there is no such clique, we put the member in a new singleton clique.\n",
    "\n",
    "NB: Cliques may *drift*, meaning that they contain members that are completely different from each other.\n",
    "They are in the same clique, because there is a path of pairwise similar members leading from the one chunk to the other.\n",
    "\n",
    "### Organizing the cliques\n",
    "In order to accomodate cases where there are many corresponding verses in corresponding chapters, we produce\n",
    "chapter-by-chapter diffs in the following way.\n",
    "\n",
    "We make a list of all chapters that are involved in cliques.\n",
    "This yields a list of chapter cliques.\n",
    "For all *binary* chapters cliques, we generate a colorful diff rendering (as html) for the complete two chapters.\n",
    "\n",
    "We only do this for *promising* experiments.\n",
    "\n",
    "### Evaluating clique sets\n",
    "\n",
    "Not all clique sets are equally worth while.\n",
    "For example, if we set the ``SIMILARITY_THRESHOLD`` too low, we might get one gigantic clique, especially\n",
    "in combination with a fine-grained chunking. In other words: we suffer from *clique drifting*.\n",
    "\n",
    "We detect clique drifting by looking at the size of the largest clique.\n",
    "If that is large compared to the total number of chunks, we deem the results unsatisfactory.\n",
    "\n",
    "On the other hand, when the ``SIMILARITY_THRESHOLD`` is too high, you might miss a lot of correspondences,\n",
    "especially when chunks are large, or when we have fixed-size chunks that are out of phase.\n",
    "\n",
    "We deem the results of experiments based on a partioning into fixed length chunks as unsatisfactory, although it\n",
    "might be interesting to inspect what exactly the damage is.\n",
    "\n",
    "At the moment, we have not yet analysed the relative merits of the similarity methods ``SET`` and ``LCS``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines\n",
    "\n",
    "The rest is code. From here we start computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.12\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, collections, pickle, math, difflib, glob\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "PICKLE_PROTOCOL = 3\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import ratio\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s USING main  DATA COMPILED AT: 2015-11-02T15-08-56\n",
      "  3.22s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/parallel/__log__parallel.txt\n",
      "  3.23s INFO: LOADING PREPARED data: please wait ... \n",
      "  3.23s prep prep: G.node_sort\n",
      "  3.34s prep prep: G.node_sort_inv\n",
      "  3.88s prep prep: L.node_up\n",
      "  7.78s prep prep: L.node_down\n",
      "    14s prep prep: V.verses\n",
      "    14s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "    15s INFO: LOADED PREPARED data\n",
      "    15s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX lexicon FOR TASK parallel AT 2016-02-21T20-08-42\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "API = fabric.load('etcbc{}'.format(version), '--', 'parallel', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype\n",
    "        lex g_word_utf8 trailer_utf8\n",
    "        book chapter verse label number\n",
    "    ''',\n",
    "    ''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='NORMAL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Here are the parameters on which the results crucially depend.\n",
    "\n",
    "There are also parameters that control the reporting of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chunking\n",
    "CHUNK_LABELS = {True: 'fixed', False: 'object'}\n",
    "CHUNK_LBS = {True: 'F', False: 'O'}\n",
    "CHUNK_SIZES = (100, 50, 20, 10)\n",
    "CHUNK_OBJECTS = ('chapter', 'verse','half_verse','sentence')\n",
    "\n",
    "# preparing\n",
    "EXCLUDED_CONS = '[>WJ=/\\[]'             # weed out weak consonants\n",
    "EXCLUDED_PAT = re.compile(EXCLUDED_CONS)\n",
    "\n",
    "# similarity\n",
    "MATRIX_THRESHOLD = 50\n",
    "SIM_METHODS = ('SET', 'LCS')\n",
    "SIMILARITIES = (100, 95, 90, 85, 80, 75, 70, 65, 60, 55, 50, 45, 40, 35, 30)\n",
    "\n",
    "# printing\n",
    "DEP_CLIQUE_RATIO = 25\n",
    "DUB_CLIQUE_RATIO = 15\n",
    "REC_CLIQUE_RATIO =  5\n",
    "LARGE_CLIQUE_SIZE = 50\n",
    "CLIQUES_PER_FILE = 50\n",
    "\n",
    "# assessing results\n",
    "VALUE_LABELS = dict(\n",
    "    mis='no results available',\n",
    "    rec='promising results: recommended',\n",
    "    dep='messy results: deprecated',\n",
    "    dub='mixed quality: take care',\n",
    "    out='method deprecated',\n",
    "    nor='unassessed quality: inspection needed',\n",
    "    lr='this experiment is the last one run',\n",
    ")\n",
    "\n",
    "# crossrefs for SHEBANQ\n",
    "SHEBANQ_MATRIX = (False, 'verse', 'SET')\n",
    "SHEBANQ_SIMILARITY = 65\n",
    "SHEBANQ_TOOL = 'parallel'\n",
    "CROSSREF_STATUS = '!'\n",
    "CROSSREF_KEYWORD = 'crossref'\n",
    "\n",
    "# progress indication\n",
    "VERBOSE = False\n",
    "MEGA = 1000000\n",
    "KILO = 1000\n",
    "SIMILARITY_PROGRESS = 5 * MEGA\n",
    "CLIQUES_PROGRESS = 1 * KILO\n",
    "\n",
    "# locations and hyperlinks\n",
    "REMOTE_BASE = 'https://surfdrive.surf.nl/files/public.php?service=files&t=dedf27be7e171ab8a8b151f84ded93e8'\n",
    "LOCAL_BASE_COMP = my_file('').rstrip('/')\n",
    "LOCAL_BASE_OUTP = 'files'\n",
    "EXPERIMENT_DIR = 'experiments'\n",
    "EXPERIMENT_FILE = 'experiments'\n",
    "EXPERIMENT_PATH = '{}/{}.txt'.format(LOCAL_BASE_OUTP, EXPERIMENT_FILE)\n",
    "EXPERIMENT_HTML = '{}/{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_FILE)\n",
    "NOTES_FILE = 'crossref'\n",
    "NOTES_PATH = '{}/{}.csv'.format(LOCAL_BASE_OUTP, NOTES_FILE)\n",
    "STORED_CLIQUE_DIR = 'stored/cliques'\n",
    "STORED_MATRIX_DIR = 'stored/matrices'\n",
    "CHAPTER_DIR = 'chapters'\n",
    "CROSSREF_DB_FILE = 'crossrefdb.csv'\n",
    "CROSSREF_DB_PATH = '{}/{}'.format(LOCAL_BASE_OUTP, CROSSREF_DB_FILE)\n",
    "\n",
    "def reset_params():\n",
    "    global CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJECT, CHUNK_LB, CHUNK_DESC\n",
    "    global SIMILARITY_METHOD, SIMILARITY_THRESHOLD, MATRIX_THRESHOLD\n",
    "    global meta\n",
    "    meta = collections.OrderedDict()\n",
    "    \n",
    "    # chunking\n",
    "    CHUNK_FIXED = None                      # kind of chunking: fixed size or by object\n",
    "    CHUNK_SIZE = None                       # only relevant for CHUNK_FIXED = True\n",
    "    CHUNK_OBJECT = None                     # only relevant for CHUNK_FIXED = False; see CHUNK_OBJECTS in next cell\n",
    "    CHUNK_LB = None                         # computed from CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJ\n",
    "    CHUNK_DESC = None                       # computed from CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJ\n",
    "    # similarity\n",
    "    MATRIX_THRESHOLD = None                 # minimal similarity used to fill the matrix of similarities\n",
    "    SIMILARITY_METHOD = None                # see SIM_METHODS in next cell\n",
    "    SIMILARITY_THRESHOLD = None             # minimal similarity used to put elements together in cliques\n",
    "    meta = collections.OrderedDict()\n",
    "\n",
    "def set_matrix_threshold(sim_m=None, chunk_o=None):\n",
    "    global MATRIX_THRESHOLD\n",
    "    the_sim_m = SIMILARITY_METHOD if sim_m == None else sim_m\n",
    "    the_chunk_o = CHUNK_OBJECT if chunk_o == None else chunk_o\n",
    "    MATRIX_THRESHOLD = 50 if the_sim_m == 'SET' else 60\n",
    "    if the_sim_m == 'SET':\n",
    "        if the_chunk_o == 'chapter': MATRIX_THRESHOLD = 30\n",
    "        else: MATRIX_THRESHOLD = 50\n",
    "    else:\n",
    "        if the_chunk_o == 'chapter': MATRIX_THRESHOLD = 55\n",
    "        else: MATRIX_THRESHOLD = 60\n",
    "\n",
    "def do_params(chunk_f, chunk_i, sim_m, sim_thr):\n",
    "    global CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJECT, CHUNK_LB, CHUNK_DESC\n",
    "    global SIMILARITY_METHOD, SIMILARITY_THRESHOLD, MATRIX_THRESHOLD\n",
    "    global meta\n",
    "    do_chunk = False\n",
    "    do_prep = False\n",
    "    do_sim = False\n",
    "    do_clique = False\n",
    "    \n",
    "    meta = collections.OrderedDict()\n",
    "    if chunk_f != CHUNK_FIXED or (chunk_f and chunk_i != CHUNK_SIZE) or (not chunk_f and chunk_i != CHUNK_OBJECT):\n",
    "        do_chunk = True\n",
    "        do_prep = True\n",
    "        do_sim = True\n",
    "        do_clique = True\n",
    "        CHUNK_FIXED = chunk_f\n",
    "        if chunk_f: CHUNK_SIZE = chunk_i\n",
    "        else: CHUNK_OBJECT = chunk_i\n",
    "    if sim_m != SIMILARITY_METHOD:\n",
    "        do_prep = True\n",
    "        do_sim = True\n",
    "        do_clique = True\n",
    "        SIMILARITY_METHOD = sim_m\n",
    "    if sim_thr != SIMILARITY_THRESHOLD:\n",
    "        do_clique = True\n",
    "        SIMILARITY_THRESHOLD = sim_thr\n",
    "    set_matrix_threshold()\n",
    "    if SIMILARITY_THRESHOLD < MATRIX_THRESHOLD : return (False, False, False, False, True)\n",
    "\n",
    "    CHUNK_LB = CHUNK_LBS[CHUNK_FIXED]\n",
    "    CHUNK_DESC = CHUNK_SIZE if CHUNK_FIXED else CHUNK_OBJECT\n",
    "\n",
    "    meta['CHUNK TYPE'] = 'FIXED {}'.format(CHUNK_SIZE) if CHUNK_FIXED else 'OBJECT {}'.format(CHUNK_OBJECT)\n",
    "    meta['MATRIX THRESHOLD'] = MATRIX_THRESHOLD\n",
    "    meta['SIMILARITY METHOD'] = SIMILARITY_METHOD\n",
    "    meta['SIMILARITY THRESHOLD'] = SIMILARITY_THRESHOLD\n",
    "    \n",
    "    \n",
    "    for p in (\n",
    "        '{}/{}'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR),\n",
    "        '{}/{}'.format(LOCAL_BASE_OUTP, CHAPTER_DIR),\n",
    "        '{}/{}'.format(LOCAL_BASE_COMP, STORED_CLIQUE_DIR),\n",
    "        '{}/{}'.format(LOCAL_BASE_COMP, STORED_MATRIX_DIR),\n",
    "    ):\n",
    "        if not os.path.exists(p): os.makedirs(p)\n",
    "\n",
    "    return (do_chunk, do_prep, do_sim, do_clique, False)\n",
    "\n",
    "reset_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunking(do_chunk):\n",
    "    global chunks, book_rank\n",
    "    if not do_chunk:\n",
    "        msg('CHUNKING ({} {}): already chunked into {} chunks'.format(CHUNK_LB, CHUNK_DESC, len(chunks)))\n",
    "        meta['# CHUNKS'] = len(chunks)\n",
    "        return\n",
    "    msg('CHUNKING ({} {})'.format(CHUNK_LB, CHUNK_DESC))\n",
    "    chunks = []\n",
    "    book_rank = {}\n",
    "    for b in F.otype.s('book'):\n",
    "        book_name = F.book.v(b)\n",
    "        book_rank[book_name] = b\n",
    "        words = L.d('word', b)\n",
    "        nwords = len(words)\n",
    "        if CHUNK_FIXED:\n",
    "            nchunks = nwords // CHUNK_SIZE\n",
    "            if nchunks == 0: \n",
    "                nchunks = 1\n",
    "                common_incr = nwords\n",
    "                special_incr = 0\n",
    "            else:            \n",
    "                rem = nwords % CHUNK_SIZE\n",
    "                common_incr = rem // nchunks\n",
    "                special_incr = rem % nchunks\n",
    "            word_in_chunk = -1\n",
    "            cur_chunk = -1\n",
    "            these_chunks = []\n",
    "\n",
    "            for w in words:\n",
    "                word_in_chunk += 1\n",
    "                if word_in_chunk == 0 or (word_in_chunk >= CHUNK_SIZE + common_incr + (1 if cur_chunk < special_incr else 0)):\n",
    "                    word_in_chunk = 0\n",
    "                    these_chunks.append([])\n",
    "                    cur_chunk += 1\n",
    "                these_chunks[-1].append(w)\n",
    "        else:\n",
    "            these_chunks = [L.d('word', c) for c in L.d(CHUNK_OBJECT, b)]\n",
    "\n",
    "        chunks.extend(these_chunks)\n",
    "\n",
    "        chunkvolume = sum(len(c) for c in these_chunks)\n",
    "        if VERBOSE:\n",
    "            msg('CHUNKING ({} {}): {:<20s} {:>5} words; {:>5} chunks; sizes {:>5} to {:>5}; {:>5}'.format(\n",
    "                CHUNK_LB, CHUNK_DESC,\n",
    "                book_name, nwords, len(these_chunks), \n",
    "                min(len(c) for c in these_chunks), \n",
    "                max(len(c) for c in these_chunks),\n",
    "                'OK' if chunkvolume == nwords else 'ERROR',\n",
    "            ))\n",
    "    meta['# CHUNKS'] = len(chunks)\n",
    "    msg('CHUNKING ({} {}): Made {} chunks'.format(CHUNK_LB, CHUNK_DESC, len(chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preparing(do_prepare):\n",
    "    global chunk_data\n",
    "    if not do_prepare:\n",
    "        msg('PREPARING ({} {} {}): Already prepared'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD))\n",
    "        return\n",
    "    msg('PREPARING ({} {} {})'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD))\n",
    "    chunk_data = []\n",
    "    if SIMILARITY_METHOD == 'SET':\n",
    "        for c in chunks:\n",
    "            words = (EXCLUDED_PAT.sub('', F.lex.v(w).replace('<', 'O')) for w in c)\n",
    "            clean_words = (w for w in words if w != '')\n",
    "            this_data = frozenset(clean_words)\n",
    "            chunk_data.append(this_data)\n",
    "    else:\n",
    "        for c in chunks:\n",
    "            words = (EXCLUDED_PAT.sub('', F.lex.v(w).replace('<', 'O')) for w in c)\n",
    "            clean_words = (w for w in words if w != '')\n",
    "            this_data = ' '.join(clean_words)\n",
    "            chunk_data.append(this_data)\n",
    "    msg('PREPARING ({} {} {}): Done {} chunks.'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, len(chunk_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity_post():\n",
    "    nequals = len({x for x in chunk_dist if chunk_dist[x] >= 100})\n",
    "    cmin = min(chunk_dist.values()) if len(chunk_dist) else '!empty set!'\n",
    "    cmax = max(chunk_dist.values()) if len(chunk_dist) else '!empty set!'\n",
    "    meta['LOWEST  AVAILABLE SIMILARITY'] = cmin\n",
    "    meta['HIGHEST AVAILABLE SIMILARITY'] = cmax\n",
    "    meta['# EQUAL COMPARISONS'] = nequals\n",
    "    msg('SIMILARITY ({} {} {} M>{}): similarities between {} and {}. {} are 100%'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        cmin, cmax, nequals,\n",
    "    ))\n",
    "    \n",
    "def similarity(do_sim):\n",
    "    global chunk_dist\n",
    "    total_chunks = len(chunks) \n",
    "    total_distances = total_chunks * (total_chunks - 1) // 2\n",
    "    meta['# SIMILARITY COMPARISONS'] = total_distances\n",
    "    \n",
    "    SIMILARITY_PROGRESS = total_distances // 100\n",
    "    if SIMILARITY_PROGRESS >= MEGA:\n",
    "        sim_unit = MEGA\n",
    "        sim_lb = 'M'\n",
    "    else:\n",
    "        sim_unit = KILO\n",
    "        sim_lb = 'K'\n",
    "    \n",
    "    if not do_sim:\n",
    "        msg('SIMILARITY ({} {} {} M>{}): Using {:>5} {} ({}) comparisons with {} entries in matrix'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "            total_distances // sim_unit, sim_lb, total_distances, len(chunk_dist),\n",
    "        ))\n",
    "        meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "        similarity_post()\n",
    "        return\n",
    "\n",
    "    matrix_path = '{}/{}/matrix_{}_{}_{}_{}'.format(\n",
    "        LOCAL_BASE_COMP, STORED_MATRIX_DIR,\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "    )\n",
    "\n",
    "    if os.path.exists(matrix_path):\n",
    "        with open(matrix_path, 'rb') as f: chunk_dist = pickle.load(f)\n",
    "        msg('SIMILARITY ({} {} {} M>{}): Loaded: {:>5} {} ({}) comparisons with {} entries in matrix'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "            total_distances // sim_unit, sim_lb, total_distances, len(chunk_dist),\n",
    "        ))\n",
    "        meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "        similarity_post()\n",
    "        return\n",
    "\n",
    "    msg('SIMILARITY ({} {} {} M>{}): Computing {:>5} {} ({}) comparisons and saving entries in matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        total_distances // sim_unit, sim_lb, total_distances\n",
    "    ))\n",
    "\n",
    "    chunk_dist = {}\n",
    "    wc = 0\n",
    "    wt = 0\n",
    "    if SIMILARITY_METHOD == 'SET':\n",
    "        # method SET: all chunks have been reduced to sets, ratio between lengths of intersection and union\n",
    "        for i in range(total_chunks):\n",
    "            c_i = chunk_data[i]\n",
    "            for j in range(i + 1, total_chunks):\n",
    "                c_j = chunk_data[j]\n",
    "                u = len(c_i | c_j)\n",
    "                d = 100 * len(c_i & c_j) / u if u != 0 else 0\n",
    "                if d >= MATRIX_THRESHOLD:\n",
    "                    chunk_dist[(i,j)] = d\n",
    "                wc += 1\n",
    "                wt += 1\n",
    "                if wc == SIMILARITY_PROGRESS:\n",
    "                    wc = 0\n",
    "                    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} comparisons and saved {} entries in matrix'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "                        wt // sim_unit, sim_lb, len(chunk_dist),\n",
    "                    ))\n",
    "    elif SIMILARITY_METHOD == 'LCS':\n",
    "        # method LCS: chunks are sequence aligned, ratio between length of all common parts and total length\n",
    "        for i in range(total_chunks):\n",
    "            c_i = chunk_data[i]\n",
    "            for j in range(i + 1, total_chunks):\n",
    "                c_j = chunk_data[j]\n",
    "                d = 100 * ratio(c_i, c_j)\n",
    "                if d >= MATRIX_THRESHOLD:\n",
    "                    chunk_dist[(i,j)] = d\n",
    "                wc += 1\n",
    "                wt += 1\n",
    "                if wc == SIMILARITY_PROGRESS:\n",
    "                    wc = 0\n",
    "                    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} comparisons and saved {} entries in matrix'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "                        wt // sim_unit, sim_lb, len(chunk_dist),\n",
    "                    ))\n",
    "\n",
    "    with  open(matrix_path, 'wb') as f: pickle.dump(chunk_dist, f, protocol=PICKLE_PROTOCOL)\n",
    "        \n",
    "    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} ({}) comparisons and saved {} entries in matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        wt // sim_unit, sim_lb, wt, len(chunk_dist),\n",
    "    ))\n",
    "    \n",
    "    meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "    similarity_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Cliques\n",
    "\n",
    "Based on the value for the ``SIMILARITY_THRESHOLD`` we use the similarity matrix to pick the *interesting*\n",
    "similar pairs out of it. From these pairs we lump together our cliques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def key_chunk(i):\n",
    "    c = chunks[i]\n",
    "    w = c[0]\n",
    "    return  (-len(c), L.u('book', w), L.u('chapter', w), L.u('verse', w))\n",
    "\n",
    "def meta_clique_pre():\n",
    "    global similars, passages\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): inspecting the similarity matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    ))\n",
    "    similars = {x for x in chunk_dist if chunk_dist[x] >= SIMILARITY_THRESHOLD}\n",
    "    passage_set = set()\n",
    "    for (i,j) in similars:\n",
    "        passage_set.add(i)\n",
    "        passage_set.add(j)\n",
    "    passages = sorted(passage_set, key=key_chunk)\n",
    "\n",
    "    meta['# SIMILAR COMPARISONS'] = len(similars)\n",
    "    meta['# SIMILAR PASSAGES'] = len(passages)    \n",
    "\n",
    "def meta_clique_pre2():\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): {} relevant similarities between {} passages'.format(\n",
    "    CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    len(similars), len(passages),\n",
    "))\n",
    "\n",
    "\n",
    "def meta_clique_post():\n",
    "    global l_c_l\n",
    "    meta['# CLIQUES'] = len(cliques)\n",
    "    scliques = collections.Counter()\n",
    "    for c in cliques:\n",
    "        scliques[len(c)] += 1\n",
    "    l_c_l = max(scliques.keys()) if len(scliques) > 0 else 0\n",
    "    totmn = 0\n",
    "    totcn = 0\n",
    "    for (ln, n) in sorted(scliques.items(), key=lambda x: x[0]):\n",
    "        totmn += ln * n\n",
    "        totcn += n\n",
    "        if VERBOSE:\n",
    "            msg('CLIQUES ({} {} {} M>{} S>{}): {:>4} cliques of length {:>4}'.format(\n",
    "                CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                n, ln,\n",
    "            ))\n",
    "        meta['# CLIQUES of LENGTH {:>4}'.format(ln)] = n\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): {} members in {} cliques'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        totmn, totcn,\n",
    "    ))\n",
    "    \n",
    "def cliqueing(do_clique):\n",
    "    global cliques\n",
    "    if not do_clique:\n",
    "        msg('CLIQUES ({} {} {} M>{} S>{}): Already loaded {} cliques out of {} candidates from {} comparisons'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(cliques), len(passages), len(similars),            \n",
    "        ))\n",
    "        meta_clique_pre2()\n",
    "        meta_clique_post()\n",
    "        return\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): fetching similars and chunk candidates'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,        \n",
    "    ))\n",
    "    meta_clique_pre()\n",
    "    meta_clique_pre2()\n",
    "    clique_path = '{}/{}/clique_{}_{}_{}_{}_{}'.format(\n",
    "        LOCAL_BASE_COMP, STORED_CLIQUE_DIR,\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    )\n",
    "    if os.path.exists(clique_path):\n",
    "        with open(clique_path, 'rb') as f: cliques = pickle.load(f)\n",
    "        msg('CLIQUES ({} {} {} M>{} S>{}): Loaded: {:>5} cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(cliques), len(passages), len(similars),            \n",
    "        ))\n",
    "        meta_clique_post()\n",
    "        return\n",
    "\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): Composing cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(passages), len(similars),            \n",
    "    ))\n",
    "    cliques_unsorted = []\n",
    "    np = 0\n",
    "    npc = 0\n",
    "    for i in passages:\n",
    "        added = None\n",
    "        removable = set()\n",
    "        for (k, c) in enumerate(cliques_unsorted):\n",
    "            origc = tuple(c)\n",
    "            for j in origc:            \n",
    "                d = chunk_dist.get((i,j), 0) if i < j else chunk_dist.get((j,i), 0) if j < i else 0\n",
    "                if d >= SIMILARITY_THRESHOLD:\n",
    "                    if added == None:\n",
    "                        c.add(i)\n",
    "                        added = k\n",
    "                    else:\n",
    "                        cliques_unsorted[added] |= c\n",
    "                        removable.add(k)\n",
    "                    break\n",
    "        if added == None:\n",
    "            cliques_unsorted.append({i})\n",
    "        else:\n",
    "            if len(removable):\n",
    "                cliques_unsorted = [c for (k,c) in enumerate(cliques_unsorted) if k not in removable]\n",
    "        np += 1\n",
    "        npc += 1\n",
    "        if npc == CLIQUES_PROGRESS:\n",
    "            npc = 0\n",
    "            msg('CLIQUES ({} {} {} M>{} S>{}): Composed {:>5} cliques out of {:>6} chunks'.format(\n",
    "                CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                len(cliques_unsorted), np,\n",
    "            ))\n",
    "    cliques = sorted([tuple(sorted(c, key=key_chunk)) for c in cliques_unsorted])\n",
    "    with  open(clique_path, 'wb') as f: pickle.dump(cliques, f, protocol=PICKLE_PROTOCOL)\n",
    "    meta_clique_post()\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): Composed and saved {:>5} cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(cliques), len(passages), len(similars),            \n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty output\n",
    "\n",
    "Here are the definitions for formatting the (HTML) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "css = '''\n",
    "td.vl {\n",
    "    font-family: Verdana, Arial, sans-serif;\n",
    "    font-size: small;\n",
    "    text-align: right;\n",
    "    color: #aaaaaa;\n",
    "    width: 10%;\n",
    "    direction: ltr;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "td.ht {\n",
    "    font-family: Ezra SIL, SBL Hebrew, Verdana, sans-serif;\n",
    "    font-size: x-large;\n",
    "    line-height: 1.7;\n",
    "    text-align: right;\n",
    "    direction: rtl;\n",
    "}\n",
    "table.ht {\n",
    "    width: 100%;\n",
    "    direction: rtl;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    "td.ht {\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "tr.ht.tb {\n",
    "    border-top: 2px solid #aaaaaa;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "tr.ht.bb {\n",
    "    border-bottom: 2px solid #aaaaaa;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "span.m {\n",
    "    background-color: #aaaaff;\n",
    "}\n",
    "span.f {\n",
    "    background-color: #ffaaaa;\n",
    "}\n",
    "span.x {\n",
    "    background-color: #ffffaa;\n",
    "    color: #bb0000;\n",
    "}\n",
    "span.delete {\n",
    "    background-color: #ffaaaa;\n",
    "}\n",
    "span.insert {\n",
    "    background-color: #aaffaa;\n",
    "}\n",
    "span.replace {\n",
    "    background-color: #ffff00;\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "diffhead = '''\n",
    "<head>\n",
    "    <meta http-equiv=\"Content-Type\"\n",
    "          content=\"text/html; charset=UTF-8\" />\n",
    "    <title></title>\n",
    "    <style type=\"text/css\">\n",
    "        table.diff {\n",
    "            font-family: Ezra SIL, SBL Hebrew, Verdana, sans-serif; \n",
    "            font-size: x-large;\n",
    "            text-align: right;\n",
    "        }\n",
    "        .diff_header {background-color:#e0e0e0}\n",
    "        td.diff_header {text-align:right}\n",
    "        .diff_next {background-color:#c0c0c0}\n",
    "        .diff_add {background-color:#aaffaa}\n",
    "        .diff_chg {background-color:#ffff77}\n",
    "        .diff_sub {background-color:#ffaaaa}\n",
    "    </style>\n",
    "</head>\n",
    "'''\n",
    "\n",
    "def xterse_chunk(i):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = L.u('book', fword)\n",
    "    chapter = L.u('chapter', fword)\n",
    "    return (book, chapter)\n",
    "\n",
    "def xterse_clique(ii):\n",
    "    return tuple(sorted({xterse_chunk(i) for i in ii}))\n",
    "\n",
    "def terse_chunk(i):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = L.u('book', fword)\n",
    "    chapter = L.u('chapter', fword)\n",
    "    verse = L.u('verse', fword)\n",
    "    return (book, chapter, verse)\n",
    "\n",
    "def terse_clique(ii):\n",
    "    return tuple(sorted({terse_chunk(i) for i in ii}))\n",
    "\n",
    "def verse_chunk(i):\n",
    "    (bk, ch, vs) = i\n",
    "    book = F.book.v(bk)\n",
    "    chapter = F.chapter.v(ch)\n",
    "    verse = F.verse.v(vs)\n",
    "    text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in L.d('word', vs))\n",
    "    verse_label = '<td class=\"vl\">{} {}:{}</td>'.format(book, chapter, verse)\n",
    "    htext = '{}<td class=\"ht\">{}</td>'.format(verse_label, text)\n",
    "    return '<tr class=\"ht\">{}</tr>'.format(htext)\n",
    "\n",
    "def verse_clique(ii):\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(verse_chunk(i) for i in sorted(ii)))\n",
    "\n",
    "def condense(vlabels):\n",
    "    cnd = ''\n",
    "    (cur_b, cur_c) = (None, None)\n",
    "    for (b, c, v) in vlabels:\n",
    "        sep = '' if cur_b == None else '. ' if cur_b != b else '; ' if cur_c != c else ', '\n",
    "        show_b = b+' ' if cur_b != b else ''\n",
    "        show_c = c+':' if cur_b != b or cur_c != c else ''\n",
    "        (cur_b, cur_c) = (b, c)\n",
    "        cnd += '{}{}{}{}'.format(sep, show_b, show_c, v)\n",
    "    return cnd\n",
    "\n",
    "def print_diff(a, b):\n",
    "    arep = ''\n",
    "    brep = ''\n",
    "    for (lb, ai, aj, bi, bj) in SequenceMatcher(isjunk=None, a=a, b=b, autojunk=False).get_opcodes():\n",
    "        if lb == 'equal':\n",
    "            arep += a[ai:aj]\n",
    "            brep += b[bi:bj]\n",
    "        elif lb == 'delete':\n",
    "            arep += '<span class=\"{}\">{}</span>'.format(lb, a[ai:aj])\n",
    "        elif lb == 'insert':\n",
    "            brep += '<span class=\"{}\">{}</span>'.format(lb, b[bi:bj])\n",
    "        else:\n",
    "            arep += '<span class=\"{}\">{}</span>'.format(lb, a[ai:aj])\n",
    "            brep += '<span class=\"{}\">{}</span>'.format(lb, b[bi:bj])\n",
    "    return (arep, brep)\n",
    "    \n",
    "def print_chunk_fine(prev, text, verse_labels, prevlabels):\n",
    "    if prev == None:\n",
    "        return '''\n",
    "<tr class=\"ht tb bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "            condense(verse_labels), \n",
    "            text,\n",
    "        )\n",
    "    else:\n",
    "        (prevline, textline) = print_diff(prev, text)\n",
    "        return '''\n",
    "<tr class=\"ht tb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "<tr class=\"ht bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "    condense(prevlabels) if prevlabels != None else 'previous',\n",
    "    prevline,\n",
    "    condense(verse_labels), \n",
    "    textline,\n",
    ")\n",
    "\n",
    "def print_chunk_coarse(text, verse_labels):\n",
    "    return '''\n",
    "<tr class=\"ht tb bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "            condense(verse_labels), \n",
    "            text,\n",
    "        )\n",
    "\n",
    "def print_clique(ii, ncliques):\n",
    "    return print_clique_fine(ii) if len(ii) < ncliques * DEP_CLIQUE_RATIO / 100 else print_clique_coarse(ii)\n",
    "    \n",
    "def print_clique_fine(ii):\n",
    "    condensed = collections.OrderedDict()\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c)):\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in chunk)\n",
    "        condensed.setdefault(text, []).append((book, chapter, verse))\n",
    "    result = []\n",
    "    nv = len(condensed.items())\n",
    "    prev = None\n",
    "    for (text, verse_labels) in condensed.items():\n",
    "        if prev == None:\n",
    "            if nv == 1: result.append(print_chunk_fine(None, text, verse_labels, None))\n",
    "            else:\n",
    "                prev = text\n",
    "                prevlabels = verse_labels\n",
    "                continue\n",
    "        else:\n",
    "            result.append(print_chunk_fine(prev, text, verse_labels, prevlabels))\n",
    "            prev = text\n",
    "            prevlabels = None\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(result))\n",
    "\n",
    "def print_clique_coarse(ii):\n",
    "    condensed = collections.OrderedDict()\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c))[0:LARGE_CLIQUE_SIZE]:\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in chunk)\n",
    "        condensed.setdefault(text, []).append((book, chapter, verse))\n",
    "    result = []\n",
    "    nv = len(condensed.items())\n",
    "    prev = None\n",
    "    for (text, verse_labels) in condensed.items():\n",
    "        result.append(print_chunk_coarse(text, verse_labels))\n",
    "    if len(ii) > LARGE_CLIQUE_SIZE:\n",
    "        result.append(print_chunk_coarse('+ {} ...'.format(len(ii) - LARGE_CLIQUE_SIZE),[]))\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(result))\n",
    "\n",
    "def index_clique(bnm, n, ii, ncliques):\n",
    "    return index_clique_fine(bnm, n, ii) if len(ii) < ncliques * DEP_CLIQUE_RATIO / 100 else index_clique_coarse(bnm, n, ii)\n",
    "    \n",
    "def index_clique_fine(bnm, n, ii):\n",
    "    verse_labels = []\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c)):\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        verse_labels.append((book, chapter, verse))\n",
    "        reffl = '{}_{}'.format(bnm, n // CLIQUES_PER_FILE)\n",
    "    return '<p><b>{}</b> <a href=\"{}.html#c_{}\">{}</a></p>'.format(\n",
    "        n, reffl, n, condense(verse_labels),\n",
    "    )\n",
    "\n",
    "def index_clique_coarse(bnm, n, ii):\n",
    "    verse_labels = []\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c))[0:LARGE_CLIQUE_SIZE]:\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        verse_labels.append((book, chapter, verse))\n",
    "        reffl = '{}_{}'.format(bnm, n // CLIQUES_PER_FILE)\n",
    "    extra = '+ {} ...'.format(len(ii) - LARGE_CLIQUE_SIZE) if len(ii) > LARGE_CLIQUE_SIZE else ''\n",
    "    return '<p><b>{}</b> <a href=\"{}.html#c_{}\">{}{}</a></p>'.format(\n",
    "        n, reffl, n, condense(verse_labels), extra,\n",
    "    )\n",
    "\n",
    "def lines_chapter(c):\n",
    "    lines = []\n",
    "    for v in L.d('verse', c):\n",
    "        vl = F.verse.v(v)\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in L.d('word', v))\n",
    "        lines.append('{} {}'.format(vl, text.replace('\\n', ' ')))\n",
    "    return lines\n",
    "\n",
    "def compare_chapters(c1, c2, lb1, lb2):\n",
    "    dh = difflib.HtmlDiff(wrapcolumn=80)\n",
    "    table_html = dh.make_table(\n",
    "        lines_chapter(c1), \n",
    "        lines_chapter(c2), \n",
    "        fromdesc=lb1, \n",
    "        todesc=lb2, \n",
    "        context=False, \n",
    "        numlines=5,\n",
    "    )\n",
    "    htext = '''<html>{}<body>{}</body></html>'''.format(diffhead, table_html)\n",
    "    return htext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assess_exp(cf, np, nc, ll):\n",
    "    return 'out' if cf else \\\n",
    "    'rec' if ll > nc * REC_CLIQUE_RATIO / 100 and ll <= nc * DUB_CLIQUE_RATIO / 100 else \\\n",
    "    'dep' if ll > nc * DEP_CLIQUE_RATIO / 100 else \\\n",
    "    'dub' if ll > nc * DUB_CLIQUE_RATIO / 100 else \\\n",
    "    'nor'\n",
    "\n",
    "def printing():\n",
    "    global outputs, bin_cliques, base_name\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): sorting out cliques'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    ))\n",
    "    xt_cliques = {xterse_clique(c) for c in cliques}     # chapter cliques as tuples of (b, ch) tuples\n",
    "    bin_cliques = {c for c in xt_cliques if len(c) == 2} # chapter cliques with exactly two chapters\n",
    "    # all chapters that occur in binary chapter cliques\n",
    "    bin_chapters = {c[0] for c in bin_cliques} | {c[1] for c in bin_cliques}\n",
    "    meta['# BINARY CHAPTER DIFFS'] = len(bin_cliques)\n",
    "\n",
    "    # We generate one kind of info for binary chapter cliques (the majority of cases).\n",
    "    # The remaining cases are verse cliques that do not occur in such chapters, e.g. because they\n",
    "    # have member chunks in the same chapter, or in multiple (more than two) chapters.\n",
    "    \n",
    "    ncliques = len(cliques)\n",
    "    chapters_ok = assess_exp(CHUNK_FIXED, len(passages), ncliques, l_c_l) in {'rec', 'nor', 'dub'}\n",
    "    cdoing = 'involving' if chapters_ok else 'skipping'\n",
    "\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): formatting {} cliques {} {} binary chapter diffs'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        ncliques, cdoing, len(bin_cliques),\n",
    "    ))\n",
    "    meta_html = '\\n'.join('{:<40} : {:>10}'.format(k, str(meta[k])) for k in meta)\n",
    "\n",
    "    base_name = '{}_{}_{}_M{}_S{}'.format(\n",
    "        CHUNK_LB,\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD,\n",
    "        MATRIX_THRESHOLD,\n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    param_spec = '''\n",
    "<table>\n",
    "<tr><th>chunking method</th><td>{}</td></tr>\n",
    "<tr><th>chunking description</th><td>{}</td></tr>\n",
    "<tr><th>similarity method</th><td>{}</td></tr>\n",
    "<tr><th>similarity threshold</th><td>{}</td></tr>\n",
    "</table>\n",
    "    '''.format(\n",
    "        CHUNK_LABELS[CHUNK_FIXED],\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD, \n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    param_lab = 'chunk-{}-{}-sim-{}-m{}-s{}'.format(\n",
    "        CHUNK_LB,\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD,\n",
    "        MATRIX_THRESHOLD,\n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    index_name = base_name\n",
    "    all_name = '{}_{}'.format('all', base_name)\n",
    "    cliques_name = '{}_{}'.format('clique', base_name)\n",
    "\n",
    "    clique_links = []\n",
    "    clique_links.append(('{}/{}.html'.format(base_name, all_name), 'Big list of all cliques'))\n",
    "\n",
    "    nexist = 0\n",
    "    nnew = 0\n",
    "    if chapters_ok:\n",
    "        chapter_diffs = []\n",
    "        msg('PRINT ({} {} {} M>{} S>{}): Chapter diffs needed: {}'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(bin_cliques),\n",
    "        ))\n",
    "\n",
    "        bcc_text = '<p>These results look good, so a binary chapter comparison has been generated</p>'\n",
    "        for cl in sorted(bin_cliques):\n",
    "            lb1 = '{} {}'.format(F.book.v(cl[0][0]), F.chapter.v(cl[0][1]))\n",
    "            lb2 = '{} {}'.format(F.book.v(cl[1][0]), F.chapter.v(cl[1][1]))\n",
    "            hfilename = '{}_vs_{}.html'.format(lb1, lb2).replace(' ','_')\n",
    "            hfilepath = '{}/{}/{}'.format(LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename)\n",
    "            chapter_diffs.append((lb1, cl[0][1], lb2, cl[1][1], '{}/{}/{}/{}'.format(\n",
    "                SHEBANQ_TOOL, LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename,\n",
    "            )))\n",
    "            if not os.path.exists(hfilepath):\n",
    "                htext = compare_chapters(cl[0][1], cl[1][1], lb1, lb2)\n",
    "                with open(hfilepath, 'w') as f: f.write(htext)\n",
    "                if VERBOSE:\n",
    "                    msg('PRINT ({} {} {} M>{} S>{}): written {}'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                        hfilename,\n",
    "                    ))\n",
    "                nnew += 1\n",
    "            else:\n",
    "                nexist += 1\n",
    "            clique_links.append((\n",
    "                '../{}/{}'.format(CHAPTER_DIR, hfilename), \n",
    "                '{} versus {}'.format(lb1, lb2),\n",
    "            ))\n",
    "        msg('PRINT ({} {} {} M>{} S>{}): Chapter diffs: {} newly created and {} already existing'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            nnew, nexist,\n",
    "        ))\n",
    "    else:\n",
    "        bcc_text = '<p>These results look dubious at best, so no binary chapter comparison has been generated</p>'\n",
    "\n",
    "\n",
    "    allgeni_html = (index_clique(cliques_name, i, c, ncliques) for (i,c) in enumerate(cliques))\n",
    "    \n",
    "    allgen_htmls = []\n",
    "    allgen_html = ''\n",
    "    \n",
    "    for (i, c) in enumerate(cliques):\n",
    "        if i % CLIQUES_PER_FILE == 0:\n",
    "            if i > 0:\n",
    "                allgen_htmls.append(allgen_html)\n",
    "            allgen_html = ''\n",
    "        allgen_html += '<h3><a name=\"c_{}\">Clique {}</a></h3>\\n{}'.format(i, i, print_clique(c, ncliques))\n",
    "    allgen_htmls.append(allgen_html)\n",
    "\n",
    "    index_html_tpl = '''\n",
    "{}\n",
    "<h1>Binary chapter comparisons</h1>\n",
    "{}\n",
    "{}\n",
    "    '''\n",
    "\n",
    "    content_file_tpl = '''<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
    "<title>{}</title>\n",
    "<style type=\"text/css\">\n",
    "{}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>{}</h1>\n",
    "{}\n",
    "<p><a href=\"#meta\">more parameters and stats</a></p>\n",
    "{}\n",
    "<h1><a name=\"meta\">Parameters and stats</a></h1>\n",
    "<pre>{}</pre>\n",
    "</body>\n",
    "</html>'''\n",
    "    \n",
    "    a_tpl_file = '<p><a target=\"_blank\" href=\"{}\">{}</a></p>'\n",
    "\n",
    "    index_html_file = index_html_tpl.format(\n",
    "        a_tpl_file.format(*clique_links[0]),\n",
    "        bcc_text,\n",
    "        '\\n'.join(a_tpl_file.format(*c) for c in clique_links[1:]),\n",
    "    )\n",
    "\n",
    "    listing_html = '{}\\n'.format(\n",
    "        '\\n'.join(allgeni_html),\n",
    "    )\n",
    "\n",
    "    for (subdir, fname, content_html, tit) in (\n",
    "        (None, index_name, index_html_file, 'Index '+param_lab),\n",
    "        (base_name, all_name, listing_html, 'Listing '+param_lab),\n",
    "        (base_name, cliques_name, allgen_htmls, 'Cliques '+param_lab),\n",
    "    ): \n",
    "        subdir = '' if subdir == None else (subdir + '/')\n",
    "        subdirabs = '{}/{}/{}'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, subdir)\n",
    "        if not os.path.exists(subdirabs): os.makedirs(subdirabs)\n",
    "\n",
    "        if type(content_html) is list:\n",
    "            for (i, c_h) in enumerate(content_html):\n",
    "                fn = '{}_{}'.format(fname, i)\n",
    "                t = '{}_{}'.format(tit, i)\n",
    "                with open('{}/{}/{}{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, subdir, fn), 'w') as f: \n",
    "                    f.write(content_file_tpl.format(t, css, t, param_spec, c_h, meta_html))\n",
    "        else:\n",
    "            with open('{}/{}/{}{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, subdir, fname), 'w') as f: \n",
    "                f.write(content_file_tpl.format(tit, css, tit, param_spec, content_html, meta_html))\n",
    "    destination = outputs.setdefault(MATRIX_THRESHOLD, {})\n",
    "    destination[(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, SIMILARITY_THRESHOLD)] = (\n",
    "        len(passages), len(cliques), l_c_l,\n",
    "    )\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): formatted {} cliques ({} files) {} {} binary chapter diffs'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(cliques), len(allgen_htmls), cdoing, len(bin_cliques)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "\n",
    "def writeoutputs():\n",
    "    global outputs\n",
    "    with open(EXPERIMENT_PATH, 'wb') as f:\n",
    "        pickle.dump(outputs, f, protocol=PICKLE_PROTOCOL)\n",
    "\n",
    "def readoutputs():\n",
    "    global outputs\n",
    "    if not os.path.exists(EXPERIMENT_PATH):\n",
    "        outputs = {}\n",
    "    else:\n",
    "        with open(EXPERIMENT_PATH, 'rb') as f:\n",
    "            outputs = pickle.load(f)\n",
    "\n",
    "ecss = '''\n",
    "<style type=\"text/css\">\n",
    ".mis {background-color: #cccccc;}\n",
    ".rec {background-color: #aaffaa;}\n",
    ".dep {background-color: #ffaaaa;}\n",
    ".dub {background-color: #ffddaa;}\n",
    ".out {background-color: #ffddff;}\n",
    ".nor {background-color: #fcfcff;}\n",
    ".ps  {font-weight: normal;}\n",
    ".mx  {font-style: italic;}\n",
    ".cl  {font-weight: bold;}\n",
    ".lr  {font-weight: bold; background-color: #ffffaa;}\n",
    "p,td {font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: small;}\n",
    "td   {border: 1pt solid #000000; padding: 4pt;}\n",
    "table {border: 1pt solid #000000; border-collapse: collapse;}\n",
    "</style>\n",
    "'''\n",
    "\n",
    "legend = '''\n",
    "<table>\n",
    "<tr><td class=\"mis\">{mis}</td></tr>\n",
    "<tr><td class=\"rec\">{rec}</td></tr>\n",
    "<tr><td class=\"dep\">{dep}</td></tr>\n",
    "<tr><td class=\"dub\">{dub}</td></tr>\n",
    "<tr><td class=\"out\">{out}</td></tr>\n",
    "<tr><td class=\"nor\">{nor}</td></tr>\n",
    "</table>\n",
    "'''.format(**VALUE_LABELS)\n",
    "\n",
    "def gen_html(standalone=False):\n",
    "    global other_exps\n",
    "    msg('EXPERIMENT: Generating html report{}'.format('(standalone)' if standalone else ''))\n",
    "    stats = collections.Counter()\n",
    "    pre = '''\n",
    "<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
    "{}\n",
    "</head>\n",
    "<body>\n",
    "'''.format(ecss) if standalone else ''\n",
    "    \n",
    "    post = '''\n",
    "</body></html>\n",
    "''' if standalone else ''\n",
    "\n",
    "    experiments = '''\n",
    "{}\n",
    "{}\n",
    "<table>\n",
    "<tr><th>chunk type</th><th>chunk size</th><th>similarity method</th>{}</tr>\n",
    "'''.format(pre, legend, ''.join('<th>{}</th>'.format(sim_thr) for sim_thr in SIMILARITIES))\n",
    "    \n",
    "    for chunk_f in (True, False):\n",
    "        if chunk_f:\n",
    "            chunk_items = CHUNK_SIZES\n",
    "        else:\n",
    "            chunk_items = CHUNK_OBJECTS\n",
    "        chunk_lb = CHUNK_LBS[chunk_f]\n",
    "        for chunk_i in chunk_items:\n",
    "            for sim_m in SIM_METHODS:\n",
    "                set_matrix_threshold(sim_m=sim_m, chunk_o=chunk_i)\n",
    "                these_outputs = outputs.get(MATRIX_THRESHOLD, {})\n",
    "                experiments += '<tr><td>{}</td><td>{}</td><td>{}</td>'.format(\n",
    "                    CHUNK_LABELS[chunk_f], chunk_i, sim_m,\n",
    "                )\n",
    "                for sim_thr in SIMILARITIES:\n",
    "                    okey = (chunk_lb, chunk_i, sim_m, sim_thr)\n",
    "                    values = these_outputs.get(okey)\n",
    "                    if values == None:\n",
    "                        result = '<td class=\"mis\">&nbsp;</td>'\n",
    "                        stats['mis'] += 1\n",
    "                    else:\n",
    "                        (npassages, ncliques, longest_clique_len) = values\n",
    "                        cls = assess_exp(chunk_f, npassages, ncliques, longest_clique_len)\n",
    "                        stats[cls] += 1\n",
    "                        (lr_el, lr_lb) = ('', '')\n",
    "                        if (CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, SIMILARITY_THRESHOLD) == (\n",
    "                            chunk_lb, chunk_i, sim_m, sim_thr,\n",
    "                        ):\n",
    "                            lr_el = '<span class=\"lr\">*</span>'\n",
    "                            lr_lb = VALUE_LABELS['lr']\n",
    "                        result = '''\n",
    "<td class=\"{}\" title=\"{}\">{}\n",
    "    <span class=\"ps\">{}</span><br/>\n",
    "    <a target=\"_blank\" href=\"{}{}/{}_{}_{}_M{}_S{}.html\"><span class=\"cl\">{}</span></a><br/>\n",
    "    <span class=\"mx\">{}</span>\n",
    "    </td>'''.format(\n",
    "        cls, lr_lb, lr_el, npassages,\n",
    "        '' if standalone else LOCAL_BASE_OUTP+'/', \n",
    "        EXPERIMENT_DIR, chunk_lb, chunk_i, sim_m, MATRIX_THRESHOLD, sim_thr,\n",
    "        ncliques, longest_clique_len,\n",
    "    )\n",
    "                    experiments += result\n",
    "                experiments += '</tr>\\n'\n",
    "    experiments += '</table>\\n{}'.format(post)\n",
    "    if standalone:\n",
    "        with open(EXPERIMENT_HTML, 'w') as f:\n",
    "            f.write(experiments)\n",
    "    else:\n",
    "        other_exps = experiments\n",
    "\n",
    "    for stat in sorted(stats):\n",
    "        msg('EXPERIMENT: {:>3} {}'.format(stats[stat], VALUE_LABELS[stat]))\n",
    "    msg(\"EXPERIMENT: Generated html report\")\n",
    "\n",
    "def do_experiment(chunk_f, chunk_i, sim_m, sim_thr, do_index):\n",
    "    if do_index:\n",
    "        readoutputs()\n",
    "    (do_chunk, do_prep, do_sim, do_clique, skip) = do_params(chunk_f, chunk_i, sim_m, sim_thr)\n",
    "    if skip: return\n",
    "    chunking(do_chunk)\n",
    "    preparing(do_prep)\n",
    "    similarity(do_sim)\n",
    "    cliqueing(do_clique)\n",
    "    printing()\n",
    "    if do_index:\n",
    "        writeoutputs()\n",
    "        gen_html()\n",
    "    \n",
    "def reset_experiments():\n",
    "    global outputs\n",
    "    readoutputs()\n",
    "    outputs = {}\n",
    "    reset_params()\n",
    "    writeoutputs()\n",
    "    gen_html()\n",
    "\n",
    "def do_all_experiments(no_fixed=False, only_object=None):\n",
    "    global outputs\n",
    "    reset_experiments()\n",
    "    for chunk_f in (False,) if no_fixed else (True, False):\n",
    "        if chunk_f:\n",
    "            chunk_items = CHUNK_SIZES\n",
    "        else:\n",
    "            chunk_items = CHUNK_OBJECTS if only_object==None else (only_object,)\n",
    "        for chunk_i in chunk_items:\n",
    "            for sim_m in SIM_METHODS:\n",
    "                for sim_thr in SIMILARITIES:\n",
    "                    do_experiment(chunk_f, chunk_i, sim_m, sim_thr, False)\n",
    "    writeoutputs()\n",
    "    gen_html()\n",
    "    gen_html(standalone=True)\n",
    "    \n",
    "def show_all_experiments():\n",
    "    readoutputs()\n",
    "    gen_html()\n",
    "    gen_html(standalone=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHEBANQ references\n",
    "\n",
    "Based on selected similarity matrices, we produce a SHEBANQ note set of cross references for similar passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_verse(i, ca=False): return get_verse_w(chunks[i][0], ca=ca)\n",
    "\n",
    "def get_verse_o(o, ca=False): return get_verse_w(L.d('word', o)[0], ca=ca)\n",
    "\n",
    "def get_verse_w(w, ca=False):\n",
    "    book = F.book.v(L.u('book', w))\n",
    "    chapter = F.chapter.v(L.u('chapter', w))\n",
    "    verse = F.verse.v(L.u('verse', w))\n",
    "    if ca: ca = F.number.v(L.u('clause_atom', w))\n",
    "    return (book, chapter, verse, ca) if ca else (book, chapter, verse)\n",
    "\n",
    "def key_verse(x):\n",
    "    return  (book_rank[x[0]], int(x[1]), int(x[2]))\n",
    "\n",
    "MAX_REFS = 10\n",
    "\n",
    "def condensex(vlabels):\n",
    "    cnd = []\n",
    "    (cur_b, cur_c) = (None, None)\n",
    "    for (b, c, v, d) in vlabels:\n",
    "        sep = '' if cur_b == None else '. ' if cur_b != b else '; ' if cur_c != c else ', '\n",
    "        show_b = b+' ' if cur_b != b else ''\n",
    "        show_c = c+':' if cur_b != b or cur_c != c else ''\n",
    "        (cur_b, cur_c) = (b, c)\n",
    "        cnd.append('{}{}{}{}{}'.format(sep, show_b, show_c, v, d))\n",
    "    return cnd\n",
    "\n",
    "dfields = '''\n",
    "    book1\n",
    "    chapter1\n",
    "    verse1\n",
    "    book2\n",
    "    chapter2\n",
    "    verse2\n",
    "    similarity\n",
    "'''.strip().split()\n",
    "\n",
    "dfields_fmt = ('{}\\t' * (len(dfields) - 1)) + '{}\\n' \n",
    "\n",
    "def get_crossrefs():\n",
    "    global crossrefs\n",
    "    msg('CROSSREFS: Fetching crossrefs')\n",
    "    crossrefs_proto = {}\n",
    "    crossrefs = {}\n",
    "    (chunk_f, chunk_i, sim_m) = SHEBANQ_MATRIX\n",
    "    sim_thr = SHEBANQ_SIMILARITY\n",
    "    (do_chunk, do_prep, do_sim, do_clique, skip) = do_params(chunk_f, chunk_i, sim_m, sim_thr)\n",
    "    if skip: return\n",
    "    msg('CROSSREFS ({} {} {} S>{})'.format(CHUNK_LBS[chunk_f], chunk_i, sim_m, sim_thr))\n",
    "    crossrefs_proto = {x for x in chunk_dist.items() if x[1] >= sim_thr}\n",
    "    msg('CROSSREFS ({} {} {} S>{}): found {} pairs'.format(\n",
    "        CHUNK_LBS[chunk_f], chunk_i, sim_m, sim_thr,\n",
    "        len(crossrefs_proto),\n",
    "    ))\n",
    "    f = open(CROSSREF_DB_PATH, 'w')\n",
    "    f.write('{}\\n'.format('\\t'.join(dfields)))        \n",
    "    for ((x,y), d) in crossrefs_proto:\n",
    "        vx = get_verse(x)\n",
    "        vy = get_verse(y)\n",
    "        rd = int(round(d))\n",
    "        crossrefs.setdefault(x, {})[vy] = rd\n",
    "        crossrefs.setdefault(y, {})[vx] = rd\n",
    "        f.write(dfields_fmt.format(*(vx+vy+(rd,))))\n",
    "    total = sum(len(x) for x in crossrefs.values())\n",
    "    f.close()\n",
    "    msg('CROSSREFS: Found {} crossreferences and wrote {} pairs'.format(total, len(crossrefs_proto)))\n",
    "\n",
    "def compile_refs():\n",
    "    global refs_compiled\n",
    "    refs_grouped = []\n",
    "    for x in sorted(crossrefs):\n",
    "        refs = crossrefs[x]\n",
    "        vys = sorted(refs.keys(), key=key_verse)\n",
    "        currefs = []\n",
    "        for vy in vys:\n",
    "            nr = len(currefs)\n",
    "            if nr == MAX_REFS:\n",
    "                refs_grouped.append((x, tuple(currefs)))\n",
    "                currefs = []            \n",
    "            currefs.append(vy)\n",
    "        if len(currefs):\n",
    "            refs_grouped.append((x, tuple(currefs)))\n",
    "    refs_compiled = []\n",
    "    for (x, vys) in refs_grouped:\n",
    "        vysd = [(vy[0], vy[1], vy[2], ' ~{}%'.format(crossrefs[x][vy])) for vy in vys]\n",
    "        vysl = condensex(vysd)\n",
    "        these_refs = []\n",
    "        for (i, vy) in enumerate(vysd):\n",
    "            link_text = vysl[i]\n",
    "            link_target = '{} {}:{}'.format(vy[0], vy[1], vy[2])\n",
    "            these_refs.append('[{}]({})'.format(link_text, link_target))\n",
    "        refs_compiled.append((x, ' '.join(these_refs)))\n",
    "    msg('CROSSREFS: Compiled cross references into {} notes'.format(len(refs_compiled)))\n",
    "\n",
    "def get_chapter_diffs():\n",
    "    global chapter_diffs\n",
    "    chapter_diffs = []\n",
    "    for cl in sorted(bin_cliques):\n",
    "        lb1 = '{} {}'.format(F.book.v(cl[0][0]), F.chapter.v(cl[0][1]))\n",
    "        lb2 = '{} {}'.format(F.book.v(cl[1][0]), F.chapter.v(cl[1][1]))\n",
    "        hfilename = '{}_vs_{}.html'.format(lb1, lb2).replace(' ','_')\n",
    "        chapter_diffs.append((lb1, cl[0][1], lb2, cl[1][1], '{}/{}/{}/{}'.format(\n",
    "            SHEBANQ_TOOL, LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename,\n",
    "        )))\n",
    "    msg('CROSSREFS: Added {} chapter diffs'.format(2*len(chapter_diffs)))\n",
    "\n",
    "        \n",
    "def get_clique_refs():\n",
    "    global clique_refs\n",
    "    clique_refs = []\n",
    "    for (i, c) in enumerate(cliques):\n",
    "        for j in c:\n",
    "            seq = i // CLIQUES_PER_FILE\n",
    "            clique_refs.append((j, i, '{}/{}/{}/{}/clique_{}_{}.html#c_{}'.format(\n",
    "                SHEBANQ_TOOL, LOCAL_BASE_OUTP, EXPERIMENT_DIR, base_name, base_name, seq, i,\n",
    "            )))\n",
    "    msg('CROSSREFS: Added {} clique references'.format(len(clique_refs)))\n",
    "\n",
    "sfields = '''\n",
    "    version\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    clause_atom\n",
    "    is_shared\n",
    "    is_published\n",
    "    status\n",
    "    keywords\n",
    "    ntext\n",
    "'''.strip().split()\n",
    "\n",
    "sfields_fmt = ('{}\\t' * (len(sfields) - 1)) + '{}\\n' \n",
    "\n",
    "def generate_notes():\n",
    "    with open(NOTES_PATH, 'w') as f:\n",
    "        f.write('{}\\n'.format('\\t'.join(sfields)))        \n",
    "        x = next(F.otype.s('word'))\n",
    "        (bk, ch, vs, ca) = get_verse(x, ca=True)\n",
    "        f.write(sfields_fmt.format(\n",
    "            version,\n",
    "            bk,\n",
    "            ch,\n",
    "            vs,\n",
    "            ca,\n",
    "            'T',\n",
    "            '',\n",
    "            CROSSREF_STATUS,\n",
    "            CROSSREF_KEYWORD,\n",
    "            '''The crossref notes are the result of a computation without manual tweaks.\n",
    "Parameters: chunk by verse, similarity method SET with threshold 65.\n",
    "[Here](tool=parallel) is an account of the generation method.'''.replace('\\n', ' ')\n",
    "        ))\n",
    "        for (lb1, ch1, lb2, ch2, fl) in chapter_diffs:\n",
    "            (bk1, ch1, vs1, ca1) = get_verse_o(ch1, ca=True)\n",
    "            (bk2, ch2, vs2, ca2) = get_verse_o(ch2, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk1,\n",
    "                ch1,\n",
    "                vs1,\n",
    "                ca1,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                '[chapter diff with {}](tool:{})'.format(lb2, fl),\n",
    "            ))\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk2,\n",
    "                ch2,\n",
    "                vs2,\n",
    "                ca2,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                '[chapter diff with {}](tool:{})'.format(lb1, fl),\n",
    "            ))\n",
    "        for (x, refs) in refs_compiled:\n",
    "            (bk, ch, vs, ca) = get_verse(x, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk,\n",
    "                ch,\n",
    "                vs,\n",
    "                ca,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                refs,\n",
    "            ))\n",
    "        for (chunk, clique, fl) in clique_refs:\n",
    "            (bk, ch, vs, ca) = get_verse(chunk, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk,\n",
    "                ch,\n",
    "                vs,\n",
    "                ca,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                '[all variants (clique {})](tool:{})'.format(clique, fl),\n",
    "            ))\n",
    "\n",
    "    msg('CROSSREFS: Generated {} notes'.format(1+len(refs_compiled) + 2 * len(chapter_diffs) + len(clique_refs)))\n",
    "\n",
    "def crossrefs2shebanq():\n",
    "    expr = SHEBANQ_MATRIX + (SHEBANQ_SIMILARITY,)\n",
    "    do_experiment(*(expr+(True,)))\n",
    "    get_crossrefs()\n",
    "    compile_refs()\n",
    "    get_chapter_diffs()\n",
    "    get_clique_refs()\n",
    "    generate_notes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47m 30s EXPERIMENT: Generating html report\n",
      "47m 30s EXPERIMENT: 240 no results available\n",
      "47m 30s EXPERIMENT: Generated html report\n",
      "47m 30s CHUNKING (F 100)\n",
      "47m 32s CHUNKING (F 100): Made 4244 chunks\n",
      "47m 32s PREPARING (F 100 SET)\n",
      "47m 32s PREPARING (F 100 SET): Done 4244 chunks.\n",
      "47m 32s SIMILARITY (F 100 SET M>50): Loaded:  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 32s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>100): fetching similars and chunk candidates\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>100): inspecting the similarity matrix\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>100): 1 relevant similarities between 2 passages\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>100): Loaded:     1 cliques out of      2 chunks from 1 comparisons\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>100): 2 members in 1 cliques\n",
      "47m 32s PRINT (F 100 SET M>50 S>100): sorting out cliques\n",
      "47m 32s PRINT (F 100 SET M>50 S>100): formatting 1 cliques skipping 1 binary chapter diffs\n",
      "47m 32s PRINT (F 100 SET M>50 S>100): formatted 1 cliques (1 files) skipping 1 binary chapter diffs\n",
      "47m 32s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 32s PREPARING (F 100 SET): Already prepared\n",
      "47m 32s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 32s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>95): fetching similars and chunk candidates\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>95): inspecting the similarity matrix\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>95): 2 relevant similarities between 4 passages\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>95): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>95): 4 members in 2 cliques\n",
      "47m 32s PRINT (F 100 SET M>50 S>95): sorting out cliques\n",
      "47m 32s PRINT (F 100 SET M>50 S>95): formatting 2 cliques skipping 2 binary chapter diffs\n",
      "47m 32s PRINT (F 100 SET M>50 S>95): formatted 2 cliques (1 files) skipping 2 binary chapter diffs\n",
      "47m 32s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 32s PREPARING (F 100 SET): Already prepared\n",
      "47m 32s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 32s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>90): fetching similars and chunk candidates\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>90): inspecting the similarity matrix\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>90): 9 relevant similarities between 18 passages\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>90): Loaded:     9 cliques out of     18 chunks from 9 comparisons\n",
      "47m 32s CLIQUES (F 100 SET M>50 S>90): 18 members in 9 cliques\n",
      "47m 32s PRINT (F 100 SET M>50 S>90): sorting out cliques\n",
      "47m 32s PRINT (F 100 SET M>50 S>90): formatting 9 cliques skipping 3 binary chapter diffs\n",
      "47m 33s PRINT (F 100 SET M>50 S>90): formatted 9 cliques (1 files) skipping 3 binary chapter diffs\n",
      "47m 33s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 33s PREPARING (F 100 SET): Already prepared\n",
      "47m 33s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 33s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>85): fetching similars and chunk candidates\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>85): inspecting the similarity matrix\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>85): 19 relevant similarities between 37 passages\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>85): Loaded:    18 cliques out of     37 chunks from 19 comparisons\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>85): 37 members in 18 cliques\n",
      "47m 33s PRINT (F 100 SET M>50 S>85): sorting out cliques\n",
      "47m 33s PRINT (F 100 SET M>50 S>85): formatting 18 cliques skipping 6 binary chapter diffs\n",
      "47m 33s PRINT (F 100 SET M>50 S>85): formatted 18 cliques (1 files) skipping 6 binary chapter diffs\n",
      "47m 33s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 33s PREPARING (F 100 SET): Already prepared\n",
      "47m 33s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 33s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>80): fetching similars and chunk candidates\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>80): inspecting the similarity matrix\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>80): 35 relevant similarities between 64 passages\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>80): Loaded:    30 cliques out of     64 chunks from 35 comparisons\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>80): 64 members in 30 cliques\n",
      "47m 33s PRINT (F 100 SET M>50 S>80): sorting out cliques\n",
      "47m 33s PRINT (F 100 SET M>50 S>80): formatting 30 cliques skipping 10 binary chapter diffs\n",
      "47m 33s PRINT (F 100 SET M>50 S>80): formatted 30 cliques (1 files) skipping 10 binary chapter diffs\n",
      "47m 33s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 33s PREPARING (F 100 SET): Already prepared\n",
      "47m 33s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 33s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>75): fetching similars and chunk candidates\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>75): inspecting the similarity matrix\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>75): 63 relevant similarities between 87 passages\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>75): Loaded:    40 cliques out of     87 chunks from 63 comparisons\n",
      "47m 33s CLIQUES (F 100 SET M>50 S>75): 87 members in 40 cliques\n",
      "47m 33s PRINT (F 100 SET M>50 S>75): sorting out cliques\n",
      "47m 33s PRINT (F 100 SET M>50 S>75): formatting 40 cliques skipping 16 binary chapter diffs\n",
      "47m 34s PRINT (F 100 SET M>50 S>75): formatted 40 cliques (1 files) skipping 16 binary chapter diffs\n",
      "47m 34s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 34s PREPARING (F 100 SET): Already prepared\n",
      "47m 34s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 34s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 34s CLIQUES (F 100 SET M>50 S>70): fetching similars and chunk candidates\n",
      "47m 34s CLIQUES (F 100 SET M>50 S>70): inspecting the similarity matrix\n",
      "47m 34s CLIQUES (F 100 SET M>50 S>70): 87 relevant similarities between 113 passages\n",
      "47m 34s CLIQUES (F 100 SET M>50 S>70): Loaded:    52 cliques out of    113 chunks from 87 comparisons\n",
      "47m 34s CLIQUES (F 100 SET M>50 S>70): 113 members in 52 cliques\n",
      "47m 34s PRINT (F 100 SET M>50 S>70): sorting out cliques\n",
      "47m 34s PRINT (F 100 SET M>50 S>70): formatting 52 cliques skipping 21 binary chapter diffs\n",
      "47m 35s PRINT (F 100 SET M>50 S>70): formatted 52 cliques (2 files) skipping 21 binary chapter diffs\n",
      "47m 35s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 35s PREPARING (F 100 SET): Already prepared\n",
      "47m 35s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 35s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 35s CLIQUES (F 100 SET M>50 S>65): fetching similars and chunk candidates\n",
      "47m 35s CLIQUES (F 100 SET M>50 S>65): inspecting the similarity matrix\n",
      "47m 35s CLIQUES (F 100 SET M>50 S>65): 115 relevant similarities between 154 passages\n",
      "47m 35s CLIQUES (F 100 SET M>50 S>65): Loaded:    70 cliques out of    154 chunks from 115 comparisons\n",
      "47m 35s CLIQUES (F 100 SET M>50 S>65): 154 members in 70 cliques\n",
      "47m 35s PRINT (F 100 SET M>50 S>65): sorting out cliques\n",
      "47m 35s PRINT (F 100 SET M>50 S>65): formatting 70 cliques skipping 28 binary chapter diffs\n",
      "47m 36s PRINT (F 100 SET M>50 S>65): formatted 70 cliques (2 files) skipping 28 binary chapter diffs\n",
      "47m 36s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 36s PREPARING (F 100 SET): Already prepared\n",
      "47m 36s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 36s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 36s CLIQUES (F 100 SET M>50 S>60): fetching similars and chunk candidates\n",
      "47m 36s CLIQUES (F 100 SET M>50 S>60): inspecting the similarity matrix\n",
      "47m 36s CLIQUES (F 100 SET M>50 S>60): 148 relevant similarities between 208 passages\n",
      "47m 36s CLIQUES (F 100 SET M>50 S>60): Loaded:    94 cliques out of    208 chunks from 148 comparisons\n",
      "47m 36s CLIQUES (F 100 SET M>50 S>60): 208 members in 94 cliques\n",
      "47m 36s PRINT (F 100 SET M>50 S>60): sorting out cliques\n",
      "47m 36s PRINT (F 100 SET M>50 S>60): formatting 94 cliques skipping 35 binary chapter diffs\n",
      "47m 37s PRINT (F 100 SET M>50 S>60): formatted 94 cliques (2 files) skipping 35 binary chapter diffs\n",
      "47m 37s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 37s PREPARING (F 100 SET): Already prepared\n",
      "47m 37s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 37s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 37s CLIQUES (F 100 SET M>50 S>55): fetching similars and chunk candidates\n",
      "47m 37s CLIQUES (F 100 SET M>50 S>55): inspecting the similarity matrix\n",
      "47m 37s CLIQUES (F 100 SET M>50 S>55): 225 relevant similarities between 309 passages\n",
      "47m 37s CLIQUES (F 100 SET M>50 S>55): Composing cliques out of    309 chunks from 225 comparisons\n",
      "47m 38s CLIQUES (F 100 SET M>50 S>55): 309 members in 138 cliques\n",
      "47m 38s CLIQUES (F 100 SET M>50 S>55): Composed and saved   138 cliques out of    309 chunks from 225 comparisons\n",
      "47m 38s PRINT (F 100 SET M>50 S>55): sorting out cliques\n",
      "47m 38s PRINT (F 100 SET M>50 S>55): formatting 138 cliques skipping 54 binary chapter diffs\n",
      "47m 40s PRINT (F 100 SET M>50 S>55): formatted 138 cliques (3 files) skipping 54 binary chapter diffs\n",
      "47m 40s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 40s PREPARING (F 100 SET): Already prepared\n",
      "47m 40s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 359 entries in matrix\n",
      "47m 40s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      "47m 40s CLIQUES (F 100 SET M>50 S>50): fetching similars and chunk candidates\n",
      "47m 40s CLIQUES (F 100 SET M>50 S>50): inspecting the similarity matrix\n",
      "47m 40s CLIQUES (F 100 SET M>50 S>50): 359 relevant similarities between 473 passages\n",
      "47m 40s CLIQUES (F 100 SET M>50 S>50): Composing cliques out of    473 chunks from 359 comparisons\n",
      "47m 40s CLIQUES (F 100 SET M>50 S>50): 473 members in 189 cliques\n",
      "47m 40s CLIQUES (F 100 SET M>50 S>50): Composed and saved   189 cliques out of    473 chunks from 359 comparisons\n",
      "47m 40s PRINT (F 100 SET M>50 S>50): sorting out cliques\n",
      "47m 40s PRINT (F 100 SET M>50 S>50): formatting 189 cliques skipping 75 binary chapter diffs\n",
      "47m 44s PRINT (F 100 SET M>50 S>50): formatted 189 cliques (4 files) skipping 75 binary chapter diffs\n",
      "47m 44s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 44s PREPARING (F 100 LCS)\n",
      "47m 45s PREPARING (F 100 LCS): Done 4244 chunks.\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): Loaded:  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>100): fetching similars and chunk candidates\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>100): inspecting the similarity matrix\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>100): 0 relevant similarities between 0 passages\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>100): 0 members in 0 cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>100): sorting out cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>100): formatting 0 cliques skipping 0 binary chapter diffs\n",
      "47m 45s PRINT (F 100 LCS M>60 S>100): formatted 0 cliques (1 files) skipping 0 binary chapter diffs\n",
      "47m 45s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 45s PREPARING (F 100 LCS): Already prepared\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>95): fetching similars and chunk candidates\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>95): inspecting the similarity matrix\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>95): 2 relevant similarities between 4 passages\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>95): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>95): 4 members in 2 cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>95): sorting out cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>95): formatting 2 cliques skipping 2 binary chapter diffs\n",
      "47m 45s PRINT (F 100 LCS M>60 S>95): formatted 2 cliques (1 files) skipping 2 binary chapter diffs\n",
      "47m 45s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 45s PREPARING (F 100 LCS): Already prepared\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>90): fetching similars and chunk candidates\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>90): inspecting the similarity matrix\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>90): 21 relevant similarities between 39 passages\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>90): Loaded:    19 cliques out of     39 chunks from 21 comparisons\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>90): 39 members in 19 cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>90): sorting out cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>90): formatting 19 cliques skipping 4 binary chapter diffs\n",
      "47m 45s PRINT (F 100 LCS M>60 S>90): formatted 19 cliques (1 files) skipping 4 binary chapter diffs\n",
      "47m 45s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 45s PREPARING (F 100 LCS): Already prepared\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 45s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>85): fetching similars and chunk candidates\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>85): inspecting the similarity matrix\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>85): 31 relevant similarities between 59 passages\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>85): Loaded:    29 cliques out of     59 chunks from 31 comparisons\n",
      "47m 45s CLIQUES (F 100 LCS M>60 S>85): 59 members in 29 cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>85): sorting out cliques\n",
      "47m 45s PRINT (F 100 LCS M>60 S>85): formatting 29 cliques skipping 10 binary chapter diffs\n",
      "47m 46s PRINT (F 100 LCS M>60 S>85): formatted 29 cliques (1 files) skipping 10 binary chapter diffs\n",
      "47m 46s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 46s PREPARING (F 100 LCS): Already prepared\n",
      "47m 46s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 46s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>80): fetching similars and chunk candidates\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>80): inspecting the similarity matrix\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>80): 46 relevant similarities between 85 passages\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>80): Loaded:    41 cliques out of     85 chunks from 46 comparisons\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>80): 85 members in 41 cliques\n",
      "47m 46s PRINT (F 100 LCS M>60 S>80): sorting out cliques\n",
      "47m 46s PRINT (F 100 LCS M>60 S>80): formatting 41 cliques skipping 16 binary chapter diffs\n",
      "47m 46s PRINT (F 100 LCS M>60 S>80): formatted 41 cliques (1 files) skipping 16 binary chapter diffs\n",
      "47m 46s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 46s PREPARING (F 100 LCS): Already prepared\n",
      "47m 46s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 46s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>75): fetching similars and chunk candidates\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>75): inspecting the similarity matrix\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>75): 77 relevant similarities between 122 passages\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>75): Loaded:    56 cliques out of    122 chunks from 77 comparisons\n",
      "47m 46s CLIQUES (F 100 LCS M>60 S>75): 122 members in 56 cliques\n",
      "47m 46s PRINT (F 100 LCS M>60 S>75): sorting out cliques\n",
      "47m 46s PRINT (F 100 LCS M>60 S>75): formatting 56 cliques skipping 25 binary chapter diffs\n",
      "47m 47s PRINT (F 100 LCS M>60 S>75): formatted 56 cliques (2 files) skipping 25 binary chapter diffs\n",
      "47m 47s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 47s PREPARING (F 100 LCS): Already prepared\n",
      "47m 47s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 47s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 47s CLIQUES (F 100 LCS M>60 S>70): fetching similars and chunk candidates\n",
      "47m 47s CLIQUES (F 100 LCS M>60 S>70): inspecting the similarity matrix\n",
      "47m 47s CLIQUES (F 100 LCS M>60 S>70): 123 relevant similarities between 189 passages\n",
      "47m 47s CLIQUES (F 100 LCS M>60 S>70): Loaded:    88 cliques out of    189 chunks from 123 comparisons\n",
      "47m 47s CLIQUES (F 100 LCS M>60 S>70): 189 members in 88 cliques\n",
      "47m 47s PRINT (F 100 LCS M>60 S>70): sorting out cliques\n",
      "47m 47s PRINT (F 100 LCS M>60 S>70): formatting 88 cliques skipping 38 binary chapter diffs\n",
      "47m 49s PRINT (F 100 LCS M>60 S>70): formatted 88 cliques (2 files) skipping 38 binary chapter diffs\n",
      "47m 49s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 49s PREPARING (F 100 LCS): Already prepared\n",
      "47m 49s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 49s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 49s CLIQUES (F 100 LCS M>60 S>65): fetching similars and chunk candidates\n",
      "47m 49s CLIQUES (F 100 LCS M>60 S>65): inspecting the similarity matrix\n",
      "47m 49s CLIQUES (F 100 LCS M>60 S>65): 182 relevant similarities between 287 passages\n",
      "47m 49s CLIQUES (F 100 LCS M>60 S>65): Loaded:   132 cliques out of    287 chunks from 182 comparisons\n",
      "47m 49s CLIQUES (F 100 LCS M>60 S>65): 287 members in 132 cliques\n",
      "47m 49s PRINT (F 100 LCS M>60 S>65): sorting out cliques\n",
      "47m 49s PRINT (F 100 LCS M>60 S>65): formatting 132 cliques skipping 55 binary chapter diffs\n",
      "47m 51s PRINT (F 100 LCS M>60 S>65): formatted 132 cliques (3 files) skipping 55 binary chapter diffs\n",
      "47m 51s CHUNKING (F 100): already chunked into 4244 chunks\n",
      "47m 51s PREPARING (F 100 LCS): Already prepared\n",
      "47m 51s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      "47m 51s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      "47m 51s CLIQUES (F 100 LCS M>60 S>60): fetching similars and chunk candidates\n",
      "47m 51s CLIQUES (F 100 LCS M>60 S>60): inspecting the similarity matrix\n",
      "47m 51s CLIQUES (F 100 LCS M>60 S>60): 393 relevant similarities between 535 passages\n",
      "47m 51s CLIQUES (F 100 LCS M>60 S>60): Loaded:   214 cliques out of    535 chunks from 393 comparisons\n",
      "47m 51s CLIQUES (F 100 LCS M>60 S>60): 535 members in 214 cliques\n",
      "47m 51s PRINT (F 100 LCS M>60 S>60): sorting out cliques\n",
      "47m 51s PRINT (F 100 LCS M>60 S>60): formatting 214 cliques skipping 100 binary chapter diffs\n",
      "47m 57s PRINT (F 100 LCS M>60 S>60): formatted 214 cliques (5 files) skipping 100 binary chapter diffs\n",
      "47m 57s CHUNKING (F 50)\n",
      "47m 58s CHUNKING (F 50): Made 8509 chunks\n",
      "47m 58s PREPARING (F 50 SET)\n",
      "47m 59s PREPARING (F 50 SET): Done 8509 chunks.\n",
      "47m 59s SIMILARITY (F 50 SET M>50): Loaded: 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "47m 59s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>100): fetching similars and chunk candidates\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>100): inspecting the similarity matrix\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>100): 0 relevant similarities between 0 passages\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>100): 0 members in 0 cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>100): sorting out cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>100): formatting 0 cliques skipping 0 binary chapter diffs\n",
      "47m 59s PRINT (F 50 SET M>50 S>100): formatted 0 cliques (1 files) skipping 0 binary chapter diffs\n",
      "47m 59s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "47m 59s PREPARING (F 50 SET): Already prepared\n",
      "47m 59s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "47m 59s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>95): fetching similars and chunk candidates\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>95): inspecting the similarity matrix\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>95): 2 relevant similarities between 4 passages\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>95): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>95): 4 members in 2 cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>95): sorting out cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>95): formatting 2 cliques skipping 2 binary chapter diffs\n",
      "47m 59s PRINT (F 50 SET M>50 S>95): formatted 2 cliques (1 files) skipping 2 binary chapter diffs\n",
      "47m 59s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "47m 59s PREPARING (F 50 SET): Already prepared\n",
      "47m 59s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "47m 59s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>90): fetching similars and chunk candidates\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>90): inspecting the similarity matrix\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>90): 12 relevant similarities between 24 passages\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>90): Loaded:    12 cliques out of     24 chunks from 12 comparisons\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>90): 24 members in 12 cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>90): sorting out cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>90): formatting 12 cliques skipping 4 binary chapter diffs\n",
      "47m 59s PRINT (F 50 SET M>50 S>90): formatted 12 cliques (1 files) skipping 4 binary chapter diffs\n",
      "47m 59s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "47m 59s PREPARING (F 50 SET): Already prepared\n",
      "47m 59s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "47m 59s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>85): fetching similars and chunk candidates\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>85): inspecting the similarity matrix\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>85): 35 relevant similarities between 57 passages\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>85): Loaded:    26 cliques out of     57 chunks from 35 comparisons\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>85): 57 members in 26 cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>85): sorting out cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>85): formatting 26 cliques skipping 9 binary chapter diffs\n",
      "47m 59s PRINT (F 50 SET M>50 S>85): formatted 26 cliques (1 files) skipping 9 binary chapter diffs\n",
      "47m 59s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "47m 59s PREPARING (F 50 SET): Already prepared\n",
      "47m 59s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "47m 59s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>80): fetching similars and chunk candidates\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>80): inspecting the similarity matrix\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>80): 69 relevant similarities between 114 passages\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>80): Loaded:    52 cliques out of    114 chunks from 69 comparisons\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>80): 114 members in 52 cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>80): sorting out cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>80): formatting 52 cliques skipping 19 binary chapter diffs\n",
      "47m 59s PRINT (F 50 SET M>50 S>80): formatted 52 cliques (2 files) skipping 19 binary chapter diffs\n",
      "47m 59s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "47m 59s PREPARING (F 50 SET): Already prepared\n",
      "47m 59s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "47m 59s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>75): fetching similars and chunk candidates\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>75): inspecting the similarity matrix\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>75): 115 relevant similarities between 186 passages\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>75): Loaded:    85 cliques out of    186 chunks from 115 comparisons\n",
      "47m 59s CLIQUES (F 50 SET M>50 S>75): 186 members in 85 cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>75): sorting out cliques\n",
      "47m 59s PRINT (F 50 SET M>50 S>75): formatting 85 cliques skipping 31 binary chapter diffs\n",
      "48m 00s PRINT (F 50 SET M>50 S>75): formatted 85 cliques (2 files) skipping 31 binary chapter diffs\n",
      "48m 00s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 00s PREPARING (F 50 SET): Already prepared\n",
      "48m 00s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "48m 00s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>70): fetching similars and chunk candidates\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>70): inspecting the similarity matrix\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>70): 171 relevant similarities between 271 passages\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>70): Loaded:   124 cliques out of    271 chunks from 171 comparisons\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>70): 271 members in 124 cliques\n",
      "48m 00s PRINT (F 50 SET M>50 S>70): sorting out cliques\n",
      "48m 00s PRINT (F 50 SET M>50 S>70): formatting 124 cliques skipping 48 binary chapter diffs\n",
      "48m 00s PRINT (F 50 SET M>50 S>70): formatted 124 cliques (3 files) skipping 48 binary chapter diffs\n",
      "48m 00s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 00s PREPARING (F 50 SET): Already prepared\n",
      "48m 00s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "48m 00s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>65): fetching similars and chunk candidates\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>65): inspecting the similarity matrix\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>65): 248 relevant similarities between 385 passages\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>65): Loaded:   176 cliques out of    385 chunks from 248 comparisons\n",
      "48m 00s CLIQUES (F 50 SET M>50 S>65): 385 members in 176 cliques\n",
      "48m 00s PRINT (F 50 SET M>50 S>65): sorting out cliques\n",
      "48m 00s PRINT (F 50 SET M>50 S>65): formatting 176 cliques skipping 61 binary chapter diffs\n",
      "48m 01s PRINT (F 50 SET M>50 S>65): formatted 176 cliques (4 files) skipping 61 binary chapter diffs\n",
      "48m 01s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 01s PREPARING (F 50 SET): Already prepared\n",
      "48m 01s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "48m 01s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "48m 01s CLIQUES (F 50 SET M>50 S>60): fetching similars and chunk candidates\n",
      "48m 01s CLIQUES (F 50 SET M>50 S>60): inspecting the similarity matrix\n",
      "48m 01s CLIQUES (F 50 SET M>50 S>60): 366 relevant similarities between 535 passages\n",
      "48m 01s CLIQUES (F 50 SET M>50 S>60): Loaded:   235 cliques out of    535 chunks from 366 comparisons\n",
      "48m 01s CLIQUES (F 50 SET M>50 S>60): 535 members in 235 cliques\n",
      "48m 01s PRINT (F 50 SET M>50 S>60): sorting out cliques\n",
      "48m 01s PRINT (F 50 SET M>50 S>60): formatting 235 cliques skipping 78 binary chapter diffs\n",
      "48m 02s PRINT (F 50 SET M>50 S>60): formatted 235 cliques (5 files) skipping 78 binary chapter diffs\n",
      "48m 02s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 02s PREPARING (F 50 SET): Already prepared\n",
      "48m 02s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "48m 02s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "48m 02s CLIQUES (F 50 SET M>50 S>55): fetching similars and chunk candidates\n",
      "48m 02s CLIQUES (F 50 SET M>50 S>55): inspecting the similarity matrix\n",
      "48m 02s CLIQUES (F 50 SET M>50 S>55): 537 relevant similarities between 748 passages\n",
      "48m 02s CLIQUES (F 50 SET M>50 S>55): Composing cliques out of    748 chunks from 537 comparisons\n",
      "48m 02s CLIQUES (F 50 SET M>50 S>55): 748 members in 315 cliques\n",
      "48m 02s CLIQUES (F 50 SET M>50 S>55): Composed and saved   315 cliques out of    748 chunks from 537 comparisons\n",
      "48m 02s PRINT (F 50 SET M>50 S>55): sorting out cliques\n",
      "48m 02s PRINT (F 50 SET M>50 S>55): formatting 315 cliques skipping 101 binary chapter diffs\n",
      "48m 04s PRINT (F 50 SET M>50 S>55): formatted 315 cliques (7 files) skipping 101 binary chapter diffs\n",
      "48m 04s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 04s PREPARING (F 50 SET): Already prepared\n",
      "48m 04s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 923 entries in matrix\n",
      "48m 04s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): fetching similars and chunk candidates\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): inspecting the similarity matrix\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): 923 relevant similarities between 1187 passages\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): Composing cliques out of   1187 chunks from 923 comparisons\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): Composed   476 cliques out of   1000 chunks\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): 1187 members in 465 cliques\n",
      "48m 04s CLIQUES (F 50 SET M>50 S>50): Composed and saved   465 cliques out of   1187 chunks from 923 comparisons\n",
      "48m 04s PRINT (F 50 SET M>50 S>50): sorting out cliques\n",
      "48m 04s PRINT (F 50 SET M>50 S>50): formatting 465 cliques skipping 138 binary chapter diffs\n",
      "48m 07s PRINT (F 50 SET M>50 S>50): formatted 465 cliques (10 files) skipping 138 binary chapter diffs\n",
      "48m 07s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 07s PREPARING (F 50 LCS)\n",
      "48m 08s PREPARING (F 50 LCS): Done 8509 chunks.\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): Loaded: 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>100): fetching similars and chunk candidates\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>100): inspecting the similarity matrix\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>100): 0 relevant similarities between 0 passages\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>100): 0 members in 0 cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>100): sorting out cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>100): formatting 0 cliques skipping 0 binary chapter diffs\n",
      "48m 08s PRINT (F 50 LCS M>60 S>100): formatted 0 cliques (1 files) skipping 0 binary chapter diffs\n",
      "48m 08s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 08s PREPARING (F 50 LCS): Already prepared\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>95): fetching similars and chunk candidates\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>95): inspecting the similarity matrix\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>95): 6 relevant similarities between 12 passages\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>95): Loaded:     6 cliques out of     12 chunks from 6 comparisons\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>95): 12 members in 6 cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>95): sorting out cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>95): formatting 6 cliques skipping 3 binary chapter diffs\n",
      "48m 08s PRINT (F 50 LCS M>60 S>95): formatted 6 cliques (1 files) skipping 3 binary chapter diffs\n",
      "48m 08s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 08s PREPARING (F 50 LCS): Already prepared\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>90): fetching similars and chunk candidates\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>90): inspecting the similarity matrix\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>90): 28 relevant similarities between 53 passages\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>90): Loaded:    25 cliques out of     53 chunks from 28 comparisons\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>90): 53 members in 25 cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>90): sorting out cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>90): formatting 25 cliques skipping 9 binary chapter diffs\n",
      "48m 08s PRINT (F 50 LCS M>60 S>90): formatted 25 cliques (1 files) skipping 9 binary chapter diffs\n",
      "48m 08s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 08s PREPARING (F 50 LCS): Already prepared\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>85): fetching similars and chunk candidates\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>85): inspecting the similarity matrix\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>85): 75 relevant similarities between 119 passages\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>85): Loaded:    53 cliques out of    119 chunks from 75 comparisons\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>85): 119 members in 53 cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>85): sorting out cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>85): formatting 53 cliques skipping 17 binary chapter diffs\n",
      "48m 08s PRINT (F 50 LCS M>60 S>85): formatted 53 cliques (2 files) skipping 17 binary chapter diffs\n",
      "48m 08s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 08s PREPARING (F 50 LCS): Already prepared\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>80): fetching similars and chunk candidates\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>80): inspecting the similarity matrix\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>80): 122 relevant similarities between 196 passages\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>80): Loaded:    89 cliques out of    196 chunks from 122 comparisons\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>80): 196 members in 89 cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>80): sorting out cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>80): formatting 89 cliques skipping 33 binary chapter diffs\n",
      "48m 08s PRINT (F 50 LCS M>60 S>80): formatted 89 cliques (2 files) skipping 33 binary chapter diffs\n",
      "48m 08s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 08s PREPARING (F 50 LCS): Already prepared\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 08s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>75): fetching similars and chunk candidates\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>75): inspecting the similarity matrix\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>75): 197 relevant similarities between 301 passages\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>75): Loaded:   135 cliques out of    301 chunks from 197 comparisons\n",
      "48m 08s CLIQUES (F 50 LCS M>60 S>75): 301 members in 135 cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>75): sorting out cliques\n",
      "48m 08s PRINT (F 50 LCS M>60 S>75): formatting 135 cliques skipping 50 binary chapter diffs\n",
      "48m 09s PRINT (F 50 LCS M>60 S>75): formatted 135 cliques (3 files) skipping 50 binary chapter diffs\n",
      "48m 09s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 09s PREPARING (F 50 LCS): Already prepared\n",
      "48m 09s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 09s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 09s CLIQUES (F 50 LCS M>60 S>70): fetching similars and chunk candidates\n",
      "48m 09s CLIQUES (F 50 LCS M>60 S>70): inspecting the similarity matrix\n",
      "48m 09s CLIQUES (F 50 LCS M>60 S>70): 312 relevant similarities between 464 passages\n",
      "48m 09s CLIQUES (F 50 LCS M>60 S>70): Loaded:   205 cliques out of    464 chunks from 312 comparisons\n",
      "48m 09s CLIQUES (F 50 LCS M>60 S>70): 464 members in 205 cliques\n",
      "48m 09s PRINT (F 50 LCS M>60 S>70): sorting out cliques\n",
      "48m 09s PRINT (F 50 LCS M>60 S>70): formatting 205 cliques skipping 65 binary chapter diffs\n",
      "48m 10s PRINT (F 50 LCS M>60 S>70): formatted 205 cliques (5 files) skipping 65 binary chapter diffs\n",
      "48m 10s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 10s PREPARING (F 50 LCS): Already prepared\n",
      "48m 10s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 10s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 10s CLIQUES (F 50 LCS M>60 S>65): fetching similars and chunk candidates\n",
      "48m 10s CLIQUES (F 50 LCS M>60 S>65): inspecting the similarity matrix\n",
      "48m 10s CLIQUES (F 50 LCS M>60 S>65): 578 relevant similarities between 761 passages\n",
      "48m 10s CLIQUES (F 50 LCS M>60 S>65): Loaded:   312 cliques out of    761 chunks from 578 comparisons\n",
      "48m 10s CLIQUES (F 50 LCS M>60 S>65): 761 members in 312 cliques\n",
      "48m 10s PRINT (F 50 LCS M>60 S>65): sorting out cliques\n",
      "48m 10s PRINT (F 50 LCS M>60 S>65): formatting 312 cliques skipping 107 binary chapter diffs\n",
      "48m 12s PRINT (F 50 LCS M>60 S>65): formatted 312 cliques (7 files) skipping 107 binary chapter diffs\n",
      "48m 12s CHUNKING (F 50): already chunked into 8509 chunks\n",
      "48m 12s PREPARING (F 50 LCS): Already prepared\n",
      "48m 12s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1833 entries in matrix\n",
      "48m 12s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      "48m 12s CLIQUES (F 50 LCS M>60 S>60): fetching similars and chunk candidates\n",
      "48m 12s CLIQUES (F 50 LCS M>60 S>60): inspecting the similarity matrix\n",
      "48m 12s CLIQUES (F 50 LCS M>60 S>60): 1833 relevant similarities between 1888 passages\n",
      "48m 12s CLIQUES (F 50 LCS M>60 S>60): Loaded:   552 cliques out of   1888 chunks from 1833 comparisons\n",
      "48m 12s CLIQUES (F 50 LCS M>60 S>60): 1888 members in 552 cliques\n",
      "48m 12s PRINT (F 50 LCS M>60 S>60): sorting out cliques\n",
      "48m 12s PRINT (F 50 LCS M>60 S>60): formatting 552 cliques skipping 228 binary chapter diffs\n",
      "48m 17s PRINT (F 50 LCS M>60 S>60): formatted 552 cliques (12 files) skipping 228 binary chapter diffs\n",
      "48m 17s CHUNKING (F 20)\n",
      "48m 18s CHUNKING (F 20): Made 21311 chunks\n",
      "48m 18s PREPARING (F 20 SET)\n",
      "48m 19s PREPARING (F 20 SET): Done 21311 chunks.\n",
      "48m 19s SIMILARITY (F 20 SET M>50): Loaded:   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 19s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>100): fetching similars and chunk candidates\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>100): inspecting the similarity matrix\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>100): 14 relevant similarities between 28 passages\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>100): Loaded:    14 cliques out of     28 chunks from 14 comparisons\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>100): 28 members in 14 cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>100): sorting out cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>100): formatting 14 cliques skipping 8 binary chapter diffs\n",
      "48m 19s PRINT (F 20 SET M>50 S>100): formatted 14 cliques (1 files) skipping 8 binary chapter diffs\n",
      "48m 19s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 19s PREPARING (F 20 SET): Already prepared\n",
      "48m 19s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 19s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>95): fetching similars and chunk candidates\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>95): inspecting the similarity matrix\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>95): 14 relevant similarities between 28 passages\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>95): Loaded:    14 cliques out of     28 chunks from 14 comparisons\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>95): 28 members in 14 cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>95): sorting out cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>95): formatting 14 cliques skipping 8 binary chapter diffs\n",
      "48m 19s PRINT (F 20 SET M>50 S>95): formatted 14 cliques (1 files) skipping 8 binary chapter diffs\n",
      "48m 19s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 19s PREPARING (F 20 SET): Already prepared\n",
      "48m 19s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 19s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>90): fetching similars and chunk candidates\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>90): inspecting the similarity matrix\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>90): 63 relevant similarities between 105 passages\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>90): Loaded:    46 cliques out of    105 chunks from 63 comparisons\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>90): 105 members in 46 cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>90): sorting out cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>90): formatting 46 cliques skipping 22 binary chapter diffs\n",
      "48m 19s PRINT (F 20 SET M>50 S>90): formatted 46 cliques (1 files) skipping 22 binary chapter diffs\n",
      "48m 19s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 19s PREPARING (F 20 SET): Already prepared\n",
      "48m 19s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 19s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>85): fetching similars and chunk candidates\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>85): inspecting the similarity matrix\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>85): 125 relevant similarities between 174 passages\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>85): Loaded:    72 cliques out of    174 chunks from 125 comparisons\n",
      "48m 19s CLIQUES (F 20 SET M>50 S>85): 174 members in 72 cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>85): sorting out cliques\n",
      "48m 19s PRINT (F 20 SET M>50 S>85): formatting 72 cliques skipping 34 binary chapter diffs\n",
      "48m 20s PRINT (F 20 SET M>50 S>85): formatted 72 cliques (2 files) skipping 34 binary chapter diffs\n",
      "48m 20s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 20s PREPARING (F 20 SET): Already prepared\n",
      "48m 20s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 20s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>80): fetching similars and chunk candidates\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>80): inspecting the similarity matrix\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>80): 230 relevant similarities between 326 passages\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>80): Loaded:   143 cliques out of    326 chunks from 230 comparisons\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>80): 326 members in 143 cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>80): sorting out cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>80): formatting 143 cliques skipping 59 binary chapter diffs\n",
      "48m 20s PRINT (F 20 SET M>50 S>80): formatted 143 cliques (3 files) skipping 59 binary chapter diffs\n",
      "48m 20s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 20s PREPARING (F 20 SET): Already prepared\n",
      "48m 20s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 20s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>75): fetching similars and chunk candidates\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>75): inspecting the similarity matrix\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>75): 382 relevant similarities between 528 passages\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>75): Loaded:   227 cliques out of    528 chunks from 382 comparisons\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>75): 528 members in 227 cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>75): sorting out cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>75): formatting 227 cliques skipping 83 binary chapter diffs\n",
      "48m 20s PRINT (F 20 SET M>50 S>75): formatted 227 cliques (5 files) skipping 83 binary chapter diffs\n",
      "48m 20s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 20s PREPARING (F 20 SET): Already prepared\n",
      "48m 20s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 20s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>70): fetching similars and chunk candidates\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>70): inspecting the similarity matrix\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>70): 546 relevant similarities between 762 passages\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>70): Loaded:   331 cliques out of    762 chunks from 546 comparisons\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>70): 762 members in 331 cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>70): sorting out cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>70): formatting 331 cliques skipping 107 binary chapter diffs\n",
      "48m 20s PRINT (F 20 SET M>50 S>70): formatted 331 cliques (7 files) skipping 107 binary chapter diffs\n",
      "48m 20s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 20s PREPARING (F 20 SET): Already prepared\n",
      "48m 20s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 20s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>65): fetching similars and chunk candidates\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>65): inspecting the similarity matrix\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>65): 787 relevant similarities between 1058 passages\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>65): Loaded:   452 cliques out of   1058 chunks from 787 comparisons\n",
      "48m 20s CLIQUES (F 20 SET M>50 S>65): 1058 members in 452 cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>65): sorting out cliques\n",
      "48m 20s PRINT (F 20 SET M>50 S>65): formatting 452 cliques skipping 136 binary chapter diffs\n",
      "48m 21s PRINT (F 20 SET M>50 S>65): formatted 452 cliques (10 files) skipping 136 binary chapter diffs\n",
      "48m 21s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 21s PREPARING (F 20 SET): Already prepared\n",
      "48m 21s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 21s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 21s CLIQUES (F 20 SET M>50 S>60): fetching similars and chunk candidates\n",
      "48m 21s CLIQUES (F 20 SET M>50 S>60): inspecting the similarity matrix\n",
      "48m 21s CLIQUES (F 20 SET M>50 S>60): 1432 relevant similarities between 1830 passages\n",
      "48m 21s CLIQUES (F 20 SET M>50 S>60): Loaded:   733 cliques out of   1830 chunks from 1432 comparisons\n",
      "48m 21s CLIQUES (F 20 SET M>50 S>60): 1830 members in 733 cliques\n",
      "48m 21s PRINT (F 20 SET M>50 S>60): sorting out cliques\n",
      "48m 21s PRINT (F 20 SET M>50 S>60): formatting 733 cliques skipping 211 binary chapter diffs\n",
      "48m 22s PRINT (F 20 SET M>50 S>60): formatted 733 cliques (15 files) skipping 211 binary chapter diffs\n",
      "48m 22s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 22s PREPARING (F 20 SET): Already prepared\n",
      "48m 22s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 22s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 22s CLIQUES (F 20 SET M>50 S>55): fetching similars and chunk candidates\n",
      "48m 22s CLIQUES (F 20 SET M>50 S>55): inspecting the similarity matrix\n",
      "48m 22s CLIQUES (F 20 SET M>50 S>55): 2425 relevant similarities between 2787 passages\n",
      "48m 22s CLIQUES (F 20 SET M>50 S>55): Composing cliques out of   2787 chunks from 2425 comparisons\n",
      "48m 22s CLIQUES (F 20 SET M>50 S>55): Composed   341 cliques out of   1000 chunks\n",
      "48m 23s CLIQUES (F 20 SET M>50 S>55): Composed   871 cliques out of   2000 chunks\n",
      "48m 24s CLIQUES (F 20 SET M>50 S>55): 2787 members in 979 cliques\n",
      "48m 24s CLIQUES (F 20 SET M>50 S>55): Composed and saved   979 cliques out of   2787 chunks from 2425 comparisons\n",
      "48m 24s PRINT (F 20 SET M>50 S>55): sorting out cliques\n",
      "48m 24s PRINT (F 20 SET M>50 S>55): formatting 979 cliques skipping 285 binary chapter diffs\n",
      "48m 26s PRINT (F 20 SET M>50 S>55): formatted 979 cliques (20 files) skipping 285 binary chapter diffs\n",
      "48m 26s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 26s PREPARING (F 20 SET): Already prepared\n",
      "48m 26s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5517 entries in matrix\n",
      "48m 26s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      "48m 26s CLIQUES (F 20 SET M>50 S>50): fetching similars and chunk candidates\n",
      "48m 26s CLIQUES (F 20 SET M>50 S>50): inspecting the similarity matrix\n",
      "48m 26s CLIQUES (F 20 SET M>50 S>50): 5517 relevant similarities between 4913 passages\n",
      "48m 26s CLIQUES (F 20 SET M>50 S>50): Composing cliques out of   4913 chunks from 5517 comparisons\n",
      "48m 26s CLIQUES (F 20 SET M>50 S>50): Composed   425 cliques out of   1000 chunks\n",
      "48m 27s CLIQUES (F 20 SET M>50 S>50): Composed   541 cliques out of   2000 chunks\n",
      "48m 28s CLIQUES (F 20 SET M>50 S>50): Composed   990 cliques out of   3000 chunks\n",
      "48m 29s CLIQUES (F 20 SET M>50 S>50): Composed  1217 cliques out of   4000 chunks\n",
      "48m 31s CLIQUES (F 20 SET M>50 S>50): 4913 members in 1203 cliques\n",
      "48m 31s CLIQUES (F 20 SET M>50 S>50): Composed and saved  1203 cliques out of   4913 chunks from 5517 comparisons\n",
      "48m 31s PRINT (F 20 SET M>50 S>50): sorting out cliques\n",
      "48m 31s PRINT (F 20 SET M>50 S>50): formatting 1203 cliques skipping 391 binary chapter diffs\n",
      "48m 33s PRINT (F 20 SET M>50 S>50): formatted 1203 cliques (25 files) skipping 391 binary chapter diffs\n",
      "48m 33s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 33s PREPARING (F 20 LCS)\n",
      "48m 34s PREPARING (F 20 LCS): Done 21311 chunks.\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): Loaded:   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>100): fetching similars and chunk candidates\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>100): inspecting the similarity matrix\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>100): 3 relevant similarities between 6 passages\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>100): Loaded:     3 cliques out of      6 chunks from 3 comparisons\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>100): 6 members in 3 cliques\n",
      "48m 34s PRINT (F 20 LCS M>60 S>100): sorting out cliques\n",
      "48m 34s PRINT (F 20 LCS M>60 S>100): formatting 3 cliques skipping 3 binary chapter diffs\n",
      "48m 34s PRINT (F 20 LCS M>60 S>100): formatted 3 cliques (1 files) skipping 3 binary chapter diffs\n",
      "48m 34s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 34s PREPARING (F 20 LCS): Already prepared\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>95): fetching similars and chunk candidates\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>95): inspecting the similarity matrix\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>95): 25 relevant similarities between 47 passages\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>95): Loaded:    22 cliques out of     47 chunks from 25 comparisons\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>95): 47 members in 22 cliques\n",
      "48m 34s PRINT (F 20 LCS M>60 S>95): sorting out cliques\n",
      "48m 34s PRINT (F 20 LCS M>60 S>95): formatting 22 cliques skipping 12 binary chapter diffs\n",
      "48m 34s PRINT (F 20 LCS M>60 S>95): formatted 22 cliques (1 files) skipping 12 binary chapter diffs\n",
      "48m 34s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 34s PREPARING (F 20 LCS): Already prepared\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>90): fetching similars and chunk candidates\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>90): inspecting the similarity matrix\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>90): 95 relevant similarities between 149 passages\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>90): Loaded:    61 cliques out of    149 chunks from 95 comparisons\n",
      "48m 34s CLIQUES (F 20 LCS M>60 S>90): 149 members in 61 cliques\n",
      "48m 34s PRINT (F 20 LCS M>60 S>90): sorting out cliques\n",
      "48m 34s PRINT (F 20 LCS M>60 S>90): formatting 61 cliques skipping 31 binary chapter diffs\n",
      "48m 34s PRINT (F 20 LCS M>60 S>90): formatted 61 cliques (2 files) skipping 31 binary chapter diffs\n",
      "48m 34s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 34s PREPARING (F 20 LCS): Already prepared\n",
      "48m 34s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 35s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>85): fetching similars and chunk candidates\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>85): inspecting the similarity matrix\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>85): 212 relevant similarities between 311 passages\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>85): Loaded:   136 cliques out of    311 chunks from 212 comparisons\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>85): 311 members in 136 cliques\n",
      "48m 35s PRINT (F 20 LCS M>60 S>85): sorting out cliques\n",
      "48m 35s PRINT (F 20 LCS M>60 S>85): formatting 136 cliques skipping 56 binary chapter diffs\n",
      "48m 35s PRINT (F 20 LCS M>60 S>85): formatted 136 cliques (3 files) skipping 56 binary chapter diffs\n",
      "48m 35s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 35s PREPARING (F 20 LCS): Already prepared\n",
      "48m 35s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 35s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>80): fetching similars and chunk candidates\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>80): inspecting the similarity matrix\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>80): 467 relevant similarities between 682 passages\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>80): Loaded:   299 cliques out of    682 chunks from 467 comparisons\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>80): 682 members in 299 cliques\n",
      "48m 35s PRINT (F 20 LCS M>60 S>80): sorting out cliques\n",
      "48m 35s PRINT (F 20 LCS M>60 S>80): formatting 299 cliques skipping 116 binary chapter diffs\n",
      "48m 35s PRINT (F 20 LCS M>60 S>80): formatted 299 cliques (6 files) skipping 116 binary chapter diffs\n",
      "48m 35s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 35s PREPARING (F 20 LCS): Already prepared\n",
      "48m 35s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 35s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>75): fetching similars and chunk candidates\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>75): inspecting the similarity matrix\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>75): 874 relevant similarities between 1137 passages\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>75): Loaded:   470 cliques out of   1137 chunks from 874 comparisons\n",
      "48m 35s CLIQUES (F 20 LCS M>60 S>75): 1137 members in 470 cliques\n",
      "48m 35s PRINT (F 20 LCS M>60 S>75): sorting out cliques\n",
      "48m 35s PRINT (F 20 LCS M>60 S>75): formatting 470 cliques skipping 162 binary chapter diffs\n",
      "48m 36s PRINT (F 20 LCS M>60 S>75): formatted 470 cliques (10 files) skipping 162 binary chapter diffs\n",
      "48m 36s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 36s PREPARING (F 20 LCS): Already prepared\n",
      "48m 36s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 36s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 36s CLIQUES (F 20 LCS M>60 S>70): fetching similars and chunk candidates\n",
      "48m 36s CLIQUES (F 20 LCS M>60 S>70): inspecting the similarity matrix\n",
      "48m 36s CLIQUES (F 20 LCS M>60 S>70): 1944 relevant similarities between 2217 passages\n",
      "48m 36s CLIQUES (F 20 LCS M>60 S>70): Loaded:   838 cliques out of   2217 chunks from 1944 comparisons\n",
      "48m 36s CLIQUES (F 20 LCS M>60 S>70): 2217 members in 838 cliques\n",
      "48m 36s PRINT (F 20 LCS M>60 S>70): sorting out cliques\n",
      "48m 36s PRINT (F 20 LCS M>60 S>70): formatting 838 cliques skipping 313 binary chapter diffs\n",
      "48m 37s PRINT (F 20 LCS M>60 S>70): formatted 838 cliques (17 files) skipping 313 binary chapter diffs\n",
      "48m 37s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 37s PREPARING (F 20 LCS): Already prepared\n",
      "48m 37s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 38s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 38s CLIQUES (F 20 LCS M>60 S>65): fetching similars and chunk candidates\n",
      "48m 38s CLIQUES (F 20 LCS M>60 S>65): inspecting the similarity matrix\n",
      "48m 38s CLIQUES (F 20 LCS M>60 S>65): 6983 relevant similarities between 5971 passages\n",
      "48m 38s CLIQUES (F 20 LCS M>60 S>65): Loaded:  1223 cliques out of   5971 chunks from 6983 comparisons\n",
      "48m 38s CLIQUES (F 20 LCS M>60 S>65): 5971 members in 1223 cliques\n",
      "48m 38s PRINT (F 20 LCS M>60 S>65): sorting out cliques\n",
      "48m 38s PRINT (F 20 LCS M>60 S>65): formatting 1223 cliques skipping 553 binary chapter diffs\n",
      "48m 40s PRINT (F 20 LCS M>60 S>65): formatted 1223 cliques (25 files) skipping 553 binary chapter diffs\n",
      "48m 40s CHUNKING (F 20): already chunked into 21311 chunks\n",
      "48m 40s PREPARING (F 20 LCS): Already prepared\n",
      "48m 40s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122055 entries in matrix\n",
      "48m 40s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      "48m 40s CLIQUES (F 20 LCS M>60 S>60): fetching similars and chunk candidates\n",
      "48m 40s CLIQUES (F 20 LCS M>60 S>60): inspecting the similarity matrix\n",
      "48m 40s CLIQUES (F 20 LCS M>60 S>60): 122055 relevant similarities between 17656 passages\n",
      "48m 40s CLIQUES (F 20 LCS M>60 S>60): Loaded:   152 cliques out of  17656 chunks from 122055 comparisons\n",
      "48m 40s CLIQUES (F 20 LCS M>60 S>60): 17656 members in 152 cliques\n",
      "48m 40s PRINT (F 20 LCS M>60 S>60): sorting out cliques\n",
      "48m 40s PRINT (F 20 LCS M>60 S>60): formatting 152 cliques skipping 94 binary chapter diffs\n",
      "48m 40s PRINT (F 20 LCS M>60 S>60): formatted 152 cliques (4 files) skipping 94 binary chapter diffs\n",
      "48m 40s CHUNKING (F 10)\n",
      "48m 42s CHUNKING (F 10): Made 42639 chunks\n",
      "48m 42s PREPARING (F 10 SET)\n",
      "48m 43s PREPARING (F 10 SET): Done 42639 chunks.\n",
      "48m 43s SIMILARITY (F 10 SET M>50): Loaded:   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 43s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>100): fetching similars and chunk candidates\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>100): inspecting the similarity matrix\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>100): 275 relevant similarities between 448 passages\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>100): Loaded:   209 cliques out of    448 chunks from 275 comparisons\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>100): 448 members in 209 cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>100): sorting out cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>100): formatting 209 cliques skipping 80 binary chapter diffs\n",
      "48m 43s PRINT (F 10 SET M>50 S>100): formatted 209 cliques (5 files) skipping 80 binary chapter diffs\n",
      "48m 43s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 43s PREPARING (F 10 SET): Already prepared\n",
      "48m 43s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 43s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>95): fetching similars and chunk candidates\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>95): inspecting the similarity matrix\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>95): 275 relevant similarities between 448 passages\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>95): Loaded:   209 cliques out of    448 chunks from 275 comparisons\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>95): 448 members in 209 cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>95): sorting out cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>95): formatting 209 cliques skipping 80 binary chapter diffs\n",
      "48m 43s PRINT (F 10 SET M>50 S>95): formatted 209 cliques (5 files) skipping 80 binary chapter diffs\n",
      "48m 43s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 43s PREPARING (F 10 SET): Already prepared\n",
      "48m 43s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 43s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>90): fetching similars and chunk candidates\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>90): inspecting the similarity matrix\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>90): 315 relevant similarities between 482 passages\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>90): Loaded:   220 cliques out of    482 chunks from 315 comparisons\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>90): 482 members in 220 cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>90): sorting out cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>90): formatting 220 cliques skipping 85 binary chapter diffs\n",
      "48m 43s PRINT (F 10 SET M>50 S>90): formatted 220 cliques (5 files) skipping 85 binary chapter diffs\n",
      "48m 43s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 43s PREPARING (F 10 SET): Already prepared\n",
      "48m 43s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 43s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>85): fetching similars and chunk candidates\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>85): inspecting the similarity matrix\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>85): 745 relevant similarities between 1114 passages\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>85): Loaded:   493 cliques out of   1114 chunks from 745 comparisons\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>85): 1114 members in 493 cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>85): sorting out cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>85): formatting 493 cliques skipping 193 binary chapter diffs\n",
      "48m 43s PRINT (F 10 SET M>50 S>85): formatted 493 cliques (10 files) skipping 193 binary chapter diffs\n",
      "48m 43s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 43s PREPARING (F 10 SET): Already prepared\n",
      "48m 43s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 43s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>80): fetching similars and chunk candidates\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>80): inspecting the similarity matrix\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>80): 1149 relevant similarities between 1536 passages\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>80): Loaded:   628 cliques out of   1536 chunks from 1149 comparisons\n",
      "48m 43s CLIQUES (F 10 SET M>50 S>80): 1536 members in 628 cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>80): sorting out cliques\n",
      "48m 43s PRINT (F 10 SET M>50 S>80): formatting 628 cliques skipping 231 binary chapter diffs\n",
      "48m 44s PRINT (F 10 SET M>50 S>80): formatted 628 cliques (13 files) skipping 231 binary chapter diffs\n",
      "48m 44s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 44s PREPARING (F 10 SET): Already prepared\n",
      "48m 44s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 44s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>75): fetching similars and chunk candidates\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>75): inspecting the similarity matrix\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>75): 2107 relevant similarities between 2754 passages\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>75): Loaded:  1094 cliques out of   2754 chunks from 2107 comparisons\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>75): 2754 members in 1094 cliques\n",
      "48m 44s PRINT (F 10 SET M>50 S>75): sorting out cliques\n",
      "48m 44s PRINT (F 10 SET M>50 S>75): formatting 1094 cliques skipping 406 binary chapter diffs\n",
      "48m 44s PRINT (F 10 SET M>50 S>75): formatted 1094 cliques (22 files) skipping 406 binary chapter diffs\n",
      "48m 44s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 44s PREPARING (F 10 SET): Already prepared\n",
      "48m 44s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 44s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>70): fetching similars and chunk candidates\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>70): inspecting the similarity matrix\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>70): 3560 relevant similarities between 4020 passages\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>70): Loaded:  1474 cliques out of   4020 chunks from 3560 comparisons\n",
      "48m 44s CLIQUES (F 10 SET M>50 S>70): 4020 members in 1474 cliques\n",
      "48m 44s PRINT (F 10 SET M>50 S>70): sorting out cliques\n",
      "48m 44s PRINT (F 10 SET M>50 S>70): formatting 1474 cliques skipping 559 binary chapter diffs\n",
      "48m 45s PRINT (F 10 SET M>50 S>70): formatted 1474 cliques (30 files) skipping 559 binary chapter diffs\n",
      "48m 45s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 45s PREPARING (F 10 SET): Already prepared\n",
      "48m 45s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 45s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 45s CLIQUES (F 10 SET M>50 S>65): fetching similars and chunk candidates\n",
      "48m 45s CLIQUES (F 10 SET M>50 S>65): inspecting the similarity matrix\n",
      "48m 45s CLIQUES (F 10 SET M>50 S>65): 5481 relevant similarities between 5785 passages\n",
      "48m 45s CLIQUES (F 10 SET M>50 S>65): Loaded:  1850 cliques out of   5785 chunks from 5481 comparisons\n",
      "48m 45s CLIQUES (F 10 SET M>50 S>65): 5785 members in 1850 cliques\n",
      "48m 45s PRINT (F 10 SET M>50 S>65): sorting out cliques\n",
      "48m 45s PRINT (F 10 SET M>50 S>65): formatting 1850 cliques skipping 692 binary chapter diffs\n",
      "48m 47s PRINT (F 10 SET M>50 S>65): formatted 1850 cliques (37 files) skipping 692 binary chapter diffs\n",
      "48m 47s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 47s PREPARING (F 10 SET): Already prepared\n",
      "48m 47s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 47s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 47s CLIQUES (F 10 SET M>50 S>60): fetching similars and chunk candidates\n",
      "48m 47s CLIQUES (F 10 SET M>50 S>60): inspecting the similarity matrix\n",
      "48m 47s CLIQUES (F 10 SET M>50 S>60): 13263 relevant similarities between 10211 passages\n",
      "48m 47s CLIQUES (F 10 SET M>50 S>60): Loaded:  2210 cliques out of  10211 chunks from 13263 comparisons\n",
      "48m 47s CLIQUES (F 10 SET M>50 S>60): 10211 members in 2210 cliques\n",
      "48m 47s PRINT (F 10 SET M>50 S>60): sorting out cliques\n",
      "48m 47s PRINT (F 10 SET M>50 S>60): formatting 2210 cliques skipping 845 binary chapter diffs\n",
      "48m 49s PRINT (F 10 SET M>50 S>60): formatted 2210 cliques (45 files) skipping 845 binary chapter diffs\n",
      "48m 49s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "48m 49s PREPARING (F 10 SET): Already prepared\n",
      "48m 49s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "48m 49s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "48m 49s CLIQUES (F 10 SET M>50 S>55): fetching similars and chunk candidates\n",
      "48m 49s CLIQUES (F 10 SET M>50 S>55): inspecting the similarity matrix\n",
      "48m 49s CLIQUES (F 10 SET M>50 S>55): 25871 relevant similarities between 14100 passages\n",
      "48m 49s CLIQUES (F 10 SET M>50 S>55): Composing cliques out of  14100 chunks from 25871 comparisons\n",
      "48m 49s CLIQUES (F 10 SET M>50 S>55): Composed   620 cliques out of   1000 chunks\n",
      "48m 50s CLIQUES (F 10 SET M>50 S>55): Composed  1049 cliques out of   2000 chunks\n",
      "48m 52s CLIQUES (F 10 SET M>50 S>55): Composed  1203 cliques out of   3000 chunks\n",
      "48m 54s CLIQUES (F 10 SET M>50 S>55): Composed  1306 cliques out of   4000 chunks\n",
      "48m 57s CLIQUES (F 10 SET M>50 S>55): Composed  1468 cliques out of   5000 chunks\n",
      "49m 00s CLIQUES (F 10 SET M>50 S>55): Composed  1625 cliques out of   6000 chunks\n",
      "49m 04s CLIQUES (F 10 SET M>50 S>55): Composed  1846 cliques out of   7000 chunks\n",
      "49m 09s CLIQUES (F 10 SET M>50 S>55): Composed  2166 cliques out of   8000 chunks\n",
      "49m 15s CLIQUES (F 10 SET M>50 S>55): Composed  2293 cliques out of   9000 chunks\n",
      "49m 20s CLIQUES (F 10 SET M>50 S>55): Composed  2295 cliques out of  10000 chunks\n",
      "49m 26s CLIQUES (F 10 SET M>50 S>55): Composed  2245 cliques out of  11000 chunks\n",
      "49m 32s CLIQUES (F 10 SET M>50 S>55): Composed  2263 cliques out of  12000 chunks\n",
      "49m 39s CLIQUES (F 10 SET M>50 S>55): Composed  2240 cliques out of  13000 chunks\n",
      "49m 49s CLIQUES (F 10 SET M>50 S>55): Composed  2044 cliques out of  14000 chunks\n",
      "49m 49s CLIQUES (F 10 SET M>50 S>55): 14100 members in 2018 cliques\n",
      "49m 49s CLIQUES (F 10 SET M>50 S>55): Composed and saved  2018 cliques out of  14100 chunks from 25871 comparisons\n",
      "49m 49s PRINT (F 10 SET M>50 S>55): sorting out cliques\n",
      "49m 49s PRINT (F 10 SET M>50 S>55): formatting 2018 cliques skipping 783 binary chapter diffs\n",
      "49m 51s PRINT (F 10 SET M>50 S>55): formatted 2018 cliques (41 files) skipping 783 binary chapter diffs\n",
      "49m 51s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "49m 51s PREPARING (F 10 SET): Already prepared\n",
      "49m 51s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 88877 entries in matrix\n",
      "49m 51s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 275 are 100%\n",
      "49m 51s CLIQUES (F 10 SET M>50 S>50): fetching similars and chunk candidates\n",
      "49m 51s CLIQUES (F 10 SET M>50 S>50): inspecting the similarity matrix\n",
      "49m 51s CLIQUES (F 10 SET M>50 S>50): 88877 relevant similarities between 23054 passages\n",
      "49m 51s CLIQUES (F 10 SET M>50 S>50): Composing cliques out of  23054 chunks from 88877 comparisons\n",
      "49m 51s CLIQUES (F 10 SET M>50 S>50): Composed   590 cliques out of   1000 chunks\n",
      "49m 52s CLIQUES (F 10 SET M>50 S>50): Composed   872 cliques out of   2000 chunks\n",
      "49m 54s CLIQUES (F 10 SET M>50 S>50): Composed  1264 cliques out of   3000 chunks\n",
      "49m 56s CLIQUES (F 10 SET M>50 S>50): Composed  1260 cliques out of   4000 chunks\n",
      "49m 59s CLIQUES (F 10 SET M>50 S>50): Composed  1314 cliques out of   5000 chunks\n",
      "50m 01s CLIQUES (F 10 SET M>50 S>50): Composed  1373 cliques out of   6000 chunks\n",
      "50m 05s CLIQUES (F 10 SET M>50 S>50): Composed  1470 cliques out of   7000 chunks\n",
      "50m 08s CLIQUES (F 10 SET M>50 S>50): Composed  1525 cliques out of   8000 chunks\n",
      "50m 12s CLIQUES (F 10 SET M>50 S>50): Composed  1590 cliques out of   9000 chunks\n",
      "50m 16s CLIQUES (F 10 SET M>50 S>50): Composed  1669 cliques out of  10000 chunks\n",
      "50m 20s CLIQUES (F 10 SET M>50 S>50): Composed  1794 cliques out of  11000 chunks\n",
      "50m 25s CLIQUES (F 10 SET M>50 S>50): Composed  1929 cliques out of  12000 chunks\n",
      "50m 30s CLIQUES (F 10 SET M>50 S>50): Composed  1972 cliques out of  13000 chunks\n",
      "50m 36s CLIQUES (F 10 SET M>50 S>50): Composed  2074 cliques out of  14000 chunks\n",
      "50m 42s CLIQUES (F 10 SET M>50 S>50): Composed  2119 cliques out of  15000 chunks\n",
      "50m 49s CLIQUES (F 10 SET M>50 S>50): Composed  2024 cliques out of  16000 chunks\n",
      "50m 56s CLIQUES (F 10 SET M>50 S>50): Composed  1964 cliques out of  17000 chunks\n",
      "51m 03s CLIQUES (F 10 SET M>50 S>50): Composed  1901 cliques out of  18000 chunks\n",
      "51m 11s CLIQUES (F 10 SET M>50 S>50): Composed  1917 cliques out of  19000 chunks\n",
      "51m 21s CLIQUES (F 10 SET M>50 S>50): Composed  1917 cliques out of  20000 chunks\n",
      "51m 30s CLIQUES (F 10 SET M>50 S>50): Composed  1869 cliques out of  21000 chunks\n",
      "51m 39s CLIQUES (F 10 SET M>50 S>50): Composed  1683 cliques out of  22000 chunks\n",
      "51m 46s CLIQUES (F 10 SET M>50 S>50): Composed  1465 cliques out of  23000 chunks\n",
      "51m 47s CLIQUES (F 10 SET M>50 S>50): 23054 members in 1455 cliques\n",
      "51m 47s CLIQUES (F 10 SET M>50 S>50): Composed and saved  1455 cliques out of  23054 chunks from 88877 comparisons\n",
      "51m 47s PRINT (F 10 SET M>50 S>50): sorting out cliques\n",
      "51m 47s PRINT (F 10 SET M>50 S>50): formatting 1455 cliques skipping 643 binary chapter diffs\n",
      "51m 48s PRINT (F 10 SET M>50 S>50): formatted 1455 cliques (30 files) skipping 643 binary chapter diffs\n",
      "51m 48s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "51m 48s PREPARING (F 10 LCS)\n",
      "51m 49s PREPARING (F 10 LCS): Done 42639 chunks.\n",
      "51m 50s SIMILARITY (F 10 LCS M>60): Loaded:   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "51m 52s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "51m 52s CLIQUES (F 10 LCS M>60 S>100): fetching similars and chunk candidates\n",
      "51m 52s CLIQUES (F 10 LCS M>60 S>100): inspecting the similarity matrix\n",
      "51m 52s CLIQUES (F 10 LCS M>60 S>100): 139 relevant similarities between 239 passages\n",
      "51m 52s CLIQUES (F 10 LCS M>60 S>100): Loaded:   114 cliques out of    239 chunks from 139 comparisons\n",
      "51m 52s CLIQUES (F 10 LCS M>60 S>100): 239 members in 114 cliques\n",
      "51m 52s PRINT (F 10 LCS M>60 S>100): sorting out cliques\n",
      "51m 52s PRINT (F 10 LCS M>60 S>100): formatting 114 cliques skipping 49 binary chapter diffs\n",
      "51m 52s PRINT (F 10 LCS M>60 S>100): formatted 114 cliques (3 files) skipping 49 binary chapter diffs\n",
      "51m 52s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "51m 52s PREPARING (F 10 LCS): Already prepared\n",
      "51m 52s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "51m 53s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "51m 53s CLIQUES (F 10 LCS M>60 S>95): fetching similars and chunk candidates\n",
      "51m 53s CLIQUES (F 10 LCS M>60 S>95): inspecting the similarity matrix\n",
      "51m 54s CLIQUES (F 10 LCS M>60 S>95): 214 relevant similarities between 379 passages\n",
      "51m 54s CLIQUES (F 10 LCS M>60 S>95): Loaded:   182 cliques out of    379 chunks from 214 comparisons\n",
      "51m 54s CLIQUES (F 10 LCS M>60 S>95): 379 members in 182 cliques\n",
      "51m 54s PRINT (F 10 LCS M>60 S>95): sorting out cliques\n",
      "51m 54s PRINT (F 10 LCS M>60 S>95): formatting 182 cliques skipping 78 binary chapter diffs\n",
      "51m 54s PRINT (F 10 LCS M>60 S>95): formatted 182 cliques (4 files) skipping 78 binary chapter diffs\n",
      "51m 54s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "51m 54s PREPARING (F 10 LCS): Already prepared\n",
      "51m 54s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "51m 55s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "51m 55s CLIQUES (F 10 LCS M>60 S>90): fetching similars and chunk candidates\n",
      "51m 55s CLIQUES (F 10 LCS M>60 S>90): inspecting the similarity matrix\n",
      "51m 56s CLIQUES (F 10 LCS M>60 S>90): 609 relevant similarities between 905 passages\n",
      "51m 56s CLIQUES (F 10 LCS M>60 S>90): Loaded:   399 cliques out of    905 chunks from 609 comparisons\n",
      "51m 56s CLIQUES (F 10 LCS M>60 S>90): 905 members in 399 cliques\n",
      "51m 56s PRINT (F 10 LCS M>60 S>90): sorting out cliques\n",
      "51m 56s PRINT (F 10 LCS M>60 S>90): formatting 399 cliques skipping 160 binary chapter diffs\n",
      "51m 56s PRINT (F 10 LCS M>60 S>90): formatted 399 cliques (8 files) skipping 160 binary chapter diffs\n",
      "51m 56s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "51m 56s PREPARING (F 10 LCS): Already prepared\n",
      "51m 56s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "51m 57s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "51m 57s CLIQUES (F 10 LCS M>60 S>85): fetching similars and chunk candidates\n",
      "51m 57s CLIQUES (F 10 LCS M>60 S>85): inspecting the similarity matrix\n",
      "51m 58s CLIQUES (F 10 LCS M>60 S>85): 1396 relevant similarities between 1917 passages\n",
      "51m 58s CLIQUES (F 10 LCS M>60 S>85): Loaded:   791 cliques out of   1917 chunks from 1396 comparisons\n",
      "51m 58s CLIQUES (F 10 LCS M>60 S>85): 1917 members in 791 cliques\n",
      "51m 58s PRINT (F 10 LCS M>60 S>85): sorting out cliques\n",
      "51m 58s PRINT (F 10 LCS M>60 S>85): formatting 791 cliques skipping 297 binary chapter diffs\n",
      "51m 58s PRINT (F 10 LCS M>60 S>85): formatted 791 cliques (16 files) skipping 297 binary chapter diffs\n",
      "51m 58s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "51m 58s PREPARING (F 10 LCS): Already prepared\n",
      "51m 58s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "51m 59s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "51m 59s CLIQUES (F 10 LCS M>60 S>80): fetching similars and chunk candidates\n",
      "51m 59s CLIQUES (F 10 LCS M>60 S>80): inspecting the similarity matrix\n",
      "52m 00s CLIQUES (F 10 LCS M>60 S>80): 3308 relevant similarities between 3850 passages\n",
      "52m 00s CLIQUES (F 10 LCS M>60 S>80): Loaded:  1418 cliques out of   3850 chunks from 3308 comparisons\n",
      "52m 00s CLIQUES (F 10 LCS M>60 S>80): 3850 members in 1418 cliques\n",
      "52m 00s PRINT (F 10 LCS M>60 S>80): sorting out cliques\n",
      "52m 00s PRINT (F 10 LCS M>60 S>80): formatting 1418 cliques skipping 549 binary chapter diffs\n",
      "52m 01s PRINT (F 10 LCS M>60 S>80): formatted 1418 cliques (29 files) skipping 549 binary chapter diffs\n",
      "52m 01s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "52m 01s PREPARING (F 10 LCS): Already prepared\n",
      "52m 01s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "52m 02s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "52m 02s CLIQUES (F 10 LCS M>60 S>75): fetching similars and chunk candidates\n",
      "52m 02s CLIQUES (F 10 LCS M>60 S>75): inspecting the similarity matrix\n",
      "52m 03s CLIQUES (F 10 LCS M>60 S>75): 9225 relevant similarities between 8552 passages\n",
      "52m 03s CLIQUES (F 10 LCS M>60 S>75): Loaded:  2342 cliques out of   8552 chunks from 9225 comparisons\n",
      "52m 03s CLIQUES (F 10 LCS M>60 S>75): 8552 members in 2342 cliques\n",
      "52m 03s PRINT (F 10 LCS M>60 S>75): sorting out cliques\n",
      "52m 03s PRINT (F 10 LCS M>60 S>75): formatting 2342 cliques skipping 989 binary chapter diffs\n",
      "52m 06s PRINT (F 10 LCS M>60 S>75): formatted 2342 cliques (47 files) skipping 989 binary chapter diffs\n",
      "52m 06s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "52m 06s PREPARING (F 10 LCS): Already prepared\n",
      "52m 06s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "52m 07s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "52m 07s CLIQUES (F 10 LCS M>60 S>70): fetching similars and chunk candidates\n",
      "52m 07s CLIQUES (F 10 LCS M>60 S>70): inspecting the similarity matrix\n",
      "52m 08s CLIQUES (F 10 LCS M>60 S>70): 38610 relevant similarities between 20382 passages\n",
      "52m 08s CLIQUES (F 10 LCS M>60 S>70): Loaded:  1926 cliques out of  20382 chunks from 38610 comparisons\n",
      "52m 08s CLIQUES (F 10 LCS M>60 S>70): 20382 members in 1926 cliques\n",
      "52m 08s PRINT (F 10 LCS M>60 S>70): sorting out cliques\n",
      "52m 08s PRINT (F 10 LCS M>60 S>70): formatting 1926 cliques skipping 1004 binary chapter diffs\n",
      "52m 10s PRINT (F 10 LCS M>60 S>70): formatted 1926 cliques (39 files) skipping 1004 binary chapter diffs\n",
      "52m 10s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "52m 10s PREPARING (F 10 LCS): Already prepared\n",
      "52m 10s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "52m 11s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "52m 11s CLIQUES (F 10 LCS M>60 S>65): fetching similars and chunk candidates\n",
      "52m 11s CLIQUES (F 10 LCS M>60 S>65): inspecting the similarity matrix\n",
      "52m 12s CLIQUES (F 10 LCS M>60 S>65): 346682 relevant similarities between 37700 passages\n",
      "52m 12s CLIQUES (F 10 LCS M>60 S>65): Loaded:   223 cliques out of  37700 chunks from 346682 comparisons\n",
      "52m 12s CLIQUES (F 10 LCS M>60 S>65): 37700 members in 223 cliques\n",
      "52m 12s PRINT (F 10 LCS M>60 S>65): sorting out cliques\n",
      "52m 12s PRINT (F 10 LCS M>60 S>65): formatting 223 cliques skipping 142 binary chapter diffs\n",
      "52m 12s PRINT (F 10 LCS M>60 S>65): formatted 223 cliques (5 files) skipping 142 binary chapter diffs\n",
      "52m 12s CHUNKING (F 10): already chunked into 42639 chunks\n",
      "52m 12s PREPARING (F 10 LCS): Already prepared\n",
      "52m 12s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2918272 entries in matrix\n",
      "52m 13s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      "52m 13s CLIQUES (F 10 LCS M>60 S>60): fetching similars and chunk candidates\n",
      "52m 13s CLIQUES (F 10 LCS M>60 S>60): inspecting the similarity matrix\n",
      "52m 16s CLIQUES (F 10 LCS M>60 S>60): 2918272 relevant similarities between 42450 passages\n",
      "52m 16s CLIQUES (F 10 LCS M>60 S>60): Loaded:     2 cliques out of  42450 chunks from 2918272 comparisons\n",
      "52m 16s CLIQUES (F 10 LCS M>60 S>60): 42450 members in 2 cliques\n",
      "52m 16s PRINT (F 10 LCS M>60 S>60): sorting out cliques\n",
      "52m 17s PRINT (F 10 LCS M>60 S>60): formatting 2 cliques skipping 1 binary chapter diffs\n",
      "52m 17s PRINT (F 10 LCS M>60 S>60): formatted 2 cliques (1 files) skipping 1 binary chapter diffs\n",
      "52m 17s CHUNKING (O chapter)\n",
      "52m 18s CHUNKING (O chapter): Made 929 chunks\n",
      "52m 18s PREPARING (O chapter SET)\n",
      "52m 18s PREPARING (O chapter SET): Done 929 chunks.\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Loaded:   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>100): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>100): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>100): 0 relevant similarities between 0 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>100): 0 members in 0 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>100): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>100): formatting 0 cliques involving 0 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>100): Chapter diffs needed: 0\n",
      "52m 19s PRINT (O chapter SET M>30 S>100): Chapter diffs: 0 newly created and 0 already existing\n",
      "52m 19s PRINT (O chapter SET M>30 S>100): formatted 0 cliques (1 files) involving 0 binary chapter diffs\n",
      "52m 19s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 19s PREPARING (O chapter SET): Already prepared\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>95): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>95): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>95): 1 relevant similarities between 2 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>95): Loaded:     1 cliques out of      2 chunks from 1 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>95): 2 members in 1 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>95): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>95): formatting 1 cliques skipping 1 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>95): formatted 1 cliques (1 files) skipping 1 binary chapter diffs\n",
      "52m 19s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 19s PREPARING (O chapter SET): Already prepared\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>90): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>90): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>90): 1 relevant similarities between 2 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>90): Loaded:     1 cliques out of      2 chunks from 1 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>90): 2 members in 1 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>90): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>90): formatting 1 cliques skipping 1 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>90): formatted 1 cliques (1 files) skipping 1 binary chapter diffs\n",
      "52m 19s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 19s PREPARING (O chapter SET): Already prepared\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>85): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>85): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>85): 1 relevant similarities between 2 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>85): Loaded:     1 cliques out of      2 chunks from 1 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>85): 2 members in 1 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>85): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>85): formatting 1 cliques skipping 1 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>85): formatted 1 cliques (1 files) skipping 1 binary chapter diffs\n",
      "52m 19s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 19s PREPARING (O chapter SET): Already prepared\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>80): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>80): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>80): 2 relevant similarities between 4 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>80): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>80): 4 members in 2 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>80): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>80): formatting 2 cliques skipping 2 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>80): formatted 2 cliques (1 files) skipping 2 binary chapter diffs\n",
      "52m 19s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 19s PREPARING (O chapter SET): Already prepared\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>75): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>75): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>75): 7 relevant similarities between 14 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>75): Loaded:     7 cliques out of     14 chunks from 7 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>75): 14 members in 7 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>75): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>75): formatting 7 cliques skipping 7 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>75): formatted 7 cliques (1 files) skipping 7 binary chapter diffs\n",
      "52m 19s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 19s PREPARING (O chapter SET): Already prepared\n",
      "52m 19s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 19s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>70): fetching similars and chunk candidates\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>70): inspecting the similarity matrix\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>70): 10 relevant similarities between 20 passages\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>70): Loaded:    10 cliques out of     20 chunks from 10 comparisons\n",
      "52m 19s CLIQUES (O chapter SET M>30 S>70): 20 members in 10 cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>70): sorting out cliques\n",
      "52m 19s PRINT (O chapter SET M>30 S>70): formatting 10 cliques involving 10 binary chapter diffs\n",
      "52m 19s PRINT (O chapter SET M>30 S>70): Chapter diffs needed: 10\n",
      "52m 19s PRINT (O chapter SET M>30 S>70): Chapter diffs: 0 newly created and 10 already existing\n",
      "52m 25s PRINT (O chapter SET M>30 S>70): formatted 10 cliques (1 files) involving 10 binary chapter diffs\n",
      "52m 25s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 25s PREPARING (O chapter SET): Already prepared\n",
      "52m 25s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 25s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 25s CLIQUES (O chapter SET M>30 S>65): fetching similars and chunk candidates\n",
      "52m 25s CLIQUES (O chapter SET M>30 S>65): inspecting the similarity matrix\n",
      "52m 25s CLIQUES (O chapter SET M>30 S>65): 12 relevant similarities between 24 passages\n",
      "52m 25s CLIQUES (O chapter SET M>30 S>65): Loaded:    12 cliques out of     24 chunks from 12 comparisons\n",
      "52m 25s CLIQUES (O chapter SET M>30 S>65): 24 members in 12 cliques\n",
      "52m 25s PRINT (O chapter SET M>30 S>65): sorting out cliques\n",
      "52m 25s PRINT (O chapter SET M>30 S>65): formatting 12 cliques involving 12 binary chapter diffs\n",
      "52m 25s PRINT (O chapter SET M>30 S>65): Chapter diffs needed: 12\n",
      "52m 25s PRINT (O chapter SET M>30 S>65): Chapter diffs: 0 newly created and 12 already existing\n",
      "52m 35s PRINT (O chapter SET M>30 S>65): formatted 12 cliques (1 files) involving 12 binary chapter diffs\n",
      "52m 35s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 35s PREPARING (O chapter SET): Already prepared\n",
      "52m 35s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 35s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 35s CLIQUES (O chapter SET M>30 S>60): fetching similars and chunk candidates\n",
      "52m 35s CLIQUES (O chapter SET M>30 S>60): inspecting the similarity matrix\n",
      "52m 35s CLIQUES (O chapter SET M>30 S>60): 17 relevant similarities between 34 passages\n",
      "52m 35s CLIQUES (O chapter SET M>30 S>60): Loaded:    17 cliques out of     34 chunks from 17 comparisons\n",
      "52m 35s CLIQUES (O chapter SET M>30 S>60): 34 members in 17 cliques\n",
      "52m 35s PRINT (O chapter SET M>30 S>60): sorting out cliques\n",
      "52m 35s PRINT (O chapter SET M>30 S>60): formatting 17 cliques involving 17 binary chapter diffs\n",
      "52m 35s PRINT (O chapter SET M>30 S>60): Chapter diffs needed: 17\n",
      "52m 35s PRINT (O chapter SET M>30 S>60): Chapter diffs: 0 newly created and 17 already existing\n",
      "52m 49s PRINT (O chapter SET M>30 S>60): formatted 17 cliques (1 files) involving 17 binary chapter diffs\n",
      "52m 49s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "52m 49s PREPARING (O chapter SET): Already prepared\n",
      "52m 49s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "52m 49s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "52m 49s CLIQUES (O chapter SET M>30 S>55): fetching similars and chunk candidates\n",
      "52m 49s CLIQUES (O chapter SET M>30 S>55): inspecting the similarity matrix\n",
      "52m 49s CLIQUES (O chapter SET M>30 S>55): 22 relevant similarities between 44 passages\n",
      "52m 49s CLIQUES (O chapter SET M>30 S>55): Loaded:    22 cliques out of     44 chunks from 22 comparisons\n",
      "52m 49s CLIQUES (O chapter SET M>30 S>55): 44 members in 22 cliques\n",
      "52m 49s PRINT (O chapter SET M>30 S>55): sorting out cliques\n",
      "52m 49s PRINT (O chapter SET M>30 S>55): formatting 22 cliques involving 22 binary chapter diffs\n",
      "52m 49s PRINT (O chapter SET M>30 S>55): Chapter diffs needed: 22\n",
      "52m 49s PRINT (O chapter SET M>30 S>55): Chapter diffs: 0 newly created and 22 already existing\n",
      "53m 05s PRINT (O chapter SET M>30 S>55): formatted 22 cliques (1 files) involving 22 binary chapter diffs\n",
      "53m 05s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "53m 05s PREPARING (O chapter SET): Already prepared\n",
      "53m 05s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "53m 05s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "53m 05s CLIQUES (O chapter SET M>30 S>50): fetching similars and chunk candidates\n",
      "53m 05s CLIQUES (O chapter SET M>30 S>50): inspecting the similarity matrix\n",
      "53m 05s CLIQUES (O chapter SET M>30 S>50): 28 relevant similarities between 56 passages\n",
      "53m 05s CLIQUES (O chapter SET M>30 S>50): Loaded:    28 cliques out of     56 chunks from 28 comparisons\n",
      "53m 05s CLIQUES (O chapter SET M>30 S>50): 56 members in 28 cliques\n",
      "53m 05s PRINT (O chapter SET M>30 S>50): sorting out cliques\n",
      "53m 05s PRINT (O chapter SET M>30 S>50): formatting 28 cliques involving 28 binary chapter diffs\n",
      "53m 05s PRINT (O chapter SET M>30 S>50): Chapter diffs needed: 28\n",
      "53m 05s PRINT (O chapter SET M>30 S>50): Chapter diffs: 0 newly created and 28 already existing\n",
      "53m 25s PRINT (O chapter SET M>30 S>50): formatted 28 cliques (1 files) involving 28 binary chapter diffs\n",
      "53m 25s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "53m 25s PREPARING (O chapter SET): Already prepared\n",
      "53m 25s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "53m 25s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "53m 25s CLIQUES (O chapter SET M>30 S>45): fetching similars and chunk candidates\n",
      "53m 25s CLIQUES (O chapter SET M>30 S>45): inspecting the similarity matrix\n",
      "53m 25s CLIQUES (O chapter SET M>30 S>45): 42 relevant similarities between 80 passages\n",
      "53m 25s CLIQUES (O chapter SET M>30 S>45): Loaded:    39 cliques out of     80 chunks from 42 comparisons\n",
      "53m 25s CLIQUES (O chapter SET M>30 S>45): 80 members in 39 cliques\n",
      "53m 25s PRINT (O chapter SET M>30 S>45): sorting out cliques\n",
      "53m 25s PRINT (O chapter SET M>30 S>45): formatting 39 cliques involving 37 binary chapter diffs\n",
      "53m 25s PRINT (O chapter SET M>30 S>45): Chapter diffs needed: 37\n",
      "53m 25s PRINT (O chapter SET M>30 S>45): Chapter diffs: 0 newly created and 37 already existing\n",
      "53m 53s PRINT (O chapter SET M>30 S>45): formatted 39 cliques (1 files) involving 37 binary chapter diffs\n",
      "53m 53s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "53m 53s PREPARING (O chapter SET): Already prepared\n",
      "53m 53s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "53m 53s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "53m 53s CLIQUES (O chapter SET M>30 S>40): fetching similars and chunk candidates\n",
      "53m 53s CLIQUES (O chapter SET M>30 S>40): inspecting the similarity matrix\n",
      "53m 53s CLIQUES (O chapter SET M>30 S>40): 87 relevant similarities between 142 passages\n",
      "53m 53s CLIQUES (O chapter SET M>30 S>40): Loaded:    62 cliques out of    142 chunks from 87 comparisons\n",
      "53m 53s CLIQUES (O chapter SET M>30 S>40): 142 members in 62 cliques\n",
      "53m 53s PRINT (O chapter SET M>30 S>40): sorting out cliques\n",
      "53m 53s PRINT (O chapter SET M>30 S>40): formatting 62 cliques involving 51 binary chapter diffs\n",
      "53m 53s PRINT (O chapter SET M>30 S>40): Chapter diffs needed: 51\n",
      "53m 53s PRINT (O chapter SET M>30 S>40): Chapter diffs: 0 newly created and 51 already existing\n",
      "54m 40s PRINT (O chapter SET M>30 S>40): formatted 62 cliques (2 files) involving 51 binary chapter diffs\n",
      "54m 40s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "54m 40s PREPARING (O chapter SET): Already prepared\n",
      "54m 40s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "54m 40s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "54m 40s CLIQUES (O chapter SET M>30 S>35): fetching similars and chunk candidates\n",
      "54m 40s CLIQUES (O chapter SET M>30 S>35): inspecting the similarity matrix\n",
      "54m 40s CLIQUES (O chapter SET M>30 S>35): 352 relevant similarities between 302 passages\n",
      "54m 40s CLIQUES (O chapter SET M>30 S>35): Loaded:    53 cliques out of    302 chunks from 352 comparisons\n",
      "54m 40s CLIQUES (O chapter SET M>30 S>35): 302 members in 53 cliques\n",
      "54m 40s PRINT (O chapter SET M>30 S>35): sorting out cliques\n",
      "54m 40s PRINT (O chapter SET M>30 S>35): formatting 53 cliques skipping 27 binary chapter diffs\n",
      "55m 31s PRINT (O chapter SET M>30 S>35): formatted 53 cliques (2 files) skipping 27 binary chapter diffs\n",
      "55m 31s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "55m 31s PREPARING (O chapter SET): Already prepared\n",
      "55m 31s SIMILARITY (O chapter SET M>30): Using   431 K (431056) comparisons with 3445 entries in matrix\n",
      "55m 31s SIMILARITY (O chapter SET M>30): similarities between 30.0 and 96.83257918552036. 0 are 100%\n",
      "55m 31s CLIQUES (O chapter SET M>30 S>30): fetching similars and chunk candidates\n",
      "55m 31s CLIQUES (O chapter SET M>30 S>30): inspecting the similarity matrix\n",
      "55m 31s CLIQUES (O chapter SET M>30 S>30): 3445 relevant similarities between 571 passages\n",
      "55m 31s CLIQUES (O chapter SET M>30 S>30): Loaded:    28 cliques out of    571 chunks from 3445 comparisons\n",
      "55m 31s CLIQUES (O chapter SET M>30 S>30): 571 members in 28 cliques\n",
      "55m 31s PRINT (O chapter SET M>30 S>30): sorting out cliques\n",
      "55m 31s PRINT (O chapter SET M>30 S>30): formatting 28 cliques skipping 18 binary chapter diffs\n",
      "55m 56s PRINT (O chapter SET M>30 S>30): formatted 28 cliques (1 files) skipping 18 binary chapter diffs\n",
      "55m 56s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "55m 56s PREPARING (O chapter LCS)\n",
      "55m 57s PREPARING (O chapter LCS): Done 929 chunks.\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): Loaded:   431 K (431056) comparisons with 53 entries in matrix\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>100): fetching similars and chunk candidates\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>100): inspecting the similarity matrix\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>100): 0 relevant similarities between 0 passages\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>100): 0 members in 0 cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>100): sorting out cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>100): formatting 0 cliques involving 0 binary chapter diffs\n",
      "55m 57s PRINT (O chapter LCS M>55 S>100): Chapter diffs needed: 0\n",
      "55m 57s PRINT (O chapter LCS M>55 S>100): Chapter diffs: 0 newly created and 0 already existing\n",
      "55m 57s PRINT (O chapter LCS M>55 S>100): formatted 0 cliques (1 files) involving 0 binary chapter diffs\n",
      "55m 57s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "55m 57s PREPARING (O chapter LCS): Already prepared\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>95): fetching similars and chunk candidates\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>95): inspecting the similarity matrix\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>95): 1 relevant similarities between 2 passages\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>95): Loaded:     1 cliques out of      2 chunks from 1 comparisons\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>95): 2 members in 1 cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>95): sorting out cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>95): formatting 1 cliques skipping 1 binary chapter diffs\n",
      "55m 57s PRINT (O chapter LCS M>55 S>95): formatted 1 cliques (1 files) skipping 1 binary chapter diffs\n",
      "55m 57s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "55m 57s PREPARING (O chapter LCS): Already prepared\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>90): fetching similars and chunk candidates\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>90): inspecting the similarity matrix\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>90): 2 relevant similarities between 4 passages\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>90): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>90): 4 members in 2 cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>90): sorting out cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>90): formatting 2 cliques skipping 2 binary chapter diffs\n",
      "55m 57s PRINT (O chapter LCS M>55 S>90): formatted 2 cliques (1 files) skipping 2 binary chapter diffs\n",
      "55m 57s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "55m 57s PREPARING (O chapter LCS): Already prepared\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>85): fetching similars and chunk candidates\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>85): inspecting the similarity matrix\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>85): 6 relevant similarities between 12 passages\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>85): Loaded:     6 cliques out of     12 chunks from 6 comparisons\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>85): 12 members in 6 cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>85): sorting out cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>85): formatting 6 cliques skipping 6 binary chapter diffs\n",
      "55m 57s PRINT (O chapter LCS M>55 S>85): formatted 6 cliques (1 files) skipping 6 binary chapter diffs\n",
      "55m 57s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "55m 57s PREPARING (O chapter LCS): Already prepared\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "55m 57s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>80): fetching similars and chunk candidates\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>80): inspecting the similarity matrix\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>80): 9 relevant similarities between 18 passages\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>80): Loaded:     9 cliques out of     18 chunks from 9 comparisons\n",
      "55m 57s CLIQUES (O chapter LCS M>55 S>80): 18 members in 9 cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>80): sorting out cliques\n",
      "55m 57s PRINT (O chapter LCS M>55 S>80): formatting 9 cliques involving 9 binary chapter diffs\n",
      "55m 57s PRINT (O chapter LCS M>55 S>80): Chapter diffs needed: 9\n",
      "55m 57s PRINT (O chapter LCS M>55 S>80): Chapter diffs: 0 newly created and 9 already existing\n",
      "56m 02s PRINT (O chapter LCS M>55 S>80): formatted 9 cliques (1 files) involving 9 binary chapter diffs\n",
      "56m 02s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "56m 02s PREPARING (O chapter LCS): Already prepared\n",
      "56m 02s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "56m 02s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "56m 02s CLIQUES (O chapter LCS M>55 S>75): fetching similars and chunk candidates\n",
      "56m 02s CLIQUES (O chapter LCS M>55 S>75): inspecting the similarity matrix\n",
      "56m 02s CLIQUES (O chapter LCS M>55 S>75): 13 relevant similarities between 26 passages\n",
      "56m 02s CLIQUES (O chapter LCS M>55 S>75): Loaded:    13 cliques out of     26 chunks from 13 comparisons\n",
      "56m 02s CLIQUES (O chapter LCS M>55 S>75): 26 members in 13 cliques\n",
      "56m 02s PRINT (O chapter LCS M>55 S>75): sorting out cliques\n",
      "56m 02s PRINT (O chapter LCS M>55 S>75): formatting 13 cliques involving 13 binary chapter diffs\n",
      "56m 02s PRINT (O chapter LCS M>55 S>75): Chapter diffs needed: 13\n",
      "56m 02s PRINT (O chapter LCS M>55 S>75): Chapter diffs: 0 newly created and 13 already existing\n",
      "56m 10s PRINT (O chapter LCS M>55 S>75): formatted 13 cliques (1 files) involving 13 binary chapter diffs\n",
      "56m 10s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "56m 10s PREPARING (O chapter LCS): Already prepared\n",
      "56m 10s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "56m 10s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "56m 10s CLIQUES (O chapter LCS M>55 S>70): fetching similars and chunk candidates\n",
      "56m 10s CLIQUES (O chapter LCS M>55 S>70): inspecting the similarity matrix\n",
      "56m 10s CLIQUES (O chapter LCS M>55 S>70): 19 relevant similarities between 38 passages\n",
      "56m 10s CLIQUES (O chapter LCS M>55 S>70): Loaded:    19 cliques out of     38 chunks from 19 comparisons\n",
      "56m 10s CLIQUES (O chapter LCS M>55 S>70): 38 members in 19 cliques\n",
      "56m 10s PRINT (O chapter LCS M>55 S>70): sorting out cliques\n",
      "56m 10s PRINT (O chapter LCS M>55 S>70): formatting 19 cliques involving 19 binary chapter diffs\n",
      "56m 10s PRINT (O chapter LCS M>55 S>70): Chapter diffs needed: 19\n",
      "56m 10s PRINT (O chapter LCS M>55 S>70): Chapter diffs: 0 newly created and 19 already existing\n",
      "56m 26s PRINT (O chapter LCS M>55 S>70): formatted 19 cliques (1 files) involving 19 binary chapter diffs\n",
      "56m 26s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "56m 26s PREPARING (O chapter LCS): Already prepared\n",
      "56m 26s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "56m 26s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "56m 26s CLIQUES (O chapter LCS M>55 S>65): fetching similars and chunk candidates\n",
      "56m 26s CLIQUES (O chapter LCS M>55 S>65): inspecting the similarity matrix\n",
      "56m 26s CLIQUES (O chapter LCS M>55 S>65): 22 relevant similarities between 44 passages\n",
      "56m 26s CLIQUES (O chapter LCS M>55 S>65): Loaded:    22 cliques out of     44 chunks from 22 comparisons\n",
      "56m 26s CLIQUES (O chapter LCS M>55 S>65): 44 members in 22 cliques\n",
      "56m 26s PRINT (O chapter LCS M>55 S>65): sorting out cliques\n",
      "56m 26s PRINT (O chapter LCS M>55 S>65): formatting 22 cliques involving 22 binary chapter diffs\n",
      "56m 26s PRINT (O chapter LCS M>55 S>65): Chapter diffs needed: 22\n",
      "56m 26s PRINT (O chapter LCS M>55 S>65): Chapter diffs: 0 newly created and 22 already existing\n",
      "56m 44s PRINT (O chapter LCS M>55 S>65): formatted 22 cliques (1 files) involving 22 binary chapter diffs\n",
      "56m 44s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "56m 44s PREPARING (O chapter LCS): Already prepared\n",
      "56m 44s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "56m 44s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "56m 44s CLIQUES (O chapter LCS M>55 S>60): fetching similars and chunk candidates\n",
      "56m 44s CLIQUES (O chapter LCS M>55 S>60): inspecting the similarity matrix\n",
      "56m 44s CLIQUES (O chapter LCS M>55 S>60): 26 relevant similarities between 52 passages\n",
      "56m 44s CLIQUES (O chapter LCS M>55 S>60): Loaded:    26 cliques out of     52 chunks from 26 comparisons\n",
      "56m 44s CLIQUES (O chapter LCS M>55 S>60): 52 members in 26 cliques\n",
      "56m 44s PRINT (O chapter LCS M>55 S>60): sorting out cliques\n",
      "56m 44s PRINT (O chapter LCS M>55 S>60): formatting 26 cliques involving 26 binary chapter diffs\n",
      "56m 44s PRINT (O chapter LCS M>55 S>60): Chapter diffs needed: 26\n",
      "56m 44s PRINT (O chapter LCS M>55 S>60): Chapter diffs: 0 newly created and 26 already existing\n",
      "57m 04s PRINT (O chapter LCS M>55 S>60): formatted 26 cliques (1 files) involving 26 binary chapter diffs\n",
      "57m 04s CHUNKING (O chapter): already chunked into 929 chunks\n",
      "57m 04s PREPARING (O chapter LCS): Already prepared\n",
      "57m 04s SIMILARITY (O chapter LCS M>55): Using   431 K (431056) comparisons with 53 entries in matrix\n",
      "57m 04s SIMILARITY (O chapter LCS M>55): similarities between 55.02239283429302 and 97.7977740942458. 0 are 100%\n",
      "57m 04s CLIQUES (O chapter LCS M>55 S>55): fetching similars and chunk candidates\n",
      "57m 04s CLIQUES (O chapter LCS M>55 S>55): inspecting the similarity matrix\n",
      "57m 04s CLIQUES (O chapter LCS M>55 S>55): 53 relevant similarities between 102 passages\n",
      "57m 04s CLIQUES (O chapter LCS M>55 S>55): Loaded:    49 cliques out of    102 chunks from 53 comparisons\n",
      "57m 04s CLIQUES (O chapter LCS M>55 S>55): 102 members in 49 cliques\n",
      "57m 04s PRINT (O chapter LCS M>55 S>55): sorting out cliques\n",
      "57m 04s PRINT (O chapter LCS M>55 S>55): formatting 49 cliques involving 46 binary chapter diffs\n",
      "57m 04s PRINT (O chapter LCS M>55 S>55): Chapter diffs needed: 46\n",
      "57m 04s PRINT (O chapter LCS M>55 S>55): Chapter diffs: 0 newly created and 46 already existing\n",
      "57m 36s PRINT (O chapter LCS M>55 S>55): formatted 49 cliques (1 files) involving 46 binary chapter diffs\n",
      "57m 36s CHUNKING (O verse)\n",
      "57m 37s CHUNKING (O verse): Made 23213 chunks\n",
      "57m 37s PREPARING (O verse SET)\n",
      "57m 38s PREPARING (O verse SET): Done 23213 chunks.\n",
      "57m 38s SIMILARITY (O verse SET M>50): Loaded:   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 38s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 38s CLIQUES (O verse SET M>50 S>100): fetching similars and chunk candidates\n",
      "57m 38s CLIQUES (O verse SET M>50 S>100): inspecting the similarity matrix\n",
      "57m 38s CLIQUES (O verse SET M>50 S>100): 4506 relevant similarities between 993 passages\n",
      "57m 38s CLIQUES (O verse SET M>50 S>100): Loaded:   388 cliques out of    993 chunks from 4506 comparisons\n",
      "57m 38s CLIQUES (O verse SET M>50 S>100): 993 members in 388 cliques\n",
      "57m 38s PRINT (O verse SET M>50 S>100): sorting out cliques\n",
      "57m 38s PRINT (O verse SET M>50 S>100): formatting 388 cliques involving 100 binary chapter diffs\n",
      "57m 38s PRINT (O verse SET M>50 S>100): Chapter diffs needed: 100\n",
      "57m 38s PRINT (O verse SET M>50 S>100): Chapter diffs: 0 newly created and 100 already existing\n",
      "57m 38s PRINT (O verse SET M>50 S>100): formatted 388 cliques (8 files) involving 100 binary chapter diffs\n",
      "57m 38s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 38s PREPARING (O verse SET): Already prepared\n",
      "57m 38s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 38s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 38s CLIQUES (O verse SET M>50 S>95): fetching similars and chunk candidates\n",
      "57m 38s CLIQUES (O verse SET M>50 S>95): inspecting the similarity matrix\n",
      "57m 38s CLIQUES (O verse SET M>50 S>95): 4524 relevant similarities between 1029 passages\n",
      "57m 38s CLIQUES (O verse SET M>50 S>95): Loaded:   406 cliques out of   1029 chunks from 4524 comparisons\n",
      "57m 38s CLIQUES (O verse SET M>50 S>95): 1029 members in 406 cliques\n",
      "57m 38s PRINT (O verse SET M>50 S>95): sorting out cliques\n",
      "57m 38s PRINT (O verse SET M>50 S>95): formatting 406 cliques involving 103 binary chapter diffs\n",
      "57m 38s PRINT (O verse SET M>50 S>95): Chapter diffs needed: 103\n",
      "57m 38s PRINT (O verse SET M>50 S>95): Chapter diffs: 0 newly created and 103 already existing\n",
      "57m 38s PRINT (O verse SET M>50 S>95): formatted 406 cliques (9 files) involving 103 binary chapter diffs\n",
      "57m 38s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 38s PREPARING (O verse SET): Already prepared\n",
      "57m 38s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 38s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 38s CLIQUES (O verse SET M>50 S>90): fetching similars and chunk candidates\n",
      "57m 38s CLIQUES (O verse SET M>50 S>90): inspecting the similarity matrix\n",
      "57m 38s CLIQUES (O verse SET M>50 S>90): 4700 relevant similarities between 1286 passages\n",
      "57m 38s CLIQUES (O verse SET M>50 S>90): Loaded:   526 cliques out of   1286 chunks from 4700 comparisons\n",
      "57m 38s CLIQUES (O verse SET M>50 S>90): 1286 members in 526 cliques\n",
      "57m 38s PRINT (O verse SET M>50 S>90): sorting out cliques\n",
      "57m 38s PRINT (O verse SET M>50 S>90): formatting 526 cliques involving 133 binary chapter diffs\n",
      "57m 38s PRINT (O verse SET M>50 S>90): Chapter diffs needed: 133\n",
      "57m 38s PRINT (O verse SET M>50 S>90): Chapter diffs: 0 newly created and 133 already existing\n",
      "57m 39s PRINT (O verse SET M>50 S>90): formatted 526 cliques (11 files) involving 133 binary chapter diffs\n",
      "57m 39s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 39s PREPARING (O verse SET): Already prepared\n",
      "57m 39s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 39s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 39s CLIQUES (O verse SET M>50 S>85): fetching similars and chunk candidates\n",
      "57m 39s CLIQUES (O verse SET M>50 S>85): inspecting the similarity matrix\n",
      "57m 39s CLIQUES (O verse SET M>50 S>85): 4932 relevant similarities between 1573 passages\n",
      "57m 39s CLIQUES (O verse SET M>50 S>85): Loaded:   651 cliques out of   1573 chunks from 4932 comparisons\n",
      "57m 39s CLIQUES (O verse SET M>50 S>85): 1573 members in 651 cliques\n",
      "57m 39s PRINT (O verse SET M>50 S>85): sorting out cliques\n",
      "57m 39s PRINT (O verse SET M>50 S>85): formatting 651 cliques involving 151 binary chapter diffs\n",
      "57m 39s PRINT (O verse SET M>50 S>85): Chapter diffs needed: 151\n",
      "57m 39s PRINT (O verse SET M>50 S>85): Chapter diffs: 0 newly created and 151 already existing\n",
      "57m 40s PRINT (O verse SET M>50 S>85): formatted 651 cliques (14 files) involving 151 binary chapter diffs\n",
      "57m 40s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 40s PREPARING (O verse SET): Already prepared\n",
      "57m 40s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 40s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 40s CLIQUES (O verse SET M>50 S>80): fetching similars and chunk candidates\n",
      "57m 40s CLIQUES (O verse SET M>50 S>80): inspecting the similarity matrix\n",
      "57m 40s CLIQUES (O verse SET M>50 S>80): 10653 relevant similarities between 1958 passages\n",
      "57m 40s CLIQUES (O verse SET M>50 S>80): Loaded:   800 cliques out of   1958 chunks from 10653 comparisons\n",
      "57m 40s CLIQUES (O verse SET M>50 S>80): 1958 members in 800 cliques\n",
      "57m 40s PRINT (O verse SET M>50 S>80): sorting out cliques\n",
      "57m 40s PRINT (O verse SET M>50 S>80): formatting 800 cliques involving 174 binary chapter diffs\n",
      "57m 40s PRINT (O verse SET M>50 S>80): Chapter diffs needed: 174\n",
      "57m 40s PRINT (O verse SET M>50 S>80): Chapter diffs: 0 newly created and 174 already existing\n",
      "57m 41s PRINT (O verse SET M>50 S>80): formatted 800 cliques (16 files) involving 174 binary chapter diffs\n",
      "57m 41s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 41s PREPARING (O verse SET): Already prepared\n",
      "57m 41s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 41s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 41s CLIQUES (O verse SET M>50 S>75): fetching similars and chunk candidates\n",
      "57m 41s CLIQUES (O verse SET M>50 S>75): inspecting the similarity matrix\n",
      "57m 41s CLIQUES (O verse SET M>50 S>75): 11181 relevant similarities between 2359 passages\n",
      "57m 41s CLIQUES (O verse SET M>50 S>75): Loaded:   961 cliques out of   2359 chunks from 11181 comparisons\n",
      "57m 41s CLIQUES (O verse SET M>50 S>75): 2359 members in 961 cliques\n",
      "57m 41s PRINT (O verse SET M>50 S>75): sorting out cliques\n",
      "57m 41s PRINT (O verse SET M>50 S>75): formatting 961 cliques involving 210 binary chapter diffs\n",
      "57m 41s PRINT (O verse SET M>50 S>75): Chapter diffs needed: 210\n",
      "57m 41s PRINT (O verse SET M>50 S>75): Chapter diffs: 0 newly created and 210 already existing\n",
      "57m 42s PRINT (O verse SET M>50 S>75): formatted 961 cliques (20 files) involving 210 binary chapter diffs\n",
      "57m 42s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 42s PREPARING (O verse SET): Already prepared\n",
      "57m 42s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 42s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 42s CLIQUES (O verse SET M>50 S>70): fetching similars and chunk candidates\n",
      "57m 42s CLIQUES (O verse SET M>50 S>70): inspecting the similarity matrix\n",
      "57m 42s CLIQUES (O verse SET M>50 S>70): 11704 relevant similarities between 2720 passages\n",
      "57m 42s CLIQUES (O verse SET M>50 S>70): Loaded:  1094 cliques out of   2720 chunks from 11704 comparisons\n",
      "57m 42s CLIQUES (O verse SET M>50 S>70): 2720 members in 1094 cliques\n",
      "57m 42s PRINT (O verse SET M>50 S>70): sorting out cliques\n",
      "57m 42s PRINT (O verse SET M>50 S>70): formatting 1094 cliques involving 237 binary chapter diffs\n",
      "57m 42s PRINT (O verse SET M>50 S>70): Chapter diffs needed: 237\n",
      "57m 42s PRINT (O verse SET M>50 S>70): Chapter diffs: 0 newly created and 237 already existing\n",
      "57m 44s PRINT (O verse SET M>50 S>70): formatted 1094 cliques (22 files) involving 237 binary chapter diffs\n",
      "57m 44s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 44s PREPARING (O verse SET): Already prepared\n",
      "57m 44s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 44s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 44s CLIQUES (O verse SET M>50 S>65): fetching similars and chunk candidates\n",
      "57m 44s CLIQUES (O verse SET M>50 S>65): inspecting the similarity matrix\n",
      "57m 44s CLIQUES (O verse SET M>50 S>65): 14353 relevant similarities between 3139 passages\n",
      "57m 44s CLIQUES (O verse SET M>50 S>65): Loaded:  1235 cliques out of   3139 chunks from 14353 comparisons\n",
      "57m 44s CLIQUES (O verse SET M>50 S>65): 3139 members in 1235 cliques\n",
      "57m 44s PRINT (O verse SET M>50 S>65): sorting out cliques\n",
      "57m 44s PRINT (O verse SET M>50 S>65): formatting 1235 cliques involving 284 binary chapter diffs\n",
      "57m 44s PRINT (O verse SET M>50 S>65): Chapter diffs needed: 284\n",
      "57m 44s PRINT (O verse SET M>50 S>65): Chapter diffs: 0 newly created and 284 already existing\n",
      "57m 46s PRINT (O verse SET M>50 S>65): formatted 1235 cliques (25 files) involving 284 binary chapter diffs\n",
      "57m 46s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 46s PREPARING (O verse SET): Already prepared\n",
      "57m 46s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 46s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 46s CLIQUES (O verse SET M>50 S>60): fetching similars and chunk candidates\n",
      "57m 46s CLIQUES (O verse SET M>50 S>60): inspecting the similarity matrix\n",
      "57m 46s CLIQUES (O verse SET M>50 S>60): 16055 relevant similarities between 3877 passages\n",
      "57m 46s CLIQUES (O verse SET M>50 S>60): Loaded:  1439 cliques out of   3877 chunks from 16055 comparisons\n",
      "57m 46s CLIQUES (O verse SET M>50 S>60): 3877 members in 1439 cliques\n",
      "57m 46s PRINT (O verse SET M>50 S>60): sorting out cliques\n",
      "57m 46s PRINT (O verse SET M>50 S>60): formatting 1439 cliques involving 358 binary chapter diffs\n",
      "57m 46s PRINT (O verse SET M>50 S>60): Chapter diffs needed: 358\n",
      "57m 46s PRINT (O verse SET M>50 S>60): Chapter diffs: 0 newly created and 358 already existing\n",
      "57m 48s PRINT (O verse SET M>50 S>60): formatted 1439 cliques (29 files) involving 358 binary chapter diffs\n",
      "57m 48s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "57m 48s PREPARING (O verse SET): Already prepared\n",
      "57m 48s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "57m 48s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "57m 48s CLIQUES (O verse SET M>50 S>55): fetching similars and chunk candidates\n",
      "57m 48s CLIQUES (O verse SET M>50 S>55): inspecting the similarity matrix\n",
      "57m 48s CLIQUES (O verse SET M>50 S>55): 18754 relevant similarities between 4735 passages\n",
      "57m 48s CLIQUES (O verse SET M>50 S>55): Composing cliques out of   4735 chunks from 18754 comparisons\n",
      "57m 49s CLIQUES (O verse SET M>50 S>55): Composed   600 cliques out of   1000 chunks\n",
      "57m 50s CLIQUES (O verse SET M>50 S>55): Composed   973 cliques out of   2000 chunks\n",
      "57m 52s CLIQUES (O verse SET M>50 S>55): Composed  1236 cliques out of   3000 chunks\n",
      "57m 54s CLIQUES (O verse SET M>50 S>55): Composed  1507 cliques out of   4000 chunks\n",
      "57m 56s CLIQUES (O verse SET M>50 S>55): 4735 members in 1638 cliques\n",
      "57m 56s CLIQUES (O verse SET M>50 S>55): Composed and saved  1638 cliques out of   4735 chunks from 18754 comparisons\n",
      "57m 56s PRINT (O verse SET M>50 S>55): sorting out cliques\n",
      "57m 56s PRINT (O verse SET M>50 S>55): formatting 1638 cliques involving 447 binary chapter diffs\n",
      "57m 56s PRINT (O verse SET M>50 S>55): Chapter diffs needed: 447\n",
      "58m 04s PRINT (O verse SET M>50 S>55): Chapter diffs: 60 newly created and 387 already existing\n",
      "58m 07s PRINT (O verse SET M>50 S>55): formatted 1638 cliques (33 files) involving 447 binary chapter diffs\n",
      "58m 07s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 07s PREPARING (O verse SET): Already prepared\n",
      "58m 07s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24832 entries in matrix\n",
      "58m 07s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4506 are 100%\n",
      "58m 07s CLIQUES (O verse SET M>50 S>50): fetching similars and chunk candidates\n",
      "58m 07s CLIQUES (O verse SET M>50 S>50): inspecting the similarity matrix\n",
      "58m 07s CLIQUES (O verse SET M>50 S>50): 24832 relevant similarities between 6711 passages\n",
      "58m 07s CLIQUES (O verse SET M>50 S>50): Composing cliques out of   6711 chunks from 24832 comparisons\n",
      "58m 07s CLIQUES (O verse SET M>50 S>50): Composed   642 cliques out of   1000 chunks\n",
      "58m 09s CLIQUES (O verse SET M>50 S>50): Composed  1029 cliques out of   2000 chunks\n",
      "58m 10s CLIQUES (O verse SET M>50 S>50): Composed  1309 cliques out of   3000 chunks\n",
      "58m 12s CLIQUES (O verse SET M>50 S>50): Composed  1490 cliques out of   4000 chunks\n",
      "58m 15s CLIQUES (O verse SET M>50 S>50): Composed  1634 cliques out of   5000 chunks\n",
      "58m 18s CLIQUES (O verse SET M>50 S>50): Composed  1801 cliques out of   6000 chunks\n",
      "58m 20s CLIQUES (O verse SET M>50 S>50): 6711 members in 1850 cliques\n",
      "58m 20s CLIQUES (O verse SET M>50 S>50): Composed and saved  1850 cliques out of   6711 chunks from 24832 comparisons\n",
      "58m 20s PRINT (O verse SET M>50 S>50): sorting out cliques\n",
      "58m 20s PRINT (O verse SET M>50 S>50): formatting 1850 cliques skipping 560 binary chapter diffs\n",
      "58m 24s PRINT (O verse SET M>50 S>50): formatted 1850 cliques (37 files) skipping 560 binary chapter diffs\n",
      "58m 24s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 24s PREPARING (O verse LCS)\n",
      "58m 25s PREPARING (O verse LCS): Done 23213 chunks.\n",
      "58m 25s SIMILARITY (O verse LCS M>60): Loaded:   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 25s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>100): fetching similars and chunk candidates\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>100): inspecting the similarity matrix\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>100): 4204 relevant similarities between 793 passages\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>100): Loaded:   295 cliques out of    793 chunks from 4204 comparisons\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>100): 793 members in 295 cliques\n",
      "58m 25s PRINT (O verse LCS M>60 S>100): sorting out cliques\n",
      "58m 25s PRINT (O verse LCS M>60 S>100): formatting 295 cliques involving 80 binary chapter diffs\n",
      "58m 25s PRINT (O verse LCS M>60 S>100): Chapter diffs needed: 80\n",
      "58m 25s PRINT (O verse LCS M>60 S>100): Chapter diffs: 0 newly created and 80 already existing\n",
      "58m 25s PRINT (O verse LCS M>60 S>100): formatted 295 cliques (6 files) involving 80 binary chapter diffs\n",
      "58m 25s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 25s PREPARING (O verse LCS): Already prepared\n",
      "58m 25s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 25s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>95): fetching similars and chunk candidates\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>95): inspecting the similarity matrix\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>95): 4489 relevant similarities between 1235 passages\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>95): Loaded:   504 cliques out of   1235 chunks from 4489 comparisons\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>95): 1235 members in 504 cliques\n",
      "58m 25s PRINT (O verse LCS M>60 S>95): sorting out cliques\n",
      "58m 25s PRINT (O verse LCS M>60 S>95): formatting 504 cliques involving 120 binary chapter diffs\n",
      "58m 25s PRINT (O verse LCS M>60 S>95): Chapter diffs needed: 120\n",
      "58m 25s PRINT (O verse LCS M>60 S>95): Chapter diffs: 0 newly created and 120 already existing\n",
      "58m 25s PRINT (O verse LCS M>60 S>95): formatted 504 cliques (11 files) involving 120 binary chapter diffs\n",
      "58m 25s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 25s PREPARING (O verse LCS): Already prepared\n",
      "58m 25s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 25s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>90): fetching similars and chunk candidates\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>90): inspecting the similarity matrix\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>90): 5538 relevant similarities between 1754 passages\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>90): Loaded:   724 cliques out of   1754 chunks from 5538 comparisons\n",
      "58m 25s CLIQUES (O verse LCS M>60 S>90): 1754 members in 724 cliques\n",
      "58m 25s PRINT (O verse LCS M>60 S>90): sorting out cliques\n",
      "58m 25s PRINT (O verse LCS M>60 S>90): formatting 724 cliques involving 151 binary chapter diffs\n",
      "58m 25s PRINT (O verse LCS M>60 S>90): Chapter diffs needed: 151\n",
      "58m 25s PRINT (O verse LCS M>60 S>90): Chapter diffs: 0 newly created and 151 already existing\n",
      "58m 26s PRINT (O verse LCS M>60 S>90): formatted 724 cliques (15 files) involving 151 binary chapter diffs\n",
      "58m 26s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 26s PREPARING (O verse LCS): Already prepared\n",
      "58m 26s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 26s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 26s CLIQUES (O verse LCS M>60 S>85): fetching similars and chunk candidates\n",
      "58m 26s CLIQUES (O verse LCS M>60 S>85): inspecting the similarity matrix\n",
      "58m 26s CLIQUES (O verse LCS M>60 S>85): 7871 relevant similarities between 2296 passages\n",
      "58m 26s CLIQUES (O verse LCS M>60 S>85): Loaded:   938 cliques out of   2296 chunks from 7871 comparisons\n",
      "58m 26s CLIQUES (O verse LCS M>60 S>85): 2296 members in 938 cliques\n",
      "58m 26s PRINT (O verse LCS M>60 S>85): sorting out cliques\n",
      "58m 26s PRINT (O verse LCS M>60 S>85): formatting 938 cliques involving 179 binary chapter diffs\n",
      "58m 26s PRINT (O verse LCS M>60 S>85): Chapter diffs needed: 179\n",
      "58m 26s PRINT (O verse LCS M>60 S>85): Chapter diffs: 0 newly created and 179 already existing\n",
      "58m 27s PRINT (O verse LCS M>60 S>85): formatted 938 cliques (19 files) involving 179 binary chapter diffs\n",
      "58m 27s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 27s PREPARING (O verse LCS): Already prepared\n",
      "58m 27s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 27s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 27s CLIQUES (O verse LCS M>60 S>80): fetching similars and chunk candidates\n",
      "58m 27s CLIQUES (O verse LCS M>60 S>80): inspecting the similarity matrix\n",
      "58m 27s CLIQUES (O verse LCS M>60 S>80): 9461 relevant similarities between 2925 passages\n",
      "58m 27s CLIQUES (O verse LCS M>60 S>80): Loaded:  1141 cliques out of   2925 chunks from 9461 comparisons\n",
      "58m 27s CLIQUES (O verse LCS M>60 S>80): 2925 members in 1141 cliques\n",
      "58m 27s PRINT (O verse LCS M>60 S>80): sorting out cliques\n",
      "58m 27s PRINT (O verse LCS M>60 S>80): formatting 1141 cliques involving 251 binary chapter diffs\n",
      "58m 27s PRINT (O verse LCS M>60 S>80): Chapter diffs needed: 251\n",
      "58m 27s PRINT (O verse LCS M>60 S>80): Chapter diffs: 0 newly created and 251 already existing\n",
      "58m 29s PRINT (O verse LCS M>60 S>80): formatted 1141 cliques (23 files) involving 251 binary chapter diffs\n",
      "58m 29s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 29s PREPARING (O verse LCS): Already prepared\n",
      "58m 29s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 29s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 29s CLIQUES (O verse LCS M>60 S>75): fetching similars and chunk candidates\n",
      "58m 29s CLIQUES (O verse LCS M>60 S>75): inspecting the similarity matrix\n",
      "58m 29s CLIQUES (O verse LCS M>60 S>75): 15543 relevant similarities between 3685 passages\n",
      "58m 29s CLIQUES (O verse LCS M>60 S>75): Loaded:  1340 cliques out of   3685 chunks from 15543 comparisons\n",
      "58m 29s CLIQUES (O verse LCS M>60 S>75): 3685 members in 1340 cliques\n",
      "58m 29s PRINT (O verse LCS M>60 S>75): sorting out cliques\n",
      "58m 29s PRINT (O verse LCS M>60 S>75): formatting 1340 cliques involving 346 binary chapter diffs\n",
      "58m 29s PRINT (O verse LCS M>60 S>75): Chapter diffs needed: 346\n",
      "58m 29s PRINT (O verse LCS M>60 S>75): Chapter diffs: 0 newly created and 346 already existing\n",
      "58m 31s PRINT (O verse LCS M>60 S>75): formatted 1340 cliques (27 files) involving 346 binary chapter diffs\n",
      "58m 31s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 31s PREPARING (O verse LCS): Already prepared\n",
      "58m 31s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 31s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 31s CLIQUES (O verse LCS M>60 S>70): fetching similars and chunk candidates\n",
      "58m 31s CLIQUES (O verse LCS M>60 S>70): inspecting the similarity matrix\n",
      "58m 31s CLIQUES (O verse LCS M>60 S>70): 19834 relevant similarities between 4958 passages\n",
      "58m 31s CLIQUES (O verse LCS M>60 S>70): Loaded:  1644 cliques out of   4958 chunks from 19834 comparisons\n",
      "58m 31s CLIQUES (O verse LCS M>60 S>70): 4958 members in 1644 cliques\n",
      "58m 31s PRINT (O verse LCS M>60 S>70): sorting out cliques\n",
      "58m 31s PRINT (O verse LCS M>60 S>70): formatting 1644 cliques involving 504 binary chapter diffs\n",
      "58m 31s PRINT (O verse LCS M>60 S>70): Chapter diffs needed: 504\n",
      "58m 31s PRINT (O verse LCS M>60 S>70): Chapter diffs: 0 newly created and 504 already existing\n",
      "58m 35s PRINT (O verse LCS M>60 S>70): formatted 1644 cliques (33 files) involving 504 binary chapter diffs\n",
      "58m 35s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 35s PREPARING (O verse LCS): Already prepared\n",
      "58m 35s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 35s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 35s CLIQUES (O verse LCS M>60 S>65): fetching similars and chunk candidates\n",
      "58m 35s CLIQUES (O verse LCS M>60 S>65): inspecting the similarity matrix\n",
      "58m 35s CLIQUES (O verse LCS M>60 S>65): 31841 relevant similarities between 9046 passages\n",
      "58m 35s CLIQUES (O verse LCS M>60 S>65): Loaded:  1821 cliques out of   9046 chunks from 31841 comparisons\n",
      "58m 35s CLIQUES (O verse LCS M>60 S>65): 9046 members in 1821 cliques\n",
      "58m 35s PRINT (O verse LCS M>60 S>65): sorting out cliques\n",
      "58m 35s PRINT (O verse LCS M>60 S>65): formatting 1821 cliques skipping 699 binary chapter diffs\n",
      "58m 40s PRINT (O verse LCS M>60 S>65): formatted 1821 cliques (37 files) skipping 699 binary chapter diffs\n",
      "58m 40s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "58m 40s PREPARING (O verse LCS): Already prepared\n",
      "58m 40s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113614 entries in matrix\n",
      "58m 40s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4204 are 100%\n",
      "58m 40s CLIQUES (O verse LCS M>60 S>60): fetching similars and chunk candidates\n",
      "58m 40s CLIQUES (O verse LCS M>60 S>60): inspecting the similarity matrix\n",
      "58m 40s CLIQUES (O verse LCS M>60 S>60): 113614 relevant similarities between 18941 passages\n",
      "58m 40s CLIQUES (O verse LCS M>60 S>60): Loaded:   380 cliques out of  18941 chunks from 113614 comparisons\n",
      "58m 40s CLIQUES (O verse LCS M>60 S>60): 18941 members in 380 cliques\n",
      "58m 40s PRINT (O verse LCS M>60 S>60): sorting out cliques\n",
      "58m 40s PRINT (O verse LCS M>60 S>60): formatting 380 cliques skipping 190 binary chapter diffs\n",
      "58m 41s PRINT (O verse LCS M>60 S>60): formatted 380 cliques (8 files) skipping 190 binary chapter diffs\n",
      "58m 41s CHUNKING (O half_verse)\n",
      "58m 42s CHUNKING (O half_verse): Made 45180 chunks\n",
      "58m 42s PREPARING (O half_verse SET)\n",
      "58m 43s PREPARING (O half_verse SET): Done 45180 chunks.\n",
      "58m 43s SIMILARITY (O half_verse SET M>50): Loaded:  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 43s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 43s CLIQUES (O half_verse SET M>50 S>100): fetching similars and chunk candidates\n",
      "58m 43s CLIQUES (O half_verse SET M>50 S>100): inspecting the similarity matrix\n",
      "58m 43s CLIQUES (O half_verse SET M>50 S>100): 10239 relevant similarities between 4327 passages\n",
      "58m 43s CLIQUES (O half_verse SET M>50 S>100): Loaded:  1725 cliques out of   4327 chunks from 10239 comparisons\n",
      "58m 43s CLIQUES (O half_verse SET M>50 S>100): 4327 members in 1725 cliques\n",
      "58m 43s PRINT (O half_verse SET M>50 S>100): sorting out cliques\n",
      "58m 43s PRINT (O half_verse SET M>50 S>100): formatting 1725 cliques involving 573 binary chapter diffs\n",
      "58m 43s PRINT (O half_verse SET M>50 S>100): Chapter diffs needed: 573\n",
      "58m 43s PRINT (O half_verse SET M>50 S>100): Chapter diffs: 0 newly created and 573 already existing\n",
      "58m 44s PRINT (O half_verse SET M>50 S>100): formatted 1725 cliques (35 files) involving 573 binary chapter diffs\n",
      "58m 44s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 44s PREPARING (O half_verse SET): Already prepared\n",
      "58m 44s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 44s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 44s CLIQUES (O half_verse SET M>50 S>95): fetching similars and chunk candidates\n",
      "58m 44s CLIQUES (O half_verse SET M>50 S>95): inspecting the similarity matrix\n",
      "58m 44s CLIQUES (O half_verse SET M>50 S>95): 10242 relevant similarities between 4333 passages\n",
      "58m 44s CLIQUES (O half_verse SET M>50 S>95): Loaded:  1728 cliques out of   4333 chunks from 10242 comparisons\n",
      "58m 44s CLIQUES (O half_verse SET M>50 S>95): 4333 members in 1728 cliques\n",
      "58m 44s PRINT (O half_verse SET M>50 S>95): sorting out cliques\n",
      "58m 44s PRINT (O half_verse SET M>50 S>95): formatting 1728 cliques involving 573 binary chapter diffs\n",
      "58m 44s PRINT (O half_verse SET M>50 S>95): Chapter diffs needed: 573\n",
      "58m 44s PRINT (O half_verse SET M>50 S>95): Chapter diffs: 0 newly created and 573 already existing\n",
      "58m 45s PRINT (O half_verse SET M>50 S>95): formatted 1728 cliques (35 files) involving 573 binary chapter diffs\n",
      "58m 45s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 45s PREPARING (O half_verse SET): Already prepared\n",
      "58m 45s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 45s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 45s CLIQUES (O half_verse SET M>50 S>90): fetching similars and chunk candidates\n",
      "58m 45s CLIQUES (O half_verse SET M>50 S>90): inspecting the similarity matrix\n",
      "58m 45s CLIQUES (O half_verse SET M>50 S>90): 10410 relevant similarities between 4618 passages\n",
      "58m 45s CLIQUES (O half_verse SET M>50 S>90): Loaded:  1863 cliques out of   4618 chunks from 10410 comparisons\n",
      "58m 45s CLIQUES (O half_verse SET M>50 S>90): 4618 members in 1863 cliques\n",
      "58m 45s PRINT (O half_verse SET M>50 S>90): sorting out cliques\n",
      "58m 45s PRINT (O half_verse SET M>50 S>90): formatting 1863 cliques involving 587 binary chapter diffs\n",
      "58m 45s PRINT (O half_verse SET M>50 S>90): Chapter diffs needed: 587\n",
      "58m 45s PRINT (O half_verse SET M>50 S>90): Chapter diffs: 0 newly created and 587 already existing\n",
      "58m 46s PRINT (O half_verse SET M>50 S>90): formatted 1863 cliques (38 files) involving 587 binary chapter diffs\n",
      "58m 46s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 46s PREPARING (O half_verse SET): Already prepared\n",
      "58m 46s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 46s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 46s CLIQUES (O half_verse SET M>50 S>85): fetching similars and chunk candidates\n",
      "58m 46s CLIQUES (O half_verse SET M>50 S>85): inspecting the similarity matrix\n",
      "58m 46s CLIQUES (O half_verse SET M>50 S>85): 11111 relevant similarities between 5145 passages\n",
      "58m 46s CLIQUES (O half_verse SET M>50 S>85): Loaded:  2072 cliques out of   5145 chunks from 11111 comparisons\n",
      "58m 46s CLIQUES (O half_verse SET M>50 S>85): 5145 members in 2072 cliques\n",
      "58m 46s PRINT (O half_verse SET M>50 S>85): sorting out cliques\n",
      "58m 46s PRINT (O half_verse SET M>50 S>85): formatting 2072 cliques involving 640 binary chapter diffs\n",
      "58m 46s PRINT (O half_verse SET M>50 S>85): Chapter diffs needed: 640\n",
      "58m 46s PRINT (O half_verse SET M>50 S>85): Chapter diffs: 0 newly created and 640 already existing\n",
      "58m 47s PRINT (O half_verse SET M>50 S>85): formatted 2072 cliques (42 files) involving 640 binary chapter diffs\n",
      "58m 47s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 47s PREPARING (O half_verse SET): Already prepared\n",
      "58m 47s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 47s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 47s CLIQUES (O half_verse SET M>50 S>80): fetching similars and chunk candidates\n",
      "58m 47s CLIQUES (O half_verse SET M>50 S>80): inspecting the similarity matrix\n",
      "58m 47s CLIQUES (O half_verse SET M>50 S>80): 20178 relevant similarities between 6422 passages\n",
      "58m 47s CLIQUES (O half_verse SET M>50 S>80): Loaded:  2474 cliques out of   6422 chunks from 20178 comparisons\n",
      "58m 47s CLIQUES (O half_verse SET M>50 S>80): 6422 members in 2474 cliques\n",
      "58m 47s PRINT (O half_verse SET M>50 S>80): sorting out cliques\n",
      "58m 47s PRINT (O half_verse SET M>50 S>80): formatting 2474 cliques involving 769 binary chapter diffs\n",
      "58m 47s PRINT (O half_verse SET M>50 S>80): Chapter diffs needed: 769\n",
      "58m 47s PRINT (O half_verse SET M>50 S>80): Chapter diffs: 0 newly created and 769 already existing\n",
      "58m 48s PRINT (O half_verse SET M>50 S>80): formatted 2474 cliques (50 files) involving 769 binary chapter diffs\n",
      "58m 48s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 48s PREPARING (O half_verse SET): Already prepared\n",
      "58m 48s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 48s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 48s CLIQUES (O half_verse SET M>50 S>75): fetching similars and chunk candidates\n",
      "58m 48s CLIQUES (O half_verse SET M>50 S>75): inspecting the similarity matrix\n",
      "58m 48s CLIQUES (O half_verse SET M>50 S>75): 23717 relevant similarities between 8265 passages\n",
      "58m 48s CLIQUES (O half_verse SET M>50 S>75): Loaded:  2888 cliques out of   8265 chunks from 23717 comparisons\n",
      "58m 48s CLIQUES (O half_verse SET M>50 S>75): 8265 members in 2888 cliques\n",
      "58m 48s PRINT (O half_verse SET M>50 S>75): sorting out cliques\n",
      "58m 48s PRINT (O half_verse SET M>50 S>75): formatting 2888 cliques involving 919 binary chapter diffs\n",
      "58m 48s PRINT (O half_verse SET M>50 S>75): Chapter diffs needed: 919\n",
      "58m 48s PRINT (O half_verse SET M>50 S>75): Chapter diffs: 0 newly created and 919 already existing\n",
      "58m 50s PRINT (O half_verse SET M>50 S>75): formatted 2888 cliques (58 files) involving 919 binary chapter diffs\n",
      "58m 50s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 50s PREPARING (O half_verse SET): Already prepared\n",
      "58m 50s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 50s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 50s CLIQUES (O half_verse SET M>50 S>70): fetching similars and chunk candidates\n",
      "58m 50s CLIQUES (O half_verse SET M>50 S>70): inspecting the similarity matrix\n",
      "58m 50s CLIQUES (O half_verse SET M>50 S>70): 25560 relevant similarities between 9388 passages\n",
      "58m 50s CLIQUES (O half_verse SET M>50 S>70): Loaded:  3193 cliques out of   9388 chunks from 25560 comparisons\n",
      "58m 50s CLIQUES (O half_verse SET M>50 S>70): 9388 members in 3193 cliques\n",
      "58m 50s PRINT (O half_verse SET M>50 S>70): sorting out cliques\n",
      "58m 50s PRINT (O half_verse SET M>50 S>70): formatting 3193 cliques involving 1014 binary chapter diffs\n",
      "58m 50s PRINT (O half_verse SET M>50 S>70): Chapter diffs needed: 1014\n",
      "58m 50s PRINT (O half_verse SET M>50 S>70): Chapter diffs: 0 newly created and 1014 already existing\n",
      "58m 52s PRINT (O half_verse SET M>50 S>70): formatted 3193 cliques (64 files) involving 1014 binary chapter diffs\n",
      "58m 52s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 52s PREPARING (O half_verse SET): Already prepared\n",
      "58m 52s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 52s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 52s CLIQUES (O half_verse SET M>50 S>65): fetching similars and chunk candidates\n",
      "58m 52s CLIQUES (O half_verse SET M>50 S>65): inspecting the similarity matrix\n",
      "58m 52s CLIQUES (O half_verse SET M>50 S>65): 37453 relevant similarities between 12162 passages\n",
      "58m 52s CLIQUES (O half_verse SET M>50 S>65): Loaded:  3342 cliques out of  12162 chunks from 37453 comparisons\n",
      "58m 52s CLIQUES (O half_verse SET M>50 S>65): 12162 members in 3342 cliques\n",
      "58m 52s PRINT (O half_verse SET M>50 S>65): sorting out cliques\n",
      "58m 52s PRINT (O half_verse SET M>50 S>65): formatting 3342 cliques skipping 1072 binary chapter diffs\n",
      "58m 54s PRINT (O half_verse SET M>50 S>65): formatted 3342 cliques (67 files) skipping 1072 binary chapter diffs\n",
      "58m 54s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 54s PREPARING (O half_verse SET): Already prepared\n",
      "58m 54s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 54s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 54s CLIQUES (O half_verse SET M>50 S>60): fetching similars and chunk candidates\n",
      "58m 54s CLIQUES (O half_verse SET M>50 S>60): inspecting the similarity matrix\n",
      "58m 55s CLIQUES (O half_verse SET M>50 S>60): 55384 relevant similarities between 16476 passages\n",
      "58m 55s CLIQUES (O half_verse SET M>50 S>60): Loaded:  3424 cliques out of  16476 chunks from 55384 comparisons\n",
      "58m 55s CLIQUES (O half_verse SET M>50 S>60): 16476 members in 3424 cliques\n",
      "58m 55s PRINT (O half_verse SET M>50 S>60): sorting out cliques\n",
      "58m 55s PRINT (O half_verse SET M>50 S>60): formatting 3424 cliques skipping 1185 binary chapter diffs\n",
      "58m 57s PRINT (O half_verse SET M>50 S>60): formatted 3424 cliques (69 files) skipping 1185 binary chapter diffs\n",
      "58m 57s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      "58m 57s PREPARING (O half_verse SET): Already prepared\n",
      "58m 57s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      "58m 57s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      "58m 57s CLIQUES (O half_verse SET M>50 S>55): fetching similars and chunk candidates\n",
      "58m 57s CLIQUES (O half_verse SET M>50 S>55): inspecting the similarity matrix\n",
      "58m 57s CLIQUES (O half_verse SET M>50 S>55): 70089 relevant similarities between 19519 passages\n",
      "58m 57s CLIQUES (O half_verse SET M>50 S>55): Composing cliques out of  19519 chunks from 70089 comparisons\n",
      "58m 58s CLIQUES (O half_verse SET M>50 S>55): Composed   604 cliques out of   1000 chunks\n",
      "58m 59s CLIQUES (O half_verse SET M>50 S>55): Composed  1098 cliques out of   2000 chunks\n",
      "59m 01s CLIQUES (O half_verse SET M>50 S>55): Composed  1587 cliques out of   3000 chunks\n",
      "59m 04s CLIQUES (O half_verse SET M>50 S>55): Composed  1974 cliques out of   4000 chunks\n",
      "59m 08s CLIQUES (O half_verse SET M>50 S>55): Composed  2356 cliques out of   5000 chunks\n",
      "59m 12s CLIQUES (O half_verse SET M>50 S>55): Composed  2683 cliques out of   6000 chunks\n",
      "59m 17s CLIQUES (O half_verse SET M>50 S>55): Composed  2971 cliques out of   7000 chunks\n",
      "59m 22s CLIQUES (O half_verse SET M>50 S>55): Composed  3126 cliques out of   8000 chunks\n",
      "59m 28s CLIQUES (O half_verse SET M>50 S>55): Composed  3277 cliques out of   9000 chunks\n",
      "59m 35s CLIQUES (O half_verse SET M>50 S>55): Composed  3271 cliques out of  10000 chunks\n",
      "59m 42s CLIQUES (O half_verse SET M>50 S>55): Composed  3316 cliques out of  11000 chunks\n",
      "59m 48s CLIQUES (O half_verse SET M>50 S>55): Composed  3241 cliques out of  12000 chunks\n",
      "59m 55s CLIQUES (O half_verse SET M>50 S>55): Composed  3384 cliques out of  13000 chunks\n",
      " 1h 00m 04s CLIQUES (O half_verse SET M>50 S>55): Composed  3387 cliques out of  14000 chunks\n",
      " 1h 00m 12s CLIQUES (O half_verse SET M>50 S>55): Composed  3459 cliques out of  15000 chunks\n",
      " 1h 00m 22s CLIQUES (O half_verse SET M>50 S>55): Composed  3567 cliques out of  16000 chunks\n",
      " 1h 00m 33s CLIQUES (O half_verse SET M>50 S>55): Composed  3471 cliques out of  17000 chunks\n",
      " 1h 00m 44s CLIQUES (O half_verse SET M>50 S>55): Composed  3480 cliques out of  18000 chunks\n",
      " 1h 00m 54s CLIQUES (O half_verse SET M>50 S>55): Composed  3279 cliques out of  19000 chunks\n",
      " 1h 01m 00s CLIQUES (O half_verse SET M>50 S>55): 19519 members in 3184 cliques\n",
      " 1h 01m 00s CLIQUES (O half_verse SET M>50 S>55): Composed and saved  3184 cliques out of  19519 chunks from 70089 comparisons\n",
      " 1h 01m 00s PRINT (O half_verse SET M>50 S>55): sorting out cliques\n",
      " 1h 01m 00s PRINT (O half_verse SET M>50 S>55): formatting 3184 cliques skipping 1149 binary chapter diffs\n",
      " 1h 01m 03s PRINT (O half_verse SET M>50 S>55): formatted 3184 cliques (64 files) skipping 1149 binary chapter diffs\n",
      " 1h 01m 03s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 01m 03s PREPARING (O half_verse SET): Already prepared\n",
      " 1h 01m 03s SIMILARITY (O half_verse SET M>50): Using  1020 M (1020593610) comparisons with 179842 entries in matrix\n",
      " 1h 01m 03s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10239 are 100%\n",
      " 1h 01m 03s CLIQUES (O half_verse SET M>50 S>50): fetching similars and chunk candidates\n",
      " 1h 01m 03s CLIQUES (O half_verse SET M>50 S>50): inspecting the similarity matrix\n",
      " 1h 01m 04s CLIQUES (O half_verse SET M>50 S>50): 179842 relevant similarities between 28990 passages\n",
      " 1h 01m 04s CLIQUES (O half_verse SET M>50 S>50): Composing cliques out of  28990 chunks from 179842 comparisons\n",
      " 1h 01m 04s CLIQUES (O half_verse SET M>50 S>50): Composed   652 cliques out of   1000 chunks\n",
      " 1h 01m 06s CLIQUES (O half_verse SET M>50 S>50): Composed  1202 cliques out of   2000 chunks\n",
      " 1h 01m 08s CLIQUES (O half_verse SET M>50 S>50): Composed  1587 cliques out of   3000 chunks\n",
      " 1h 01m 10s CLIQUES (O half_verse SET M>50 S>50): Composed  1958 cliques out of   4000 chunks\n",
      " 1h 01m 13s CLIQUES (O half_verse SET M>50 S>50): Composed  2279 cliques out of   5000 chunks\n",
      " 1h 01m 17s CLIQUES (O half_verse SET M>50 S>50): Composed  2478 cliques out of   6000 chunks\n",
      " 1h 01m 21s CLIQUES (O half_verse SET M>50 S>50): Composed  2663 cliques out of   7000 chunks\n",
      " 1h 01m 25s CLIQUES (O half_verse SET M>50 S>50): Composed  2828 cliques out of   8000 chunks\n",
      " 1h 01m 31s CLIQUES (O half_verse SET M>50 S>50): Composed  2961 cliques out of   9000 chunks\n",
      " 1h 01m 37s CLIQUES (O half_verse SET M>50 S>50): Composed  3058 cliques out of  10000 chunks\n",
      " 1h 01m 44s CLIQUES (O half_verse SET M>50 S>50): Composed  3206 cliques out of  11000 chunks\n",
      " 1h 01m 50s CLIQUES (O half_verse SET M>50 S>50): Composed  3278 cliques out of  12000 chunks\n",
      " 1h 01m 57s CLIQUES (O half_verse SET M>50 S>50): Composed  3297 cliques out of  13000 chunks\n",
      " 1h 02m 05s CLIQUES (O half_verse SET M>50 S>50): Composed  3354 cliques out of  14000 chunks\n",
      " 1h 02m 11s CLIQUES (O half_verse SET M>50 S>50): Composed  3281 cliques out of  15000 chunks\n",
      " 1h 02m 19s CLIQUES (O half_verse SET M>50 S>50): Composed  3373 cliques out of  16000 chunks\n",
      " 1h 02m 27s CLIQUES (O half_verse SET M>50 S>50): Composed  3260 cliques out of  17000 chunks\n",
      " 1h 02m 37s CLIQUES (O half_verse SET M>50 S>50): Composed  3240 cliques out of  18000 chunks\n",
      " 1h 02m 46s CLIQUES (O half_verse SET M>50 S>50): Composed  3378 cliques out of  19000 chunks\n",
      " 1h 02m 54s CLIQUES (O half_verse SET M>50 S>50): Composed  3281 cliques out of  20000 chunks\n",
      " 1h 03m 03s CLIQUES (O half_verse SET M>50 S>50): Composed  3127 cliques out of  21000 chunks\n",
      " 1h 03m 13s CLIQUES (O half_verse SET M>50 S>50): Composed  3111 cliques out of  22000 chunks\n",
      " 1h 03m 23s CLIQUES (O half_verse SET M>50 S>50): Composed  3080 cliques out of  23000 chunks\n",
      " 1h 03m 33s CLIQUES (O half_verse SET M>50 S>50): Composed  2926 cliques out of  24000 chunks\n",
      " 1h 03m 43s CLIQUES (O half_verse SET M>50 S>50): Composed  2779 cliques out of  25000 chunks\n",
      " 1h 03m 55s CLIQUES (O half_verse SET M>50 S>50): Composed  2738 cliques out of  26000 chunks\n",
      " 1h 04m 08s CLIQUES (O half_verse SET M>50 S>50): Composed  2711 cliques out of  27000 chunks\n",
      " 1h 04m 18s CLIQUES (O half_verse SET M>50 S>50): Composed  2378 cliques out of  28000 chunks\n",
      " 1h 04m 28s CLIQUES (O half_verse SET M>50 S>50): 28990 members in 2031 cliques\n",
      " 1h 04m 28s CLIQUES (O half_verse SET M>50 S>50): Composed and saved  2031 cliques out of  28990 chunks from 179842 comparisons\n",
      " 1h 04m 28s PRINT (O half_verse SET M>50 S>50): sorting out cliques\n",
      " 1h 04m 29s PRINT (O half_verse SET M>50 S>50): formatting 2031 cliques skipping 802 binary chapter diffs\n",
      " 1h 04m 30s PRINT (O half_verse SET M>50 S>50): formatted 2031 cliques (41 files) skipping 802 binary chapter diffs\n",
      " 1h 04m 30s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 30s PREPARING (O half_verse LCS)\n",
      " 1h 04m 31s PREPARING (O half_verse LCS): Done 45180 chunks.\n",
      " 1h 04m 32s SIMILARITY (O half_verse LCS M>60): Loaded:  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 33s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 33s CLIQUES (O half_verse LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 1h 04m 33s CLIQUES (O half_verse LCS M>60 S>100): inspecting the similarity matrix\n",
      " 1h 04m 33s CLIQUES (O half_verse LCS M>60 S>100): 9270 relevant similarities between 3799 passages\n",
      " 1h 04m 33s CLIQUES (O half_verse LCS M>60 S>100): Loaded:  1514 cliques out of   3799 chunks from 9270 comparisons\n",
      " 1h 04m 33s CLIQUES (O half_verse LCS M>60 S>100): 3799 members in 1514 cliques\n",
      " 1h 04m 33s PRINT (O half_verse LCS M>60 S>100): sorting out cliques\n",
      " 1h 04m 33s PRINT (O half_verse LCS M>60 S>100): formatting 1514 cliques involving 493 binary chapter diffs\n",
      " 1h 04m 33s PRINT (O half_verse LCS M>60 S>100): Chapter diffs needed: 493\n",
      " 1h 04m 33s PRINT (O half_verse LCS M>60 S>100): Chapter diffs: 0 newly created and 493 already existing\n",
      " 1h 04m 34s PRINT (O half_verse LCS M>60 S>100): formatted 1514 cliques (31 files) involving 493 binary chapter diffs\n",
      " 1h 04m 34s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 34s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 34s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 35s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 35s CLIQUES (O half_verse LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 1h 04m 35s CLIQUES (O half_verse LCS M>60 S>95): inspecting the similarity matrix\n",
      " 1h 04m 35s CLIQUES (O half_verse LCS M>60 S>95): 9663 relevant similarities between 4342 passages\n",
      " 1h 04m 35s CLIQUES (O half_verse LCS M>60 S>95): Loaded:  1771 cliques out of   4342 chunks from 9663 comparisons\n",
      " 1h 04m 35s CLIQUES (O half_verse LCS M>60 S>95): 4342 members in 1771 cliques\n",
      " 1h 04m 35s PRINT (O half_verse LCS M>60 S>95): sorting out cliques\n",
      " 1h 04m 35s PRINT (O half_verse LCS M>60 S>95): formatting 1771 cliques involving 543 binary chapter diffs\n",
      " 1h 04m 35s PRINT (O half_verse LCS M>60 S>95): Chapter diffs needed: 543\n",
      " 1h 04m 35s PRINT (O half_verse LCS M>60 S>95): Chapter diffs: 0 newly created and 543 already existing\n",
      " 1h 04m 36s PRINT (O half_verse LCS M>60 S>95): formatted 1771 cliques (36 files) involving 543 binary chapter diffs\n",
      " 1h 04m 36s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 36s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 36s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 37s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 37s CLIQUES (O half_verse LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 1h 04m 37s CLIQUES (O half_verse LCS M>60 S>90): inspecting the similarity matrix\n",
      " 1h 04m 37s CLIQUES (O half_verse LCS M>60 S>90): 12125 relevant similarities between 5776 passages\n",
      " 1h 04m 37s CLIQUES (O half_verse LCS M>60 S>90): Loaded:  2336 cliques out of   5776 chunks from 12125 comparisons\n",
      " 1h 04m 37s CLIQUES (O half_verse LCS M>60 S>90): 5776 members in 2336 cliques\n",
      " 1h 04m 37s PRINT (O half_verse LCS M>60 S>90): sorting out cliques\n",
      " 1h 04m 37s PRINT (O half_verse LCS M>60 S>90): formatting 2336 cliques involving 732 binary chapter diffs\n",
      " 1h 04m 37s PRINT (O half_verse LCS M>60 S>90): Chapter diffs needed: 732\n",
      " 1h 04m 37s PRINT (O half_verse LCS M>60 S>90): Chapter diffs: 0 newly created and 732 already existing\n",
      " 1h 04m 38s PRINT (O half_verse LCS M>60 S>90): formatted 2336 cliques (47 files) involving 732 binary chapter diffs\n",
      " 1h 04m 38s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 38s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 38s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 39s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 39s CLIQUES (O half_verse LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 1h 04m 39s CLIQUES (O half_verse LCS M>60 S>85): inspecting the similarity matrix\n",
      " 1h 04m 40s CLIQUES (O half_verse LCS M>60 S>85): 17551 relevant similarities between 7970 passages\n",
      " 1h 04m 40s CLIQUES (O half_verse LCS M>60 S>85): Loaded:  2983 cliques out of   7970 chunks from 17551 comparisons\n",
      " 1h 04m 40s CLIQUES (O half_verse LCS M>60 S>85): 7970 members in 2983 cliques\n",
      " 1h 04m 40s PRINT (O half_verse LCS M>60 S>85): sorting out cliques\n",
      " 1h 04m 40s PRINT (O half_verse LCS M>60 S>85): formatting 2983 cliques involving 975 binary chapter diffs\n",
      " 1h 04m 40s PRINT (O half_verse LCS M>60 S>85): Chapter diffs needed: 975\n",
      " 1h 04m 40s PRINT (O half_verse LCS M>60 S>85): Chapter diffs: 0 newly created and 975 already existing\n",
      " 1h 04m 41s PRINT (O half_verse LCS M>60 S>85): formatted 2983 cliques (60 files) involving 975 binary chapter diffs\n",
      " 1h 04m 41s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 41s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 41s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 42s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 42s CLIQUES (O half_verse LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 1h 04m 42s CLIQUES (O half_verse LCS M>60 S>80): inspecting the similarity matrix\n",
      " 1h 04m 43s CLIQUES (O half_verse LCS M>60 S>80): 27273 relevant similarities between 12504 passages\n",
      " 1h 04m 43s CLIQUES (O half_verse LCS M>60 S>80): Loaded:  3540 cliques out of  12504 chunks from 27273 comparisons\n",
      " 1h 04m 43s CLIQUES (O half_verse LCS M>60 S>80): 12504 members in 3540 cliques\n",
      " 1h 04m 43s PRINT (O half_verse LCS M>60 S>80): sorting out cliques\n",
      " 1h 04m 43s PRINT (O half_verse LCS M>60 S>80): formatting 3540 cliques skipping 1230 binary chapter diffs\n",
      " 1h 04m 46s PRINT (O half_verse LCS M>60 S>80): formatted 3540 cliques (71 files) skipping 1230 binary chapter diffs\n",
      " 1h 04m 46s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 46s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 46s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 47s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 47s CLIQUES (O half_verse LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 1h 04m 47s CLIQUES (O half_verse LCS M>60 S>75): inspecting the similarity matrix\n",
      " 1h 04m 49s CLIQUES (O half_verse LCS M>60 S>75): 53981 relevant similarities between 19148 passages\n",
      " 1h 04m 49s CLIQUES (O half_verse LCS M>60 S>75): Loaded:  3084 cliques out of  19148 chunks from 53981 comparisons\n",
      " 1h 04m 49s CLIQUES (O half_verse LCS M>60 S>75): 19148 members in 3084 cliques\n",
      " 1h 04m 49s PRINT (O half_verse LCS M>60 S>75): sorting out cliques\n",
      " 1h 04m 49s PRINT (O half_verse LCS M>60 S>75): formatting 3084 cliques skipping 1134 binary chapter diffs\n",
      " 1h 04m 51s PRINT (O half_verse LCS M>60 S>75): formatted 3084 cliques (62 files) skipping 1134 binary chapter diffs\n",
      " 1h 04m 51s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 51s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 51s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 52s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 52s CLIQUES (O half_verse LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 1h 04m 52s CLIQUES (O half_verse LCS M>60 S>70): inspecting the similarity matrix\n",
      " 1h 04m 53s CLIQUES (O half_verse LCS M>60 S>70): 126162 relevant similarities between 28472 passages\n",
      " 1h 04m 53s CLIQUES (O half_verse LCS M>60 S>70): Loaded:  1894 cliques out of  28472 chunks from 126162 comparisons\n",
      " 1h 04m 53s CLIQUES (O half_verse LCS M>60 S>70): 28472 members in 1894 cliques\n",
      " 1h 04m 53s PRINT (O half_verse LCS M>60 S>70): sorting out cliques\n",
      " 1h 04m 54s PRINT (O half_verse LCS M>60 S>70): formatting 1894 cliques skipping 747 binary chapter diffs\n",
      " 1h 04m 55s PRINT (O half_verse LCS M>60 S>70): formatted 1894 cliques (38 files) skipping 747 binary chapter diffs\n",
      " 1h 04m 55s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 55s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 55s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 04m 56s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 04m 56s CLIQUES (O half_verse LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 1h 04m 56s CLIQUES (O half_verse LCS M>60 S>65): inspecting the similarity matrix\n",
      " 1h 04m 58s CLIQUES (O half_verse LCS M>60 S>65): 393325 relevant similarities between 38180 passages\n",
      " 1h 04m 58s CLIQUES (O half_verse LCS M>60 S>65): Loaded:   665 cliques out of  38180 chunks from 393325 comparisons\n",
      " 1h 04m 58s CLIQUES (O half_verse LCS M>60 S>65): 38180 members in 665 cliques\n",
      " 1h 04m 58s PRINT (O half_verse LCS M>60 S>65): sorting out cliques\n",
      " 1h 04m 58s PRINT (O half_verse LCS M>60 S>65): formatting 665 cliques skipping 287 binary chapter diffs\n",
      " 1h 04m 59s PRINT (O half_verse LCS M>60 S>65): formatted 665 cliques (14 files) skipping 287 binary chapter diffs\n",
      " 1h 04m 59s CHUNKING (O half_verse): already chunked into 45180 chunks\n",
      " 1h 04m 59s PREPARING (O half_verse LCS): Already prepared\n",
      " 1h 04m 59s SIMILARITY (O half_verse LCS M>60): Using  1020 M (1020593610) comparisons with 2017661 entries in matrix\n",
      " 1h 05m 00s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9270 are 100%\n",
      " 1h 05m 00s CLIQUES (O half_verse LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 1h 05m 00s CLIQUES (O half_verse LCS M>60 S>60): inspecting the similarity matrix\n",
      " 1h 05m 02s CLIQUES (O half_verse LCS M>60 S>60): 2017661 relevant similarities between 44011 passages\n",
      " 1h 05m 02s CLIQUES (O half_verse LCS M>60 S>60): Loaded:    89 cliques out of  44011 chunks from 2017661 comparisons\n",
      " 1h 05m 02s CLIQUES (O half_verse LCS M>60 S>60): 44011 members in 89 cliques\n",
      " 1h 05m 02s PRINT (O half_verse LCS M>60 S>60): sorting out cliques\n",
      " 1h 05m 02s PRINT (O half_verse LCS M>60 S>60): formatting 89 cliques skipping 57 binary chapter diffs\n",
      " 1h 05m 02s PRINT (O half_verse LCS M>60 S>60): formatted 89 cliques (2 files) skipping 57 binary chapter diffs\n",
      " 1h 05m 02s CHUNKING (O sentence)\n",
      " 1h 05m 03s CHUNKING (O sentence): Made 63586 chunks\n",
      " 1h 05m 03s PREPARING (O sentence SET)\n",
      " 1h 05m 04s PREPARING (O sentence SET): Done 63586 chunks.\n",
      " 1h 05m 07s SIMILARITY (O sentence SET M>50): Loaded:  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 09s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 09s CLIQUES (O sentence SET M>50 S>100): fetching similars and chunk candidates\n",
      " 1h 05m 09s CLIQUES (O sentence SET M>50 S>100): inspecting the similarity matrix\n",
      " 1h 05m 11s CLIQUES (O sentence SET M>50 S>100): 938441 relevant similarities between 19028 passages\n",
      " 1h 05m 11s CLIQUES (O sentence SET M>50 S>100): Loaded:  4325 cliques out of  19028 chunks from 938441 comparisons\n",
      " 1h 05m 11s CLIQUES (O sentence SET M>50 S>100): 19028 members in 4325 cliques\n",
      " 1h 05m 11s PRINT (O sentence SET M>50 S>100): sorting out cliques\n",
      " 1h 05m 11s PRINT (O sentence SET M>50 S>100): formatting 4325 cliques involving 1528 binary chapter diffs\n",
      " 1h 05m 11s PRINT (O sentence SET M>50 S>100): Chapter diffs needed: 1528\n",
      " 1h 05m 11s PRINT (O sentence SET M>50 S>100): Chapter diffs: 0 newly created and 1528 already existing\n",
      " 1h 05m 13s PRINT (O sentence SET M>50 S>100): formatted 4325 cliques (87 files) involving 1528 binary chapter diffs\n",
      " 1h 05m 13s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 13s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 13s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 15s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 15s CLIQUES (O sentence SET M>50 S>95): fetching similars and chunk candidates\n",
      " 1h 05m 15s CLIQUES (O sentence SET M>50 S>95): inspecting the similarity matrix\n",
      " 1h 05m 17s CLIQUES (O sentence SET M>50 S>95): 938445 relevant similarities between 19036 passages\n",
      " 1h 05m 17s CLIQUES (O sentence SET M>50 S>95): Loaded:  4329 cliques out of  19036 chunks from 938445 comparisons\n",
      " 1h 05m 18s CLIQUES (O sentence SET M>50 S>95): 19036 members in 4329 cliques\n",
      " 1h 05m 18s PRINT (O sentence SET M>50 S>95): sorting out cliques\n",
      " 1h 05m 18s PRINT (O sentence SET M>50 S>95): formatting 4329 cliques involving 1529 binary chapter diffs\n",
      " 1h 05m 18s PRINT (O sentence SET M>50 S>95): Chapter diffs needed: 1529\n",
      " 1h 05m 18s PRINT (O sentence SET M>50 S>95): Chapter diffs: 0 newly created and 1529 already existing\n",
      " 1h 05m 20s PRINT (O sentence SET M>50 S>95): formatted 4329 cliques (87 files) involving 1529 binary chapter diffs\n",
      " 1h 05m 20s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 20s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 20s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 22s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 22s CLIQUES (O sentence SET M>50 S>90): fetching similars and chunk candidates\n",
      " 1h 05m 22s CLIQUES (O sentence SET M>50 S>90): inspecting the similarity matrix\n",
      " 1h 05m 24s CLIQUES (O sentence SET M>50 S>90): 938584 relevant similarities between 19208 passages\n",
      " 1h 05m 24s CLIQUES (O sentence SET M>50 S>90): Loaded:  4404 cliques out of  19208 chunks from 938584 comparisons\n",
      " 1h 05m 24s CLIQUES (O sentence SET M>50 S>90): 19208 members in 4404 cliques\n",
      " 1h 05m 24s PRINT (O sentence SET M>50 S>90): sorting out cliques\n",
      " 1h 05m 24s PRINT (O sentence SET M>50 S>90): formatting 4404 cliques involving 1536 binary chapter diffs\n",
      " 1h 05m 24s PRINT (O sentence SET M>50 S>90): Chapter diffs needed: 1536\n",
      " 1h 05m 24s PRINT (O sentence SET M>50 S>90): Chapter diffs: 0 newly created and 1536 already existing\n",
      " 1h 05m 26s PRINT (O sentence SET M>50 S>90): formatted 4404 cliques (89 files) involving 1536 binary chapter diffs\n",
      " 1h 05m 26s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 26s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 26s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 28s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 28s CLIQUES (O sentence SET M>50 S>85): fetching similars and chunk candidates\n",
      " 1h 05m 28s CLIQUES (O sentence SET M>50 S>85): inspecting the similarity matrix\n",
      " 1h 05m 30s CLIQUES (O sentence SET M>50 S>85): 939433 relevant similarities between 19771 passages\n",
      " 1h 05m 30s CLIQUES (O sentence SET M>50 S>85): Loaded:  4606 cliques out of  19771 chunks from 939433 comparisons\n",
      " 1h 05m 30s CLIQUES (O sentence SET M>50 S>85): 19771 members in 4606 cliques\n",
      " 1h 05m 30s PRINT (O sentence SET M>50 S>85): sorting out cliques\n",
      " 1h 05m 30s PRINT (O sentence SET M>50 S>85): formatting 4606 cliques involving 1587 binary chapter diffs\n",
      " 1h 05m 30s PRINT (O sentence SET M>50 S>85): Chapter diffs needed: 1587\n",
      " 1h 05m 30s PRINT (O sentence SET M>50 S>85): Chapter diffs: 0 newly created and 1587 already existing\n",
      " 1h 05m 32s PRINT (O sentence SET M>50 S>85): formatted 4606 cliques (93 files) involving 1587 binary chapter diffs\n",
      " 1h 05m 32s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 32s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 32s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 34s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 34s CLIQUES (O sentence SET M>50 S>80): fetching similars and chunk candidates\n",
      " 1h 05m 34s CLIQUES (O sentence SET M>50 S>80): inspecting the similarity matrix\n",
      " 1h 05m 36s CLIQUES (O sentence SET M>50 S>80): 961541 relevant similarities between 22063 passages\n",
      " 1h 05m 36s CLIQUES (O sentence SET M>50 S>80): Loaded:  5066 cliques out of  22063 chunks from 961541 comparisons\n",
      " 1h 05m 36s CLIQUES (O sentence SET M>50 S>80): 22063 members in 5066 cliques\n",
      " 1h 05m 36s PRINT (O sentence SET M>50 S>80): sorting out cliques\n",
      " 1h 05m 36s PRINT (O sentence SET M>50 S>80): formatting 5066 cliques involving 1745 binary chapter diffs\n",
      " 1h 05m 36s PRINT (O sentence SET M>50 S>80): Chapter diffs needed: 1745\n",
      " 1h 05m 36s PRINT (O sentence SET M>50 S>80): Chapter diffs: 0 newly created and 1745 already existing\n",
      " 1h 05m 39s PRINT (O sentence SET M>50 S>80): formatted 5066 cliques (102 files) involving 1745 binary chapter diffs\n",
      " 1h 05m 39s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 39s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 39s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 42s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 42s CLIQUES (O sentence SET M>50 S>75): fetching similars and chunk candidates\n",
      " 1h 05m 42s CLIQUES (O sentence SET M>50 S>75): inspecting the similarity matrix\n",
      " 1h 05m 44s CLIQUES (O sentence SET M>50 S>75): 1009869 relevant similarities between 25724 passages\n",
      " 1h 05m 44s CLIQUES (O sentence SET M>50 S>75): Loaded:  4993 cliques out of  25724 chunks from 1009869 comparisons\n",
      " 1h 05m 44s CLIQUES (O sentence SET M>50 S>75): 25724 members in 4993 cliques\n",
      " 1h 05m 44s PRINT (O sentence SET M>50 S>75): sorting out cliques\n",
      " 1h 05m 44s PRINT (O sentence SET M>50 S>75): formatting 4993 cliques skipping 1743 binary chapter diffs\n",
      " 1h 05m 46s PRINT (O sentence SET M>50 S>75): formatted 4993 cliques (100 files) skipping 1743 binary chapter diffs\n",
      " 1h 05m 46s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 46s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 46s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 48s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 48s CLIQUES (O sentence SET M>50 S>70): fetching similars and chunk candidates\n",
      " 1h 05m 48s CLIQUES (O sentence SET M>50 S>70): inspecting the similarity matrix\n",
      " 1h 05m 51s CLIQUES (O sentence SET M>50 S>70): 1012567 relevant similarities between 26880 passages\n",
      " 1h 05m 51s CLIQUES (O sentence SET M>50 S>70): Loaded:  5222 cliques out of  26880 chunks from 1012567 comparisons\n",
      " 1h 05m 51s CLIQUES (O sentence SET M>50 S>70): 26880 members in 5222 cliques\n",
      " 1h 05m 51s PRINT (O sentence SET M>50 S>70): sorting out cliques\n",
      " 1h 05m 51s PRINT (O sentence SET M>50 S>70): formatting 5222 cliques skipping 1819 binary chapter diffs\n",
      " 1h 05m 53s PRINT (O sentence SET M>50 S>70): formatted 5222 cliques (105 files) skipping 1819 binary chapter diffs\n",
      " 1h 05m 53s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 05m 53s PREPARING (O sentence SET): Already prepared\n",
      " 1h 05m 53s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 05m 55s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 05m 55s CLIQUES (O sentence SET M>50 S>65): fetching similars and chunk candidates\n",
      " 1h 05m 55s CLIQUES (O sentence SET M>50 S>65): inspecting the similarity matrix\n",
      " 1h 05m 58s CLIQUES (O sentence SET M>50 S>65): 1332342 relevant similarities between 33378 passages\n",
      " 1h 05m 58s CLIQUES (O sentence SET M>50 S>65): Loaded:  4111 cliques out of  33378 chunks from 1332342 comparisons\n",
      " 1h 05m 58s CLIQUES (O sentence SET M>50 S>65): 33378 members in 4111 cliques\n",
      " 1h 05m 58s PRINT (O sentence SET M>50 S>65): sorting out cliques\n",
      " 1h 05m 58s PRINT (O sentence SET M>50 S>65): formatting 4111 cliques skipping 1474 binary chapter diffs\n",
      " 1h 06m 00s PRINT (O sentence SET M>50 S>65): formatted 4111 cliques (83 files) skipping 1474 binary chapter diffs\n",
      " 1h 06m 00s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 06m 00s PREPARING (O sentence SET): Already prepared\n",
      " 1h 06m 00s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 06m 02s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 06m 02s CLIQUES (O sentence SET M>50 S>60): fetching similars and chunk candidates\n",
      " 1h 06m 02s CLIQUES (O sentence SET M>50 S>60): inspecting the similarity matrix\n",
      " 1h 06m 05s CLIQUES (O sentence SET M>50 S>60): 1431575 relevant similarities between 38807 passages\n",
      " 1h 06m 05s CLIQUES (O sentence SET M>50 S>60): Loaded:  3753 cliques out of  38807 chunks from 1431575 comparisons\n",
      " 1h 06m 05s CLIQUES (O sentence SET M>50 S>60): 38807 members in 3753 cliques\n",
      " 1h 06m 05s PRINT (O sentence SET M>50 S>60): sorting out cliques\n",
      " 1h 06m 05s PRINT (O sentence SET M>50 S>60): formatting 3753 cliques skipping 1386 binary chapter diffs\n",
      " 1h 06m 08s PRINT (O sentence SET M>50 S>60): formatted 3753 cliques (76 files) skipping 1386 binary chapter diffs\n",
      " 1h 06m 08s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 06m 08s PREPARING (O sentence SET): Already prepared\n",
      " 1h 06m 08s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 06m 10s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 06m 10s CLIQUES (O sentence SET M>50 S>55): fetching similars and chunk candidates\n",
      " 1h 06m 10s CLIQUES (O sentence SET M>50 S>55): inspecting the similarity matrix\n",
      " 1h 06m 12s CLIQUES (O sentence SET M>50 S>55): 1459808 relevant similarities between 41835 passages\n",
      " 1h 06m 12s CLIQUES (O sentence SET M>50 S>55): Composing cliques out of  41835 chunks from 1459808 comparisons\n",
      " 1h 06m 13s CLIQUES (O sentence SET M>50 S>55): Composed   545 cliques out of   1000 chunks\n",
      " 1h 06m 14s CLIQUES (O sentence SET M>50 S>55): Composed  1054 cliques out of   2000 chunks\n",
      " 1h 06m 16s CLIQUES (O sentence SET M>50 S>55): Composed  1495 cliques out of   3000 chunks\n",
      " 1h 06m 19s CLIQUES (O sentence SET M>50 S>55): Composed  1917 cliques out of   4000 chunks\n",
      " 1h 06m 24s CLIQUES (O sentence SET M>50 S>55): Composed  2303 cliques out of   5000 chunks\n",
      " 1h 06m 29s CLIQUES (O sentence SET M>50 S>55): Composed  2664 cliques out of   6000 chunks\n",
      " 1h 06m 35s CLIQUES (O sentence SET M>50 S>55): Composed  2820 cliques out of   7000 chunks\n",
      " 1h 06m 41s CLIQUES (O sentence SET M>50 S>55): Composed  3083 cliques out of   8000 chunks\n",
      " 1h 06m 47s CLIQUES (O sentence SET M>50 S>55): Composed  3177 cliques out of   9000 chunks\n",
      " 1h 06m 54s CLIQUES (O sentence SET M>50 S>55): Composed  3320 cliques out of  10000 chunks\n",
      " 1h 07m 01s CLIQUES (O sentence SET M>50 S>55): Composed  3487 cliques out of  11000 chunks\n",
      " 1h 07m 09s CLIQUES (O sentence SET M>50 S>55): Composed  3462 cliques out of  12000 chunks\n",
      " 1h 07m 20s CLIQUES (O sentence SET M>50 S>55): Composed  3497 cliques out of  13000 chunks\n",
      " 1h 07m 30s CLIQUES (O sentence SET M>50 S>55): Composed  3647 cliques out of  14000 chunks\n",
      " 1h 07m 41s CLIQUES (O sentence SET M>50 S>55): Composed  3811 cliques out of  15000 chunks\n",
      " 1h 07m 53s CLIQUES (O sentence SET M>50 S>55): Composed  3808 cliques out of  16000 chunks\n",
      " 1h 08m 05s CLIQUES (O sentence SET M>50 S>55): Composed  3789 cliques out of  17000 chunks\n",
      " 1h 08m 20s CLIQUES (O sentence SET M>50 S>55): Composed  3757 cliques out of  18000 chunks\n",
      " 1h 08m 35s CLIQUES (O sentence SET M>50 S>55): Composed  3880 cliques out of  19000 chunks\n",
      " 1h 08m 55s CLIQUES (O sentence SET M>50 S>55): Composed  3995 cliques out of  20000 chunks\n",
      " 1h 09m 10s CLIQUES (O sentence SET M>50 S>55): Composed  4038 cliques out of  21000 chunks\n",
      " 1h 09m 26s CLIQUES (O sentence SET M>50 S>55): Composed  4069 cliques out of  22000 chunks\n",
      " 1h 09m 40s CLIQUES (O sentence SET M>50 S>55): Composed  4032 cliques out of  23000 chunks\n",
      " 1h 09m 55s CLIQUES (O sentence SET M>50 S>55): Composed  4079 cliques out of  24000 chunks\n",
      " 1h 10m 13s CLIQUES (O sentence SET M>50 S>55): Composed  4153 cliques out of  25000 chunks\n",
      " 1h 10m 31s CLIQUES (O sentence SET M>50 S>55): Composed  4189 cliques out of  26000 chunks\n",
      " 1h 10m 56s CLIQUES (O sentence SET M>50 S>55): Composed  4308 cliques out of  27000 chunks\n",
      " 1h 11m 19s CLIQUES (O sentence SET M>50 S>55): Composed  4192 cliques out of  28000 chunks\n",
      " 1h 11m 34s CLIQUES (O sentence SET M>50 S>55): Composed  3970 cliques out of  29000 chunks\n",
      " 1h 11m 51s CLIQUES (O sentence SET M>50 S>55): Composed  3906 cliques out of  30000 chunks\n",
      " 1h 12m 07s CLIQUES (O sentence SET M>50 S>55): Composed  3896 cliques out of  31000 chunks\n",
      " 1h 12m 25s CLIQUES (O sentence SET M>50 S>55): Composed  3858 cliques out of  32000 chunks\n",
      " 1h 12m 42s CLIQUES (O sentence SET M>50 S>55): Composed  3833 cliques out of  33000 chunks\n",
      " 1h 13m 13s CLIQUES (O sentence SET M>50 S>55): Composed  3791 cliques out of  34000 chunks\n",
      " 1h 13m 37s CLIQUES (O sentence SET M>50 S>55): Composed  3771 cliques out of  35000 chunks\n",
      " 1h 13m 59s CLIQUES (O sentence SET M>50 S>55): Composed  3786 cliques out of  36000 chunks\n",
      " 1h 14m 24s CLIQUES (O sentence SET M>50 S>55): Composed  3730 cliques out of  37000 chunks\n",
      " 1h 14m 45s CLIQUES (O sentence SET M>50 S>55): Composed  3635 cliques out of  38000 chunks\n",
      " 1h 15m 09s CLIQUES (O sentence SET M>50 S>55): Composed  3546 cliques out of  39000 chunks\n",
      " 1h 15m 35s CLIQUES (O sentence SET M>50 S>55): Composed  3481 cliques out of  40000 chunks\n",
      " 1h 16m 02s CLIQUES (O sentence SET M>50 S>55): Composed  3493 cliques out of  41000 chunks\n",
      " 1h 16m 27s CLIQUES (O sentence SET M>50 S>55): 41835 members in 3505 cliques\n",
      " 1h 16m 27s CLIQUES (O sentence SET M>50 S>55): Composed and saved  3505 cliques out of  41835 chunks from 1459808 comparisons\n",
      " 1h 16m 27s PRINT (O sentence SET M>50 S>55): sorting out cliques\n",
      " 1h 16m 27s PRINT (O sentence SET M>50 S>55): formatting 3505 cliques skipping 1341 binary chapter diffs\n",
      " 1h 16m 29s PRINT (O sentence SET M>50 S>55): formatted 3505 cliques (71 files) skipping 1341 binary chapter diffs\n",
      " 1h 16m 29s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 16m 29s PREPARING (O sentence SET): Already prepared\n",
      " 1h 16m 29s SIMILARITY (O sentence SET M>50): Using  2021 M (2021557905) comparisons with 3959201 entries in matrix\n",
      " 1h 16m 31s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 938441 are 100%\n",
      " 1h 16m 31s CLIQUES (O sentence SET M>50 S>50): fetching similars and chunk candidates\n",
      " 1h 16m 31s CLIQUES (O sentence SET M>50 S>50): inspecting the similarity matrix\n",
      " 1h 16m 35s CLIQUES (O sentence SET M>50 S>50): 3959201 relevant similarities between 53117 passages\n",
      " 1h 16m 35s CLIQUES (O sentence SET M>50 S>50): Composing cliques out of  53117 chunks from 3959201 comparisons\n",
      " 1h 16m 36s CLIQUES (O sentence SET M>50 S>50): Composed   567 cliques out of   1000 chunks\n",
      " 1h 16m 37s CLIQUES (O sentence SET M>50 S>50): Composed  1007 cliques out of   2000 chunks\n",
      " 1h 16m 39s CLIQUES (O sentence SET M>50 S>50): Composed  1424 cliques out of   3000 chunks\n",
      " 1h 16m 41s CLIQUES (O sentence SET M>50 S>50): Composed  1737 cliques out of   4000 chunks\n",
      " 1h 16m 45s CLIQUES (O sentence SET M>50 S>50): Composed  2058 cliques out of   5000 chunks\n",
      " 1h 16m 50s CLIQUES (O sentence SET M>50 S>50): Composed  2194 cliques out of   6000 chunks\n",
      " 1h 16m 55s CLIQUES (O sentence SET M>50 S>50): Composed  2430 cliques out of   7000 chunks\n",
      " 1h 17m 00s CLIQUES (O sentence SET M>50 S>50): Composed  2603 cliques out of   8000 chunks\n",
      " 1h 17m 05s CLIQUES (O sentence SET M>50 S>50): Composed  2760 cliques out of   9000 chunks\n",
      " 1h 17m 11s CLIQUES (O sentence SET M>50 S>50): Composed  2796 cliques out of  10000 chunks\n",
      " 1h 17m 19s CLIQUES (O sentence SET M>50 S>50): Composed  3005 cliques out of  11000 chunks\n",
      " 1h 17m 26s CLIQUES (O sentence SET M>50 S>50): Composed  3006 cliques out of  12000 chunks\n",
      " 1h 17m 33s CLIQUES (O sentence SET M>50 S>50): Composed  3004 cliques out of  13000 chunks\n",
      " 1h 17m 41s CLIQUES (O sentence SET M>50 S>50): Composed  3114 cliques out of  14000 chunks\n",
      " 1h 17m 50s CLIQUES (O sentence SET M>50 S>50): Composed  3207 cliques out of  15000 chunks\n",
      " 1h 17m 58s CLIQUES (O sentence SET M>50 S>50): Composed  3202 cliques out of  16000 chunks\n",
      " 1h 18m 07s CLIQUES (O sentence SET M>50 S>50): Composed  3161 cliques out of  17000 chunks\n",
      " 1h 18m 17s CLIQUES (O sentence SET M>50 S>50): Composed  3264 cliques out of  18000 chunks\n",
      " 1h 18m 28s CLIQUES (O sentence SET M>50 S>50): Composed  3374 cliques out of  19000 chunks\n",
      " 1h 18m 38s CLIQUES (O sentence SET M>50 S>50): Composed  3439 cliques out of  20000 chunks\n",
      " 1h 18m 48s CLIQUES (O sentence SET M>50 S>50): Composed  3300 cliques out of  21000 chunks\n",
      " 1h 18m 57s CLIQUES (O sentence SET M>50 S>50): Composed  3172 cliques out of  22000 chunks\n",
      " 1h 19m 07s CLIQUES (O sentence SET M>50 S>50): Composed  3075 cliques out of  23000 chunks\n",
      " 1h 19m 19s CLIQUES (O sentence SET M>50 S>50): Composed  3147 cliques out of  24000 chunks\n",
      " 1h 19m 33s CLIQUES (O sentence SET M>50 S>50): Composed  3127 cliques out of  25000 chunks\n",
      " 1h 19m 47s CLIQUES (O sentence SET M>50 S>50): Composed  3159 cliques out of  26000 chunks\n",
      " 1h 20m 04s CLIQUES (O sentence SET M>50 S>50): Composed  3259 cliques out of  27000 chunks\n",
      " 1h 20m 18s CLIQUES (O sentence SET M>50 S>50): Composed  3242 cliques out of  28000 chunks\n",
      " 1h 20m 30s CLIQUES (O sentence SET M>50 S>50): Composed  3130 cliques out of  29000 chunks\n",
      " 1h 20m 41s CLIQUES (O sentence SET M>50 S>50): Composed  3018 cliques out of  30000 chunks\n",
      " 1h 20m 52s CLIQUES (O sentence SET M>50 S>50): Composed  2942 cliques out of  31000 chunks\n",
      " 1h 21m 06s CLIQUES (O sentence SET M>50 S>50): Composed  2961 cliques out of  32000 chunks\n",
      " 1h 21m 18s CLIQUES (O sentence SET M>50 S>50): Composed  2934 cliques out of  33000 chunks\n",
      " 1h 21m 33s CLIQUES (O sentence SET M>50 S>50): Composed  2962 cliques out of  34000 chunks\n",
      " 1h 21m 51s CLIQUES (O sentence SET M>50 S>50): Composed  3073 cliques out of  35000 chunks\n",
      " 1h 22m 08s CLIQUES (O sentence SET M>50 S>50): Composed  3084 cliques out of  36000 chunks\n",
      " 1h 22m 23s CLIQUES (O sentence SET M>50 S>50): Composed  2935 cliques out of  37000 chunks\n",
      " 1h 22m 34s CLIQUES (O sentence SET M>50 S>50): Composed  2736 cliques out of  38000 chunks\n",
      " 1h 22m 47s CLIQUES (O sentence SET M>50 S>50): Composed  2651 cliques out of  39000 chunks\n",
      " 1h 23m 03s CLIQUES (O sentence SET M>50 S>50): Composed  2629 cliques out of  40000 chunks\n",
      " 1h 23m 17s CLIQUES (O sentence SET M>50 S>50): Composed  2532 cliques out of  41000 chunks\n",
      " 1h 23m 35s CLIQUES (O sentence SET M>50 S>50): Composed  2477 cliques out of  42000 chunks\n",
      " 1h 23m 52s CLIQUES (O sentence SET M>50 S>50): Composed  2437 cliques out of  43000 chunks\n",
      " 1h 24m 09s CLIQUES (O sentence SET M>50 S>50): Composed  2414 cliques out of  44000 chunks\n",
      " 1h 24m 19s CLIQUES (O sentence SET M>50 S>50): Composed  1975 cliques out of  45000 chunks\n",
      " 1h 24m 29s CLIQUES (O sentence SET M>50 S>50): Composed  1820 cliques out of  46000 chunks\n",
      " 1h 24m 37s CLIQUES (O sentence SET M>50 S>50): Composed  1765 cliques out of  47000 chunks\n",
      " 1h 24m 48s CLIQUES (O sentence SET M>50 S>50): Composed  1650 cliques out of  48000 chunks\n",
      " 1h 24m 59s CLIQUES (O sentence SET M>50 S>50): Composed  1539 cliques out of  49000 chunks\n",
      " 1h 25m 11s CLIQUES (O sentence SET M>50 S>50): Composed  1454 cliques out of  50000 chunks\n",
      " 1h 25m 23s CLIQUES (O sentence SET M>50 S>50): Composed  1333 cliques out of  51000 chunks\n",
      " 1h 25m 32s CLIQUES (O sentence SET M>50 S>50): Composed  1238 cliques out of  52000 chunks\n",
      " 1h 25m 45s CLIQUES (O sentence SET M>50 S>50): Composed  1178 cliques out of  53000 chunks\n",
      " 1h 25m 46s CLIQUES (O sentence SET M>50 S>50): 53117 members in 1174 cliques\n",
      " 1h 25m 46s CLIQUES (O sentence SET M>50 S>50): Composed and saved  1174 cliques out of  53117 chunks from 3959201 comparisons\n",
      " 1h 25m 46s PRINT (O sentence SET M>50 S>50): sorting out cliques\n",
      " 1h 25m 46s PRINT (O sentence SET M>50 S>50): formatting 1174 cliques skipping 468 binary chapter diffs\n",
      " 1h 25m 47s PRINT (O sentence SET M>50 S>50): formatted 1174 cliques (24 files) skipping 468 binary chapter diffs\n",
      " 1h 25m 47s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 25m 47s PREPARING (O sentence LCS)\n",
      " 1h 25m 48s PREPARING (O sentence LCS): Done 63586 chunks.\n",
      " 1h 25m 54s SIMILARITY (O sentence LCS M>60): Loaded:  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 26m 00s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 26m 00s CLIQUES (O sentence LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 1h 26m 00s CLIQUES (O sentence LCS M>60 S>100): inspecting the similarity matrix\n",
      " 1h 26m 05s CLIQUES (O sentence LCS M>60 S>100): 903811 relevant similarities between 17532 passages\n",
      " 1h 26m 05s CLIQUES (O sentence LCS M>60 S>100): Loaded:  3981 cliques out of  17532 chunks from 903811 comparisons\n",
      " 1h 26m 05s CLIQUES (O sentence LCS M>60 S>100): 17532 members in 3981 cliques\n",
      " 1h 26m 05s PRINT (O sentence LCS M>60 S>100): sorting out cliques\n",
      " 1h 26m 05s PRINT (O sentence LCS M>60 S>100): formatting 3981 cliques skipping 1364 binary chapter diffs\n",
      " 1h 26m 06s PRINT (O sentence LCS M>60 S>100): formatted 3981 cliques (80 files) skipping 1364 binary chapter diffs\n",
      " 1h 26m 06s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 26m 06s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 26m 06s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 26m 12s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 26m 12s CLIQUES (O sentence LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 1h 26m 12s CLIQUES (O sentence LCS M>60 S>95): inspecting the similarity matrix\n",
      " 1h 26m 16s CLIQUES (O sentence LCS M>60 S>95): 904511 relevant similarities between 18079 passages\n",
      " 1h 26m 16s CLIQUES (O sentence LCS M>60 S>95): Loaded:  4215 cliques out of  18079 chunks from 904511 comparisons\n",
      " 1h 26m 16s CLIQUES (O sentence LCS M>60 S>95): 18079 members in 4215 cliques\n",
      " 1h 26m 16s PRINT (O sentence LCS M>60 S>95): sorting out cliques\n",
      " 1h 26m 16s PRINT (O sentence LCS M>60 S>95): formatting 4215 cliques skipping 1418 binary chapter diffs\n",
      " 1h 26m 18s PRINT (O sentence LCS M>60 S>95): formatted 4215 cliques (85 files) skipping 1418 binary chapter diffs\n",
      " 1h 26m 18s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 26m 18s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 26m 18s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 26m 24s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 26m 24s CLIQUES (O sentence LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 1h 26m 24s CLIQUES (O sentence LCS M>60 S>90): inspecting the similarity matrix\n",
      " 1h 26m 28s CLIQUES (O sentence LCS M>60 S>90): 915567 relevant similarities between 21246 passages\n",
      " 1h 26m 28s CLIQUES (O sentence LCS M>60 S>90): Loaded:  4993 cliques out of  21246 chunks from 915567 comparisons\n",
      " 1h 26m 28s CLIQUES (O sentence LCS M>60 S>90): 21246 members in 4993 cliques\n",
      " 1h 26m 28s PRINT (O sentence LCS M>60 S>90): sorting out cliques\n",
      " 1h 26m 28s PRINT (O sentence LCS M>60 S>90): formatting 4993 cliques involving 1704 binary chapter diffs\n",
      " 1h 26m 28s PRINT (O sentence LCS M>60 S>90): Chapter diffs needed: 1704\n",
      " 1h 26m 28s PRINT (O sentence LCS M>60 S>90): Chapter diffs: 0 newly created and 1704 already existing\n",
      " 1h 26m 30s PRINT (O sentence LCS M>60 S>90): formatted 4993 cliques (100 files) involving 1704 binary chapter diffs\n",
      " 1h 26m 30s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 26m 30s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 26m 30s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 26m 35s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 26m 35s CLIQUES (O sentence LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 1h 26m 35s CLIQUES (O sentence LCS M>60 S>85): inspecting the similarity matrix\n",
      " 1h 26m 40s CLIQUES (O sentence LCS M>60 S>85): 980912 relevant similarities between 26473 passages\n",
      " 1h 26m 40s CLIQUES (O sentence LCS M>60 S>85): Loaded:  4853 cliques out of  26473 chunks from 980912 comparisons\n",
      " 1h 26m 40s CLIQUES (O sentence LCS M>60 S>85): 26473 members in 4853 cliques\n",
      " 1h 26m 40s PRINT (O sentence LCS M>60 S>85): sorting out cliques\n",
      " 1h 26m 40s PRINT (O sentence LCS M>60 S>85): formatting 4853 cliques skipping 1709 binary chapter diffs\n",
      " 1h 26m 42s PRINT (O sentence LCS M>60 S>85): formatted 4853 cliques (98 files) skipping 1709 binary chapter diffs\n",
      " 1h 26m 42s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 26m 42s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 26m 42s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 26m 48s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 26m 48s CLIQUES (O sentence LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 1h 26m 48s CLIQUES (O sentence LCS M>60 S>80): inspecting the similarity matrix\n",
      " 1h 26m 53s CLIQUES (O sentence LCS M>60 S>80): 1301411 relevant similarities between 35626 passages\n",
      " 1h 26m 53s CLIQUES (O sentence LCS M>60 S>80): Loaded:  3470 cliques out of  35626 chunks from 1301411 comparisons\n",
      " 1h 26m 53s CLIQUES (O sentence LCS M>60 S>80): 35626 members in 3470 cliques\n",
      " 1h 26m 53s PRINT (O sentence LCS M>60 S>80): sorting out cliques\n",
      " 1h 26m 53s PRINT (O sentence LCS M>60 S>80): formatting 3470 cliques skipping 1296 binary chapter diffs\n",
      " 1h 26m 55s PRINT (O sentence LCS M>60 S>80): formatted 3470 cliques (70 files) skipping 1296 binary chapter diffs\n",
      " 1h 26m 55s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 26m 55s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 26m 55s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 27m 00s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 27m 00s CLIQUES (O sentence LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 1h 27m 00s CLIQUES (O sentence LCS M>60 S>75): inspecting the similarity matrix\n",
      " 1h 27m 05s CLIQUES (O sentence LCS M>60 S>75): 1620210 relevant similarities between 44307 passages\n",
      " 1h 27m 05s CLIQUES (O sentence LCS M>60 S>75): Loaded:  2293 cliques out of  44307 chunks from 1620210 comparisons\n",
      " 1h 27m 05s CLIQUES (O sentence LCS M>60 S>75): 44307 members in 2293 cliques\n",
      " 1h 27m 05s PRINT (O sentence LCS M>60 S>75): sorting out cliques\n",
      " 1h 27m 05s PRINT (O sentence LCS M>60 S>75): formatting 2293 cliques skipping 889 binary chapter diffs\n",
      " 1h 27m 07s PRINT (O sentence LCS M>60 S>75): formatted 2293 cliques (46 files) skipping 889 binary chapter diffs\n",
      " 1h 27m 07s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 27m 07s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 27m 07s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 27m 12s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 27m 12s CLIQUES (O sentence LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 1h 27m 12s CLIQUES (O sentence LCS M>60 S>70): inspecting the similarity matrix\n",
      " 1h 27m 18s CLIQUES (O sentence LCS M>60 S>70): 2182513 relevant similarities between 52535 passages\n",
      " 1h 27m 18s CLIQUES (O sentence LCS M>60 S>70): Loaded:  1197 cliques out of  52535 chunks from 2182513 comparisons\n",
      " 1h 27m 18s CLIQUES (O sentence LCS M>60 S>70): 52535 members in 1197 cliques\n",
      " 1h 27m 18s PRINT (O sentence LCS M>60 S>70): sorting out cliques\n",
      " 1h 27m 18s PRINT (O sentence LCS M>60 S>70): formatting 1197 cliques skipping 455 binary chapter diffs\n",
      " 1h 27m 19s PRINT (O sentence LCS M>60 S>70): formatted 1197 cliques (24 files) skipping 455 binary chapter diffs\n",
      " 1h 27m 19s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 27m 19s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 27m 19s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 27m 25s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 27m 25s CLIQUES (O sentence LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 1h 27m 25s CLIQUES (O sentence LCS M>60 S>65): inspecting the similarity matrix\n",
      " 1h 27m 32s CLIQUES (O sentence LCS M>60 S>65): 4831555 relevant similarities between 58863 passages\n",
      " 1h 27m 32s CLIQUES (O sentence LCS M>60 S>65): Loaded:   460 cliques out of  58863 chunks from 4831555 comparisons\n",
      " 1h 27m 32s CLIQUES (O sentence LCS M>60 S>65): 58863 members in 460 cliques\n",
      " 1h 27m 32s PRINT (O sentence LCS M>60 S>65): sorting out cliques\n",
      " 1h 27m 33s PRINT (O sentence LCS M>60 S>65): formatting 460 cliques skipping 207 binary chapter diffs\n",
      " 1h 27m 33s PRINT (O sentence LCS M>60 S>65): formatted 460 cliques (10 files) skipping 207 binary chapter diffs\n",
      " 1h 27m 33s CHUNKING (O sentence): already chunked into 63586 chunks\n",
      " 1h 27m 33s PREPARING (O sentence LCS): Already prepared\n",
      " 1h 27m 33s SIMILARITY (O sentence LCS M>60): Using  2021 M (2021557905) comparisons with 10271722 entries in matrix\n",
      " 1h 27m 38s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 903811 are 100%\n",
      " 1h 27m 38s CLIQUES (O sentence LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 1h 27m 38s CLIQUES (O sentence LCS M>60 S>60): inspecting the similarity matrix\n",
      " 1h 27m 50s CLIQUES (O sentence LCS M>60 S>60): 10271722 relevant similarities between 62379 passages\n",
      " 1h 27m 50s CLIQUES (O sentence LCS M>60 S>60): Loaded:   105 cliques out of  62379 chunks from 10271722 comparisons\n",
      " 1h 27m 50s CLIQUES (O sentence LCS M>60 S>60): 62379 members in 105 cliques\n",
      " 1h 27m 50s PRINT (O sentence LCS M>60 S>60): sorting out cliques\n",
      " 1h 27m 50s PRINT (O sentence LCS M>60 S>60): formatting 105 cliques skipping 55 binary chapter diffs\n",
      " 1h 27m 51s PRINT (O sentence LCS M>60 S>60): formatted 105 cliques (3 files) skipping 55 binary chapter diffs\n",
      " 1h 27m 51s EXPERIMENT: Generating html report\n",
      " 1h 27m 51s EXPERIMENT:  36 messy results: deprecated\n",
      " 1h 27m 51s EXPERIMENT:  22 mixed quality: take care\n",
      " 1h 27m 51s EXPERIMENT:  75 no results available\n",
      " 1h 27m 51s EXPERIMENT:   9 unassessed quality: inspection needed\n",
      " 1h 27m 51s EXPERIMENT:  80 method deprecated\n",
      " 1h 27m 51s EXPERIMENT:  18 promising results: recommended\n",
      " 1h 27m 51s EXPERIMENT: Generated html report\n",
      " 1h 27m 51s EXPERIMENT: Generating html report(standalone)\n",
      " 1h 27m 51s EXPERIMENT:  36 messy results: deprecated\n",
      " 1h 27m 51s EXPERIMENT:  22 mixed quality: take care\n",
      " 1h 27m 51s EXPERIMENT:  75 no results available\n",
      " 1h 27m 51s EXPERIMENT:   9 unassessed quality: inspection needed\n",
      " 1h 27m 51s EXPERIMENT:  80 method deprecated\n",
      " 1h 27m 51s EXPERIMENT:  18 promising results: recommended\n",
      " 1h 27m 51s EXPERIMENT: Generated html report\n",
      " 1h 27m 51s EXPERIMENT: Generating html report\n",
      " 1h 27m 51s EXPERIMENT:  36 messy results: deprecated\n",
      " 1h 27m 51s EXPERIMENT:  22 mixed quality: take care\n",
      " 1h 27m 51s EXPERIMENT:  75 no results available\n",
      " 1h 27m 51s EXPERIMENT:   9 unassessed quality: inspection needed\n",
      " 1h 27m 51s EXPERIMENT:  80 method deprecated\n",
      " 1h 27m 51s EXPERIMENT:  18 promising results: recommended\n",
      " 1h 27m 51s EXPERIMENT: Generated html report\n",
      " 1h 27m 51s EXPERIMENT: Generating html report(standalone)\n",
      " 1h 27m 51s EXPERIMENT:  36 messy results: deprecated\n",
      " 1h 27m 51s EXPERIMENT:  22 mixed quality: take care\n",
      " 1h 27m 51s EXPERIMENT:  75 no results available\n",
      " 1h 27m 51s EXPERIMENT:   9 unassessed quality: inspection needed\n",
      " 1h 27m 51s EXPERIMENT:  80 method deprecated\n",
      " 1h 27m 51s EXPERIMENT:  18 promising results: recommended\n",
      " 1h 27m 51s EXPERIMENT: Generated html report\n"
     ]
    }
   ],
   "source": [
    "reset_params()\n",
    "#do_experiment(False, 'sentence', 'LCS', 60, False)\n",
    "do_all_experiments()\n",
    "#do_all_experiments(no_fixed=True, only_object='chapter')\n",
    "#crossrefs2shebanq()\n",
    "show_all_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       ".mis {background-color: #cccccc;}\n",
       ".rec {background-color: #aaffaa;}\n",
       ".dep {background-color: #ffaaaa;}\n",
       ".dub {background-color: #ffddaa;}\n",
       ".out {background-color: #ffddff;}\n",
       ".nor {background-color: #fcfcff;}\n",
       ".ps  {font-weight: normal;}\n",
       ".mx  {font-style: italic;}\n",
       ".cl  {font-weight: bold;}\n",
       ".lr  {font-weight: bold; background-color: #ffffaa;}\n",
       "p,td {font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: small;}\n",
       "td   {border: 1pt solid #000000; padding: 4pt;}\n",
       "table {border: 1pt solid #000000; border-collapse: collapse;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(ecss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "This is sample code for plotting characteristics of the similarity matrix.\n",
    "It does not have a role in the experiments or the assessments of the results.\n",
    "\n",
    "# Overview of the similarities\n",
    "\n",
    "Here is a plot of the similarity matrix.\n",
    "Horizontally you see the degree of similarity from 0 to 100%, vertically the number of pairs that have that (rounded) similarity. This axis is logarithmic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell after the cells below\n",
    "distances = collections.Counter()\n",
    "for (x, d) in chunk_dist.items():\n",
    "    distances[int(round(d))] += 1\n",
    "\n",
    "x = range(MATRIX_THRESHOLD, 101)\n",
    "fig = plt.figure(figsize=[15, 4])\n",
    "plt.plot(x, [math.log(max((1, distances[y]))) for y in x], 'b-')\n",
    "plt.axis([MATRIX_THRESHOLD, 101, 0, 15])\n",
    "plt.xlabel('similarity as %')\n",
    "plt.ylabel('log # similarities')\n",
    "plt.xticks(x, x, rotation='vertical')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15);\n",
    "plt.title('distances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
