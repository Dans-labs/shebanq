{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"https://www.academic-bible.com/en/online-bibles/biblia-hebraica-stuttgartensia-bhs/read-the-bible-text/\" target=\"_blank\"><img align=\"right\" src=\"files/images/DBG-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"50%\" src=\"files/images/parallel.png\"/>\n",
    "\n",
    "# Parallel Passages in the MT\n",
    "\n",
    "We want to make a list of **all** parallel passages in the Masoretic Text (MT) of the Hebrew Bible.\n",
    "More precisely, we want to produce a set of *cliques*, a clique being a set of passages that are *quite* similar.\n",
    "\n",
    "Here is a quote that triggered Dirk to write this notebook:\n",
    "\n",
    "> Finally, the Old Testament Parallels module in Accordance is a helpful resource that enables the researcher to examine 435 sets of parallel texts, or in some cases very similar wording in different texts, in both the MT and translation, but the large number of sets of texts in this database should not fool one to think it is complete or even nearly complete for all parallel writings in the Hebrew Bible.\n",
    "\n",
    "Robert Rezetko and Ian Young.\n",
    "  Historical linguistics & Biblical Hebrew. Steps Toward an Integrated Approach.\n",
    "  *Ancient Near East Monographs, Number9*. SBL Press Atlanta. 2014. \n",
    "  [PDF Open access available](https://www.google.nl/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0CCgQFjAB&url=http%3A%2F%2Fwww.sbl-site.org%2Fassets%2Fpdfs%2Fpubs%2F9781628370461_OA.pdf&ei=2QSdVf-vAYSGzAPArJeYCg&usg=AFQjCNFA3TymYlsebQ0MwXq2FmJCSHNUtg&sig2=LaXuAC5k3V7fSXC6ZVx05w&bvm=bv.96952980,d.bGQ)\n",
    "\n",
    "\n",
    "# Authors\n",
    "\n",
    "[Dirk Roorda](mailto:dirk.roorda@dans.knaw.nl) while discussing ideas with \n",
    "[Martijn Naaijer](mailto:m.naaijer@vu.nl). \n",
    "\n",
    "# Status\n",
    "\n",
    "**Last modified: 2015-07-28**\n",
    "\n",
    "126 experiments have been carried out, of which 9 with promising results.\n",
    "All results can be easily inspected, just by clicking in your browser.\n",
    "One of the experiments has been chosen as the basis for\n",
    "[crossref](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnxjcm9zc3JlZg__&tp=txt_tb1&nget=v)\n",
    "annotations in SHEBANQ.\n",
    "\n",
    "# Results\n",
    "\n",
    "Click in a green cell to see interesting results. The numbers in the cell indicate\n",
    "\n",
    "* the number of passages that have a variant elsewhere\n",
    "* the number of *cliques* they form (cliques are sets of similar passages)\n",
    "* the number of passages in the biggest clique\n",
    "\n",
    "Below the results is an account of the method that we used, followed by the actual code to produce these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "<table>\n",
       "<tr><td class=\"mis\">no results available</td></tr>\n",
       "<tr><td class=\"rec\">promising results: recommended</td></tr>\n",
       "<tr><td class=\"dep\">messy results: deprecated</td></tr>\n",
       "<tr><td class=\"dub\">mixed quality: take care</td></tr>\n",
       "<tr><td class=\"out\">method deprecated</td></tr>\n",
       "<tr><td class=\"nor\">unassessed quality: inspection needed</td></tr>\n",
       "</table>\n",
       "\n",
       "<table>\n",
       "<tr><th>chunk type</th><th>chunk size</th><th>similarity method</th><th>100</th><th>95</th><th>90</th><th>85</th><th>80</th><th>75</th><th>70</th><th>65</th><th>60</th></tr>\n",
       "<tr><td>fixed</td><td>100</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S100.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">18</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S90.html\"><span class=\"cl\">9</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">37</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S85.html\"><span class=\"cl\">18</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">64</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S80.html\"><span class=\"cl\">30</span></a><br/>\n",
       "    <span class=\"mx\">6</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">88</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S75.html\"><span class=\"cl\">40</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">113</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S70.html\"><span class=\"cl\">52</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">156</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S65.html\"><span class=\"cl\">71</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">206</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_SET_M50_S60.html\"><span class=\"cl\">93</span></a><br/>\n",
       "    <span class=\"mx\">10</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>100</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">39</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S90.html\"><span class=\"cl\">19</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">59</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S85.html\"><span class=\"cl\">29</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">85</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S80.html\"><span class=\"cl\">41</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">122</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S75.html\"><span class=\"cl\">56</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">189</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S70.html\"><span class=\"cl\">88</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">287</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S65.html\"><span class=\"cl\">132</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">535</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_100_LCS_M60_S60.html\"><span class=\"cl\">214</span></a><br/>\n",
       "    <span class=\"mx\">31</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>50</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">24</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S90.html\"><span class=\"cl\">12</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">57</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S85.html\"><span class=\"cl\">26</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">114</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S80.html\"><span class=\"cl\">52</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">188</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S75.html\"><span class=\"cl\">86</span></a><br/>\n",
       "    <span class=\"mx\">8</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">273</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S70.html\"><span class=\"cl\">125</span></a><br/>\n",
       "    <span class=\"mx\">10</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">385</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S65.html\"><span class=\"cl\">176</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">538</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_SET_M50_S60.html\"><span class=\"cl\">236</span></a><br/>\n",
       "    <span class=\"mx\">15</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>50</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">12</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S95.html\"><span class=\"cl\">6</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">53</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S90.html\"><span class=\"cl\">25</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">119</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S85.html\"><span class=\"cl\">53</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">196</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S80.html\"><span class=\"cl\">89</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">301</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S75.html\"><span class=\"cl\">135</span></a><br/>\n",
       "    <span class=\"mx\">19</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">467</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S70.html\"><span class=\"cl\">206</span></a><br/>\n",
       "    <span class=\"mx\">20</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">761</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S65.html\"><span class=\"cl\">312</span></a><br/>\n",
       "    <span class=\"mx\">28</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1894</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_50_LCS_M60_S60.html\"><span class=\"cl\">553</span></a><br/>\n",
       "    <span class=\"mx\">112</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>20</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">28</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S100.html\"><span class=\"cl\">14</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">28</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S95.html\"><span class=\"cl\">14</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">103</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S90.html\"><span class=\"cl\">45</span></a><br/>\n",
       "    <span class=\"mx\">8</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">172</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S85.html\"><span class=\"cl\">71</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">330</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S80.html\"><span class=\"cl\">145</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">530</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S75.html\"><span class=\"cl\">228</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">764</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S70.html\"><span class=\"cl\">332</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1058</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S65.html\"><span class=\"cl\">450</span></a><br/>\n",
       "    <span class=\"mx\">13</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1828</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_SET_M50_S60.html\"><span class=\"cl\">732</span></a><br/>\n",
       "    <span class=\"mx\">29</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>20</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">6</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S100.html\"><span class=\"cl\">3</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">47</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S95.html\"><span class=\"cl\">22</span></a><br/>\n",
       "    <span class=\"mx\">4</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">149</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S90.html\"><span class=\"cl\">61</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">311</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S85.html\"><span class=\"cl\">136</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">684</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S80.html\"><span class=\"cl\">300</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1137</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S75.html\"><span class=\"cl\">471</span></a><br/>\n",
       "    <span class=\"mx\">27</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2219</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S70.html\"><span class=\"cl\">841</span></a><br/>\n",
       "    <span class=\"mx\">52</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">5994</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S65.html\"><span class=\"cl\">1234</span></a><br/>\n",
       "    <span class=\"mx\">2718</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">17680</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_20_LCS_M60_S60.html\"><span class=\"cl\">154</span></a><br/>\n",
       "    <span class=\"mx\">17348</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>10</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">446</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S100.html\"><span class=\"cl\">208</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">446</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S95.html\"><span class=\"cl\">208</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">480</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S90.html\"><span class=\"cl\">219</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1120</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S85.html\"><span class=\"cl\">495</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1546</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S80.html\"><span class=\"cl\">632</span></a><br/>\n",
       "    <span class=\"mx\">36</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2772</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S75.html\"><span class=\"cl\">1100</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4050</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S70.html\"><span class=\"cl\">1485</span></a><br/>\n",
       "    <span class=\"mx\">141</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">5789</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S65.html\"><span class=\"cl\">1849</span></a><br/>\n",
       "    <span class=\"mx\">658</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">10213</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_SET_M50_S60.html\"><span class=\"cl\">2205</span></a><br/>\n",
       "    <span class=\"mx\">4164</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>10</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">236</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S100.html\"><span class=\"cl\">112</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">374</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S95.html\"><span class=\"cl\">179</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">903</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S90.html\"><span class=\"cl\">398</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1909</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S85.html\"><span class=\"cl\">788</span></a><br/>\n",
       "    <span class=\"mx\">71</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">3852</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S80.html\"><span class=\"cl\">1418</span></a><br/>\n",
       "    <span class=\"mx\">134</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">8562</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S75.html\"><span class=\"cl\">2341</span></a><br/>\n",
       "    <span class=\"mx\">1999</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">20423</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S70.html\"><span class=\"cl\">1919</span></a><br/>\n",
       "    <span class=\"mx\">15782</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">37712</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S65.html\"><span class=\"cl\">227</span></a><br/>\n",
       "    <span class=\"mx\">37238</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">42451</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/F_10_LCS_M60_S60.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">42449</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>verse</td><td>SET</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">995</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S100.html\"><span class=\"cl\">389</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">1031</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S95.html\"><span class=\"cl\">407</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1290</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S90.html\"><span class=\"cl\">528</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1577</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S85.html\"><span class=\"cl\">653</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">1964</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S80.html\"><span class=\"cl\">803</span></a><br/>\n",
       "    <span class=\"mx\">154</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2365</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S75.html\"><span class=\"cl\">964</span></a><br/>\n",
       "    <span class=\"mx\">156</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2723</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S70.html\"><span class=\"cl\">1095</span></a><br/>\n",
       "    <span class=\"mx\">166</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"this experiment is the last one run\"><span class=\"lr\">*</span>\n",
       "    <span class=\"ps\">3141</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S65.html\"><span class=\"cl\">1235</span></a><br/>\n",
       "    <span class=\"mx\">172</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3893</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_SET_M50_S60.html\"><span class=\"cl\">1443</span></a><br/>\n",
       "    <span class=\"mx\">202</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>verse</td><td>LCS</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">795</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S100.html\"><span class=\"cl\">296</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1235</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S95.html\"><span class=\"cl\">504</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1754</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S90.html\"><span class=\"cl\">724</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2298</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S85.html\"><span class=\"cl\">939</span></a><br/>\n",
       "    <span class=\"mx\">160</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2925</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S80.html\"><span class=\"cl\">1141</span></a><br/>\n",
       "    <span class=\"mx\">174</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3683</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S75.html\"><span class=\"cl\">1339</span></a><br/>\n",
       "    <span class=\"mx\">190</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">4964</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S70.html\"><span class=\"cl\">1646</span></a><br/>\n",
       "    <span class=\"mx\">257</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">9052</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S65.html\"><span class=\"cl\">1820</span></a><br/>\n",
       "    <span class=\"mx\">4237</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">18937</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_verse_LCS_M60_S60.html\"><span class=\"cl\">378</span></a><br/>\n",
       "    <span class=\"mx\">18077</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>half_verse</td><td>SET</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4308</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S100.html\"><span class=\"cl\">1717</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4314</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S95.html\"><span class=\"cl\">1720</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4603</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S90.html\"><span class=\"cl\">1857</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">5131</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S85.html\"><span class=\"cl\">2066</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">6407</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S80.html\"><span class=\"cl\">2466</span></a><br/>\n",
       "    <span class=\"mx\">195</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">8242</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S75.html\"><span class=\"cl\">2878</span></a><br/>\n",
       "    <span class=\"mx\">535</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">9363</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S70.html\"><span class=\"cl\">3181</span></a><br/>\n",
       "    <span class=\"mx\">680</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12139</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S65.html\"><span class=\"cl\">3337</span></a><br/>\n",
       "    <span class=\"mx\">2834</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">16431</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_SET_M50_S60.html\"><span class=\"cl\">3414</span></a><br/>\n",
       "    <span class=\"mx\">6918</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>half_verse</td><td>LCS</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">3779</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S100.html\"><span class=\"cl\">1505</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4324</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S95.html\"><span class=\"cl\">1763</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">5752</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S90.html\"><span class=\"cl\">2325</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">7944</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S85.html\"><span class=\"cl\">2973</span></a><br/>\n",
       "    <span class=\"mx\">189</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12463</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S80.html\"><span class=\"cl\">3528</span></a><br/>\n",
       "    <span class=\"mx\">2359</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">19071</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S75.html\"><span class=\"cl\">3074</span></a><br/>\n",
       "    <span class=\"mx\">11036</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">28373</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S70.html\"><span class=\"cl\">1890</span></a><br/>\n",
       "    <span class=\"mx\">23768</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">38059</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S65.html\"><span class=\"cl\">668</span></a><br/>\n",
       "    <span class=\"mx\">36526</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">43903</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_half_verse_LCS_M60_S60.html\"><span class=\"cl\">92</span></a><br/>\n",
       "    <span class=\"mx\">43708</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>sentence</td><td>SET</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19247</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S100.html\"><span class=\"cl\">4351</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19255</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S95.html\"><span class=\"cl\">4355</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19415</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S90.html\"><span class=\"cl\">4425</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19976</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S85.html\"><span class=\"cl\">4628</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">22348</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S80.html\"><span class=\"cl\">5100</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">26090</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S75.html\"><span class=\"cl\">5003</span></a><br/>\n",
       "    <span class=\"mx\">5019</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">27265</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S70.html\"><span class=\"cl\">5237</span></a><br/>\n",
       "    <span class=\"mx\">5425</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">33892</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S65.html\"><span class=\"cl\">4053</span></a><br/>\n",
       "    <span class=\"mx\">18213</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">39418</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_SET_M50_S60.html\"><span class=\"cl\">3697</span></a><br/>\n",
       "    <span class=\"mx\">24919</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>sentence</td><td>LCS</td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">17698</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S100.html\"><span class=\"cl\">3992</span></a><br/>\n",
       "    <span class=\"mx\">1057</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">18239</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S95.html\"><span class=\"cl\">4224</span></a><br/>\n",
       "    <span class=\"mx\">1057</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">21484</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S90.html\"><span class=\"cl\">5005</span></a><br/>\n",
       "    <span class=\"mx\">1057</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">26842</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S85.html\"><span class=\"cl\">4832</span></a><br/>\n",
       "    <span class=\"mx\">7659</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">36154</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S80.html\"><span class=\"cl\">3428</span></a><br/>\n",
       "    <span class=\"mx\">26190</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">44920</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S75.html\"><span class=\"cl\">2245</span></a><br/>\n",
       "    <span class=\"mx\">38988</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">53180</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S70.html\"><span class=\"cl\">1167</span></a><br/>\n",
       "    <span class=\"mx\">50037</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">59474</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S65.html\"><span class=\"cl\">449</span></a><br/>\n",
       "    <span class=\"mx\">58395</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">62942</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/O_sentence_LCS_M60_S60.html\"><span class=\"cl\">105</span></a><br/>\n",
       "    <span class=\"mx\">62697</span>\n",
       "    </td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell after all other cells\n",
    "HTML(other_exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and results\n",
    "\n",
    "We have conducted 126 experiments, all corresponding to a specific choice of parameters.\n",
    "Every experiment is an attempt to identify variants and collect them in *cliques*.\n",
    "\n",
    "The table gives an overview of the experiments conducted.\n",
    "\n",
    "Every *row* corresponds to a particular way of chunking and a method of measuring the similarity.\n",
    "\n",
    "There are *columns* for each similarity *threshold* that we have tried.\n",
    "The idea is that chunks are similar if their similarity is above the threshold.\n",
    "\n",
    "The outcomes of one experiment have been added to SHEBANQ as the note set\n",
    "[crossref](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnxjcm9zc3JlZg__&tp=txt_tb1&nget=v).\n",
    "The experiment chosen for this is currently\n",
    "\n",
    "* *chunking*: **object verse**\n",
    "* *similarity method*: **SET**\n",
    "* *similarity threshold*: **65**\n",
    "\n",
    "\n",
    "## Assessing the outcomes\n",
    "\n",
    "Not all experiments lead to useful results.\n",
    "We have indicated the value of a result by a color coding, based on objective characteristics,\n",
    "such as the number of passages, the number of cliques, the size of the greatest clique, and the way of chunking.\n",
    "These numbers are shown in the cells.\n",
    "\n",
    "If you click on the hyperlink in the cell, you are taken to a page that gives you\n",
    "all the details of the results:\n",
    "\n",
    "1. A link to a file with all *cliques* (which are the sets of similar passages)\n",
    "1. A list of links to chapter-by-chapter diff files (for cliques with just two members), and only for\n",
    "   experiments with outcomes that are labeled as *promising* or *unassessed quality* or *mixed results*.\n",
    "\n",
    "To get into the variants quickly, inspect the list (2) and click through \n",
    "to see the actual variant material in chapter context.\n",
    "\n",
    "Not all variants occur here, so continue with (1) to see the remaining cliques.\n",
    "\n",
    "Sometimes in (2) a chapter diff file does not indicate clearly the relevant common part of both chapters.\n",
    "In that case you have to consult the big list (1)\n",
    "\n",
    "All these results can be downloaded from the\n",
    "[SHEBANQ github repo](https://github.com/ETCBC/shebanq/tree/master/static/docs/tools/parallel/files)\n",
    "After downloading the whole directory, open ``experiments.html`` in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This is an IPython notebook. \n",
    "It contains a working program to carry out the computations needed to obtain the results reported here.\n",
    "\n",
    "You can download this notebook and run it on your computer, provided you have\n",
    "[LAF-Fabric](http://laf-fabric.readthedocs.org/en/latest/texts/welcome.html) installed.\n",
    "An easy way to do that is describe [here](https://github.com/ETCBC/llshebanq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method description\n",
    "\n",
    "Here we discuss the method we used to arrive at a list of parallel passages \n",
    "in the Masoretic Text (MT) of the Hebrew Bible.\n",
    "\n",
    "## Similarity\n",
    "\n",
    "We have to find passages in the MT that are *similar*.\n",
    "Therefore we *chunk* the text in some way, and then compute the similarities between pairs of chunks.\n",
    "\n",
    "There are many ways to define and compute similarity between texts.\n",
    "Here, we have tried two methods ``SET`` and ``LCS``.\n",
    "Both methods define similarity as the fraction of common material with respect to the total material.\n",
    "\n",
    "### SET\n",
    "\n",
    "The ``SET`` method reduces textual chunks to *sets* of *lexemes*.\n",
    "This method abstracts from the order and number of occurrences of words in chunks.\n",
    "\n",
    "We use as measure for the similarity of chunks $C_1$ and $C_2$ (taken as sets):\n",
    "\n",
    "$$ s_{\\rm set}(C_1, C_2) = {\\vert C_1 \\cap C_2\\vert \\over \\vert C_1 \\cup C_2 \\vert} $$\n",
    "\n",
    "where $\\vert X \\vert$ is the number of elements in set $X$.\n",
    "\n",
    "### LCS\n",
    "\n",
    "The ``LCS`` method is less reductive: chunks are *strings* of *lexemes*, \n",
    "so the order and number of occurrences of words is retained.\n",
    "\n",
    "We use as measure for the similarity of chunks $C_1$ and $C_2$ (taken as strings):\n",
    "\n",
    "$$ s_{\\rm lcs}(C_1, C_2) = {\\vert {\\rm LCS}(C_1,C_2)\\vert \\over \\vert C_1\\vert + \\vert C_2 \\vert - \n",
    "\\vert {\\rm LCS}(C_1,C_2)\\vert} $$\n",
    "\n",
    "where ${\\rm LCS}(C_1, C_2)$ is the\n",
    "[longest common subsequence](https://en.wikipedia.org/wiki/Longest_common_subsequence_problem)\n",
    "of $C_1$ and $C_2$ and\n",
    "$\\vert X\\vert$ is the length of sequence $X$.\n",
    "\n",
    "It remains to be seen whether we need the extra sophistication of ``LCS``.\n",
    "The risk is that ``LCS`` could fail to spot related passages when there is a large amount of transposition going on.\n",
    "The results should have the last word. \n",
    "\n",
    "We need to compute the LCS efficiently, and for this we used the python ``Levenshtein`` module:\n",
    "\n",
    "``pip install python-Levenshtein``\n",
    "\n",
    "whose documentation is\n",
    "[here](http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html).\n",
    "\n",
    "## Performance\n",
    "\n",
    "Similarity computation is the part where the heavy lifting occurs.\n",
    "It is basically quadratic in the number of chunks, so if you have verses as chunks (~ 23,000),\n",
    "you need to do ~ 270,000,000 similarity computations, and if you use sentences (~ 64,000), \n",
    "you need to do ~ 2,000,000,000 ones!\n",
    "The computation of a single similarity should be *really* fast.\n",
    "\n",
    "Besides that, we use two ways to economize:\n",
    "\n",
    "* after having computed a matrix for a specific set of parameter values, we save the matrix to disk;\n",
    "  new runs can load the matrix from disk in a matter of seconds;\n",
    "* we do not store low similarity values in the matrix, low being < ``MATRIX_THRESHOLD``.\n",
    "\n",
    "The ``LCS`` method is more complicated.\n",
    "We have tried the ``ratio`` method from the ``difflib`` package that is present in the standard python distribution.\n",
    "This is unbearably slow for our purposes.\n",
    "The ``ratio`` method in the ``Levenshtein`` package is much quicker.\n",
    "\n",
    "See the table for an indication of the amount of work to create the similarity matrix\n",
    "and the performance per similarity method.\n",
    "\n",
    "The *matrix threshold* is the lower bound of similarities that are stored in the matrix.\n",
    "If a pair of chunks has a lower similarity, no entry will be made in the matrix.\n",
    "\n",
    "The computing has been done on a Macbook Air (11\", mid 2012, 1.7 GHz Intel Core i5, 8GB RAM).\n",
    "\n",
    "|chunk type |chunk size|similarity method|matrix threshold|# of comparisons|size of matrix (KB)|computing time (min)|\n",
    "|:----------|---------:|----------------:|---------------:|---------------:|------------------:|-------------------:|\n",
    "|fixed      |100       |LCS              |60              |       9,003,646|                  7|                  ? |\n",
    "|fixed      |100       |SET              |50              |       9,003,646|                  7|                  ? |\n",
    "|fixed      |50        |LCS              |60              |      36,197,286|                 37|                  ? |\n",
    "|fixed      |50        |SET              |50              |      36,197,286|                 18|                  ? |\n",
    "|fixed      |20        |LCS              |60              |     227,068,705|              2,400|                  ? |\n",
    "|fixed      |20        |SET              |50              |     227,068,705|                113|                  ? |\n",
    "|fixed      |10        |LCS              |60              |     909,020,841|             59,000|                  ? |\n",
    "|fixed      |10        |SET              |50              |     909,020,841|              1,800|                  ? |\n",
    "|object     |verse     |LCS              |60              |     269,410,078|              2,300|                  31|\n",
    "|object     |verse     |SET              |50              |     269,410,078|                509|                  14|\n",
    "|object     |half_verse|LCS              |60              |   1,016,396,241|             40,000|                  50|\n",
    "|object     |half_verse|SET              |50              |   1,016,396,241|              3,600|                  41|\n",
    "|object     |sentence  |LCS              |60              |   2,055,975,750|            212,000|                  68|\n",
    "|object     |sentence  |SET              |50              |   2,055,975,750|             82,000|                  63|\n",
    "\n",
    "\n",
    "## Chunking\n",
    "\n",
    "There are several ways to chunk the text:\n",
    "\n",
    "* fixed chunks of approximately ``CHUNK_SIZE`` words\n",
    "* by object, such as verse, sentence\n",
    "\n",
    "After chunking, we prepare the chunks for similarity measuring.\n",
    "\n",
    "### Observations\n",
    "\n",
    "#### Fixed chunking\n",
    "Fixed chunking is unnatural, but if the chunk size is small, it can yield fair results.\n",
    "The results are somewhat difficult to inspect, because they generally do not respect constituent boundaries.\n",
    "It is to be expected that fixed chunks in variant passages will be mutually *out of phase*, \n",
    "meaning that the chunks involved in these passages are not aligned with each other.\n",
    "So they will have a lower similarity than they could have if they were aligned.\n",
    "This is a source of artificial noise in the outcome and/or missed cases.\n",
    "\n",
    "If the chunking respects \"natural\" boundaries in the text, there is far less misalignment.\n",
    "\n",
    "#### Object chunking\n",
    "We can also chunk by object, such as verse, half_verse or sentence.\n",
    "\n",
    "Chunking by *verse* is very much like chunking in fixed chunks of size 20, performance-wise.\n",
    "\n",
    "Chunking by *half_verse* is comparable to fixed chunks of size 10.\n",
    "\n",
    "Chunking by *sentence* will generate an enormous amount of\n",
    "false positives, because there are very many very short sentences (down to 1-word) in the text.\n",
    "Besides that, the performance overhead is huge.\n",
    "\n",
    "The *half_verses* seem to be a very interesting candidate. \n",
    "They are smaller than verses, but there are less *degenerate cases* compared to with sentences. \n",
    "From the table above it can be read that half verses require only half as many similarity computations as sentences.\n",
    "\n",
    "\n",
    "## Preparing\n",
    "\n",
    "We prepare the chunks for the application of the chosen method of similarity computation (``SET`` or ``LCS``).\n",
    "\n",
    "In both cases we reduce the text to a sequence of transliterated consonantal *lexemes* without disambiguation.\n",
    "In fact, we go one step further: we remove the consonants (alef, wav, yod) that are often silent.\n",
    "\n",
    "For ``SET``, we represent each chunk as the set of its reduced lexemes.\n",
    "\n",
    "For ``LCS``, we represent each chunk as the string obtained by joining its reduced lexemes separated by white spaces.\n",
    "\n",
    "## Cliques\n",
    "\n",
    "After having computed a sufficient part of the similarity matrix, we set a value for ``SIMILARITY_THRESHOLD``.\n",
    "All pairs of chunks having at least that similarity are deemed *interesting*.\n",
    "\n",
    "We organize the members of such pairs in *cliques*, groups of chunks of which each member is \n",
    "similar (*similarity* > ``SIMILARITY_THRESHOLD``) to at least one other member.\n",
    "\n",
    "We start with no cliques and walk through the pairs whose similarity is above ``SIMILARITY_THRESHOLD``, \n",
    "and try to put each member into a clique.\n",
    "\n",
    "If there is not yet a clique, we make the member in question into a new singleton clique.\n",
    "\n",
    "If there are cliques, we find the cliques that have a member similar to the member in question.\n",
    "If we find several, we merge them all into one clique.\n",
    "\n",
    "If there is no such clique, we put the member in a new singleton clique.\n",
    "\n",
    "NB: Cliques may *drift*, meaning that they contain members that are completely different from each other.\n",
    "They are in the same clique, because there is a path of pairwise similar members leading from the one chunk to the other.\n",
    "\n",
    "### Organizing the cliques\n",
    "In order to accomodate cases where there are many corresponding verses in corresponding chapters, we produce\n",
    "chapter-by-chapter diffs in the following way.\n",
    "\n",
    "We make a list of all chapters that are involved in cliques.\n",
    "This yields a list of chapter cliques.\n",
    "For all *binary* chapters cliques, we generate a colorful diff rendering (as html) for the complete two chapters.\n",
    "\n",
    "We only do this for *promising* experiments.\n",
    "\n",
    "### Evaluating clique sets\n",
    "\n",
    "Not all clique sets are equally worth while.\n",
    "For example, if we set the ``SIMILARITY_THRESHOLD`` too low, we might get one gigantic clique, especially\n",
    "in combination with a fine-grained chunking. In other words: we suffer from *clique drifting*.\n",
    "\n",
    "We detect clique drifting by looking at the size of the largest clique.\n",
    "If that is large compared to the total number of chunks, we deem the results unsatisfactory.\n",
    "\n",
    "On the other hand, when the ``SIMILARITY_THRESHOLD`` is too high, you might miss a lot of correspondences,\n",
    "especially when chunks are large, or when we have fixed-size chunks that are out of phase.\n",
    "\n",
    "We deem the results of experiments based on a partioning into fixed length chunks as unsatisfactory, although it\n",
    "might be interesting to inspect what exactly the damage is.\n",
    "\n",
    "At the moment, we have not yet analysed the relative merits of the similarity methods ``SET`` and ``LCS``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines\n",
    "\n",
    "The rest is code. From here we start computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.4\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, collections, pickle, math, difflib, glob\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "PICKLE_PROTOCOL = 3\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import ratio\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  4.27s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/parallel/__log__parallel.txt\n",
      "    21s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.01s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK parallel AT 2015-09-29T07-15-56\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK parallel AT 2015-09-29T07-15-56\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "API = fabric.load('etcbc{}'.format(version), '--', 'parallel', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype\n",
    "        lex g_word_utf8 trailer_utf8\n",
    "        book chapter verse label number\n",
    "    ''',\n",
    "    ''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='NORMAL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Here are the parameters on which the results crucially depend.\n",
    "\n",
    "There are also parameters that control the reporting of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chunking\n",
    "CHUNK_LABELS = {True: 'fixed', False: 'object'}\n",
    "CHUNK_LBS = {True: 'F', False: 'O'}\n",
    "CHUNK_SIZES = (100, 50, 20, 10)\n",
    "CHUNK_OBJECTS = ('verse','half_verse','sentence')\n",
    "\n",
    "# preparing\n",
    "EXCLUDED_CONS = '[>WJ=/\\[]'             # weed out weak consonants\n",
    "EXCLUDED_PAT = re.compile(EXCLUDED_CONS)\n",
    "\n",
    "# similarity\n",
    "MATRIX_THRESHOLD = 50\n",
    "SIM_METHODS = ('SET', 'LCS')\n",
    "SIMILARITIES = (100, 95, 90, 85, 80, 75, 70, 65, 60)\n",
    "\n",
    "# printing\n",
    "DEP_CLIQUE_RATIO = 25\n",
    "DUB_CLIQUE_RATIO = 15\n",
    "REC_CLIQUE_RATIO =  5\n",
    "LARGE_CLIQUE_SIZE = 50\n",
    "CLIQUES_PER_FILE = 50\n",
    "\n",
    "# assessing results\n",
    "VALUE_LABELS = dict(\n",
    "    mis='no results available',\n",
    "    rec='promising results: recommended',\n",
    "    dep='messy results: deprecated',\n",
    "    dub='mixed quality: take care',\n",
    "    out='method deprecated',\n",
    "    nor='unassessed quality: inspection needed',\n",
    "    lr='this experiment is the last one run',\n",
    ")\n",
    "\n",
    "# crossrefs for SHEBANQ\n",
    "SHEBANQ_MATRIX = (False, 'verse', 'SET')\n",
    "SHEBANQ_SIMILARITY = 65\n",
    "SHEBANQ_TOOL = 'parallel'\n",
    "CROSSREF_STATUS = '!'\n",
    "CROSSREF_KEYWORD = 'crossref'\n",
    "\n",
    "# progress indication\n",
    "VERBOSE = False\n",
    "MEGA = 1000000\n",
    "KILO = 1000\n",
    "SIMILARITY_PROGRESS = 5 * MEGA\n",
    "CLIQUES_PROGRESS = 1 * KILO\n",
    "\n",
    "# locations and hyperlinks\n",
    "REMOTE_BASE = 'https://surfdrive.surf.nl/files/public.php?service=files&t=dedf27be7e171ab8a8b151f84ded93e8'\n",
    "LOCAL_BASE_COMP = my_file('').rstrip('/')\n",
    "LOCAL_BASE_OUTP = 'files'\n",
    "EXPERIMENT_DIR = 'experiments'\n",
    "EXPERIMENT_FILE = 'experiments'\n",
    "EXPERIMENT_PATH = '{}/{}.txt'.format(LOCAL_BASE_OUTP, EXPERIMENT_FILE)\n",
    "EXPERIMENT_HTML = '{}/{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_FILE)\n",
    "NOTES_FILE = 'crossref'\n",
    "NOTES_PATH = '{}/{}.csv'.format(LOCAL_BASE_OUTP, NOTES_FILE)\n",
    "STORED_CLIQUE_DIR = 'stored/cliques'\n",
    "STORED_MATRIX_DIR = 'stored/matrices'\n",
    "CHAPTER_DIR = 'chapters'\n",
    "\n",
    "def reset_params():\n",
    "    global CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJECT, CHUNK_LB, CHUNK_DESC\n",
    "    global SIMILARITY_METHOD, SIMILARITY_THRESHOLD, MATRIX_THRESHOLD\n",
    "    global meta\n",
    "    meta = collections.OrderedDict()\n",
    "    \n",
    "    # chunking\n",
    "    CHUNK_FIXED = None                      # kind of chunking: fixed size or by object\n",
    "    CHUNK_SIZE = None                       # only relevant for CHUNK_FIXED = True\n",
    "    CHUNK_OBJECT = None                     # only relevant for CHUNK_FIXED = False; see CHUNK_OBJECTS in next cell\n",
    "    CHUNK_LB = None                         # computed from CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJ\n",
    "    CHUNK_DESC = None                       # computed from CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJ\n",
    "    # similarity\n",
    "    MATRIX_THRESHOLD = None                 # minimal similarity used to fill the matrix of similarities\n",
    "    SIMILARITY_METHOD = None                # see SIM_METHODS in next cell\n",
    "    SIMILARITY_THRESHOLD = None             # minimal similarity used to put elements together in cliques\n",
    "    meta = collections.OrderedDict()\n",
    "\n",
    "def set_matrix_threshold(sim_m=None):\n",
    "    global MATRIX_THRESHOLD\n",
    "    the_sim_m = SIMILARITY_METHOD if sim_m == None else sim_m\n",
    "    MATRIX_THRESHOLD = 50 if the_sim_m == 'SET' else 60\n",
    "\n",
    "def do_params(chunk_f, chunk_i, sim_m, sim_thr):\n",
    "    global CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJECT, CHUNK_LB, CHUNK_DESC\n",
    "    global SIMILARITY_METHOD, SIMILARITY_THRESHOLD, MATRIX_THRESHOLD\n",
    "    global meta\n",
    "    do_chunk = False\n",
    "    do_prep = False\n",
    "    do_sim = False\n",
    "    do_clique = False\n",
    "    meta = collections.OrderedDict()\n",
    "    if chunk_f != CHUNK_FIXED or (chunk_f and chunk_i != CHUNK_SIZE) or (not chunk_f and chunk_i != CHUNK_OBJECT):\n",
    "        do_chunk = True\n",
    "        do_prep = True\n",
    "        do_sim = True\n",
    "        do_clique = True\n",
    "        CHUNK_FIXED = chunk_f\n",
    "        if chunk_f: CHUNK_SIZE = chunk_i\n",
    "        else: CHUNK_OBJECT = chunk_i\n",
    "    if sim_m != SIMILARITY_METHOD:\n",
    "        do_prep = True\n",
    "        do_sim = True\n",
    "        do_clique = True\n",
    "        SIMILARITY_METHOD = sim_m\n",
    "    if sim_thr != SIMILARITY_THRESHOLD:\n",
    "        do_clique = True\n",
    "        SIMILARITY_THRESHOLD = sim_thr\n",
    "    set_matrix_threshold()\n",
    "    CHUNK_LB = CHUNK_LBS[CHUNK_FIXED]\n",
    "    CHUNK_DESC = CHUNK_SIZE if CHUNK_FIXED else CHUNK_OBJECT\n",
    "\n",
    "    meta['CHUNK TYPE'] = 'FIXED {}'.format(CHUNK_SIZE) if CHUNK_FIXED else 'OBJECT {}'.format(CHUNK_OBJECT)\n",
    "    meta['MATRIX THRESHOLD'] = MATRIX_THRESHOLD\n",
    "    meta['SIMILARITY METHOD'] = SIMILARITY_METHOD\n",
    "    meta['SIMILARITY THRESHOLD'] = SIMILARITY_THRESHOLD\n",
    "    \n",
    "    \n",
    "    for p in (\n",
    "        '{}/{}'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR),\n",
    "        '{}/{}'.format(LOCAL_BASE_OUTP, CHAPTER_DIR),\n",
    "        '{}/{}'.format(LOCAL_BASE_COMP, STORED_CLIQUE_DIR),\n",
    "        '{}/{}'.format(LOCAL_BASE_COMP, STORED_MATRIX_DIR),\n",
    "    ):\n",
    "        if not os.path.exists(p): os.makedirs(p)\n",
    "\n",
    "    return (do_chunk, do_prep, do_sim, do_clique)\n",
    "\n",
    "reset_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunking(do_chunk):\n",
    "    global chunks, book_rank\n",
    "    if not do_chunk:\n",
    "        msg('CHUNKING ({} {}): already chunked into {} chunks'.format(CHUNK_LB, CHUNK_DESC, len(chunks)))\n",
    "        meta['# CHUNKS'] = len(chunks)\n",
    "        return\n",
    "    msg('CHUNKING ({} {})'.format(CHUNK_LB, CHUNK_DESC))\n",
    "    chunks = []\n",
    "    book_rank = {}\n",
    "    for b in F.otype.s('book'):\n",
    "        book_name = F.book.v(b)\n",
    "        book_rank[book_name] = b\n",
    "        words = L.d('word', b)\n",
    "        nwords = len(words)\n",
    "        if CHUNK_FIXED:\n",
    "            nchunks = nwords // CHUNK_SIZE\n",
    "            if nchunks == 0: \n",
    "                nchunks = 1\n",
    "                common_incr = nwords\n",
    "                special_incr = 0\n",
    "            else:            \n",
    "                rem = nwords % CHUNK_SIZE\n",
    "                common_incr = rem // nchunks\n",
    "                special_incr = rem % nchunks\n",
    "            word_in_chunk = -1\n",
    "            cur_chunk = -1\n",
    "            these_chunks = []\n",
    "\n",
    "            for w in words:\n",
    "                word_in_chunk += 1\n",
    "                if word_in_chunk == 0 or (word_in_chunk >= CHUNK_SIZE + common_incr + (1 if cur_chunk < special_incr else 0)):\n",
    "                    word_in_chunk = 0\n",
    "                    these_chunks.append([])\n",
    "                    cur_chunk += 1\n",
    "                these_chunks[-1].append(w)\n",
    "        else:\n",
    "            these_chunks = [L.d('word', c) for c in L.d(CHUNK_OBJECT, b)]\n",
    "\n",
    "        chunks.extend(these_chunks)\n",
    "\n",
    "        chunkvolume = sum(len(c) for c in these_chunks)\n",
    "        if VERBOSE:\n",
    "            msg('CHUNKING ({} {}): {:<20s} {:>5} words; {:>5} chunks; sizes {:>5} to {:>5}; {:>5}'.format(\n",
    "                CHUNK_LB, CHUNK_DESC,\n",
    "                book_name, nwords, len(these_chunks), \n",
    "                min(len(c) for c in these_chunks), \n",
    "                max(len(c) for c in these_chunks),\n",
    "                'OK' if chunkvolume == nwords else 'ERROR',\n",
    "            ))\n",
    "    meta['# CHUNKS'] = len(chunks)\n",
    "    msg('CHUNKING ({} {}): Made {} chunks'.format(CHUNK_LB, CHUNK_DESC, len(chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preparing(do_prepare):\n",
    "    global chunk_data\n",
    "    if not do_prepare:\n",
    "        msg('PREPARING ({} {} {}): Already prepared'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD))\n",
    "        return\n",
    "    msg('PREPARING ({} {} {})'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD))\n",
    "    chunk_data = []\n",
    "    if SIMILARITY_METHOD == 'SET':\n",
    "        for c in chunks:\n",
    "            words = (EXCLUDED_PAT.sub('', F.lex.v(w).replace('<', 'O')) for w in c)\n",
    "            clean_words = (w for w in words if w != '')\n",
    "            this_data = frozenset(clean_words)\n",
    "            chunk_data.append(this_data)\n",
    "    else:\n",
    "        for c in chunks:\n",
    "            words = (EXCLUDED_PAT.sub('', F.lex.v(w).replace('<', 'O')) for w in c)\n",
    "            clean_words = (w for w in words if w != '')\n",
    "            this_data = ' '.join(clean_words)\n",
    "            chunk_data.append(this_data)\n",
    "    msg('PREPARING ({} {} {}): Done {} chunks.'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, len(chunk_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity_post():\n",
    "    nequals = len({x for x in chunk_dist if chunk_dist[x] >= 100})\n",
    "    cmin = min(chunk_dist.values()) if len(chunk_dist) else '!empty set!'\n",
    "    cmax = max(chunk_dist.values()) if len(chunk_dist) else '!empty set!'\n",
    "    meta['LOWEST  AVAILABLE SIMILARITY'] = cmin\n",
    "    meta['HIGHEST AVAILABLE SIMILARITY'] = cmax\n",
    "    meta['# EQUAL COMPARISONS'] = nequals\n",
    "    msg('SIMILARITY ({} {} {} M>{}): similarities between {} and {}. {} are 100%'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        cmin, cmax, nequals,\n",
    "    ))\n",
    "    \n",
    "def similarity(do_sim):\n",
    "    global chunk_dist\n",
    "    total_chunks = len(chunks) \n",
    "    total_distances = total_chunks * (total_chunks - 1) // 2\n",
    "    meta['# SIMILARITY COMPARISONS'] = total_distances\n",
    "    \n",
    "    SIMILARITY_PROGRESS = total_distances // 100\n",
    "    if SIMILARITY_PROGRESS >= MEGA:\n",
    "        sim_unit = MEGA\n",
    "        sim_lb = 'M'\n",
    "    else:\n",
    "        sim_unit = KILO\n",
    "        sim_lb = 'K'\n",
    "    \n",
    "    if not do_sim:\n",
    "        msg('SIMILARITY ({} {} {} M>{}): Using {:>5} {} ({}) comparisons with {} entries in matrix'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "            total_distances // sim_unit, sim_lb, total_distances, len(chunk_dist),\n",
    "        ))\n",
    "        meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "        similarity_post()\n",
    "        return\n",
    "\n",
    "    matrix_path = '{}/{}/matrix_{}_{}_{}_{}'.format(\n",
    "        LOCAL_BASE_COMP, STORED_MATRIX_DIR,\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "    )\n",
    "\n",
    "    if os.path.exists(matrix_path):\n",
    "        with open(matrix_path, 'rb') as f: chunk_dist = pickle.load(f)\n",
    "        msg('SIMILARITY ({} {} {} M>{}): Loaded: {:>5} {} ({}) comparisons with {} entries in matrix'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "            total_distances // sim_unit, sim_lb, total_distances, len(chunk_dist),\n",
    "        ))\n",
    "        meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "        similarity_post()\n",
    "        return\n",
    "\n",
    "    msg('SIMILARITY ({} {} {} M>{}): Computing {:>5} {} ({}) comparisons and saving entries in matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        total_distances // sim_unit, sim_lb, total_distances\n",
    "    ))\n",
    "\n",
    "    chunk_dist = {}\n",
    "    wc = 0\n",
    "    wt = 0\n",
    "    if SIMILARITY_METHOD == 'SET':\n",
    "        # method SET: all chunks have been reduced to sets, ratio between lengths of intersection and union\n",
    "        for i in range(total_chunks):\n",
    "            c_i = chunk_data[i]\n",
    "            for j in range(i + 1, total_chunks):\n",
    "                c_j = chunk_data[j]\n",
    "                u = len(c_i | c_j)\n",
    "                d = 100 * len(c_i & c_j) / u if u != 0 else 0\n",
    "                if d >= MATRIX_THRESHOLD:\n",
    "                    chunk_dist[(i,j)] = d\n",
    "                wc += 1\n",
    "                wt += 1\n",
    "                if wc == SIMILARITY_PROGRESS:\n",
    "                    wc = 0\n",
    "                    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} comparisons and saved {} entries in matrix'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "                        wt // sim_unit, sim_lb, len(chunk_dist),\n",
    "                    ))\n",
    "    elif SIMILARITY_METHOD == 'LCS':\n",
    "        # method LCS: chunks are sequence aligned, ratio between length of all common parts and total length\n",
    "        for i in range(total_chunks):\n",
    "            c_i = chunk_data[i]\n",
    "            for j in range(i + 1, total_chunks):\n",
    "                c_j = chunk_data[j]\n",
    "                d = 100 * ratio(c_i, c_j)\n",
    "                if d >= MATRIX_THRESHOLD:\n",
    "                    chunk_dist[(i,j)] = d\n",
    "                wc += 1\n",
    "                wt += 1\n",
    "                if wc == SIMILARITY_PROGRESS:\n",
    "                    wc = 0\n",
    "                    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} comparisons and saved {} entries in matrix'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "                        wt // sim_unit, sim_lb, len(chunk_dist),\n",
    "                    ))\n",
    "\n",
    "    with  open(matrix_path, 'wb') as f: pickle.dump(chunk_dist, f, protocol=PICKLE_PROTOCOL)\n",
    "        \n",
    "    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} ({}) comparisons and saved {} entries in matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        wt // sim_unit, sim_lb, wt, len(chunk_dist),\n",
    "    ))\n",
    "    \n",
    "    meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "    similarity_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Cliques\n",
    "\n",
    "Based on the value for the ``SIMILARITY_THRESHOLD`` we use the similarity matrix to pick the *interesting*\n",
    "similar pairs out of it. From these pairs we lump together our cliques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def key_chunk(i):\n",
    "    c = chunks[i]\n",
    "    w = c[0]\n",
    "    return  (-len(c), L.u('book', w), L.u('chapter', w), L.u('verse', w))\n",
    "\n",
    "def meta_clique_pre():\n",
    "    global similars, passages\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): inspecting the similarity matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    ))\n",
    "    similars = {x for x in chunk_dist if chunk_dist[x] >= SIMILARITY_THRESHOLD}\n",
    "    passage_set = set()\n",
    "    for (i,j) in similars:\n",
    "        passage_set.add(i)\n",
    "        passage_set.add(j)\n",
    "    passages = sorted(passage_set, key=key_chunk)\n",
    "\n",
    "    meta['# SIMILAR COMPARISONS'] = len(similars)\n",
    "    meta['# SIMILAR PASSAGES'] = len(passages)    \n",
    "\n",
    "def meta_clique_pre2():\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): {} relevant similarities between {} passages'.format(\n",
    "    CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    len(similars), len(passages),\n",
    "))\n",
    "\n",
    "\n",
    "def meta_clique_post():\n",
    "    global l_c_l\n",
    "    meta['# CLIQUES'] = len(cliques)\n",
    "    scliques = collections.Counter()\n",
    "    for c in cliques:\n",
    "        scliques[len(c)] += 1\n",
    "    l_c_l = max(scliques.keys()) if len(scliques) > 0 else 0\n",
    "    totmn = 0\n",
    "    totcn = 0\n",
    "    for (ln, n) in sorted(scliques.items(), key=lambda x: x[0]):\n",
    "        totmn += ln * n\n",
    "        totcn += n\n",
    "        if VERBOSE:\n",
    "            msg('CLIQUES ({} {} {} M>{} S>{}): {:>4} cliques of length {:>4}'.format(\n",
    "                CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                n, ln,\n",
    "            ))\n",
    "        meta['# CLIQUES of LENGTH {:>4}'.format(ln)] = n\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): {} members in {} cliques'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        totmn, totcn,\n",
    "    ))\n",
    "    \n",
    "def cliqueing(do_clique):\n",
    "    global cliques\n",
    "    if not do_clique:\n",
    "        msg('CLIQUES ({} {} {} M>{} S>{}): Already loaded {} cliques out of {} candidates from {} comparisons'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(cliques), len(passages), len(similars),            \n",
    "        ))\n",
    "        meta_clique_pre2()\n",
    "        meta_clique_poest()\n",
    "        return\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): fetching similars and chunk candidates'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,        \n",
    "    ))\n",
    "    meta_clique_pre()\n",
    "    meta_clique_pre2()\n",
    "    clique_path = '{}/{}/clique_{}_{}_{}_{}_{}'.format(\n",
    "        LOCAL_BASE_COMP, STORED_CLIQUE_DIR,\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    )\n",
    "    if os.path.exists(clique_path):\n",
    "        with open(clique_path, 'rb') as f: cliques = pickle.load(f)\n",
    "        msg('CLIQUES ({} {} {} M>{} S>{}): Loaded: {:>5} cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(cliques), len(passages), len(similars),            \n",
    "        ))\n",
    "        meta_clique_post()\n",
    "        return\n",
    "\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): Composing cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(passages), len(similars),            \n",
    "    ))\n",
    "    cliques_unsorted = []\n",
    "    np = 0\n",
    "    npc = 0\n",
    "    for i in passages:\n",
    "        added = None\n",
    "        removable = set()\n",
    "        for (k, c) in enumerate(cliques_unsorted):\n",
    "            origc = tuple(c)\n",
    "            for j in origc:            \n",
    "                d = chunk_dist.get((i,j), 0) if i < j else chunk_dist.get((j,i), 0) if j < i else 0\n",
    "                if d >= SIMILARITY_THRESHOLD:\n",
    "                    if added == None:\n",
    "                        c.add(i)\n",
    "                        added = k\n",
    "                    else:\n",
    "                        cliques_unsorted[added] |= c\n",
    "                        removable.add(k)\n",
    "                    break\n",
    "        if added == None:\n",
    "            cliques_unsorted.append({i})\n",
    "        else:\n",
    "            if len(removable):\n",
    "                cliques_unsorted = [c for (k,c) in enumerate(cliques_unsorted) if k not in removable]\n",
    "        np += 1\n",
    "        npc += 1\n",
    "        if npc == CLIQUES_PROGRESS:\n",
    "            npc = 0\n",
    "            msg('CLIQUES ({} {} {} M>{} S>{}): Composed {:>5} cliques out of {:>6} chunks'.format(\n",
    "                CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                len(cliques_unsorted), np,\n",
    "            ))\n",
    "    cliques = sorted([tuple(sorted(c, key=key_chunk)) for c in cliques_unsorted])\n",
    "    with  open(clique_path, 'wb') as f: pickle.dump(cliques, f, protocol=PICKLE_PROTOCOL)\n",
    "    meta_clique_post()\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): Composed and saved {:>5} cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(cliques), len(passages), len(similars),            \n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty output\n",
    "\n",
    "Here are the definitions for formatting the (HTML) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "css = '''\n",
    "td.vl {\n",
    "    font-family: Verdana, Arial, sans-serif;\n",
    "    font-size: small;\n",
    "    text-align: right;\n",
    "    color: #aaaaaa;\n",
    "    width: 10%;\n",
    "    direction: ltr;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "td.ht {\n",
    "    font-family: Ezra SIL, SBL Hebrew, Verdana, sans-serif;\n",
    "    font-size: x-large;\n",
    "    line-height: 1.7;\n",
    "    text-align: right;\n",
    "    direction: rtl;\n",
    "}\n",
    "table.ht {\n",
    "    width: 100%;\n",
    "    direction: rtl;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    "td.ht {\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "tr.ht.tb {\n",
    "    border-top: 2px solid #aaaaaa;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "tr.ht.bb {\n",
    "    border-bottom: 2px solid #aaaaaa;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "span.m {\n",
    "    background-color: #aaaaff;\n",
    "}\n",
    "span.f {\n",
    "    background-color: #ffaaaa;\n",
    "}\n",
    "span.x {\n",
    "    background-color: #ffffaa;\n",
    "    color: #bb0000;\n",
    "}\n",
    "span.delete {\n",
    "    background-color: #ffaaaa;\n",
    "}\n",
    "span.insert {\n",
    "    background-color: #aaffaa;\n",
    "}\n",
    "span.replace {\n",
    "    background-color: #ffff00;\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "diffhead = '''\n",
    "<head>\n",
    "    <meta http-equiv=\"Content-Type\"\n",
    "          content=\"text/html; charset=UTF-8\" />\n",
    "    <title></title>\n",
    "    <style type=\"text/css\">\n",
    "        table.diff {\n",
    "            font-family: Ezra SIL, SBL Hebrew, Verdana, sans-serif; \n",
    "            font-size: x-large;\n",
    "            text-align: right;\n",
    "        }\n",
    "        .diff_header {background-color:#e0e0e0}\n",
    "        td.diff_header {text-align:right}\n",
    "        .diff_next {background-color:#c0c0c0}\n",
    "        .diff_add {background-color:#aaffaa}\n",
    "        .diff_chg {background-color:#ffff77}\n",
    "        .diff_sub {background-color:#ffaaaa}\n",
    "    </style>\n",
    "</head>\n",
    "'''\n",
    "\n",
    "def xterse_chunk(i):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = L.u('book', fword)\n",
    "    chapter = L.u('chapter', fword)\n",
    "    return (book, chapter)\n",
    "\n",
    "def xterse_clique(ii):\n",
    "    return tuple(sorted({xterse_chunk(i) for i in ii}))\n",
    "\n",
    "def terse_chunk(i):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = L.u('book', fword)\n",
    "    chapter = L.u('chapter', fword)\n",
    "    verse = L.u('verse', fword)\n",
    "    return (book, chapter, verse)\n",
    "\n",
    "def terse_clique(ii):\n",
    "    return tuple(sorted({terse_chunk(i) for i in ii}))\n",
    "\n",
    "def verse_chunk(i):\n",
    "    (bk, ch, vs) = i\n",
    "    book = F.book.v(bk)\n",
    "    chapter = F.chapter.v(ch)\n",
    "    verse = F.verse.v(vs)\n",
    "    text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in L.d('word', vs))\n",
    "    verse_label = '<td class=\"vl\">{} {}:{}</td>'.format(book, chapter, verse)\n",
    "    htext = '{}<td class=\"ht\">{}</td>'.format(verse_label, text)\n",
    "    return '<tr class=\"ht\">{}</tr>'.format(htext)\n",
    "\n",
    "def verse_clique(ii):\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(verse_chunk(i) for i in sorted(ii)))\n",
    "\n",
    "def condense(vlabels):\n",
    "    cnd = ''\n",
    "    (cur_b, cur_c) = (None, None)\n",
    "    for (b, c, v) in vlabels:\n",
    "        sep = '' if cur_b == None else '. ' if cur_b != b else '; ' if cur_c != c else ', '\n",
    "        show_b = b+' ' if cur_b != b else ''\n",
    "        show_c = c+':' if cur_b != b or cur_c != c else ''\n",
    "        (cur_b, cur_c) = (b, c)\n",
    "        cnd += '{}{}{}{}'.format(sep, show_b, show_c, v)\n",
    "    return cnd\n",
    "\n",
    "def print_diff(a, b):\n",
    "    arep = ''\n",
    "    brep = ''\n",
    "    for (lb, ai, aj, bi, bj) in SequenceMatcher(isjunk=None, a=a, b=b, autojunk=False).get_opcodes():\n",
    "        if lb == 'equal':\n",
    "            arep += a[ai:aj]\n",
    "            brep += b[bi:bj]\n",
    "        elif lb == 'delete':\n",
    "            arep += '<span class=\"{}\">{}</span>'.format(lb, a[ai:aj])\n",
    "        elif lb == 'insert':\n",
    "            brep += '<span class=\"{}\">{}</span>'.format(lb, b[bi:bj])\n",
    "        else:\n",
    "            arep += '<span class=\"{}\">{}</span>'.format(lb, a[ai:aj])\n",
    "            brep += '<span class=\"{}\">{}</span>'.format(lb, b[bi:bj])\n",
    "    return (arep, brep)\n",
    "    \n",
    "def print_chunk_fine(prev, text, verse_labels, prevlabels):\n",
    "    if prev == None:\n",
    "        return '''\n",
    "<tr class=\"ht tb bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "            condense(verse_labels), \n",
    "            text,\n",
    "        )\n",
    "    else:\n",
    "        (prevline, textline) = print_diff(prev, text)\n",
    "        return '''\n",
    "<tr class=\"ht tb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "<tr class=\"ht bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "    condense(prevlabels) if prevlabels != None else 'previous',\n",
    "    prevline,\n",
    "    condense(verse_labels), \n",
    "    textline,\n",
    ")\n",
    "\n",
    "def print_chunk_coarse(text, verse_labels):\n",
    "    return '''\n",
    "<tr class=\"ht tb bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "            condense(verse_labels), \n",
    "            text,\n",
    "        )\n",
    "\n",
    "def print_clique(ii, ncliques):\n",
    "    return print_clique_fine(ii) if len(ii) < ncliques * DEP_CLIQUE_RATIO / 100 else print_clique_coarse(ii)\n",
    "    \n",
    "def print_clique_fine(ii):\n",
    "    condensed = collections.OrderedDict()\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c)):\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in chunk)\n",
    "        condensed.setdefault(text, []).append((book, chapter, verse))\n",
    "    result = []\n",
    "    nv = len(condensed.items())\n",
    "    prev = None\n",
    "    for (text, verse_labels) in condensed.items():\n",
    "        if prev == None:\n",
    "            if nv == 1: result.append(print_chunk_fine(None, text, verse_labels, None))\n",
    "            else:\n",
    "                prev = text\n",
    "                prevlabels = verse_labels\n",
    "                continue\n",
    "        else:\n",
    "            result.append(print_chunk_fine(prev, text, verse_labels, prevlabels))\n",
    "            prev = text\n",
    "            prevlabels = None\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(result))\n",
    "\n",
    "def print_clique_coarse(ii):\n",
    "    condensed = collections.OrderedDict()\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c))[0:LARGE_CLIQUE_SIZE]:\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in chunk)\n",
    "        condensed.setdefault(text, []).append((book, chapter, verse))\n",
    "    result = []\n",
    "    nv = len(condensed.items())\n",
    "    prev = None\n",
    "    for (text, verse_labels) in condensed.items():\n",
    "        result.append(print_chunk_coarse(text, verse_labels))\n",
    "    if len(ii) > LARGE_CLIQUE_SIZE:\n",
    "        result.append(print_chunk_coarse('+ {} ...'.format(len(ii) - LARGE_CLIQUE_SIZE),[]))\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(result))\n",
    "\n",
    "def index_clique(bnm, n, ii, ncliques):\n",
    "    return index_clique_fine(bnm, n, ii) if len(ii) < ncliques * DEP_CLIQUE_RATIO / 100 else index_clique_coarse(bnm, n, ii)\n",
    "    \n",
    "def index_clique_fine(bnm, n, ii):\n",
    "    verse_labels = []\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c)):\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        verse_labels.append((book, chapter, verse))\n",
    "        reffl = '{}_{}'.format(bnm, n // CLIQUES_PER_FILE)\n",
    "    return '<p><b>{}</b> <a href=\"{}.html#c_{}\">{}</a></p>'.format(\n",
    "        n, reffl, n, condense(verse_labels),\n",
    "    )\n",
    "\n",
    "def index_clique_coarse(bnm, n, ii):\n",
    "    verse_labels = []\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c))[0:LARGE_CLIQUE_SIZE]:\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        verse_labels.append((book, chapter, verse))\n",
    "        reffl = '{}_{}'.format(bnm, n // CLIQUES_PER_FILE)\n",
    "    extra = '+ {} ...'.format(len(ii) - LARGE_CLIQUE_SIZE) if len(ii) > LARGE_CLIQUE_SIZE else ''\n",
    "    return '<p><b>{}</b> <a href=\"{}.html#c_{}\">{}{}</a></p>'.format(\n",
    "        n, reffl, n, condense(verse_labels), extra,\n",
    "    )\n",
    "\n",
    "def lines_chapter(c):\n",
    "    lines = []\n",
    "    for v in L.d('verse', c):\n",
    "        vl = F.verse.v(v)\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in L.d('word', v))\n",
    "        lines.append('{} {}'.format(vl, text.replace('\\n', ' ')))\n",
    "    return lines\n",
    "\n",
    "def compare_chapters(c1, c2, lb1, lb2):\n",
    "    dh = difflib.HtmlDiff(wrapcolumn=80)\n",
    "    table_html = dh.make_table(\n",
    "        lines_chapter(c1), \n",
    "        lines_chapter(c2), \n",
    "        fromdesc=lb1, \n",
    "        todesc=lb2, \n",
    "        context=False, \n",
    "        numlines=5,\n",
    "    )\n",
    "    htext = '''<html>{}<body>{}</body></html>'''.format(diffhead, table_html)\n",
    "    return htext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assess_exp(cf, np, nc, ll):\n",
    "    return 'out' if cf else \\\n",
    "    'rec' if ll > nc * REC_CLIQUE_RATIO / 100 and ll <= nc * DUB_CLIQUE_RATIO / 100 else \\\n",
    "    'dep' if ll > nc * DEP_CLIQUE_RATIO / 100 else \\\n",
    "    'dub' if ll > nc * DUB_CLIQUE_RATIO / 100 else \\\n",
    "    'nor'\n",
    "\n",
    "def printing():\n",
    "    global outputs, bin_cliques, base_name\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): sorting out cliques'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    ))\n",
    "    xt_cliques = {xterse_clique(c) for c in cliques}     # chapter cliques as tuples of (b, ch) tuples\n",
    "    bin_cliques = {c for c in xt_cliques if len(c) == 2} # chapter cliques with exactly two chapters\n",
    "    # all chapters that occur in binary chapter cliques\n",
    "    bin_chapters = {c[0] for c in bin_cliques} | {c[1] for c in bin_cliques}\n",
    "    meta['# BINARY CHAPTER DIFFS'] = len(bin_cliques)\n",
    "\n",
    "    # We generate one kind of info for binary chapter cliques (the majority of cases).\n",
    "    # The remaining cases are verse cliques that do not occur in such chapters, e.g. because they\n",
    "    # have member chunks in the same chapter, or in multiple (more than two) chapters.\n",
    "    \n",
    "    ncliques = len(cliques)\n",
    "    chapters_ok = assess_exp(CHUNK_FIXED, len(passages), ncliques, l_c_l) in {'rec', 'nor', 'dub'}\n",
    "    cdoing = 'involving' if chapters_ok else 'skipping'\n",
    "\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): formatting {} cliques {} {} binary chapter diffs'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        ncliques, cdoing, len(bin_cliques),\n",
    "    ))\n",
    "    meta_html = '\\n'.join('{:<40} : {:>10}'.format(k, str(meta[k])) for k in meta)\n",
    "\n",
    "    base_name = '{}_{}_{}_M{}_S{}'.format(\n",
    "        CHUNK_LB,\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD,\n",
    "        MATRIX_THRESHOLD,\n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    param_spec = '''\n",
    "<table>\n",
    "<tr><th>chunking method</th><td>{}</td></tr>\n",
    "<tr><th>chunking description</th><td>{}</td></tr>\n",
    "<tr><th>similarity method</th><td>{}</td></tr>\n",
    "<tr><th>similarity threshold</th><td>{}</td></tr>\n",
    "</table>\n",
    "    '''.format(\n",
    "        CHUNK_LABELS[CHUNK_FIXED],\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD, \n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    param_lab = 'chunk-{}-{}-sim-{}-m{}-s{}'.format(\n",
    "        CHUNK_LB,\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD,\n",
    "        MATRIX_THRESHOLD,\n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    index_name = base_name\n",
    "    all_name = '{}_{}'.format('all', base_name)\n",
    "    cliques_name = '{}_{}'.format('clique', base_name)\n",
    "\n",
    "    clique_links = []\n",
    "    clique_links.append(('{}/{}.html'.format(base_name, all_name), 'Big list of all cliques'))\n",
    "\n",
    "    nexist = 0\n",
    "    nnew = 0\n",
    "    if chapters_ok:\n",
    "        chapter_diffs = []\n",
    "        msg('PRINT ({} {} {} M>{} S>{}): Chapter diffs needed: {}'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(bin_cliques),\n",
    "        ))\n",
    "\n",
    "        bcc_text = '<p>These results look good, so a binary chapter comparison has been generated</p>'\n",
    "        for cl in sorted(bin_cliques):\n",
    "            lb1 = '{} {}'.format(F.book.v(cl[0][0]), F.chapter.v(cl[0][1]))\n",
    "            lb2 = '{} {}'.format(F.book.v(cl[1][0]), F.chapter.v(cl[1][1]))\n",
    "            hfilename = '{}_vs_{}.html'.format(lb1, lb2).replace(' ','_')\n",
    "            hfilepath = '{}/{}/{}'.format(LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename)\n",
    "            chapter_diffs.append((lb1, cl[0][1], lb2, cl[1][1], '{}/{}/{}/{}'.format(\n",
    "                SHEBANQ_TOOL, LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename,\n",
    "            )))\n",
    "            if not os.path.exists(hfilepath):\n",
    "                htext = compare_chapters(cl[0][1], cl[1][1], lb1, lb2)\n",
    "                with open(hfilepath, 'w') as f: f.write(htext)\n",
    "                if VERBOSE:\n",
    "                    msg('PRINT ({} {} {} M>{} S>{}): written {}'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                        hfilename,\n",
    "                    ))\n",
    "                nnew += 1\n",
    "            else:\n",
    "                nexist += 1\n",
    "            clique_links.append((\n",
    "                '../{}/{}'.format(CHAPTER_DIR, hfilename), \n",
    "                '{} versus {}'.format(lb1, lb2),\n",
    "            ))\n",
    "        msg('PRINT ({} {} {} M>{} S>{}): Chapter diffs: {} newly created and {} already existing'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            nnew, nexist,\n",
    "        ))\n",
    "    else:\n",
    "        bcc_text = '<p>These results look dubious at best, so no binary chapter comparison has been generated</p>'\n",
    "\n",
    "\n",
    "    allgeni_html = (index_clique(cliques_name, i, c, ncliques) for (i,c) in enumerate(cliques))\n",
    "    \n",
    "    allgen_htmls = []\n",
    "    allgen_html = ''\n",
    "    \n",
    "    for (i, c) in enumerate(cliques):\n",
    "        if i % CLIQUES_PER_FILE == 0:\n",
    "            if i > 0:\n",
    "                allgen_htmls.append(allgen_html)\n",
    "            allgen_html = ''\n",
    "        allgen_html += '<h3><a name=\"c_{}\">Clique {}</a></h3>\\n{}'.format(i, i, print_clique(c, ncliques))\n",
    "    allgen_htmls.append(allgen_html)\n",
    "\n",
    "    index_html_tpl = '''\n",
    "{}\n",
    "<h1>Binary chapter comparisons</h1>\n",
    "{}\n",
    "{}\n",
    "    '''\n",
    "\n",
    "    content_file_tpl = '''<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
    "<title>{}</title>\n",
    "<style type=\"text/css\">\n",
    "{}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>{}</h1>\n",
    "{}\n",
    "<p><a href=\"#meta\">more parameters and stats</a></p>\n",
    "{}\n",
    "<h1><a name=\"meta\">Parameters and stats</a></h1>\n",
    "<pre>{}</pre>\n",
    "</body>\n",
    "</html>'''\n",
    "    \n",
    "    a_tpl_file = '<p><a target=\"_blank\" href=\"{}\">{}</a></p>'\n",
    "\n",
    "    index_html_file = index_html_tpl.format(\n",
    "        a_tpl_file.format(*clique_links[0]),\n",
    "        bcc_text,\n",
    "        '\\n'.join(a_tpl_file.format(*c) for c in clique_links[1:]),\n",
    "    )\n",
    "\n",
    "    listing_html = '{}\\n'.format(\n",
    "        '\\n'.join(allgeni_html),\n",
    "    )\n",
    "\n",
    "    for (subdir, fname, content_html, tit) in (\n",
    "        (None, index_name, index_html_file, 'Index '+param_lab),\n",
    "        (base_name, all_name, listing_html, 'Listing '+param_lab),\n",
    "        (base_name, cliques_name, allgen_htmls, 'Cliques '+param_lab),\n",
    "    ): \n",
    "        subdir = '' if subdir == None else (subdir + '/')\n",
    "        subdirabs = '{}/{}/{}'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, subdir)\n",
    "        if not os.path.exists(subdirabs): os.makedirs(subdirabs)\n",
    "\n",
    "        if type(content_html) is list:\n",
    "            for (i, c_h) in enumerate(content_html):\n",
    "                fn = '{}_{}'.format(fname, i)\n",
    "                t = '{}_{}'.format(tit, i)\n",
    "                with open('{}/{}/{}{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, subdir, fn), 'w') as f: \n",
    "                    f.write(content_file_tpl.format(t, css, t, param_spec, c_h, meta_html))\n",
    "        else:\n",
    "            with open('{}/{}/{}{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, subdir, fname), 'w') as f: \n",
    "                f.write(content_file_tpl.format(tit, css, tit, param_spec, content_html, meta_html))\n",
    "    destination = outputs.setdefault(MATRIX_THRESHOLD, {})\n",
    "    destination[(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, SIMILARITY_THRESHOLD)] = (\n",
    "        len(passages), len(cliques), l_c_l,\n",
    "    )\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): formatted {} cliques ({} files) {} {} binary chapter diffs'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(cliques), len(allgen_htmls), cdoing, len(bin_cliques)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "\n",
    "def writeoutputs():\n",
    "    global outputs\n",
    "    with open(EXPERIMENT_PATH, 'wb') as f:\n",
    "        pickle.dump(outputs, f, protocol=PICKLE_PROTOCOL)\n",
    "\n",
    "def readoutputs():\n",
    "    global outputs\n",
    "    if not os.path.exists(EXPERIMENT_PATH):\n",
    "        outputs = {}\n",
    "    else:\n",
    "        with open(EXPERIMENT_PATH, 'rb') as f:\n",
    "            outputs = pickle.load(f)\n",
    "\n",
    "ecss = '''\n",
    "<style type=\"text/css\">\n",
    ".mis {background-color: #cccccc;}\n",
    ".rec {background-color: #aaffaa;}\n",
    ".dep {background-color: #ffaaaa;}\n",
    ".dub {background-color: #ffddaa;}\n",
    ".out {background-color: #ffddff;}\n",
    ".nor {background-color: #fcfcff;}\n",
    ".ps  {font-weight: normal;}\n",
    ".mx  {font-style: italic;}\n",
    ".cl  {font-weight: bold;}\n",
    ".lr  {font-weight: bold; background-color: #ffffaa;}\n",
    "p,td {font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: small;}\n",
    "td   {border: 1pt solid #000000; padding: 4pt;}\n",
    "table {border: 1pt solid #000000; border-collapse: collapse;}\n",
    "</style>\n",
    "'''\n",
    "\n",
    "legend = '''\n",
    "<table>\n",
    "<tr><td class=\"mis\">{mis}</td></tr>\n",
    "<tr><td class=\"rec\">{rec}</td></tr>\n",
    "<tr><td class=\"dep\">{dep}</td></tr>\n",
    "<tr><td class=\"dub\">{dub}</td></tr>\n",
    "<tr><td class=\"out\">{out}</td></tr>\n",
    "<tr><td class=\"nor\">{nor}</td></tr>\n",
    "</table>\n",
    "'''.format(**VALUE_LABELS)\n",
    "\n",
    "def gen_html(standalone=False):\n",
    "    global other_exps\n",
    "    msg('EXPERIMENT: Generating html report{}'.format('(standalone)' if standalone else ''))\n",
    "    stats = collections.Counter()\n",
    "    pre = '''\n",
    "<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
    "{}\n",
    "</head>\n",
    "<body>\n",
    "'''.format(ecss) if standalone else ''\n",
    "    \n",
    "    post = '''\n",
    "</body></html>\n",
    "''' if standalone else ''\n",
    "\n",
    "    experiments = '''\n",
    "{}\n",
    "{}\n",
    "<table>\n",
    "<tr><th>chunk type</th><th>chunk size</th><th>similarity method</th>{}</tr>\n",
    "'''.format(pre, legend, ''.join('<th>{}</th>'.format(sim_thr) for sim_thr in SIMILARITIES))\n",
    "    \n",
    "    for chunk_f in (True, False):\n",
    "        if chunk_f:\n",
    "            chunk_items = CHUNK_SIZES\n",
    "        else:\n",
    "            chunk_items = CHUNK_OBJECTS\n",
    "        chunk_lb = CHUNK_LBS[chunk_f]\n",
    "        for chunk_i in chunk_items:\n",
    "            for sim_m in SIM_METHODS:\n",
    "                set_matrix_threshold(sim_m=sim_m)\n",
    "                these_outputs = outputs.get(MATRIX_THRESHOLD, {})\n",
    "                experiments += '<tr><td>{}</td><td>{}</td><td>{}</td>'.format(\n",
    "                    CHUNK_LABELS[chunk_f], chunk_i, sim_m,\n",
    "                )\n",
    "                for sim_thr in SIMILARITIES:\n",
    "                    okey = (chunk_lb, chunk_i, sim_m, sim_thr)\n",
    "                    values = these_outputs.get(okey)\n",
    "                    if values == None:\n",
    "                        result = '<td class=\"mis\">&nbsp;</td>'\n",
    "                        stats['mis'] += 1\n",
    "                    else:\n",
    "                        (npassages, ncliques, longest_clique_len) = values\n",
    "                        cls = assess_exp(chunk_f, npassages, ncliques, longest_clique_len)\n",
    "                        stats[cls] += 1\n",
    "                        (lr_el, lr_lb) = ('', '')\n",
    "                        if (CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, SIMILARITY_THRESHOLD) == (\n",
    "                            chunk_lb, chunk_i, sim_m, sim_thr,\n",
    "                        ):\n",
    "                            lr_el = '<span class=\"lr\">*</span>'\n",
    "                            lr_lb = VALUE_LABELS['lr']\n",
    "                        result = '''\n",
    "<td class=\"{}\" title=\"{}\">{}\n",
    "    <span class=\"ps\">{}</span><br/>\n",
    "    <a target=\"_blank\" href=\"{}{}/{}_{}_{}_M{}_S{}.html\"><span class=\"cl\">{}</span></a><br/>\n",
    "    <span class=\"mx\">{}</span>\n",
    "    </td>'''.format(\n",
    "        cls, lr_lb, lr_el, npassages,\n",
    "        '' if standalone else LOCAL_BASE_OUTP+'/', \n",
    "        EXPERIMENT_DIR, chunk_lb, chunk_i, sim_m, MATRIX_THRESHOLD, sim_thr,\n",
    "        ncliques, longest_clique_len,\n",
    "    )\n",
    "                    experiments += result\n",
    "                experiments += '</tr>\\n'\n",
    "    experiments += '</table>\\n{}'.format(post)\n",
    "    if standalone:\n",
    "        with open(EXPERIMENT_HTML, 'w') as f:\n",
    "            f.write(experiments)\n",
    "    else:\n",
    "        other_exps = experiments\n",
    "\n",
    "    for stat in sorted(stats):\n",
    "        msg('EXPERIMENT: {:>3} {}'.format(stats[stat], VALUE_LABELS[stat]))\n",
    "    msg(\"EXPERIMENT: Generated html report\")\n",
    "\n",
    "def do_experiment(chunk_f, chunk_i, sim_m, sim_thr, do_index):\n",
    "    if do_index:\n",
    "        readoutputs()\n",
    "    (do_chunk, do_prep, do_sim, do_clique) = do_params(chunk_f, chunk_i, sim_m, sim_thr)\n",
    "    chunking(do_chunk)\n",
    "    preparing(do_prep)\n",
    "    similarity(do_sim)\n",
    "    cliqueing(do_clique)\n",
    "    printing()\n",
    "    if do_index:\n",
    "        writeoutputs()\n",
    "        gen_html()\n",
    "    \n",
    "def reset_experiments():\n",
    "    global outputs\n",
    "    readoutputs()\n",
    "    outputs = {}\n",
    "    reset_params()\n",
    "    writeoutputs()\n",
    "    gen_html()\n",
    "\n",
    "def do_all_experiments():\n",
    "    global outputs\n",
    "    reset_experiments()\n",
    "    for chunk_f in (True, False):\n",
    "        if chunk_f:\n",
    "            chunk_items = CHUNK_SIZES\n",
    "        else:\n",
    "            chunk_items = CHUNK_OBJECTS\n",
    "        for chunk_i in chunk_items:\n",
    "            for sim_m in SIM_METHODS:\n",
    "                for sim_thr in SIMILARITIES:\n",
    "                    do_experiment(chunk_f, chunk_i, sim_m, sim_thr, False)\n",
    "    writeoutputs()\n",
    "    gen_html()\n",
    "    gen_html(standalone=True)\n",
    "    \n",
    "def show_all_experiments():\n",
    "    readoutputs()\n",
    "    gen_html()\n",
    "    gen_html(standalone=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHEBANQ references\n",
    "\n",
    "Based on selected similarity matrices, we produce a SHEBANQ note set of cross references for similar passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_verse(i, ca=False): return get_verse_w(chunks[i][0], ca=ca)\n",
    "\n",
    "def get_verse_o(o, ca=False): return get_verse_w(L.d('word', o)[0], ca=ca)\n",
    "\n",
    "def get_verse_w(w, ca=False):\n",
    "    book = F.book.v(L.u('book', w))\n",
    "    chapter = F.chapter.v(L.u('chapter', w))\n",
    "    verse = F.verse.v(L.u('verse', w))\n",
    "    if ca: ca = F.number.v(L.u('clause_atom', w))\n",
    "    return (book, chapter, verse, ca) if ca else (book, chapter, verse)\n",
    "\n",
    "def key_verse(x):\n",
    "    return  (book_rank[x[0]], int(x[1]), int(x[2]))\n",
    "\n",
    "MAX_REFS = 10\n",
    "\n",
    "def condensex(vlabels):\n",
    "    cnd = []\n",
    "    (cur_b, cur_c) = (None, None)\n",
    "    for (b, c, v, d) in vlabels:\n",
    "        sep = '' if cur_b == None else '. ' if cur_b != b else '; ' if cur_c != c else ', '\n",
    "        show_b = b+' ' if cur_b != b else ''\n",
    "        show_c = c+':' if cur_b != b or cur_c != c else ''\n",
    "        (cur_b, cur_c) = (b, c)\n",
    "        cnd.append('{}{}{}{}{}'.format(sep, show_b, show_c, v, d))\n",
    "    return cnd\n",
    "\n",
    "def get_crossrefs():\n",
    "    global crossrefs\n",
    "    msg('CROSSREFS: Fetching crossrefs')\n",
    "    crossrefs_proto = {}\n",
    "    crossrefs = {}\n",
    "    (chunk_f, chunk_i, sim_m) = SHEBANQ_MATRIX\n",
    "    sim_thr = SHEBANQ_SIMILARITY\n",
    "    msg('CROSSREFS ({} {} {} S>{})'.format(CHUNK_LBS[chunk_f], chunk_i, sim_m, sim_thr))\n",
    "    (do_chunk, do_prep, do_sim, do_clique) = do_params(chunk_f, chunk_i, sim_m, sim_thr)\n",
    "    crossrefs_proto = {x for x in chunk_dist.items() if x[1] >= sim_thr}\n",
    "    msg('CROSSREFS ({} {} {} S>{}): found {} pairs'.format(\n",
    "        CHUNK_LBS[chunk_f], chunk_i, sim_m, sim_thr,\n",
    "        len(crossrefs_proto),\n",
    "    ))\n",
    "    for ((x,y), d) in crossrefs_proto:\n",
    "        vx = get_verse(x)\n",
    "        vy = get_verse(y)\n",
    "        rd = int(round(d))\n",
    "        crossrefs.setdefault(x, {})[vy] = rd\n",
    "        crossrefs.setdefault(y, {})[vx] = rd\n",
    "    total = sum(len(x) for x in crossrefs.values())\n",
    "    msg('CROSSREFS: Found {} crossreferences'.format(total))\n",
    "\n",
    "def compile_refs():\n",
    "    global refs_compiled\n",
    "    refs_grouped = []\n",
    "    for x in sorted(crossrefs):\n",
    "        refs = crossrefs[x]\n",
    "        vys = sorted(refs.keys(), key=key_verse)\n",
    "        currefs = []\n",
    "        for vy in vys:\n",
    "            nr = len(currefs)\n",
    "            if nr == MAX_REFS:\n",
    "                refs_grouped.append((x, tuple(currefs)))\n",
    "                currefs = []            \n",
    "            currefs.append(vy)\n",
    "        if len(currefs):\n",
    "            refs_grouped.append((x, tuple(currefs)))\n",
    "    refs_compiled = []\n",
    "    for (x, vys) in refs_grouped:\n",
    "        vysd = [(vy[0], vy[1], vy[2], ' ~{}%'.format(crossrefs[x][vy])) for vy in vys]\n",
    "        vysl = condensex(vysd)\n",
    "        these_refs = []\n",
    "        for (i, vy) in enumerate(vysd):\n",
    "            link_text = vysl[i]\n",
    "            link_target = '{} {}:{}'.format(vy[0], vy[1], vy[2])\n",
    "            these_refs.append('[{}]({})'.format(link_text, link_target))\n",
    "        refs_compiled.append((x, ' '.join(these_refs)))\n",
    "    msg('CROSSREFS: Compiled cross references into {} notes'.format(len(refs_compiled)))\n",
    "\n",
    "def get_chapter_diffs():\n",
    "    global chapter_diffs\n",
    "    chapter_diffs = []\n",
    "    for cl in sorted(bin_cliques):\n",
    "        lb1 = '{} {}'.format(F.book.v(cl[0][0]), F.chapter.v(cl[0][1]))\n",
    "        lb2 = '{} {}'.format(F.book.v(cl[1][0]), F.chapter.v(cl[1][1]))\n",
    "        hfilename = '{}_vs_{}.html'.format(lb1, lb2).replace(' ','_')\n",
    "        chapter_diffs.append((lb1, cl[0][1], lb2, cl[1][1], '{}/{}/{}/{}'.format(\n",
    "            SHEBANQ_TOOL, LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename,\n",
    "        )))\n",
    "    msg('CROSSREFS: Added {} chapter diffs'.format(2*len(chapter_diffs)))\n",
    "\n",
    "        \n",
    "def get_clique_refs():\n",
    "    global clique_refs\n",
    "    clique_refs = []\n",
    "    for (i, c) in enumerate(cliques):\n",
    "        for j in c:\n",
    "            seq = i // CLIQUES_PER_FILE\n",
    "            clique_refs.append((j, i, '{}/{}/{}/{}/clique_{}_{}.html#c_{}'.format(\n",
    "                SHEBANQ_TOOL, LOCAL_BASE_OUTP, EXPERIMENT_DIR, base_name, base_name, seq, i,\n",
    "            )))\n",
    "    msg('CROSSREFS: Added {} clique references'.format(len(clique_refs)))\n",
    "\n",
    "sfields = '''\n",
    "    version\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    clause_atom\n",
    "    is_shared\n",
    "    is_published\n",
    "    status\n",
    "    keywords\n",
    "    ntext\n",
    "'''.strip().split()\n",
    "\n",
    "sfields_fmt = ('{}\\t' * (len(sfields) - 1)) + '{}\\n' \n",
    "\n",
    "def generate_notes():\n",
    "    with open(NOTES_PATH, 'w') as f:\n",
    "        f.write('{}\\n'.format('\\t'.join(sfields)))        \n",
    "        x = next(F.otype.s('word'))\n",
    "        (bk, ch, vs, ca) = get_verse(x, ca=True)\n",
    "        f.write(sfields_fmt.format(\n",
    "            version,\n",
    "            bk,\n",
    "            ch,\n",
    "            vs,\n",
    "            ca,\n",
    "            'T',\n",
    "            '',\n",
    "            CROSSREF_STATUS,\n",
    "            CROSSREF_KEYWORD,\n",
    "            '''The crossref notes are the result of a computation without manual tweaks.\n",
    "Parameters: chunk by verse, similarity method SET with threshold 65.\n",
    "[Here](tool=parallel) is an account of the generation method.'''.replace('\\n', ' ')\n",
    "        ))\n",
    "        for (lb1, ch1, lb2, ch2, fl) in chapter_diffs:\n",
    "            (bk1, ch1, vs1, ca1) = get_verse_o(ch1, ca=True)\n",
    "            (bk2, ch2, vs2, ca2) = get_verse_o(ch2, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk1,\n",
    "                ch1,\n",
    "                vs1,\n",
    "                ca1,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                '[chapter diff with {}](tool:{})'.format(lb2, fl),\n",
    "            ))\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk2,\n",
    "                ch2,\n",
    "                vs2,\n",
    "                ca2,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                '[chapter diff with {}](tool:{})'.format(lb1, fl),\n",
    "            ))\n",
    "        for (x, refs) in refs_compiled:\n",
    "            (bk, ch, vs, ca) = get_verse(x, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk,\n",
    "                ch,\n",
    "                vs,\n",
    "                ca,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                refs,\n",
    "            ))\n",
    "        for (chunk, clique, fl) in clique_refs:\n",
    "            (bk, ch, vs, ca) = get_verse(chunk, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk,\n",
    "                ch,\n",
    "                vs,\n",
    "                ca,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                '[all variants (clique {})](tool:{})'.format(clique, fl),\n",
    "            ))\n",
    "\n",
    "    msg('CROSSREFS: Generated {} notes'.format(1+len(refs_compiled) + 2 * len(chapter_diffs) + len(clique_refs)))\n",
    "\n",
    "def crossrefs2shebanq():\n",
    "    expr = SHEBANQ_MATRIX + (SHEBANQ_SIMILARITY,)\n",
    "    do_experiment(*(expr+(True,)))\n",
    "    get_crossrefs()\n",
    "    compile_refs()\n",
    "    get_chapter_diffs()\n",
    "    get_clique_refs()\n",
    "    generate_notes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    43s CHUNKING (O verse)\n",
      "    45s CHUNKING (O verse): Made 23213 chunks\n",
      "    45s PREPARING (O verse SET)\n",
      "    46s PREPARING (O verse SET): Done 23213 chunks.\n",
      "    47s SIMILARITY (O verse SET M>50): Loaded:   269 M (269410078) comparisons with 24867 entries in matrix\n",
      "    47s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      "    47s CLIQUES (O verse SET M>50 S>65): fetching similars and chunk candidates\n",
      "    47s CLIQUES (O verse SET M>50 S>65): inspecting the similarity matrix\n",
      "    47s CLIQUES (O verse SET M>50 S>65): 14357 relevant similarities between 3141 passages\n",
      "    47s CLIQUES (O verse SET M>50 S>65): Loaded:  1235 cliques out of   3141 chunks from 14357 comparisons\n",
      "    47s CLIQUES (O verse SET M>50 S>65): 3141 members in 1235 cliques\n",
      "    47s PRINT (O verse SET M>50 S>65): sorting out cliques\n",
      "    47s PRINT (O verse SET M>50 S>65): formatting 1235 cliques involving 284 binary chapter diffs\n",
      "    47s PRINT (O verse SET M>50 S>65): Chapter diffs needed: 284\n",
      "    47s PRINT (O verse SET M>50 S>65): Chapter diffs: 0 newly created and 284 already existing\n",
      "    50s PRINT (O verse SET M>50 S>65): formatted 1235 cliques (25 files) involving 284 binary chapter diffs\n",
      "    50s EXPERIMENT: Generating html report\n",
      "    50s EXPERIMENT:  21 messy results: deprecated\n",
      "    50s EXPERIMENT:  17 mixed quality: take care\n",
      "    50s EXPERIMENT:   7 unassessed quality: inspection needed\n",
      "    50s EXPERIMENT:  72 method deprecated\n",
      "    50s EXPERIMENT:   9 promising results: recommended\n",
      "    50s EXPERIMENT: Generated html report\n",
      "    50s CROSSREFS: Fetching crossrefs\n",
      "    50s CROSSREFS (O verse SET S>65)\n",
      "    50s CROSSREFS (O verse SET S>65): found 14357 pairs\n",
      "    50s CROSSREFS: Found 28714 crossreferences\n",
      "    50s CROSSREFS: Compiled cross references into 5495 notes\n",
      "    50s CROSSREFS: Added 568 chapter diffs\n",
      "    50s CROSSREFS: Added 3141 clique references\n",
      "    51s CROSSREFS: Generated 9205 notes\n"
     ]
    }
   ],
   "source": [
    "#reset_params()\n",
    "#do_experiment(False, 'sentence', 'LCS', 60, False)\n",
    "#do_all_experiments()\n",
    "crossrefs2shebanq()\n",
    "#show_all_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       ".mis {background-color: #cccccc;}\n",
       ".rec {background-color: #aaffaa;}\n",
       ".dep {background-color: #ffaaaa;}\n",
       ".dub {background-color: #ffddaa;}\n",
       ".out {background-color: #ffddff;}\n",
       ".nor {background-color: #fcfcff;}\n",
       ".ps  {font-weight: normal;}\n",
       ".mx  {font-style: italic;}\n",
       ".cl  {font-weight: bold;}\n",
       ".lr  {font-weight: bold; background-color: #ffffaa;}\n",
       "p,td {font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: small;}\n",
       "td   {border: 1pt solid #000000; padding: 4pt;}\n",
       "table {border: 1pt solid #000000; border-collapse: collapse;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(ecss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "This is sample code for plotting characteristics of the similarity matrix.\n",
    "It does not have a role in the experiments or the assessments of the results.\n",
    "\n",
    "# Overview of the similarities\n",
    "\n",
    "Here is a plot of the similarity matrix.\n",
    "Horizontally you see the degree of similarity from 0 to 100%, vertically the number of pairs that have that (rounded) similarity. This axis is logarithmic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell after the cells below\n",
    "distances = collections.Counter()\n",
    "for (x, d) in chunk_dist.items():\n",
    "    distances[int(round(d))] += 1\n",
    "\n",
    "x = range(MATRIX_THRESHOLD, 101)\n",
    "fig = plt.figure(figsize=[15, 4])\n",
    "plt.plot(x, [math.log(max((1, distances[y]))) for y in x], 'b-')\n",
    "plt.axis([MATRIX_THRESHOLD, 101, 0, 15])\n",
    "plt.xlabel('similarity as %')\n",
    "plt.ylabel('log # similarities')\n",
    "plt.xticks(x, x, rotation='vertical')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15);\n",
    "plt.title('distances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
