{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
    "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
    "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"right\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
    "<a href=\"https://www.academic-bible.com/en/online-bibles/biblia-hebraica-stuttgartensia-bhs/read-the-bible-text/\" target=\"_blank\"><img align=\"right\" src=\"files/images/DBG-xsmall.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"50%\" src=\"files/images/parallel.png\"/>\n",
    "\n",
    "# Parallel Passages in the MT\n",
    "\n",
    "We want to make a list of **all** parallel passages in the Masoretic text.\n",
    "More precisely, we want to produce a set of *cliques*, a clique being a set of passages that are *quite* similar.\n",
    "\n",
    "Here is a quote triggered Dirk to write this notebook:\n",
    "\n",
    "> Finally, the Old Testament Parallels module in Accordance is a helpful resource that enables the researcher to examine 435 sets of parallel texts, or in some cases very similar wording in different texts, in both the MT and translation, but the large number of sets of texts in this database should not fool one to think it is complete or even nearly complete for all parallel writings in the Hebrew Bible.\n",
    "\n",
    "Robert Rezetko and Ian Young.\n",
    "  Historical linguistics & Biblical Hebrew. Steps Toward an Integrated Approach.\n",
    "  *Ancient Near East Monographs, Number9*. SBL Press Atlanta. 2014. \n",
    "  [PDF Open access available](https://www.google.nl/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0CCgQFjAB&url=http%3A%2F%2Fwww.sbl-site.org%2Fassets%2Fpdfs%2Fpubs%2F9781628370461_OA.pdf&ei=2QSdVf-vAYSGzAPArJeYCg&usg=AFQjCNFA3TymYlsebQ0MwXq2FmJCSHNUtg&sig2=LaXuAC5k3V7fSXC6ZVx05w&bvm=bv.96952980,d.bGQ)\n",
    "\n",
    "\n",
    "# Authors\n",
    "\n",
    "[Dirk Roorda](dirk.roorda@dans.knaw.nl) while discussing ideas with \n",
    "[Martijn Naaijer](m.naaijer@vu.nl). \n",
    "\n",
    "# Status\n",
    "\n",
    "**Last modified: 2015-07-22**\n",
    "\n",
    "126 experiments have been carried out, of which 9 with promising results.\n",
    "All results can be easily inspected, just by clicking in your browser.\n",
    "\n",
    "# Results\n",
    "\n",
    "Click in a green cell to see interesting results. The numbers in the cell indicate\n",
    "\n",
    "* the number of passages that have a variant elsewhere\n",
    "* the number of *cliques* they form (cliques are sets of similar passages)\n",
    "* the number of passages in the biggest clique\n",
    "\n",
    "Below the results is an account of the method that we used, followed by the actual code to produce these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "<table>\n",
       "<tr><td class=\"mis\">no results available</td></tr>\n",
       "<tr><td class=\"rec\">promising results: recommended</td></tr>\n",
       "<tr><td class=\"dep\">messy results: deprecated</td></tr>\n",
       "<tr><td class=\"dub\">mixed quality: take care</td></tr>\n",
       "<tr><td class=\"out\">method deprecated</td></tr>\n",
       "<tr><td class=\"nor\">unassessed quality: inspection needed</td></tr>\n",
       "</table>\n",
       "\n",
       "<table>\n",
       "<tr><th>chunk type</th><th>chunk size</th><th>similarity method</th><th>100</th><th>95</th><th>90</th><th>85</th><th>80</th><th>75</th><th>70</th><th>65</th><th>60</th></tr>\n",
       "<tr><td>fixed</td><td>100</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S100.html\"><span class=\"cl\">1</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">18</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S90.html\"><span class=\"cl\">9</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">37</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S85.html\"><span class=\"cl\">18</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">64</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S80.html\"><span class=\"cl\">30</span></a><br/>\n",
       "    <span class=\"mx\">6</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">88</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S75.html\"><span class=\"cl\">40</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">113</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S70.html\"><span class=\"cl\">52</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">156</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S65.html\"><span class=\"cl\">71</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">206</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_SET_M50_S60.html\"><span class=\"cl\">93</span></a><br/>\n",
       "    <span class=\"mx\">10</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>100</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">39</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S90.html\"><span class=\"cl\">19</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">59</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S85.html\"><span class=\"cl\">29</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">85</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S80.html\"><span class=\"cl\">41</span></a><br/>\n",
       "    <span class=\"mx\">3</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">122</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S75.html\"><span class=\"cl\">56</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">189</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S70.html\"><span class=\"cl\">88</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">287</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S65.html\"><span class=\"cl\">132</span></a><br/>\n",
       "    <span class=\"mx\">9</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">535</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_100_LCS_M60_S60.html\"><span class=\"cl\">214</span></a><br/>\n",
       "    <span class=\"mx\">31</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>50</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S95.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">24</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S90.html\"><span class=\"cl\">12</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">57</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S85.html\"><span class=\"cl\">26</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">114</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S80.html\"><span class=\"cl\">52</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">188</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S75.html\"><span class=\"cl\">86</span></a><br/>\n",
       "    <span class=\"mx\">8</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">273</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S70.html\"><span class=\"cl\">125</span></a><br/>\n",
       "    <span class=\"mx\">10</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">385</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S65.html\"><span class=\"cl\">176</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">538</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_SET_M50_S60.html\"><span class=\"cl\">236</span></a><br/>\n",
       "    <span class=\"mx\">15</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>50</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">0</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S100.html\"><span class=\"cl\">0</span></a><br/>\n",
       "    <span class=\"mx\">0</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">12</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S95.html\"><span class=\"cl\">6</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">53</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S90.html\"><span class=\"cl\">25</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">119</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S85.html\"><span class=\"cl\">53</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">196</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S80.html\"><span class=\"cl\">89</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">301</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S75.html\"><span class=\"cl\">135</span></a><br/>\n",
       "    <span class=\"mx\">19</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">467</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S70.html\"><span class=\"cl\">206</span></a><br/>\n",
       "    <span class=\"mx\">20</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">761</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S65.html\"><span class=\"cl\">312</span></a><br/>\n",
       "    <span class=\"mx\">28</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1894</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_50_LCS_M60_S60.html\"><span class=\"cl\">553</span></a><br/>\n",
       "    <span class=\"mx\">112</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>20</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">28</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S100.html\"><span class=\"cl\">14</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">28</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S95.html\"><span class=\"cl\">14</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">103</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S90.html\"><span class=\"cl\">45</span></a><br/>\n",
       "    <span class=\"mx\">8</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">172</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S85.html\"><span class=\"cl\">71</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">330</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S80.html\"><span class=\"cl\">145</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">530</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S75.html\"><span class=\"cl\">228</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">764</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S70.html\"><span class=\"cl\">332</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1058</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S65.html\"><span class=\"cl\">450</span></a><br/>\n",
       "    <span class=\"mx\">13</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1828</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_SET_M50_S60.html\"><span class=\"cl\">732</span></a><br/>\n",
       "    <span class=\"mx\">29</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>20</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">6</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S100.html\"><span class=\"cl\">3</span></a><br/>\n",
       "    <span class=\"mx\">2</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">47</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S95.html\"><span class=\"cl\">22</span></a><br/>\n",
       "    <span class=\"mx\">4</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">149</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S90.html\"><span class=\"cl\">61</span></a><br/>\n",
       "    <span class=\"mx\">11</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">311</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S85.html\"><span class=\"cl\">136</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">684</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S80.html\"><span class=\"cl\">300</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1137</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S75.html\"><span class=\"cl\">471</span></a><br/>\n",
       "    <span class=\"mx\">27</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2219</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S70.html\"><span class=\"cl\">841</span></a><br/>\n",
       "    <span class=\"mx\">52</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">5994</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S65.html\"><span class=\"cl\">1234</span></a><br/>\n",
       "    <span class=\"mx\">2718</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">17680</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_20_LCS_M60_S60.html\"><span class=\"cl\">154</span></a><br/>\n",
       "    <span class=\"mx\">17348</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>10</td><td>SET</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">446</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S100.html\"><span class=\"cl\">208</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">446</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S95.html\"><span class=\"cl\">208</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">480</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S90.html\"><span class=\"cl\">219</span></a><br/>\n",
       "    <span class=\"mx\">7</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1120</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S85.html\"><span class=\"cl\">495</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1546</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S80.html\"><span class=\"cl\">632</span></a><br/>\n",
       "    <span class=\"mx\">36</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">2772</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S75.html\"><span class=\"cl\">1100</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">4050</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S70.html\"><span class=\"cl\">1485</span></a><br/>\n",
       "    <span class=\"mx\">141</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">5789</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S65.html\"><span class=\"cl\">1849</span></a><br/>\n",
       "    <span class=\"mx\">658</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">10213</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_SET_M50_S60.html\"><span class=\"cl\">2205</span></a><br/>\n",
       "    <span class=\"mx\">4164</span>\n",
       "    </td></tr>\n",
       "<tr><td>fixed</td><td>10</td><td>LCS</td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">236</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S100.html\"><span class=\"cl\">112</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">374</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S95.html\"><span class=\"cl\">179</span></a><br/>\n",
       "    <span class=\"mx\">5</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">903</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S90.html\"><span class=\"cl\">398</span></a><br/>\n",
       "    <span class=\"mx\">12</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">1909</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S85.html\"><span class=\"cl\">788</span></a><br/>\n",
       "    <span class=\"mx\">71</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">3852</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S80.html\"><span class=\"cl\">1418</span></a><br/>\n",
       "    <span class=\"mx\">134</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">8562</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S75.html\"><span class=\"cl\">2341</span></a><br/>\n",
       "    <span class=\"mx\">1999</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">20423</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S70.html\"><span class=\"cl\">1919</span></a><br/>\n",
       "    <span class=\"mx\">15782</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">37712</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S65.html\"><span class=\"cl\">227</span></a><br/>\n",
       "    <span class=\"mx\">37238</span>\n",
       "    </td>\n",
       "<td class=\"out\" title=\"\">\n",
       "    <span class=\"ps\">42451</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_F_10_LCS_M60_S60.html\"><span class=\"cl\">2</span></a><br/>\n",
       "    <span class=\"mx\">42449</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>verse</td><td>SET</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">995</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S100.html\"><span class=\"cl\">389</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">1031</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S95.html\"><span class=\"cl\">407</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1290</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S90.html\"><span class=\"cl\">528</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1577</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S85.html\"><span class=\"cl\">653</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">1964</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S80.html\"><span class=\"cl\">803</span></a><br/>\n",
       "    <span class=\"mx\">154</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2365</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S75.html\"><span class=\"cl\">964</span></a><br/>\n",
       "    <span class=\"mx\">156</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2723</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S70.html\"><span class=\"cl\">1095</span></a><br/>\n",
       "    <span class=\"mx\">166</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3141</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S65.html\"><span class=\"cl\">1235</span></a><br/>\n",
       "    <span class=\"mx\">172</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3893</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_SET_M50_S60.html\"><span class=\"cl\">1443</span></a><br/>\n",
       "    <span class=\"mx\">202</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>verse</td><td>LCS</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">795</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S100.html\"><span class=\"cl\">296</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1235</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S95.html\"><span class=\"cl\">504</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">1754</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S90.html\"><span class=\"cl\">724</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2298</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S85.html\"><span class=\"cl\">939</span></a><br/>\n",
       "    <span class=\"mx\">160</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">2925</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S80.html\"><span class=\"cl\">1141</span></a><br/>\n",
       "    <span class=\"mx\">174</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">3683</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S75.html\"><span class=\"cl\">1339</span></a><br/>\n",
       "    <span class=\"mx\">190</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">4964</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S70.html\"><span class=\"cl\">1646</span></a><br/>\n",
       "    <span class=\"mx\">257</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">9052</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S65.html\"><span class=\"cl\">1820</span></a><br/>\n",
       "    <span class=\"mx\">4237</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">18937</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_verse_LCS_M60_S60.html\"><span class=\"cl\">378</span></a><br/>\n",
       "    <span class=\"mx\">18077</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>half_verse</td><td>SET</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4308</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S100.html\"><span class=\"cl\">1717</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4314</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S95.html\"><span class=\"cl\">1720</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4603</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S90.html\"><span class=\"cl\">1857</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">5131</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S85.html\"><span class=\"cl\">2066</span></a><br/>\n",
       "    <span class=\"mx\">70</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">6407</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S80.html\"><span class=\"cl\">2466</span></a><br/>\n",
       "    <span class=\"mx\">195</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">8242</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S75.html\"><span class=\"cl\">2878</span></a><br/>\n",
       "    <span class=\"mx\">535</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">9363</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S70.html\"><span class=\"cl\">3181</span></a><br/>\n",
       "    <span class=\"mx\">680</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12139</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S65.html\"><span class=\"cl\">3337</span></a><br/>\n",
       "    <span class=\"mx\">2834</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">16431</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_SET_M50_S60.html\"><span class=\"cl\">3414</span></a><br/>\n",
       "    <span class=\"mx\">6918</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>half_verse</td><td>LCS</td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">3779</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S100.html\"><span class=\"cl\">1505</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">4324</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S95.html\"><span class=\"cl\">1763</span></a><br/>\n",
       "    <span class=\"mx\">69</span>\n",
       "    </td>\n",
       "<td class=\"nor\" title=\"\">\n",
       "    <span class=\"ps\">5752</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S90.html\"><span class=\"cl\">2325</span></a><br/>\n",
       "    <span class=\"mx\">74</span>\n",
       "    </td>\n",
       "<td class=\"rec\" title=\"\">\n",
       "    <span class=\"ps\">7944</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S85.html\"><span class=\"cl\">2973</span></a><br/>\n",
       "    <span class=\"mx\">189</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">12463</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S80.html\"><span class=\"cl\">3528</span></a><br/>\n",
       "    <span class=\"mx\">2359</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">19071</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S75.html\"><span class=\"cl\">3074</span></a><br/>\n",
       "    <span class=\"mx\">11036</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">28373</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S70.html\"><span class=\"cl\">1890</span></a><br/>\n",
       "    <span class=\"mx\">23768</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">38059</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S65.html\"><span class=\"cl\">668</span></a><br/>\n",
       "    <span class=\"mx\">36526</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">43903</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_half_verse_LCS_M60_S60.html\"><span class=\"cl\">92</span></a><br/>\n",
       "    <span class=\"mx\">43708</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>sentence</td><td>SET</td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19247</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S100.html\"><span class=\"cl\">4351</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19255</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S95.html\"><span class=\"cl\">4355</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19415</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S90.html\"><span class=\"cl\">4425</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">19976</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S85.html\"><span class=\"cl\">4628</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">22348</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S80.html\"><span class=\"cl\">5100</span></a><br/>\n",
       "    <span class=\"mx\">1059</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">26090</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S75.html\"><span class=\"cl\">5003</span></a><br/>\n",
       "    <span class=\"mx\">5019</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">27265</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S70.html\"><span class=\"cl\">5237</span></a><br/>\n",
       "    <span class=\"mx\">5425</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">33892</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S65.html\"><span class=\"cl\">4053</span></a><br/>\n",
       "    <span class=\"mx\">18213</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">39418</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_SET_M50_S60.html\"><span class=\"cl\">3697</span></a><br/>\n",
       "    <span class=\"mx\">24919</span>\n",
       "    </td></tr>\n",
       "<tr><td>object</td><td>sentence</td><td>LCS</td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">17698</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S100.html\"><span class=\"cl\">3992</span></a><br/>\n",
       "    <span class=\"mx\">1057</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">18239</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S95.html\"><span class=\"cl\">4224</span></a><br/>\n",
       "    <span class=\"mx\">1057</span>\n",
       "    </td>\n",
       "<td class=\"dub\" title=\"\">\n",
       "    <span class=\"ps\">21484</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S90.html\"><span class=\"cl\">5005</span></a><br/>\n",
       "    <span class=\"mx\">1057</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">26842</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S85.html\"><span class=\"cl\">4832</span></a><br/>\n",
       "    <span class=\"mx\">7659</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">36154</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S80.html\"><span class=\"cl\">3428</span></a><br/>\n",
       "    <span class=\"mx\">26190</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">44920</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S75.html\"><span class=\"cl\">2245</span></a><br/>\n",
       "    <span class=\"mx\">38988</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">53180</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S70.html\"><span class=\"cl\">1167</span></a><br/>\n",
       "    <span class=\"mx\">50037</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"\">\n",
       "    <span class=\"ps\">59474</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S65.html\"><span class=\"cl\">449</span></a><br/>\n",
       "    <span class=\"mx\">58395</span>\n",
       "    </td>\n",
       "<td class=\"dep\" title=\"this experiment is the last one run\"><span class=\"lr\">*</span>\n",
       "    <span class=\"ps\">62942</span><br/>\n",
       "    <a target=\"_blank\" href=\"files/experiments/00index_O_sentence_LCS_M60_S60.html\"><span class=\"cl\">105</span></a><br/>\n",
       "    <span class=\"mx\">62697</span>\n",
       "    </td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell after all other cells\n",
    "HTML(other_exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and results\n",
    "\n",
    "We have conducted 126 experiments, all corresponding to a specific choice of parameters.\n",
    "Every experiment is an attempt to identify variants and collect them in *cliques*.\n",
    "\n",
    "The table gives an overview of the experiments conducted.\n",
    "\n",
    "Every *row* corresponds to a particular way of chunking and a method of measuring the similarity.\n",
    "\n",
    "There are *columns* for each similarity *threshold* that we have tried.\n",
    "The idea is that chunks are similar if their similarity is above the threshold.\n",
    "\n",
    "The outcomes of the best results have been added to SHEBANQ as the note set\n",
    "[crossref](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnxjcm9zc3JlZg__&tp=txt_tb1&nget=v)\n",
    "\n",
    "## Assessing the outcomes\n",
    "\n",
    "Not all experiments lead to useful results.\n",
    "We have indicated the value of a result by a color coding, based on objective characteristics,\n",
    "such as the number of passages, the number of cliques, the size of the greatest clique, and the way of chunking.\n",
    "These numbers are shown in the cells.\n",
    "\n",
    "If you click on the hyperlink in the cell, you are taken to a page that gives you\n",
    "all the details of the results:\n",
    "\n",
    "1. A link to a file with all *cliques* (which are the sets of similar passages)\n",
    "1. A list of links to chapter-by-chapter diff files (for cliques with just two members), and only for\n",
    "   experiments with outcomes that are labeled as *promising* or *unassessed quality*.\n",
    "\n",
    "To get into the variants quickly, inspect the list (2) and click through \n",
    "to see the actual variant material in chapter context.\n",
    "\n",
    "Not all variants occur here, so continue with (1) to see the remaining cliques.\n",
    "\n",
    "Sometimes in (2) a chapter diff file does not indicate clearly the relevant common part of both chapters.\n",
    "In that case you have to consult the big list (1)\n",
    "\n",
    "All these results can be downloaded from my\n",
    "[SURFdrive](https://surfdrive.surf.nl/files/public.php?service=files&t=ae6f5b0a5d0113a88ef45be32a253426)\n",
    "as well. \n",
    "After downloading the whole directory, open ``experiments.html`` in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This is an IPython notebook. \n",
    "It contains a working program to carry out the computations needed to obtain the results reported here.\n",
    "\n",
    "You can download this notebook and run it on your computer, provided you have\n",
    "[LAF-Fabric](http://laf-fabric.readthedocs.org/en/latest/texts/welcome.html) installed.\n",
    "An easy way to do that is describe [here](https://github.com/ETCBC/llshebanq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method description\n",
    "\n",
    "Here we discuss the method we used to arrive at a list of parallel passages \n",
    "in the Masoretic Text (MT) of the Hebrew Bible.\n",
    "\n",
    "## Similarity\n",
    "\n",
    "We have to find passages in the MT that are *similar*.\n",
    "Therefore we *chunk* the text in some way, and then compute the similarities between pairs of chunks.\n",
    "\n",
    "There are many ways to define and compute similarity between texts.\n",
    "Here, we have tried two methods ``SET`` and ``LCS``.\n",
    "Both methods define similarity as the fraction of common material with respect to the total material.\n",
    "\n",
    "### SET\n",
    "\n",
    "The ``SET`` method reduces textual chunks to *sets* of *lexemes*.\n",
    "This method abstracts from the order and number of occurrences of words in chunks.\n",
    "\n",
    "We use as measure for the similarity of chunks $C_1$ and $C_2$ (taken as sets):\n",
    "\n",
    "$$ s_{\\rm set}(C_1, C_2) = {\\vert C_1 \\cap C_2\\vert \\over \\vert C_1 \\cup C_2 \\vert} $$\n",
    "\n",
    "where $\\vert X \\vert$ is the number of elements in set $X$.\n",
    "\n",
    "### LCS\n",
    "\n",
    "The ``LCS`` method is less reductive: chunks are *strings* of *lexemes*, \n",
    "so the order and number of occurrences of words is retained.\n",
    "\n",
    "We use as measure for the similarity of chunks $C_1$ and $C_2$ (taken as strings):\n",
    "\n",
    "$$ s_{\\rm lcs}(C_1, C_2) = {\\vert {\\rm LCS}(C_1,C_2)\\vert \\over \\vert C_1\\vert + \\vert C_2 \\vert - \n",
    "\\vert {\\rm LCS}(C_1,C_2)\\vert} $$\n",
    "\n",
    "where ${\\rm LCS}(C_1, C_2)$ is the\n",
    "[longest common subsequence](https://en.wikipedia.org/wiki/Longest_common_subsequence_problem)\n",
    "of $C_1$ and $C_2$ and\n",
    "$\\vert X\\vert$ is the length of sequence $X$.\n",
    "\n",
    "It remains to be seen whether we need the extra sophistication of ``LCS``.\n",
    "The risk is that ``LCS`` could fail to spot related passages when there is a large amount of transposition going on.\n",
    "The results should have the last word. \n",
    "\n",
    "We need to compute the LCS efficiently, and for this we used the python ``Levenshtein`` module:\n",
    "\n",
    "``pip install python-Levenshtein``\n",
    "\n",
    "whose documentation is\n",
    "[here](http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html).\n",
    "\n",
    "## Performance\n",
    "\n",
    "Similarity computation is the part where the heavy lifting occurs.\n",
    "It is basically quadratic in the number of chunks, so if you have verses as chunks (~ 23,000),\n",
    "you need to do ~ 270,000,000 similarity computations, and if you use sentences (~ 64,000), \n",
    "you need to do ~ 2,000,000,000 ones!\n",
    "The computation of a single similarity should be *really* fast.\n",
    "\n",
    "Besides that, we use two ways to economize:\n",
    "\n",
    "* after having computed a matrix for a specific set of parameter values, we save the matrix to disk;\n",
    "  new runs can load the matrix from disk in a matter of seconds;\n",
    "* we do not store low similarity values in the matrix, low being < ``MATRIX_THRESHOLD``.\n",
    "\n",
    "The ``LCS`` method is more complicated.\n",
    "We have tried the ``ratio`` method from the ``difflib`` package that is present in the standard python distribution.\n",
    "This is unbearably slow for our purposes.\n",
    "The ``ratio`` method in the ``Levenshtein`` package is much quicker.\n",
    "\n",
    "See the table for an indication of the amount of work to create the similarity matrix\n",
    "and the performance per similarity method.\n",
    "\n",
    "The *matrix threshold* is the lower bound of similarities that are stored in the matrix.\n",
    "If a pair of chunks has a lower similarity, no entry will be made in the matrix.\n",
    "\n",
    "The computing has been done on a Macbook Air (11\", mid 2012, 1.7 GHz Intel Core i5, 8GB RAM).\n",
    "\n",
    "|chunk type |chunk size|similarity method|matrix threshold|# of comparisons|size of matrix (KB)|computing time (min)|\n",
    "|:----------|---------:|----------------:|---------------:|---------------:|------------------:|-------------------:|\n",
    "|fixed      |100       |LCS              |60              |       9,003,646|                  7|                  ? |\n",
    "|fixed      |100       |SET              |50              |       9,003,646|                  7|                  ? |\n",
    "|fixed      |50        |LCS              |60              |      36,197,286|                 37|                  ? |\n",
    "|fixed      |50        |SET              |50              |      36,197,286|                 18|                  ? |\n",
    "|fixed      |20        |LCS              |60              |     227,068,705|              2,400|                  ? |\n",
    "|fixed      |20        |SET              |50              |     227,068,705|                113|                  ? |\n",
    "|fixed      |10        |LCS              |60              |     909,020,841|             59,000|                  ? |\n",
    "|fixed      |10        |SET              |50              |     909,020,841|              1,800|                  ? |\n",
    "|object     |verse     |LCS              |60              |     269,410,078|              2,300|                  31|\n",
    "|object     |verse     |SET              |50              |     269,410,078|                509|                  14|\n",
    "|object     |half_verse|LCS              |60              |   1,016,396,241|             40,000|                  50|\n",
    "|object     |half_verse|SET              |50              |   1,016,396,241|              3,600|                  41|\n",
    "|object     |sentence  |LCS              |60              |   2,055,975,750|            212,000|                  68|\n",
    "|object     |sentence  |SET              |50              |   2,055,975,750|             82,000|                  63|\n",
    "\n",
    "\n",
    "## Chunking\n",
    "\n",
    "There are several ways to chunk the text:\n",
    "\n",
    "* fixed chunks of approximately ``CHUNK_SIZE`` words\n",
    "* by object, such as verse, sentence\n",
    "\n",
    "After chunking, we prepare the chunks for similarity measuring.\n",
    "\n",
    "### Observations\n",
    "\n",
    "#### Fixed chunking\n",
    "Fixed chunking is unnatural, but if the chunk size is small, it can yield fair results.\n",
    "The results are somewhat difficult to inspect, because they generally do not respect constituent boundaries.\n",
    "It is to be expected that fixed chunks in variant passages will be mutually *out of phase*, \n",
    "meaning that the chunks involved in these passages are not aligned with each other.\n",
    "So they will have a lower similarity than they could have if they were aligned.\n",
    "This is a source of artificial noise in the outcome and/or missed cases.\n",
    "\n",
    "If the chunking respects \"natural\" boundaries in the text, there is far less misalignment.\n",
    "\n",
    "#### Object chunking\n",
    "We can also chunk by object, such as verse, half_verse or sentence.\n",
    "\n",
    "Chunking by *verse* is very much like chunking in fixed chunks of size 20, performance-wise.\n",
    "\n",
    "Chunking by *half_verse* is comparable to fixed chunks of size 10.\n",
    "\n",
    "Chunking by *sentence* will generate an enormous amount of\n",
    "false positives, because there are very many very short sentences (down to 1-word) in the text.\n",
    "Besides that, the performance overhead is huge.\n",
    "\n",
    "The *half_verses* seem to be a very interesting candidate. \n",
    "They are smaller than verses, but there are less *degenerate cases* compared to with sentences. \n",
    "From the table above it can be read that half verses require only half as many similarity computations as sentences.\n",
    "\n",
    "\n",
    "## Preparing\n",
    "\n",
    "We prepare the chunks for the application of the chosen method of similarity computation (``SET`` or ``LCS``).\n",
    "\n",
    "In both cases we reduce the text to a sequence of transliterated consonantal *lexemes* without disambiguation.\n",
    "In fact, we go one step further: we remove the consonants (alef, wav, yod) that are often silent.\n",
    "\n",
    "For ``SET``, we represent each chunk as the set of its reduced lexemes.\n",
    "\n",
    "For ``LCS``, we represent each chunk as the string obtained by joining its reduced lexemes separated by white spaces.\n",
    "\n",
    "## Cliques\n",
    "\n",
    "After having computed a sufficient part of the similarity matrix, we set a value for ``SIMILARITY_THRESHOLD``.\n",
    "All pairs of chunks having at least that similarity are deemed *interesting*.\n",
    "\n",
    "We organize the members of such pairs in *cliques*, groups of chunks of which each member is \n",
    "similar (*similarity* > ``SIMILARITY_THRESHOLD``) to at least one other member.\n",
    "\n",
    "We start with no cliques and walk through the pairs whose similarity is above ``SIMILARITY_THRESHOLD``, \n",
    "and try to put each member into a clique.\n",
    "\n",
    "If there is not yet a clique, we make the member in question into a new singleton clique.\n",
    "\n",
    "If there are cliques, we find the cliques that have a member similar to the member in question.\n",
    "If we find several, we merge them all into one clique.\n",
    "\n",
    "If there is no such clique, we put the member in a new singleton clique.\n",
    "\n",
    "NB: Cliques may *drift*, meaning that they contain members that are completely different from each other.\n",
    "They are in the same clique, because there is a path of pairwise similar members leading from the one chunk to the other.\n",
    "\n",
    "### Organizing the cliques\n",
    "In order to accomodate cases where there are many corresponding verses in corresponding chapters, we produce\n",
    "chapter-by-chapter diffs in the following way.\n",
    "\n",
    "We make a list of all chapters that are involved in cliques.\n",
    "This yields a list of chapter cliques.\n",
    "For all *binary* chapters cliques, we generate a colorful diff rendering (as html) for the complete two chapters.\n",
    "\n",
    "We only do this for *promising* experiments.\n",
    "\n",
    "### Evaluating clique sets\n",
    "\n",
    "Not all clique sets are equally worth while.\n",
    "For example, if we set the ``SIMILARITY_THRESHOLD`` too low, we might get one gigantic clique, especially\n",
    "in combination with a fine-grained chunking. In other words: we suffer from *clique drifting*.\n",
    "\n",
    "We detect clique drifting by looking at the size of the largest clique.\n",
    "If that is large compared to the total number of chunks, we deem the results unsatisfactory.\n",
    "\n",
    "On the other hand, when the ``SIMILARITY_THRESHOLD`` is too high, you might miss a lot of correspondences,\n",
    "especially when chunks are large, or when we have fixed-size chunks that are out of phase.\n",
    "\n",
    "We deem the results of experiments based on a partioning into fixed length chunks as unsatisfactory, although it\n",
    "might be interesting to inspect what exactly the damage is.\n",
    "\n",
    "At the moment, we have not yet analysed the relative merits of the similarity methods ``SET`` and ``LCS``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines\n",
    "\n",
    "The rest is code. From here we start computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.3\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: http://shebanq-doc.readthedocs.org/en/latest/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, collections, pickle, math, difflib, glob\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "PICKLE_PROTOCOL = 3\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import ratio\n",
    "\n",
    "import laf\n",
    "from laf.fabric import LafFabric\n",
    "from etcbc.preprocess import prepare\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  2.50s LOGFILE=/Users/dirk/SURFdrive/laf-fabric-output/etcbc4b/parallel/__log__parallel.txt\n",
      "    12s ETCBC reference: http://laf-fabric.readthedocs.org/en/latest/texts/ETCBC-reference.html\n",
      "  0.00s LOADING API with EXTRAs: please wait ... \n",
      "  0.00s INFO: USING DATA COMPILED AT: 2015-06-29T05-30-49\n",
      "  0.01s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK parallel AT 2015-07-23T10-49-58\n",
      "  0.00s INFO: DATA LOADED FROM SOURCE etcbc4b AND ANNOX -- FOR TASK parallel AT 2015-07-23T10-49-58\n"
     ]
    }
   ],
   "source": [
    "version = '4b'\n",
    "API = fabric.load('etcbc{}'.format(version), '--', 'parallel', {\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": ('''\n",
    "        otype\n",
    "        lex g_word_utf8 trailer_utf8\n",
    "        book chapter verse label number\n",
    "    ''',\n",
    "    ''),\n",
    "    \"prepare\": prepare,\n",
    "    \"primary\": False,\n",
    "}, verbose='NORMAL')\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Here are the parameters on which the results crucially depend.\n",
    "\n",
    "There are also parameters that control the reporting of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chunking\n",
    "CHUNK_LABELS = {True: 'fixed', False: 'object'}\n",
    "CHUNK_LBS = {True: 'F', False: 'O'}\n",
    "CHUNK_SIZES = (100, 50, 20, 10)\n",
    "CHUNK_OBJECTS = ('verse','half_verse','sentence')\n",
    "\n",
    "# preparing\n",
    "EXCLUDED_CONS = '[>WJ=/\\[]'             # weed out weak consonants\n",
    "EXCLUDED_PAT = re.compile(EXCLUDED_CONS)\n",
    "\n",
    "# similarity\n",
    "MATRIX_THRESHOLD = 50\n",
    "SIM_METHODS = ('SET', 'LCS')\n",
    "SIMILARITIES = (100, 95, 90, 85, 80, 75, 70, 65, 60)\n",
    "\n",
    "# printing\n",
    "DEP_CLIQUE_RATIO = 25\n",
    "DUB_CLIQUE_RATIO = 15\n",
    "REC_CLIQUE_RATIO =  5\n",
    "LARGE_CLIQUE_SIZE = 50\n",
    "\n",
    "# crossrefs for SHEBANQ\n",
    "SHEBANQ_MATRICES = (\n",
    "    (False, 'verse', 'SET'),\n",
    "    (False, 'verse', 'LCS'),\n",
    ")\n",
    "SHEBANQ_SIMILARITIES = dict(\n",
    "    SET=85,\n",
    "    LCS=90,\n",
    ")\n",
    "CROSSREF_STATUS = '!'\n",
    "CROSSREF_KEYWORD = 'crossref'\n",
    "\n",
    "# progress indication\n",
    "VERBOSE = False\n",
    "MEGA = 1000000\n",
    "KILO = 1000\n",
    "SIMILARITY_PROGRESS = 5 * MEGA\n",
    "CLIQUES_PROGRESS = 1 * KILO\n",
    "\n",
    "# locations and hyperlinks\n",
    "REMOTE_BASE = 'https://surfdrive.surf.nl/files/public.php?service=files&t=dedf27be7e171ab8a8b151f84ded93e8'\n",
    "LOCAL_BASE_COMP = my_file('').rstrip('/')\n",
    "LOCAL_BASE_OUTP = 'files'\n",
    "EXPERIMENT_DIR = 'experiments'\n",
    "EXPERIMENT_FILE = 'experiments'\n",
    "EXPERIMENT_PATH = '{}/{}.txt'.format(LOCAL_BASE_OUTP, EXPERIMENT_FILE)\n",
    "EXPERIMENT_HTML = '{}/{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_FILE)\n",
    "NOTES_FILE = 'crossref'\n",
    "NOTES_PATH = '{}/{}.csv'.format(LOCAL_BASE_OUTP, NOTES_FILE)\n",
    "STORED_CLIQUE_DIR = 'stored/cliques'\n",
    "STORED_MATRIX_DIR = 'stored/matrices'\n",
    "CHAPTER_DIR = 'chapters'\n",
    "\n",
    "def reset_params():\n",
    "    global CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJECT, CHUNK_LB, CHUNK_DESC\n",
    "    global SIMILARITY_METHOD, SIMILARITY_THRESHOLD, MATRIX_THRESHOLD\n",
    "    global meta\n",
    "    meta = collections.OrderedDict()\n",
    "    \n",
    "    # chunking\n",
    "    CHUNK_FIXED = None                      # kind of chunking: fixed size or by object\n",
    "    CHUNK_SIZE = None                       # only relevant for CHUNK_FIXED = True\n",
    "    CHUNK_OBJECT = None                     # only relevant for CHUNK_FIXED = False; see CHUNK_OBJECTS in next cell\n",
    "    CHUNK_LB = None                         # computed from CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJ\n",
    "    CHUNK_DESC = None                       # computed from CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJ\n",
    "    # similarity\n",
    "    MATRIX_THRESHOLD = None                 # minimal similarity used to fill the matrix of similarities\n",
    "    SIMILARITY_METHOD = None                # see SIM_METHODS in next cell\n",
    "    SIMILARITY_THRESHOLD = None             # minimal similarity used to put elements together in cliques\n",
    "    meta = collections.OrderedDict()\n",
    "\n",
    "def set_matrix_threshold(sim_m=None):\n",
    "    global MATRIX_THRESHOLD\n",
    "    the_sim_m = SIMILARITY_METHOD if sim_m == None else sim_m\n",
    "    MATRIX_THRESHOLD = 50 if the_sim_m == 'SET' else 60\n",
    "\n",
    "def do_params(chunk_f, chunk_i, sim_m, sim_thr):\n",
    "    global CHUNK_FIXED, CHUNK_SIZE, CHUNK_OBJECT, CHUNK_LB, CHUNK_DESC\n",
    "    global SIMILARITY_METHOD, SIMILARITY_THRESHOLD, MATRIX_THRESHOLD\n",
    "    global meta\n",
    "    do_chunk = False\n",
    "    do_prep = False\n",
    "    do_sim = False\n",
    "    do_clique = False\n",
    "    meta = collections.OrderedDict()\n",
    "    if chunk_f != CHUNK_FIXED or (chunk_f and chunk_i != CHUNK_SIZE) or (not chunk_f and chunk_i != CHUNK_OBJECT):\n",
    "        do_chunk = True\n",
    "        do_prep = True\n",
    "        do_sim = True\n",
    "        do_clique = True\n",
    "        CHUNK_FIXED = chunk_f\n",
    "        if chunk_f: CHUNK_SIZE = chunk_i\n",
    "        else: CHUNK_OBJECT = chunk_i\n",
    "    if sim_m != SIMILARITY_METHOD:\n",
    "        do_prep = True\n",
    "        do_sim = True\n",
    "        do_clique = True\n",
    "        SIMILARITY_METHOD = sim_m\n",
    "    if sim_thr != SIMILARITY_THRESHOLD:\n",
    "        do_clique = True\n",
    "        SIMILARITY_THRESHOLD = sim_thr\n",
    "    set_matrix_threshold()\n",
    "    CHUNK_LB = CHUNK_LBS[CHUNK_FIXED]\n",
    "    CHUNK_DESC = CHUNK_SIZE if CHUNK_FIXED else CHUNK_OBJECT\n",
    "\n",
    "    meta['CHUNK TYPE'] = 'FIXED {}'.format(CHUNK_SIZE) if CHUNK_FIXED else 'OBJECT {}'.format(CHUNK_OBJECT)\n",
    "    meta['MATRIX THRESHOLD'] = MATRIX_THRESHOLD\n",
    "    meta['SIMILARITY METHOD'] = SIMILARITY_METHOD\n",
    "    meta['SIMILARITY THRESHOLD'] = SIMILARITY_THRESHOLD\n",
    "    return (do_chunk, do_prep, do_sim, do_clique)\n",
    "\n",
    "reset_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunking(do_chunk):\n",
    "    global chunks, book_rank\n",
    "    if not do_chunk:\n",
    "        msg('CHUNKING ({} {}): already chunked into {} chunks'.format(CHUNK_LB, CHUNK_DESC, len(chunks)))\n",
    "        meta['# CHUNKS'] = len(chunks)\n",
    "        return\n",
    "    msg('CHUNKING ({} {})'.format(CHUNK_LB, CHUNK_DESC))\n",
    "    chunks = []\n",
    "    book_rank = {}\n",
    "    for b in F.otype.s('book'):\n",
    "        book_name = F.book.v(b)\n",
    "        book_rank[book_name] = b\n",
    "        words = L.d('word', b)\n",
    "        nwords = len(words)\n",
    "        if CHUNK_FIXED:\n",
    "            nchunks = nwords // CHUNK_SIZE\n",
    "            if nchunks == 0: \n",
    "                nchunks = 1\n",
    "                common_incr = nwords\n",
    "                special_incr = 0\n",
    "            else:            \n",
    "                rem = nwords % CHUNK_SIZE\n",
    "                common_incr = rem // nchunks\n",
    "                special_incr = rem % nchunks\n",
    "            word_in_chunk = -1\n",
    "            cur_chunk = -1\n",
    "            these_chunks = []\n",
    "\n",
    "            for w in words:\n",
    "                word_in_chunk += 1\n",
    "                if word_in_chunk == 0 or (word_in_chunk >= CHUNK_SIZE + common_incr + (1 if cur_chunk < special_incr else 0)):\n",
    "                    word_in_chunk = 0\n",
    "                    these_chunks.append([])\n",
    "                    cur_chunk += 1\n",
    "                these_chunks[-1].append(w)\n",
    "        else:\n",
    "            these_chunks = [L.d('word', c) for c in L.d(CHUNK_OBJECT, b)]\n",
    "\n",
    "        chunks.extend(these_chunks)\n",
    "\n",
    "        chunkvolume = sum(len(c) for c in these_chunks)\n",
    "        if VERBOSE:\n",
    "            msg('CHUNKING ({} {}): {:<20s} {:>5} words; {:>5} chunks; sizes {:>5} to {:>5}; {:>5}'.format(\n",
    "                CHUNK_LB, CHUNK_DESC,\n",
    "                book_name, nwords, len(these_chunks), \n",
    "                min(len(c) for c in these_chunks), \n",
    "                max(len(c) for c in these_chunks),\n",
    "                'OK' if chunkvolume == nwords else 'ERROR',\n",
    "            ))\n",
    "    meta['# CHUNKS'] = len(chunks)\n",
    "    msg('CHUNKING ({} {}): Made {} chunks'.format(CHUNK_LB, CHUNK_DESC, len(chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preparing(do_prepare):\n",
    "    global chunk_data\n",
    "    if not do_prepare:\n",
    "        msg('PREPARING ({} {} {}): Already prepared'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD))\n",
    "        return\n",
    "    msg('PREPARING ({} {} {})'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD))\n",
    "    chunk_data = []\n",
    "    if SIMILARITY_METHOD == 'SET':\n",
    "        for c in chunks:\n",
    "            words = (EXCLUDED_PAT.sub('', F.lex.v(w).replace('<', 'O')) for w in c)\n",
    "            clean_words = (w for w in words if w != '')\n",
    "            this_data = frozenset(clean_words)\n",
    "            chunk_data.append(this_data)\n",
    "    else:\n",
    "        for c in chunks:\n",
    "            words = (EXCLUDED_PAT.sub('', F.lex.v(w).replace('<', 'O')) for w in c)\n",
    "            clean_words = (w for w in words if w != '')\n",
    "            this_data = ' '.join(clean_words)\n",
    "            chunk_data.append(this_data)\n",
    "    msg('PREPARING ({} {} {}): Done {} chunks.'.format(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, len(chunk_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity_post():\n",
    "    nequals = len({x for x in chunk_dist if chunk_dist[x] >= 100})\n",
    "    cmin = min(chunk_dist.values()) if len(chunk_dist) else '!empty set!'\n",
    "    cmax = max(chunk_dist.values()) if len(chunk_dist) else '!empty set!'\n",
    "    meta['LOWEST  AVAILABLE SIMILARITY'] = cmin\n",
    "    meta['HIGHEST AVAILABLE SIMILARITY'] = cmax\n",
    "    meta['# EQUAL COMPARISONS'] = nequals\n",
    "    msg('SIMILARITY ({} {} {} M>{}): similarities between {} and {}. {} are 100%'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        cmin, cmax, nequals,\n",
    "    ))\n",
    "    \n",
    "def similarity(do_sim):\n",
    "    global chunk_dist\n",
    "    total_chunks = len(chunks) \n",
    "    total_distances = total_chunks * (total_chunks - 1) // 2\n",
    "    meta['# SIMILARITY COMPARISONS'] = total_distances\n",
    "    \n",
    "    SIMILARITY_PROGRESS = total_distances // 100\n",
    "    if SIMILARITY_PROGRESS >= MEGA:\n",
    "        sim_unit = MEGA\n",
    "        sim_lb = 'M'\n",
    "    else:\n",
    "        sim_unit = KILO\n",
    "        sim_lb = 'K'\n",
    "    \n",
    "    if not do_sim:\n",
    "        msg('SIMILARITY ({} {} {} M>{}): Using {:>5} {} ({}) comparisons with {} entries in matrix'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "            total_distances // sim_unit, sim_lb, total_distances, len(chunk_dist),\n",
    "        ))\n",
    "        meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "        similarity_post()\n",
    "        return\n",
    "\n",
    "    matrix_path = '{}/{}/matrix_{}_{}_{}_{}'.format(\n",
    "        LOCAL_BASE_COMP, STORED_MATRIX_DIR,\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "    )\n",
    "\n",
    "    if os.path.exists(matrix_path):\n",
    "        with open(matrix_path, 'rb') as f: chunk_dist = pickle.load(f)\n",
    "        msg('SIMILARITY ({} {} {} M>{}): Loaded: {:>5} {} ({}) comparisons with {} entries in matrix'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "            total_distances // sim_unit, sim_lb, total_distances, len(chunk_dist),\n",
    "        ))\n",
    "        meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "        similarity_post()\n",
    "        return\n",
    "\n",
    "    msg('SIMILARITY ({} {} {} M>{}): Computing {:>5} {} ({}) comparisons and saving entries in matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        total_distances // sim_unit, sim_lb, total_distances\n",
    "    ))\n",
    "\n",
    "    chunk_dist = {}\n",
    "    wc = 0\n",
    "    wt = 0\n",
    "    if SIMILARITY_METHOD == 'SET':\n",
    "        # method SET: all chunks have been reduced to sets, ratio between lengths of intersection and union\n",
    "        for i in range(total_chunks):\n",
    "            c_i = chunk_data[i]\n",
    "            for j in range(i + 1, total_chunks):\n",
    "                c_j = chunk_data[j]\n",
    "                u = len(c_i | c_j)\n",
    "                d = 100 * len(c_i & c_j) / u if u != 0 else 0\n",
    "                if d >= MATRIX_THRESHOLD:\n",
    "                    chunk_dist[(i,j)] = d\n",
    "                wc += 1\n",
    "                wt += 1\n",
    "                if wc == SIMILARITY_PROGRESS:\n",
    "                    wc = 0\n",
    "                    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} comparisons and saved {} entries in matrix'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "                        wt // sim_unit, sim_lb, len(chunk_dist),\n",
    "                    ))\n",
    "    elif SIMILARITY_METHOD == 'LCS':\n",
    "        # method LCS: chunks are sequence aligned, ratio between length of all common parts and total length\n",
    "        for i in range(total_chunks):\n",
    "            c_i = chunk_data[i]\n",
    "            for j in range(i + 1, total_chunks):\n",
    "                c_j = chunk_data[j]\n",
    "                d = 100 * ratio(c_i, c_j)\n",
    "                if d >= MATRIX_THRESHOLD:\n",
    "                    chunk_dist[(i,j)] = d\n",
    "                wc += 1\n",
    "                wt += 1\n",
    "                if wc == SIMILARITY_PROGRESS:\n",
    "                    wc = 0\n",
    "                    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} comparisons and saved {} entries in matrix'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "                        wt // sim_unit, sim_lb, len(chunk_dist),\n",
    "                    ))\n",
    "\n",
    "    with  open(matrix_path, 'wb') as f: pickle.dump(chunk_dist, f, protocol=PICKLE_PROTOCOL)\n",
    "        \n",
    "    msg('SIMILARITY ({} {} {} M>{}): Computed {:>5} {} ({}) comparisons and saved {} entries in matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD,\n",
    "        wt // sim_unit, sim_lb, wt, len(chunk_dist),\n",
    "    ))\n",
    "    \n",
    "    meta['# STORED SIMILARITIES'] = len(chunk_dist)\n",
    "    similarity_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Cliques\n",
    "\n",
    "Based on the value for the ``SIMILARITY_THRESHOLD`` we use the similarity matrix to pick the *interesting*\n",
    "similar pairs out of it. From these pairs we lump together our cliques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def key_chunk(i):\n",
    "    c = chunks[i]\n",
    "    w = c[0]\n",
    "    return  (-len(c), L.u('book', w), L.u('chapter', w), L.u('verse', w))\n",
    "\n",
    "def meta_clique_pre():\n",
    "    global similars, passages\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): inspecting the similarity matrix'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    ))\n",
    "    similars = {x for x in chunk_dist if chunk_dist[x] >= SIMILARITY_THRESHOLD}\n",
    "    passage_set = set()\n",
    "    for (i,j) in similars:\n",
    "        passage_set.add(i)\n",
    "        passage_set.add(j)\n",
    "    passages = sorted(passage_set, key=key_chunk)\n",
    "\n",
    "    meta['# SIMILAR COMPARISONS'] = len(similars)\n",
    "    meta['# SIMILAR PASSAGES'] = len(passages)    \n",
    "\n",
    "def meta_clique_pre2():\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): {} relevant similarities between {} passages'.format(\n",
    "    CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    len(similars), len(passages),\n",
    "))\n",
    "\n",
    "\n",
    "def meta_clique_post():\n",
    "    global l_c_l\n",
    "    meta['# CLIQUES'] = len(cliques)\n",
    "    scliques = collections.Counter()\n",
    "    for c in cliques:\n",
    "        scliques[len(c)] += 1\n",
    "    l_c_l = max(scliques.keys()) if len(scliques) > 0 else 0\n",
    "    totmn = 0\n",
    "    totcn = 0\n",
    "    for (ln, n) in sorted(scliques.items(), key=lambda x: x[0]):\n",
    "        totmn += ln * n\n",
    "        totcn += n\n",
    "        if VERBOSE:\n",
    "            msg('CLIQUES ({} {} {} M>{} S>{}): {:>4} cliques of length {:>4}'.format(\n",
    "                CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                n, ln,\n",
    "            ))\n",
    "        meta['# CLIQUES of LENGTH {:>4}'.format(ln)] = n\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): {} members in {} cliques'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        totmn, totcn,\n",
    "    ))\n",
    "    \n",
    "def cliqueing(do_clique):\n",
    "    global cliques\n",
    "    if not do_clique:\n",
    "        msg('CLIQUES ({} {} {} M>{} S>{}): Already loaded {} cliques out of {} candidates from {} comparisons'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(cliques), len(passages), len(similars),            \n",
    "        ))\n",
    "        meta_clique_pre2()\n",
    "        return\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): fetching similars and chunk candidates'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,        \n",
    "    ))\n",
    "    meta_clique_pre()\n",
    "    meta_clique_pre2()\n",
    "    clique_path = '{}/{}/clique_{}_{}_{}_{}_{}'.format(\n",
    "        LOCAL_BASE_COMP, STORED_CLIQUE_DIR,\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    )\n",
    "    if os.path.exists(clique_path):\n",
    "        with open(clique_path, 'rb') as f: cliques = pickle.load(f)\n",
    "        msg('CLIQUES ({} {} {} M>{} S>{}): Loaded: {:>5} cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(cliques), len(passages), len(similars),            \n",
    "        ))\n",
    "        meta_clique_post()\n",
    "        return\n",
    "\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): Composing cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(passages), len(similars),            \n",
    "    ))\n",
    "    cliques_unsorted = []\n",
    "    np = 0\n",
    "    npc = 0\n",
    "    for i in passages:\n",
    "        added = None\n",
    "        removable = set()\n",
    "        for (k, c) in enumerate(cliques_unsorted):\n",
    "            origc = tuple(c)\n",
    "            for j in origc:            \n",
    "                d = chunk_dist.get((i,j), 0) if i < j else chunk_dist.get((j,i), 0) if j < i else 0\n",
    "                if d >= SIMILARITY_THRESHOLD:\n",
    "                    if added == None:\n",
    "                        c.add(i)\n",
    "                        added = k\n",
    "                    else:\n",
    "                        cliques_unsorted[added] |= c\n",
    "                        removable.add(k)\n",
    "                    break\n",
    "        if added == None:\n",
    "            cliques_unsorted.append({i})\n",
    "        else:\n",
    "            if len(removable):\n",
    "                cliques_unsorted = [c for (k,c) in enumerate(cliques_unsorted) if k not in removable]\n",
    "        np += 1\n",
    "        npc += 1\n",
    "        if npc == CLIQUES_PROGRESS:\n",
    "            npc = 0\n",
    "            msg('CLIQUES ({} {} {} M>{} S>{}): Composed {:>5} cliques out of {:>6} chunks'.format(\n",
    "                CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                len(cliques_unsorted), np,\n",
    "            ))\n",
    "    cliques = sorted([tuple(sorted(c, key=key_chunk)) for c in cliques_unsorted])\n",
    "    with  open(clique_path, 'wb') as f: pickle.dump(cliques, f, protocol=PICKLE_PROTOCOL)\n",
    "    meta_clique_post()\n",
    "    msg('CLIQUES ({} {} {} M>{} S>{}): Composed and saved {:>5} cliques out of {:>6} chunks from {} comparisons'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(cliques), len(passages), len(similars),            \n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty output\n",
    "\n",
    "Here are the definitions for formatting the (HTML) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "css = '''\n",
    "td.vl {\n",
    "    font-family: Verdana, Arial, sans-serif;\n",
    "    font-size: small;\n",
    "    text-align: right;\n",
    "    color: #aaaaaa;\n",
    "    width: 10%;\n",
    "    direction: ltr;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "td.ht {\n",
    "    font-family: Ezra SIL, SBL Hebrew, Verdana, sans-serif;\n",
    "    font-size: x-large;\n",
    "    line-height: 1.7;\n",
    "    text-align: right;\n",
    "    direction: rtl;\n",
    "}\n",
    "table.ht {\n",
    "    width: 100%;\n",
    "    direction: rtl;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    "td.ht {\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "tr.ht.tb {\n",
    "    border-top: 2px solid #aaaaaa;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "tr.ht.bb {\n",
    "    border-bottom: 2px solid #aaaaaa;\n",
    "    border-left: 2px solid #aaaaaa;\n",
    "    border-right: 2px solid #aaaaaa;\n",
    "}\n",
    "span.m {\n",
    "    background-color: #aaaaff;\n",
    "}\n",
    "span.f {\n",
    "    background-color: #ffaaaa;\n",
    "}\n",
    "span.x {\n",
    "    background-color: #ffffaa;\n",
    "    color: #bb0000;\n",
    "}\n",
    "span.delete {\n",
    "    background-color: #ffaaaa;\n",
    "}\n",
    "span.insert {\n",
    "    background-color: #aaffaa;\n",
    "}\n",
    "span.replace {\n",
    "    background-color: #ffff00;\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "diffhead = '''\n",
    "<head>\n",
    "    <meta http-equiv=\"Content-Type\"\n",
    "          content=\"text/html; charset=UTF-8\" />\n",
    "    <title></title>\n",
    "    <style type=\"text/css\">\n",
    "        table.diff {\n",
    "            font-family: Ezra SIL, SBL Hebrew, Verdana, sans-serif; \n",
    "            font-size: x-large;\n",
    "            text-align: right;\n",
    "        }\n",
    "        .diff_header {background-color:#e0e0e0}\n",
    "        td.diff_header {text-align:right}\n",
    "        .diff_next {background-color:#c0c0c0}\n",
    "        .diff_add {background-color:#aaffaa}\n",
    "        .diff_chg {background-color:#ffff77}\n",
    "        .diff_sub {background-color:#ffaaaa}\n",
    "    </style>\n",
    "</head>\n",
    "'''\n",
    "\n",
    "def xterse_chunk(i):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = L.u('book', fword)\n",
    "    chapter = L.u('chapter', fword)\n",
    "    return (book, chapter)\n",
    "\n",
    "def xterse_clique(ii):\n",
    "    return tuple(sorted({xterse_chunk(i) for i in ii}))\n",
    "\n",
    "def terse_chunk(i):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = L.u('book', fword)\n",
    "    chapter = L.u('chapter', fword)\n",
    "    verse = L.u('verse', fword)\n",
    "    return (book, chapter, verse)\n",
    "\n",
    "def terse_clique(ii):\n",
    "    return tuple(sorted({terse_chunk(i) for i in ii}))\n",
    "\n",
    "def verse_chunk(i):\n",
    "    (bk, ch, vs) = i\n",
    "    book = F.book.v(bk)\n",
    "    chapter = F.chapter.v(ch)\n",
    "    verse = F.verse.v(vs)\n",
    "    text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in L.d('word', vs))\n",
    "    verse_label = '<td class=\"vl\">{} {}:{}</td>'.format(book, chapter, verse)\n",
    "    htext = '{}<td class=\"ht\">{}</td>'.format(verse_label, text)\n",
    "    return '<tr class=\"ht\">{}</tr>'.format(htext)\n",
    "\n",
    "def verse_clique(ii):\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(verse_chunk(i) for i in sorted(ii)))\n",
    "\n",
    "def condense(vlabels):\n",
    "    cnd = ''\n",
    "    (cur_b, cur_c) = (None, None)\n",
    "    for (b, c, v) in vlabels:\n",
    "        sep = '' if cur_b == None else '. ' if cur_b != b else '; ' if cur_c != c else ', '\n",
    "        show_b = b+' ' if cur_b != b else ''\n",
    "        show_c = c+':' if cur_b != b or cur_c != c else ''\n",
    "        (cur_b, cur_c) = (b, c)\n",
    "        cnd += '{}{}{}{}'.format(sep, show_b, show_c, v)\n",
    "    return cnd\n",
    "\n",
    "def print_diff(a, b):\n",
    "    arep = ''\n",
    "    brep = ''\n",
    "    for (lb, ai, aj, bi, bj) in SequenceMatcher(isjunk=None, a=a, b=b, autojunk=False).get_opcodes():\n",
    "        if lb == 'equal':\n",
    "            arep += a[ai:aj]\n",
    "            brep += b[bi:bj]\n",
    "        elif lb == 'delete':\n",
    "            arep += '<span class=\"{}\">{}</span>'.format(lb, a[ai:aj])\n",
    "        elif lb == 'insert':\n",
    "            brep += '<span class=\"{}\">{}</span>'.format(lb, b[bi:bj])\n",
    "        else:\n",
    "            arep += '<span class=\"{}\">{}</span>'.format(lb, a[ai:aj])\n",
    "            brep += '<span class=\"{}\">{}</span>'.format(lb, b[bi:bj])\n",
    "    return (arep, brep)\n",
    "    \n",
    "def print_chunk_fine(prev, text, verse_labels, prevlabels):\n",
    "    if prev == None:\n",
    "        return '''\n",
    "<tr class=\"ht tb bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "            condense(verse_labels), \n",
    "            text,\n",
    "        )\n",
    "    else:\n",
    "        (prevline, textline) = print_diff(prev, text)\n",
    "        return '''\n",
    "<tr class=\"ht tb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "<tr class=\"ht bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "    condense(prevlabels) if prevlabels != None else 'previous',\n",
    "    prevline,\n",
    "    condense(verse_labels), \n",
    "    textline,\n",
    ")\n",
    "\n",
    "def print_chunk_coarse(text, verse_labels):\n",
    "    return '''\n",
    "<tr class=\"ht tb bb\"><td class=\"vl\">{}</td><td class=\"ht\">{}</td></tr>\n",
    "'''.format(\n",
    "            condense(verse_labels), \n",
    "            text,\n",
    "        )\n",
    "\n",
    "def print_clique(ii, ncliques):\n",
    "    return print_clique_fine(ii) if len(ii) < ncliques * DEP_CLIQUE_RATIO / 100 else print_clique_coarse(ii)\n",
    "    \n",
    "def print_clique_fine(ii):\n",
    "    condensed = collections.OrderedDict()\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c)):\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in chunk)\n",
    "        condensed.setdefault(text, []).append((book, chapter, verse))\n",
    "    result = []\n",
    "    nv = len(condensed.items())\n",
    "    prev = None\n",
    "    for (text, verse_labels) in condensed.items():\n",
    "        if prev == None:\n",
    "            if nv == 1: result.append(print_chunk_fine(None, text, verse_labels, None))\n",
    "            else:\n",
    "                prev = text\n",
    "                prevlabels = verse_labels\n",
    "                continue\n",
    "        else:\n",
    "            result.append(print_chunk_fine(prev, text, verse_labels, prevlabels))\n",
    "            prev = text\n",
    "            prevlabels = None\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(result))\n",
    "\n",
    "def print_clique_coarse(ii):\n",
    "    condensed = collections.OrderedDict()\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c))[0:LARGE_CLIQUE_SIZE]:\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in chunk)\n",
    "        condensed.setdefault(text, []).append((book, chapter, verse))\n",
    "    result = []\n",
    "    nv = len(condensed.items())\n",
    "    prev = None\n",
    "    for (text, verse_labels) in condensed.items():\n",
    "        result.append(print_chunk_coarse(text, verse_labels))\n",
    "    if len(ii) > LARGE_CLIQUE_SIZE:\n",
    "        result.append(print_chunk_coarse('+ {} ...'.format(len(ii) - LARGE_CLIQUE_SIZE),[]))\n",
    "    return '<table class=\"ht\">{}</table>\\n'.format(''.join(result))\n",
    "\n",
    "def index_clique(n, ii, ncliques):\n",
    "    return index_clique_fine(n, ii) if len(ii) < ncliques * DEP_CLIQUE_RATIO / 100 else index_clique_coarse(n, ii)\n",
    "    \n",
    "def index_clique_fine(n, ii):\n",
    "    verse_labels = []\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c)):\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        verse_labels.append((book, chapter, verse))\n",
    "    return '<p><b>{}</b> <a href=\"#c_{}\">{}</a></p>'.format(\n",
    "        n, n, condense(verse_labels),\n",
    "    )\n",
    "\n",
    "def index_clique_coarse(n, ii):\n",
    "    verse_labels = []\n",
    "    for i in sorted(ii, key = lambda c: (-len(chunks[c]), c))[0:LARGE_CLIQUE_SIZE]:\n",
    "        chunk = chunks[i]\n",
    "        fword = chunk[0]\n",
    "        book = F.book.v(L.u('book', fword))\n",
    "        chapter = F.chapter.v(L.u('chapter', fword))\n",
    "        verse = F.verse.v(L.u('verse', fword))\n",
    "        verse_labels.append((book, chapter, verse))\n",
    "    extra = '+ {} ...'.format(len(ii) - LARGE_CLIQUE_SIZE) if len(ii) > LARGE_CLIQUE_SIZE else ''\n",
    "    return '<p><b>{}</b> <a href=\"#c_{}\">{}{}</a></p>'.format(\n",
    "        n, n, condense(verse_labels), extra,\n",
    "    )\n",
    "\n",
    "def lines_chapter(c):\n",
    "    lines = []\n",
    "    for v in L.d('verse', c):\n",
    "        vl = F.verse.v(v)\n",
    "        text = ''.join('{}{}'.format(F.g_word_utf8.v(w), F.trailer_utf8.v(w)) for w in L.d('word', v))\n",
    "        lines.append('{} {}'.format(vl, text.replace('\\n', ' ')))\n",
    "    return lines\n",
    "\n",
    "def compare_chapters(c1, c2, lb1, lb2):\n",
    "    dh = difflib.HtmlDiff(wrapcolumn=80)\n",
    "    table_html = dh.make_table(\n",
    "        lines_chapter(c1), \n",
    "        lines_chapter(c2), \n",
    "        fromdesc=lb1, \n",
    "        todesc=lb2, \n",
    "        context=False, \n",
    "        numlines=5,\n",
    "    )\n",
    "    htext = '''<html>{}<body>{}</body></html>'''.format(diffhead, table_html)\n",
    "    return htext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assess_exp(cf, np, nc, ll):\n",
    "    return 'out' if cf else \\\n",
    "    'rec' if ll > nc * REC_CLIQUE_RATIO / 100 and ll <= nc * DUB_CLIQUE_RATIO / 100 else \\\n",
    "    'dep' if ll > nc * DEP_CLIQUE_RATIO / 100 else \\\n",
    "    'dub' if ll > nc * DUB_CLIQUE_RATIO / 100 else \\\n",
    "    'nor'\n",
    "\n",
    "def printing():\n",
    "    global outputs\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): sorting out cliques'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "    ))\n",
    "    xt_cliques = {xterse_clique(c) for c in cliques}     # chapter cliques as tuples of (b, ch) tuples\n",
    "    bin_cliques = {c for c in xt_cliques if len(c) == 2} # chapter cliques with exactly two chapters\n",
    "    # all chapters that occur in binary chapter cliques\n",
    "    bin_chapters = {c[0] for c in bin_cliques} | {c[1] for c in bin_cliques}\n",
    "    meta['# BINARY CHAPTER DIFFS'] = len(bin_cliques)\n",
    "\n",
    "    # We generate one kind of info for binary chapter cliques (the majority of cases).\n",
    "    # The remaining cases are verse cliques that do not occur in such chapters, e.g. because they\n",
    "    # have member chunks in the same chapter, or in multiple (more than two) chapters.\n",
    "    \n",
    "    ncliques = len(cliques)\n",
    "    chapters_ok = assess_exp(CHUNK_FIXED, len(passages), ncliques, l_c_l) in {'rec', 'nor'}\n",
    "    cdoing = 'involving' if chapters_ok else 'skipping'\n",
    "\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): formatting {} cliques {} {} binary chapter diffs'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        ncliques, cdoing, len(bin_cliques),\n",
    "    ))\n",
    "    meta_html = '\\n'.join('{:<40} : {:>10}'.format(k, str(meta[k])) for k in meta)\n",
    "\n",
    "    base_tpl = '{{}}_{}_{}_{}_M{}_S{}'.format(\n",
    "        CHUNK_LB,\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD,\n",
    "        MATRIX_THRESHOLD,\n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    param_spec = '''\n",
    "<table>\n",
    "<tr><th>chunking method</th><td>{}</td></tr>\n",
    "<tr><th>chunking description</th><td>{}</td></tr>\n",
    "<tr><th>similarity method</th><td>{}</td></tr>\n",
    "<tr><th>similarity threshold</th><td>{}</td></tr>\n",
    "</table>\n",
    "    '''.format(\n",
    "        CHUNK_LABELS[CHUNK_FIXED],\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD, \n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    param_lab = 'chunk-{}-{}-sim-{}-m{}-s{}'.format(\n",
    "        CHUNK_LB,\n",
    "        CHUNK_DESC,\n",
    "        SIMILARITY_METHOD,\n",
    "        MATRIX_THRESHOLD,\n",
    "        SIMILARITY_THRESHOLD, \n",
    "    )\n",
    "    base_name = base_tpl.format('00index')\n",
    "    all_name = base_tpl.format('01all')\n",
    "\n",
    "    clique_links = []\n",
    "    clique_links.append(('{}.html'.format(all_name), 'Big list of all cliques'))\n",
    "\n",
    "    nexist = 0\n",
    "    nnew = 0\n",
    "    if chapters_ok:\n",
    "        msg('PRINT ({} {} {} M>{} S>{}): Chapter diffs needed: {}'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            len(bin_cliques),\n",
    "        ))\n",
    "        bcc_text = '<p>These results look good, so a binary chapter comparison has been generated</p>'\n",
    "        for cl in sorted(bin_cliques):\n",
    "            lb1 = '{} {}'.format(F.book.v(cl[0][0]), F.chapter.v(cl[0][1]))\n",
    "            lb2 = '{} {}'.format(F.book.v(cl[1][0]), F.chapter.v(cl[1][1]))\n",
    "            hfilename = '{}_vs_{}.html'.format(lb1, lb2).replace(' ','_')\n",
    "            hfilepath = '{}/{}/{}'.format(LOCAL_BASE_OUTP, CHAPTER_DIR, hfilename)\n",
    "            if not os.path.exists(hfilepath):\n",
    "                htext = compare_chapters(cl[0][1], cl[1][1], lb1, lb2)\n",
    "                with open(hfilepath, 'w') as f: f.write(htext)\n",
    "                if VERBOSE:\n",
    "                    msg('PRINT ({} {} {} M>{} S>{}): written {}'.format(\n",
    "                        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "                        hfilename,\n",
    "                    ))\n",
    "                nnew += 1\n",
    "            else:\n",
    "                nexist += 1\n",
    "            clique_links.append((\n",
    "                '../{}/{}'.format(CHAPTER_DIR, hfilename), \n",
    "                '{} versus {}'.format(lb1, lb2),\n",
    "            ))\n",
    "        msg('PRINT ({} {} {} M>{} S>{}): Chapter diffs: {} newly created and {} already existing'.format(\n",
    "            CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "            nnew, nexist,\n",
    "        ))\n",
    "    else:\n",
    "        bcc_text = '<p>These results look dubious at best, so no binary chapter comparison has been generated</p>'\n",
    "\n",
    "\n",
    "    allgeni_html = (index_clique(i, c, ncliques) for (i,c) in enumerate(cliques))\n",
    "    allgen_html = ('<h3><a name=\"c_{}\">Clique {}</a></h3>\\n{}'.format(\n",
    "        i, i, print_clique(c, ncliques),\n",
    "    ) for (i,c) in enumerate(cliques))\n",
    "\n",
    "    index_html_tpl = '''\n",
    "    {}\n",
    "    <h1>Binary chapter comparisons</h1>\n",
    "    {}\n",
    "    {}\n",
    "    '''\n",
    "\n",
    "    a_tpl_file = '<p><a target=\"_blank\" href=\"{}\">{}</a></p>'\n",
    "\n",
    "    index_html_file = index_html_tpl.format(\n",
    "        a_tpl_file.format(*clique_links[0]),\n",
    "        bcc_text,\n",
    "        '\\n'.join(a_tpl_file.format(*c) for c in clique_links[1:]),\n",
    "    )\n",
    "\n",
    "    listing_html = '{}\\n{}'.format(\n",
    "        '\\n'.join(allgeni_html),\n",
    "        '\\n'.join(allgen_html),\n",
    "    )\n",
    "\n",
    "    for (fname, content_html, tit) in (\n",
    "        (base_name, index_html_file, 'Index '+param_lab),\n",
    "        (all_name, listing_html, 'Listing '+param_lab),\n",
    "    ):                            \n",
    "        with open('{}/{}/{}.html'.format(LOCAL_BASE_OUTP, EXPERIMENT_DIR, fname), 'w') as f: f.write('''<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
    "<title>{}</title>\n",
    "<style type=\"text/css\">\n",
    "{}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>{}</h1>\n",
    "{}\n",
    "<p><a href=\"#meta\">more parameters and stats</a></p>\n",
    "{}\n",
    "<h1><a name=\"meta\">Parameters and stats</a></h1>\n",
    "<pre>{}</pre>\n",
    "</body>\n",
    "</html>'''.format(\n",
    "            tit,\n",
    "            css,\n",
    "            tit,\n",
    "            param_spec,\n",
    "            content_html,\n",
    "            meta_html,\n",
    "        ))\n",
    "    destination = outputs.setdefault(MATRIX_THRESHOLD, {})\n",
    "    destination[(CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, SIMILARITY_THRESHOLD)] = (\n",
    "        len(passages), len(cliques), l_c_l,\n",
    "    )\n",
    "    msg('PRINT ({} {} {} M>{} S>{}): formatted {} cliques {} {} binary chapter diffs'.format(\n",
    "        CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, MATRIX_THRESHOLD, SIMILARITY_THRESHOLD,\n",
    "        len(cliques), cdoing, len(bin_cliques)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHEBANQ references\n",
    "\n",
    "Based on selected similarity matrices, we produce a SHEBANQ note set of cross references for similar passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_verse(i, ca=False):\n",
    "    chunk = chunks[i]\n",
    "    fword = chunk[0]\n",
    "    book = F.book.v(L.u('book', fword))\n",
    "    chapter = F.chapter.v(L.u('chapter', fword))\n",
    "    verse = F.verse.v(L.u('verse', fword))\n",
    "    if ca: ca = F.number.v(L.u('clause_atom', fword))\n",
    "    return (book, chapter, verse, ca) if ca else (book, chapter, verse)\n",
    "\n",
    "def key_verse(x):\n",
    "    return  (book_rank[x[0]], int(x[1]), int(x[2]))\n",
    "\n",
    "MAX_REFS = 10\n",
    "\n",
    "def condensex(vlabels):\n",
    "    cnd = ''\n",
    "    (cur_b, cur_c) = (None, None)\n",
    "    for (b, c, v, d) in vlabels:\n",
    "        sep = '' if cur_b == None else '. ' if cur_b != b else '; ' if cur_c != c else ', '\n",
    "        show_b = b+' ' if cur_b != b else ''\n",
    "        show_c = c+':' if cur_b != b or cur_c != c else ''\n",
    "        (cur_b, cur_c) = (b, c)\n",
    "        cnd += '{}{}{}{}{}'.format(sep, show_b, show_c, v, d)\n",
    "    return cnd\n",
    "\n",
    "def get_crossrefs():\n",
    "    global crossrefs\n",
    "    msg('CROSSREFS: Fetching crossrefs')\n",
    "    crossrefs_proto = {}\n",
    "    crossrefs = {}\n",
    "    for (chunk_f, chunk_i, sim_m) in SHEBANQ_MATRICES:\n",
    "        sim_thr = SHEBANQ_SIMILARITIES[sim_m]\n",
    "        msg('CROSSREFS ({} {} {} S>{})'.format(CHUNK_LBS[chunk_f], chunk_i, sim_m, sim_thr))\n",
    "        (do_chunk, do_prep, do_sim, do_clique) = do_params(chunk_f, chunk_i, sim_m, sim_thr)\n",
    "        chunking(do_chunk)\n",
    "        preparing(do_prep)\n",
    "        similarity(do_sim)\n",
    "        crossrefs_proto[sim_m] = {x for x in chunk_dist.items() if x[1] >= sim_thr}\n",
    "        msg('CROSSREFS ({} {} {} S>{}): found {} pairs'.format(\n",
    "            CHUNK_LBS[chunk_f], chunk_i, sim_m, sim_thr,\n",
    "            len(crossrefs_proto[sim_m]),\n",
    "        ))\n",
    "    for sim_m in crossrefs_proto:\n",
    "        for ((x,y), d) in crossrefs_proto[sim_m]:\n",
    "            vx = get_verse(x)\n",
    "            vy = get_verse(y)\n",
    "            rd = int(round(d))\n",
    "            crossrefs.setdefault(x, {}).setdefault(vy, {})[sim_m] = rd\n",
    "            crossrefs.setdefault(y, {}).setdefault(vx, {})[sim_m] = rd\n",
    "    total = sum(len(x) for x in crossrefs.values())\n",
    "    msg('CROSSREFS: Found {} crossreferences'.format(total))\n",
    "\n",
    "\n",
    "def compile_refs():\n",
    "    global refs_compiled\n",
    "    refs_grouped = []\n",
    "    for x in crossrefs:\n",
    "        refs = crossrefs[x]\n",
    "        vys = sorted(refs.keys(), key=key_verse)\n",
    "        currefs = []\n",
    "        (curb, curc) = (None, None)\n",
    "        for (thisb, thisc, thisv) in vys:\n",
    "            nr = len(currefs)\n",
    "            if nr == MAX_REFS or (nr > 0 and (thisb != curb or thisc != curc)):\n",
    "                refs_grouped.append((x, tuple(currefs)))\n",
    "                currefs = []            \n",
    "            (curb, curc) = (thisb, thisc)\n",
    "            currefs.append((thisb, thisc, thisv))\n",
    "        if len(currefs):\n",
    "            refs_grouped.append((x, tuple(currefs)))\n",
    "    refs_compiled = []\n",
    "    for (x, vys) in refs_grouped:\n",
    "        vysd = ((vy[0], vy[1], vy[2], '~{}%~{}%'.format(\n",
    "            crossrefs[x][vy].get('SET','x'), \n",
    "            crossrefs[x][vy].get('LCS','x'), \n",
    "        )) for vy in vys)\n",
    "        link_text = condensex(vysd)\n",
    "        link_target = '{} {}'.format(vys[0][0], vys[0][1])\n",
    "        refs_compiled.append((x, '[{}]({})'.format(link_text, link_target)))\n",
    "    msg('CROSSREFS: Compiled crossreferences into {} notes'.format(len(refs_compiled)))\n",
    "\n",
    "sfields = '''\n",
    "    version\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    clause_atom\n",
    "    is_shared\n",
    "    is_published\n",
    "    status\n",
    "    keywords\n",
    "    ntext\n",
    "'''.strip().split()\n",
    "\n",
    "sfields_fmt = ('{}\\t' * (len(sfields) - 1)) + '{}\\n' \n",
    "\n",
    "def generate_notes():\n",
    "    with open(NOTES_PATH, 'w') as f:\n",
    "        f.write('{}\\n'.format('\\t'.join(sfields)))\n",
    "        for (x, refs) in refs_compiled:\n",
    "            (bk, ch, vs, ca) = get_verse(x, ca=True)\n",
    "            f.write(sfields_fmt.format(\n",
    "                version,\n",
    "                bk,\n",
    "                ch,\n",
    "                vs,\n",
    "                ca,\n",
    "                'T',\n",
    "                '',\n",
    "                CROSSREF_STATUS,\n",
    "                CROSSREF_KEYWORD,\n",
    "                refs,\n",
    "            ))\n",
    "    msg('CROSSREFS: Generated {} notes'.format(len(refs_compiled)))\n",
    "\n",
    "def crossrefs2shebanq():\n",
    "    get_crossrefs()\n",
    "    compile_refs()\n",
    "    generate_notes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALUE_LABELS = dict(\n",
    "    mis='no results available',\n",
    "    rec='promising results: recommended',\n",
    "    dep='messy results: deprecated',\n",
    "    dub='mixed quality: take care',\n",
    "    out='method deprecated',\n",
    "    nor='unassessed quality: inspection needed',\n",
    "    lr='this experiment is the last one run',\n",
    ")\n",
    "\n",
    "def writeoutputs():\n",
    "    global outputs\n",
    "    with open(EXPERIMENT_PATH, 'wb') as f:\n",
    "        pickle.dump(outputs, f, protocol=PICKLE_PROTOCOL)\n",
    "\n",
    "def readoutputs():\n",
    "    global outputs\n",
    "    if not os.path.exists(EXPERIMENT_PATH):\n",
    "        outputs = {}\n",
    "    else:\n",
    "        with open(EXPERIMENT_PATH, 'rb') as f:\n",
    "            outputs = pickle.load(f)\n",
    "\n",
    "ecss = '''\n",
    "<style type=\"text/css\">\n",
    ".mis {background-color: #cccccc;}\n",
    ".rec {background-color: #aaffaa;}\n",
    ".dep {background-color: #ffaaaa;}\n",
    ".dub {background-color: #ffddaa;}\n",
    ".out {background-color: #ffddff;}\n",
    ".nor {background-color: #fcfcff;}\n",
    ".ps  {font-weight: normal;}\n",
    ".mx  {font-style: italic;}\n",
    ".cl  {font-weight: bold;}\n",
    ".lr  {font-weight: bold; background-color: #ffffaa;}\n",
    "p,td {font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: small;}\n",
    "td   {border: 1pt solid #000000; padding: 4pt;}\n",
    "table {border: 1pt solid #000000; border-collapse: collapse;}\n",
    "</style>\n",
    "'''\n",
    "\n",
    "legend = '''\n",
    "<table>\n",
    "<tr><td class=\"mis\">{mis}</td></tr>\n",
    "<tr><td class=\"rec\">{rec}</td></tr>\n",
    "<tr><td class=\"dep\">{dep}</td></tr>\n",
    "<tr><td class=\"dub\">{dub}</td></tr>\n",
    "<tr><td class=\"out\">{out}</td></tr>\n",
    "<tr><td class=\"nor\">{nor}</td></tr>\n",
    "</table>\n",
    "'''.format(**VALUE_LABELS)\n",
    "\n",
    "def gen_html(standalone=False):\n",
    "    global other_exps\n",
    "    msg('EXPERIMENT: Generating html report{}'.format('(standalone)' if standalone else ''))\n",
    "    stats = collections.Counter()\n",
    "    pre = '''\n",
    "<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
    "{}\n",
    "</head>\n",
    "<body>\n",
    "'''.format(ecss) if standalone else ''\n",
    "    \n",
    "    post = '''\n",
    "</body></html>\n",
    "''' if standalone else ''\n",
    "\n",
    "    experiments = '''\n",
    "{}\n",
    "{}\n",
    "<table>\n",
    "<tr><th>chunk type</th><th>chunk size</th><th>similarity method</th>{}</tr>\n",
    "'''.format(pre, legend, ''.join('<th>{}</th>'.format(sim_thr) for sim_thr in SIMILARITIES))\n",
    "    \n",
    "    for chunk_f in (True, False):\n",
    "        if chunk_f:\n",
    "            chunk_items = CHUNK_SIZES\n",
    "        else:\n",
    "            chunk_items = CHUNK_OBJECTS\n",
    "        chunk_lb = CHUNK_LBS[chunk_f]\n",
    "        for chunk_i in chunk_items:\n",
    "            for sim_m in SIM_METHODS:\n",
    "                set_matrix_threshold(sim_m=sim_m)\n",
    "                these_outputs = outputs.get(MATRIX_THRESHOLD, {})\n",
    "                experiments += '<tr><td>{}</td><td>{}</td><td>{}</td>'.format(\n",
    "                    CHUNK_LABELS[chunk_f], chunk_i, sim_m,\n",
    "                )\n",
    "                for sim_thr in SIMILARITIES:\n",
    "                    okey = (chunk_lb, chunk_i, sim_m, sim_thr)\n",
    "                    values = these_outputs.get(okey)\n",
    "                    if values == None:\n",
    "                        result = '<td class=\"mis\">&nbsp;</td>'\n",
    "                        stats['mis'] += 1\n",
    "                    else:\n",
    "                        (npassages, ncliques, longest_clique_len) = values\n",
    "                        cls = assess_exp(chunk_f, npassages, ncliques, longest_clique_len)\n",
    "                        stats[cls] += 1\n",
    "                        (lr_el, lr_lb) = ('', '')\n",
    "                        if (CHUNK_LB, CHUNK_DESC, SIMILARITY_METHOD, SIMILARITY_THRESHOLD) == (\n",
    "                            chunk_lb, chunk_i, sim_m, sim_thr,\n",
    "                        ):\n",
    "                            lr_el = '<span class=\"lr\">*</span>'\n",
    "                            lr_lb = VALUE_LABELS['lr']\n",
    "                        result = '''\n",
    "<td class=\"{}\" title=\"{}\">{}\n",
    "    <span class=\"ps\">{}</span><br/>\n",
    "    <a target=\"_blank\" href=\"{}{}/00index_{}_{}_{}_M{}_S{}.html\"><span class=\"cl\">{}</span></a><br/>\n",
    "    <span class=\"mx\">{}</span>\n",
    "    </td>'''.format(\n",
    "        cls, lr_lb, lr_el, npassages,\n",
    "        '' if standalone else LOCAL_BASE_OUTP+'/', \n",
    "        EXPERIMENT_DIR, chunk_lb, chunk_i, sim_m, MATRIX_THRESHOLD, sim_thr,\n",
    "        ncliques, longest_clique_len,\n",
    "    )\n",
    "                    experiments += result\n",
    "                experiments += '</tr>\\n'\n",
    "    experiments += '</table>\\n{}'.format(post)\n",
    "    if standalone:\n",
    "        with open(EXPERIMENT_HTML, 'w') as f:\n",
    "            f.write(experiments)\n",
    "    else:\n",
    "        other_exps = experiments\n",
    "\n",
    "    for stat in sorted(stats):\n",
    "        msg('EXPERIMENT: {:>3} {}'.format(stats[stat], VALUE_LABELS[stat]))\n",
    "    msg(\"EXPERIMENT: Generated html report\")\n",
    "\n",
    "def do_experiment(chunk_f, chunk_i, sim_m, sim_thr, do_index):\n",
    "    if do_index:\n",
    "        readoutputs()\n",
    "    (do_chunk, do_prep, do_sim, do_clique) = do_params(chunk_f, chunk_i, sim_m, sim_thr)\n",
    "    chunking(do_chunk)\n",
    "    preparing(do_prep)\n",
    "    similarity(do_sim)\n",
    "    cliqueing(do_clique)\n",
    "    printing()\n",
    "    if do_index:\n",
    "        writeoutputs()\n",
    "        gen_html()\n",
    "    \n",
    "def reset_experiments():\n",
    "    global outputs\n",
    "    readoutputs()\n",
    "    outputs = {}\n",
    "    reset_params()\n",
    "    writeoutputs()\n",
    "    gen_html()\n",
    "\n",
    "def do_all_experiments():\n",
    "    global outputs\n",
    "    reset_experiments()\n",
    "    for chunk_f in (True, False):\n",
    "        if chunk_f:\n",
    "            chunk_items = CHUNK_SIZES\n",
    "        else:\n",
    "            chunk_items = CHUNK_OBJECTS\n",
    "        for chunk_i in chunk_items:\n",
    "            for sim_m in SIM_METHODS:\n",
    "                for sim_thr in SIMILARITIES:\n",
    "                    do_experiment(chunk_f, chunk_i, sim_m, sim_thr, False)\n",
    "    writeoutputs()\n",
    "    gen_html()\n",
    "    gen_html(standalone=True)\n",
    "    \n",
    "def show_all_experiments():\n",
    "    readoutputs()\n",
    "    gen_html()\n",
    "    gen_html(standalone=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 4m 49s EXPERIMENT: Generating html report\n",
      " 4m 49s EXPERIMENT: 126 no results available\n",
      " 4m 49s EXPERIMENT: Generated html report\n",
      " 4m 49s CHUNKING (F 100)\n",
      " 4m 51s CHUNKING (F 100): Made 4244 chunks\n",
      " 4m 51s PREPARING (F 100 SET)\n",
      " 4m 52s PREPARING (F 100 SET): Done 4244 chunks.\n",
      " 4m 52s SIMILARITY (F 100 SET M>50): Loaded:  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 52s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>100): fetching similars and chunk candidates\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>100): inspecting the similarity matrix\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>100): 1 relevant similarities between 2 passages\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>100): Loaded:     1 cliques out of      2 chunks from 1 comparisons\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>100): 2 members in 1 cliques\n",
      " 4m 52s PRINT (F 100 SET M>50 S>100): sorting out cliques\n",
      " 4m 52s PRINT (F 100 SET M>50 S>100): formatting 1 cliques skipping 1 binary chapter diffs\n",
      " 4m 52s PRINT (F 100 SET M>50 S>100): formatted 1 cliques skipping 1 binary chapter diffs\n",
      " 4m 52s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 52s PREPARING (F 100 SET): Already prepared\n",
      " 4m 52s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 52s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>95): fetching similars and chunk candidates\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>95): inspecting the similarity matrix\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>95): 2 relevant similarities between 4 passages\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>95): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>95): 4 members in 2 cliques\n",
      " 4m 52s PRINT (F 100 SET M>50 S>95): sorting out cliques\n",
      " 4m 52s PRINT (F 100 SET M>50 S>95): formatting 2 cliques skipping 2 binary chapter diffs\n",
      " 4m 52s PRINT (F 100 SET M>50 S>95): formatted 2 cliques skipping 2 binary chapter diffs\n",
      " 4m 52s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 52s PREPARING (F 100 SET): Already prepared\n",
      " 4m 52s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 52s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>90): fetching similars and chunk candidates\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>90): inspecting the similarity matrix\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>90): 9 relevant similarities between 18 passages\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>90): Loaded:     9 cliques out of     18 chunks from 9 comparisons\n",
      " 4m 52s CLIQUES (F 100 SET M>50 S>90): 18 members in 9 cliques\n",
      " 4m 52s PRINT (F 100 SET M>50 S>90): sorting out cliques\n",
      " 4m 52s PRINT (F 100 SET M>50 S>90): formatting 9 cliques skipping 3 binary chapter diffs\n",
      " 4m 53s PRINT (F 100 SET M>50 S>90): formatted 9 cliques skipping 3 binary chapter diffs\n",
      " 4m 53s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 53s PREPARING (F 100 SET): Already prepared\n",
      " 4m 53s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 53s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>85): fetching similars and chunk candidates\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>85): inspecting the similarity matrix\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>85): 19 relevant similarities between 37 passages\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>85): Loaded:    18 cliques out of     37 chunks from 19 comparisons\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>85): 37 members in 18 cliques\n",
      " 4m 53s PRINT (F 100 SET M>50 S>85): sorting out cliques\n",
      " 4m 53s PRINT (F 100 SET M>50 S>85): formatting 18 cliques skipping 6 binary chapter diffs\n",
      " 4m 53s PRINT (F 100 SET M>50 S>85): formatted 18 cliques skipping 6 binary chapter diffs\n",
      " 4m 53s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 53s PREPARING (F 100 SET): Already prepared\n",
      " 4m 53s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 53s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>80): fetching similars and chunk candidates\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>80): inspecting the similarity matrix\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>80): 35 relevant similarities between 64 passages\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>80): Loaded:    30 cliques out of     64 chunks from 35 comparisons\n",
      " 4m 53s CLIQUES (F 100 SET M>50 S>80): 64 members in 30 cliques\n",
      " 4m 53s PRINT (F 100 SET M>50 S>80): sorting out cliques\n",
      " 4m 53s PRINT (F 100 SET M>50 S>80): formatting 30 cliques skipping 10 binary chapter diffs\n",
      " 4m 54s PRINT (F 100 SET M>50 S>80): formatted 30 cliques skipping 10 binary chapter diffs\n",
      " 4m 54s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 54s PREPARING (F 100 SET): Already prepared\n",
      " 4m 54s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 54s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 54s CLIQUES (F 100 SET M>50 S>75): fetching similars and chunk candidates\n",
      " 4m 54s CLIQUES (F 100 SET M>50 S>75): inspecting the similarity matrix\n",
      " 4m 54s CLIQUES (F 100 SET M>50 S>75): 64 relevant similarities between 88 passages\n",
      " 4m 54s CLIQUES (F 100 SET M>50 S>75): Loaded:    40 cliques out of     88 chunks from 64 comparisons\n",
      " 4m 54s CLIQUES (F 100 SET M>50 S>75): 88 members in 40 cliques\n",
      " 4m 54s PRINT (F 100 SET M>50 S>75): sorting out cliques\n",
      " 4m 54s PRINT (F 100 SET M>50 S>75): formatting 40 cliques skipping 16 binary chapter diffs\n",
      " 4m 55s PRINT (F 100 SET M>50 S>75): formatted 40 cliques skipping 16 binary chapter diffs\n",
      " 4m 55s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 55s PREPARING (F 100 SET): Already prepared\n",
      " 4m 55s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 55s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 55s CLIQUES (F 100 SET M>50 S>70): fetching similars and chunk candidates\n",
      " 4m 55s CLIQUES (F 100 SET M>50 S>70): inspecting the similarity matrix\n",
      " 4m 55s CLIQUES (F 100 SET M>50 S>70): 88 relevant similarities between 113 passages\n",
      " 4m 55s CLIQUES (F 100 SET M>50 S>70): Loaded:    52 cliques out of    113 chunks from 88 comparisons\n",
      " 4m 55s CLIQUES (F 100 SET M>50 S>70): 113 members in 52 cliques\n",
      " 4m 55s PRINT (F 100 SET M>50 S>70): sorting out cliques\n",
      " 4m 55s PRINT (F 100 SET M>50 S>70): formatting 52 cliques skipping 21 binary chapter diffs\n",
      " 4m 56s PRINT (F 100 SET M>50 S>70): formatted 52 cliques skipping 21 binary chapter diffs\n",
      " 4m 56s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 56s PREPARING (F 100 SET): Already prepared\n",
      " 4m 56s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 56s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 56s CLIQUES (F 100 SET M>50 S>65): fetching similars and chunk candidates\n",
      " 4m 56s CLIQUES (F 100 SET M>50 S>65): inspecting the similarity matrix\n",
      " 4m 56s CLIQUES (F 100 SET M>50 S>65): 116 relevant similarities between 156 passages\n",
      " 4m 56s CLIQUES (F 100 SET M>50 S>65): Loaded:    71 cliques out of    156 chunks from 116 comparisons\n",
      " 4m 56s CLIQUES (F 100 SET M>50 S>65): 156 members in 71 cliques\n",
      " 4m 56s PRINT (F 100 SET M>50 S>65): sorting out cliques\n",
      " 4m 56s PRINT (F 100 SET M>50 S>65): formatting 71 cliques skipping 29 binary chapter diffs\n",
      " 4m 58s PRINT (F 100 SET M>50 S>65): formatted 71 cliques skipping 29 binary chapter diffs\n",
      " 4m 58s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 4m 58s PREPARING (F 100 SET): Already prepared\n",
      " 4m 58s SIMILARITY (F 100 SET M>50): Using  9003 K (9003646) comparisons with 360 entries in matrix\n",
      " 4m 58s SIMILARITY (F 100 SET M>50): similarities between 50.0 and 100.0. 1 are 100%\n",
      " 4m 58s CLIQUES (F 100 SET M>50 S>60): fetching similars and chunk candidates\n",
      " 4m 58s CLIQUES (F 100 SET M>50 S>60): inspecting the similarity matrix\n",
      " 4m 58s CLIQUES (F 100 SET M>50 S>60): 148 relevant similarities between 206 passages\n",
      " 4m 58s CLIQUES (F 100 SET M>50 S>60): Loaded:    93 cliques out of    206 chunks from 148 comparisons\n",
      " 4m 58s CLIQUES (F 100 SET M>50 S>60): 206 members in 93 cliques\n",
      " 4m 58s PRINT (F 100 SET M>50 S>60): sorting out cliques\n",
      " 4m 58s PRINT (F 100 SET M>50 S>60): formatting 93 cliques skipping 35 binary chapter diffs\n",
      " 5m 01s PRINT (F 100 SET M>50 S>60): formatted 93 cliques skipping 35 binary chapter diffs\n",
      " 5m 01s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 01s PREPARING (F 100 LCS)\n",
      " 5m 02s PREPARING (F 100 LCS): Done 4244 chunks.\n",
      " 5m 02s SIMILARITY (F 100 LCS M>60): Loaded:  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 02s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>100): inspecting the similarity matrix\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>100): 0 relevant similarities between 0 passages\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>100): 0 members in 0 cliques\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>100): sorting out cliques\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>100): formatting 0 cliques skipping 0 binary chapter diffs\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>100): formatted 0 cliques skipping 0 binary chapter diffs\n",
      " 5m 02s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 02s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 02s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 02s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>95): inspecting the similarity matrix\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>95): 2 relevant similarities between 4 passages\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>95): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>95): 4 members in 2 cliques\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>95): sorting out cliques\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>95): formatting 2 cliques skipping 2 binary chapter diffs\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>95): formatted 2 cliques skipping 2 binary chapter diffs\n",
      " 5m 02s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 02s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 02s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 02s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>90): inspecting the similarity matrix\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>90): 21 relevant similarities between 39 passages\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>90): Loaded:    19 cliques out of     39 chunks from 21 comparisons\n",
      " 5m 02s CLIQUES (F 100 LCS M>60 S>90): 39 members in 19 cliques\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>90): sorting out cliques\n",
      " 5m 02s PRINT (F 100 LCS M>60 S>90): formatting 19 cliques skipping 4 binary chapter diffs\n",
      " 5m 03s PRINT (F 100 LCS M>60 S>90): formatted 19 cliques skipping 4 binary chapter diffs\n",
      " 5m 03s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 03s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 03s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 03s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 03s CLIQUES (F 100 LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 5m 03s CLIQUES (F 100 LCS M>60 S>85): inspecting the similarity matrix\n",
      " 5m 03s CLIQUES (F 100 LCS M>60 S>85): 31 relevant similarities between 59 passages\n",
      " 5m 03s CLIQUES (F 100 LCS M>60 S>85): Loaded:    29 cliques out of     59 chunks from 31 comparisons\n",
      " 5m 03s CLIQUES (F 100 LCS M>60 S>85): 59 members in 29 cliques\n",
      " 5m 03s PRINT (F 100 LCS M>60 S>85): sorting out cliques\n",
      " 5m 03s PRINT (F 100 LCS M>60 S>85): formatting 29 cliques skipping 10 binary chapter diffs\n",
      " 5m 04s PRINT (F 100 LCS M>60 S>85): formatted 29 cliques skipping 10 binary chapter diffs\n",
      " 5m 04s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 04s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 04s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 04s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 04s CLIQUES (F 100 LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 5m 04s CLIQUES (F 100 LCS M>60 S>80): inspecting the similarity matrix\n",
      " 5m 04s CLIQUES (F 100 LCS M>60 S>80): 46 relevant similarities between 85 passages\n",
      " 5m 04s CLIQUES (F 100 LCS M>60 S>80): Loaded:    41 cliques out of     85 chunks from 46 comparisons\n",
      " 5m 04s CLIQUES (F 100 LCS M>60 S>80): 85 members in 41 cliques\n",
      " 5m 04s PRINT (F 100 LCS M>60 S>80): sorting out cliques\n",
      " 5m 04s PRINT (F 100 LCS M>60 S>80): formatting 41 cliques skipping 16 binary chapter diffs\n",
      " 5m 05s PRINT (F 100 LCS M>60 S>80): formatted 41 cliques skipping 16 binary chapter diffs\n",
      " 5m 05s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 05s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 05s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 05s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 05s CLIQUES (F 100 LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 5m 05s CLIQUES (F 100 LCS M>60 S>75): inspecting the similarity matrix\n",
      " 5m 05s CLIQUES (F 100 LCS M>60 S>75): 77 relevant similarities between 122 passages\n",
      " 5m 05s CLIQUES (F 100 LCS M>60 S>75): Loaded:    56 cliques out of    122 chunks from 77 comparisons\n",
      " 5m 05s CLIQUES (F 100 LCS M>60 S>75): 122 members in 56 cliques\n",
      " 5m 05s PRINT (F 100 LCS M>60 S>75): sorting out cliques\n",
      " 5m 05s PRINT (F 100 LCS M>60 S>75): formatting 56 cliques skipping 25 binary chapter diffs\n",
      " 5m 07s PRINT (F 100 LCS M>60 S>75): formatted 56 cliques skipping 25 binary chapter diffs\n",
      " 5m 07s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 07s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 07s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 07s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 07s CLIQUES (F 100 LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 5m 07s CLIQUES (F 100 LCS M>60 S>70): inspecting the similarity matrix\n",
      " 5m 07s CLIQUES (F 100 LCS M>60 S>70): 123 relevant similarities between 189 passages\n",
      " 5m 07s CLIQUES (F 100 LCS M>60 S>70): Loaded:    88 cliques out of    189 chunks from 123 comparisons\n",
      " 5m 07s CLIQUES (F 100 LCS M>60 S>70): 189 members in 88 cliques\n",
      " 5m 07s PRINT (F 100 LCS M>60 S>70): sorting out cliques\n",
      " 5m 07s PRINT (F 100 LCS M>60 S>70): formatting 88 cliques skipping 38 binary chapter diffs\n",
      " 5m 10s PRINT (F 100 LCS M>60 S>70): formatted 88 cliques skipping 38 binary chapter diffs\n",
      " 5m 10s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 10s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 10s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 10s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 10s CLIQUES (F 100 LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 5m 10s CLIQUES (F 100 LCS M>60 S>65): inspecting the similarity matrix\n",
      " 5m 10s CLIQUES (F 100 LCS M>60 S>65): 182 relevant similarities between 287 passages\n",
      " 5m 10s CLIQUES (F 100 LCS M>60 S>65): Loaded:   132 cliques out of    287 chunks from 182 comparisons\n",
      " 5m 10s CLIQUES (F 100 LCS M>60 S>65): 287 members in 132 cliques\n",
      " 5m 10s PRINT (F 100 LCS M>60 S>65): sorting out cliques\n",
      " 5m 10s PRINT (F 100 LCS M>60 S>65): formatting 132 cliques skipping 55 binary chapter diffs\n",
      " 5m 14s PRINT (F 100 LCS M>60 S>65): formatted 132 cliques skipping 55 binary chapter diffs\n",
      " 5m 14s CHUNKING (F 100): already chunked into 4244 chunks\n",
      " 5m 14s PREPARING (F 100 LCS): Already prepared\n",
      " 5m 14s SIMILARITY (F 100 LCS M>60): Using  9003 K (9003646) comparisons with 393 entries in matrix\n",
      " 5m 14s SIMILARITY (F 100 LCS M>60): similarities between 60.0 and 97.6923076923077. 0 are 100%\n",
      " 5m 14s CLIQUES (F 100 LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 5m 14s CLIQUES (F 100 LCS M>60 S>60): inspecting the similarity matrix\n",
      " 5m 14s CLIQUES (F 100 LCS M>60 S>60): 393 relevant similarities between 535 passages\n",
      " 5m 14s CLIQUES (F 100 LCS M>60 S>60): Loaded:   214 cliques out of    535 chunks from 393 comparisons\n",
      " 5m 14s CLIQUES (F 100 LCS M>60 S>60): 535 members in 214 cliques\n",
      " 5m 14s PRINT (F 100 LCS M>60 S>60): sorting out cliques\n",
      " 5m 14s PRINT (F 100 LCS M>60 S>60): formatting 214 cliques skipping 100 binary chapter diffs\n",
      " 5m 23s PRINT (F 100 LCS M>60 S>60): formatted 214 cliques skipping 100 binary chapter diffs\n",
      " 5m 23s CHUNKING (F 50)\n",
      " 5m 25s CHUNKING (F 50): Made 8509 chunks\n",
      " 5m 25s PREPARING (F 50 SET)\n",
      " 5m 27s PREPARING (F 50 SET): Done 8509 chunks.\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): Loaded: 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>100): fetching similars and chunk candidates\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>100): inspecting the similarity matrix\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>100): 0 relevant similarities between 0 passages\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>100): 0 members in 0 cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>100): sorting out cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>100): formatting 0 cliques skipping 0 binary chapter diffs\n",
      " 5m 27s PRINT (F 50 SET M>50 S>100): formatted 0 cliques skipping 0 binary chapter diffs\n",
      " 5m 27s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 27s PREPARING (F 50 SET): Already prepared\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>95): fetching similars and chunk candidates\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>95): inspecting the similarity matrix\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>95): 2 relevant similarities between 4 passages\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>95): Loaded:     2 cliques out of      4 chunks from 2 comparisons\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>95): 4 members in 2 cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>95): sorting out cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>95): formatting 2 cliques skipping 2 binary chapter diffs\n",
      " 5m 27s PRINT (F 50 SET M>50 S>95): formatted 2 cliques skipping 2 binary chapter diffs\n",
      " 5m 27s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 27s PREPARING (F 50 SET): Already prepared\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>90): fetching similars and chunk candidates\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>90): inspecting the similarity matrix\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>90): 12 relevant similarities between 24 passages\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>90): Loaded:    12 cliques out of     24 chunks from 12 comparisons\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>90): 24 members in 12 cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>90): sorting out cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>90): formatting 12 cliques skipping 4 binary chapter diffs\n",
      " 5m 27s PRINT (F 50 SET M>50 S>90): formatted 12 cliques skipping 4 binary chapter diffs\n",
      " 5m 27s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 27s PREPARING (F 50 SET): Already prepared\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>85): fetching similars and chunk candidates\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>85): inspecting the similarity matrix\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>85): 35 relevant similarities between 57 passages\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>85): Loaded:    26 cliques out of     57 chunks from 35 comparisons\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>85): 57 members in 26 cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>85): sorting out cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>85): formatting 26 cliques skipping 9 binary chapter diffs\n",
      " 5m 27s PRINT (F 50 SET M>50 S>85): formatted 26 cliques skipping 9 binary chapter diffs\n",
      " 5m 27s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 27s PREPARING (F 50 SET): Already prepared\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>80): fetching similars and chunk candidates\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>80): inspecting the similarity matrix\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>80): 69 relevant similarities between 114 passages\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>80): Loaded:    52 cliques out of    114 chunks from 69 comparisons\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>80): 114 members in 52 cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>80): sorting out cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>80): formatting 52 cliques skipping 19 binary chapter diffs\n",
      " 5m 27s PRINT (F 50 SET M>50 S>80): formatted 52 cliques skipping 19 binary chapter diffs\n",
      " 5m 27s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 27s PREPARING (F 50 SET): Already prepared\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 27s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>75): fetching similars and chunk candidates\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>75): inspecting the similarity matrix\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>75): 116 relevant similarities between 188 passages\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>75): Loaded:    86 cliques out of    188 chunks from 116 comparisons\n",
      " 5m 27s CLIQUES (F 50 SET M>50 S>75): 188 members in 86 cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>75): sorting out cliques\n",
      " 5m 27s PRINT (F 50 SET M>50 S>75): formatting 86 cliques skipping 32 binary chapter diffs\n",
      " 5m 28s PRINT (F 50 SET M>50 S>75): formatted 86 cliques skipping 32 binary chapter diffs\n",
      " 5m 28s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 28s PREPARING (F 50 SET): Already prepared\n",
      " 5m 28s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 28s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 28s CLIQUES (F 50 SET M>50 S>70): fetching similars and chunk candidates\n",
      " 5m 28s CLIQUES (F 50 SET M>50 S>70): inspecting the similarity matrix\n",
      " 5m 28s CLIQUES (F 50 SET M>50 S>70): 172 relevant similarities between 273 passages\n",
      " 5m 28s CLIQUES (F 50 SET M>50 S>70): Loaded:   125 cliques out of    273 chunks from 172 comparisons\n",
      " 5m 28s CLIQUES (F 50 SET M>50 S>70): 273 members in 125 cliques\n",
      " 5m 28s PRINT (F 50 SET M>50 S>70): sorting out cliques\n",
      " 5m 28s PRINT (F 50 SET M>50 S>70): formatting 125 cliques skipping 48 binary chapter diffs\n",
      " 5m 29s PRINT (F 50 SET M>50 S>70): formatted 125 cliques skipping 48 binary chapter diffs\n",
      " 5m 29s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 29s PREPARING (F 50 SET): Already prepared\n",
      " 5m 29s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 29s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 29s CLIQUES (F 50 SET M>50 S>65): fetching similars and chunk candidates\n",
      " 5m 29s CLIQUES (F 50 SET M>50 S>65): inspecting the similarity matrix\n",
      " 5m 29s CLIQUES (F 50 SET M>50 S>65): 248 relevant similarities between 385 passages\n",
      " 5m 29s CLIQUES (F 50 SET M>50 S>65): Loaded:   176 cliques out of    385 chunks from 248 comparisons\n",
      " 5m 29s CLIQUES (F 50 SET M>50 S>65): 385 members in 176 cliques\n",
      " 5m 29s PRINT (F 50 SET M>50 S>65): sorting out cliques\n",
      " 5m 29s PRINT (F 50 SET M>50 S>65): formatting 176 cliques skipping 61 binary chapter diffs\n",
      " 5m 31s PRINT (F 50 SET M>50 S>65): formatted 176 cliques skipping 61 binary chapter diffs\n",
      " 5m 31s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 31s PREPARING (F 50 SET): Already prepared\n",
      " 5m 31s SIMILARITY (F 50 SET M>50): Using 36197 K (36197286) comparisons with 928 entries in matrix\n",
      " 5m 31s SIMILARITY (F 50 SET M>50): similarities between 50.0 and 96.96969696969697. 0 are 100%\n",
      " 5m 31s CLIQUES (F 50 SET M>50 S>60): fetching similars and chunk candidates\n",
      " 5m 31s CLIQUES (F 50 SET M>50 S>60): inspecting the similarity matrix\n",
      " 5m 31s CLIQUES (F 50 SET M>50 S>60): 368 relevant similarities between 538 passages\n",
      " 5m 31s CLIQUES (F 50 SET M>50 S>60): Loaded:   236 cliques out of    538 chunks from 368 comparisons\n",
      " 5m 31s CLIQUES (F 50 SET M>50 S>60): 538 members in 236 cliques\n",
      " 5m 31s PRINT (F 50 SET M>50 S>60): sorting out cliques\n",
      " 5m 31s PRINT (F 50 SET M>50 S>60): formatting 236 cliques skipping 79 binary chapter diffs\n",
      " 5m 33s PRINT (F 50 SET M>50 S>60): formatted 236 cliques skipping 79 binary chapter diffs\n",
      " 5m 33s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 33s PREPARING (F 50 LCS)\n",
      " 5m 34s PREPARING (F 50 LCS): Done 8509 chunks.\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): Loaded: 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>100): inspecting the similarity matrix\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>100): 0 relevant similarities between 0 passages\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>100): Loaded:     0 cliques out of      0 chunks from 0 comparisons\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>100): 0 members in 0 cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>100): sorting out cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>100): formatting 0 cliques skipping 0 binary chapter diffs\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>100): formatted 0 cliques skipping 0 binary chapter diffs\n",
      " 5m 34s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 34s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>95): inspecting the similarity matrix\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>95): 6 relevant similarities between 12 passages\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>95): Loaded:     6 cliques out of     12 chunks from 6 comparisons\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>95): 12 members in 6 cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>95): sorting out cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>95): formatting 6 cliques skipping 3 binary chapter diffs\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>95): formatted 6 cliques skipping 3 binary chapter diffs\n",
      " 5m 34s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 34s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>90): inspecting the similarity matrix\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>90): 28 relevant similarities between 53 passages\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>90): Loaded:    25 cliques out of     53 chunks from 28 comparisons\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>90): 53 members in 25 cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>90): sorting out cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>90): formatting 25 cliques skipping 9 binary chapter diffs\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>90): formatted 25 cliques skipping 9 binary chapter diffs\n",
      " 5m 34s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 34s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 34s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>85): inspecting the similarity matrix\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>85): 75 relevant similarities between 119 passages\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>85): Loaded:    53 cliques out of    119 chunks from 75 comparisons\n",
      " 5m 34s CLIQUES (F 50 LCS M>60 S>85): 119 members in 53 cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>85): sorting out cliques\n",
      " 5m 34s PRINT (F 50 LCS M>60 S>85): formatting 53 cliques skipping 17 binary chapter diffs\n",
      " 5m 35s PRINT (F 50 LCS M>60 S>85): formatted 53 cliques skipping 17 binary chapter diffs\n",
      " 5m 35s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 35s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 35s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 35s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 35s CLIQUES (F 50 LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 5m 35s CLIQUES (F 50 LCS M>60 S>80): inspecting the similarity matrix\n",
      " 5m 35s CLIQUES (F 50 LCS M>60 S>80): 122 relevant similarities between 196 passages\n",
      " 5m 35s CLIQUES (F 50 LCS M>60 S>80): Loaded:    89 cliques out of    196 chunks from 122 comparisons\n",
      " 5m 35s CLIQUES (F 50 LCS M>60 S>80): 196 members in 89 cliques\n",
      " 5m 35s PRINT (F 50 LCS M>60 S>80): sorting out cliques\n",
      " 5m 35s PRINT (F 50 LCS M>60 S>80): formatting 89 cliques skipping 33 binary chapter diffs\n",
      " 5m 36s PRINT (F 50 LCS M>60 S>80): formatted 89 cliques skipping 33 binary chapter diffs\n",
      " 5m 36s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 36s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 36s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 36s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 36s CLIQUES (F 50 LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 5m 36s CLIQUES (F 50 LCS M>60 S>75): inspecting the similarity matrix\n",
      " 5m 36s CLIQUES (F 50 LCS M>60 S>75): 197 relevant similarities between 301 passages\n",
      " 5m 36s CLIQUES (F 50 LCS M>60 S>75): Loaded:   135 cliques out of    301 chunks from 197 comparisons\n",
      " 5m 36s CLIQUES (F 50 LCS M>60 S>75): 301 members in 135 cliques\n",
      " 5m 36s PRINT (F 50 LCS M>60 S>75): sorting out cliques\n",
      " 5m 36s PRINT (F 50 LCS M>60 S>75): formatting 135 cliques skipping 50 binary chapter diffs\n",
      " 5m 37s PRINT (F 50 LCS M>60 S>75): formatted 135 cliques skipping 50 binary chapter diffs\n",
      " 5m 37s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 37s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 37s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 37s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 37s CLIQUES (F 50 LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 5m 37s CLIQUES (F 50 LCS M>60 S>70): inspecting the similarity matrix\n",
      " 5m 37s CLIQUES (F 50 LCS M>60 S>70): 314 relevant similarities between 467 passages\n",
      " 5m 37s CLIQUES (F 50 LCS M>60 S>70): Loaded:   206 cliques out of    467 chunks from 314 comparisons\n",
      " 5m 37s CLIQUES (F 50 LCS M>60 S>70): 467 members in 206 cliques\n",
      " 5m 37s PRINT (F 50 LCS M>60 S>70): sorting out cliques\n",
      " 5m 37s PRINT (F 50 LCS M>60 S>70): formatting 206 cliques skipping 66 binary chapter diffs\n",
      " 5m 39s PRINT (F 50 LCS M>60 S>70): formatted 206 cliques skipping 66 binary chapter diffs\n",
      " 5m 39s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 39s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 39s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 39s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 39s CLIQUES (F 50 LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 5m 39s CLIQUES (F 50 LCS M>60 S>65): inspecting the similarity matrix\n",
      " 5m 39s CLIQUES (F 50 LCS M>60 S>65): 579 relevant similarities between 761 passages\n",
      " 5m 39s CLIQUES (F 50 LCS M>60 S>65): Loaded:   312 cliques out of    761 chunks from 579 comparisons\n",
      " 5m 39s CLIQUES (F 50 LCS M>60 S>65): 761 members in 312 cliques\n",
      " 5m 39s PRINT (F 50 LCS M>60 S>65): sorting out cliques\n",
      " 5m 39s PRINT (F 50 LCS M>60 S>65): formatting 312 cliques skipping 107 binary chapter diffs\n",
      " 5m 42s PRINT (F 50 LCS M>60 S>65): formatted 312 cliques skipping 107 binary chapter diffs\n",
      " 5m 42s CHUNKING (F 50): already chunked into 8509 chunks\n",
      " 5m 42s PREPARING (F 50 LCS): Already prepared\n",
      " 5m 42s SIMILARITY (F 50 LCS M>60): Using 36197 K (36197286) comparisons with 1849 entries in matrix\n",
      " 5m 42s SIMILARITY (F 50 LCS M>60): similarities between 60.0 and 97.52650176678446. 0 are 100%\n",
      " 5m 42s CLIQUES (F 50 LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 5m 42s CLIQUES (F 50 LCS M>60 S>60): inspecting the similarity matrix\n",
      " 5m 42s CLIQUES (F 50 LCS M>60 S>60): 1849 relevant similarities between 1894 passages\n",
      " 5m 42s CLIQUES (F 50 LCS M>60 S>60): Loaded:   553 cliques out of   1894 chunks from 1849 comparisons\n",
      " 5m 42s CLIQUES (F 50 LCS M>60 S>60): 1894 members in 553 cliques\n",
      " 5m 42s PRINT (F 50 LCS M>60 S>60): sorting out cliques\n",
      " 5m 42s PRINT (F 50 LCS M>60 S>60): formatting 553 cliques skipping 230 binary chapter diffs\n",
      " 5m 52s PRINT (F 50 LCS M>60 S>60): formatted 553 cliques skipping 230 binary chapter diffs\n",
      " 5m 52s CHUNKING (F 20)\n",
      " 5m 54s CHUNKING (F 20): Made 21311 chunks\n",
      " 5m 54s PREPARING (F 20 SET)\n",
      " 5m 56s PREPARING (F 20 SET): Done 21311 chunks.\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): Loaded:   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>100): fetching similars and chunk candidates\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>100): inspecting the similarity matrix\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>100): 14 relevant similarities between 28 passages\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>100): Loaded:    14 cliques out of     28 chunks from 14 comparisons\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>100): 28 members in 14 cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>100): sorting out cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>100): formatting 14 cliques skipping 8 binary chapter diffs\n",
      " 5m 56s PRINT (F 20 SET M>50 S>100): formatted 14 cliques skipping 8 binary chapter diffs\n",
      " 5m 56s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 56s PREPARING (F 20 SET): Already prepared\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>95): fetching similars and chunk candidates\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>95): inspecting the similarity matrix\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>95): 14 relevant similarities between 28 passages\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>95): Loaded:    14 cliques out of     28 chunks from 14 comparisons\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>95): 28 members in 14 cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>95): sorting out cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>95): formatting 14 cliques skipping 8 binary chapter diffs\n",
      " 5m 56s PRINT (F 20 SET M>50 S>95): formatted 14 cliques skipping 8 binary chapter diffs\n",
      " 5m 56s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 56s PREPARING (F 20 SET): Already prepared\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>90): fetching similars and chunk candidates\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>90): inspecting the similarity matrix\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>90): 62 relevant similarities between 103 passages\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>90): Loaded:    45 cliques out of    103 chunks from 62 comparisons\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>90): 103 members in 45 cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>90): sorting out cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>90): formatting 45 cliques skipping 22 binary chapter diffs\n",
      " 5m 56s PRINT (F 20 SET M>50 S>90): formatted 45 cliques skipping 22 binary chapter diffs\n",
      " 5m 56s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 56s PREPARING (F 20 SET): Already prepared\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>85): fetching similars and chunk candidates\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>85): inspecting the similarity matrix\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>85): 124 relevant similarities between 172 passages\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>85): Loaded:    71 cliques out of    172 chunks from 124 comparisons\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>85): 172 members in 71 cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>85): sorting out cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>85): formatting 71 cliques skipping 34 binary chapter diffs\n",
      " 5m 56s PRINT (F 20 SET M>50 S>85): formatted 71 cliques skipping 34 binary chapter diffs\n",
      " 5m 56s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 56s PREPARING (F 20 SET): Already prepared\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 56s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>80): fetching similars and chunk candidates\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>80): inspecting the similarity matrix\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>80): 232 relevant similarities between 330 passages\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>80): Loaded:   145 cliques out of    330 chunks from 232 comparisons\n",
      " 5m 56s CLIQUES (F 20 SET M>50 S>80): 330 members in 145 cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>80): sorting out cliques\n",
      " 5m 56s PRINT (F 20 SET M>50 S>80): formatting 145 cliques skipping 60 binary chapter diffs\n",
      " 5m 57s PRINT (F 20 SET M>50 S>80): formatted 145 cliques skipping 60 binary chapter diffs\n",
      " 5m 57s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 57s PREPARING (F 20 SET): Already prepared\n",
      " 5m 57s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 57s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>75): fetching similars and chunk candidates\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>75): inspecting the similarity matrix\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>75): 383 relevant similarities between 530 passages\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>75): Loaded:   228 cliques out of    530 chunks from 383 comparisons\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>75): 530 members in 228 cliques\n",
      " 5m 57s PRINT (F 20 SET M>50 S>75): sorting out cliques\n",
      " 5m 57s PRINT (F 20 SET M>50 S>75): formatting 228 cliques skipping 84 binary chapter diffs\n",
      " 5m 57s PRINT (F 20 SET M>50 S>75): formatted 228 cliques skipping 84 binary chapter diffs\n",
      " 5m 57s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 57s PREPARING (F 20 SET): Already prepared\n",
      " 5m 57s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 57s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>70): fetching similars and chunk candidates\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>70): inspecting the similarity matrix\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>70): 547 relevant similarities between 764 passages\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>70): Loaded:   332 cliques out of    764 chunks from 547 comparisons\n",
      " 5m 57s CLIQUES (F 20 SET M>50 S>70): 764 members in 332 cliques\n",
      " 5m 57s PRINT (F 20 SET M>50 S>70): sorting out cliques\n",
      " 5m 57s PRINT (F 20 SET M>50 S>70): formatting 332 cliques skipping 107 binary chapter diffs\n",
      " 5m 58s PRINT (F 20 SET M>50 S>70): formatted 332 cliques skipping 107 binary chapter diffs\n",
      " 5m 58s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 58s PREPARING (F 20 SET): Already prepared\n",
      " 5m 58s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 58s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 58s CLIQUES (F 20 SET M>50 S>65): fetching similars and chunk candidates\n",
      " 5m 58s CLIQUES (F 20 SET M>50 S>65): inspecting the similarity matrix\n",
      " 5m 58s CLIQUES (F 20 SET M>50 S>65): 790 relevant similarities between 1058 passages\n",
      " 5m 58s CLIQUES (F 20 SET M>50 S>65): Loaded:   450 cliques out of   1058 chunks from 790 comparisons\n",
      " 5m 58s CLIQUES (F 20 SET M>50 S>65): 1058 members in 450 cliques\n",
      " 5m 58s PRINT (F 20 SET M>50 S>65): sorting out cliques\n",
      " 5m 58s PRINT (F 20 SET M>50 S>65): formatting 450 cliques skipping 134 binary chapter diffs\n",
      " 5m 59s PRINT (F 20 SET M>50 S>65): formatted 450 cliques skipping 134 binary chapter diffs\n",
      " 5m 59s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 5m 59s PREPARING (F 20 SET): Already prepared\n",
      " 5m 59s SIMILARITY (F 20 SET M>50): Using   227 M (227068705) comparisons with 5548 entries in matrix\n",
      " 5m 59s SIMILARITY (F 20 SET M>50): similarities between 50.0 and 100.0. 14 are 100%\n",
      " 5m 59s CLIQUES (F 20 SET M>50 S>60): fetching similars and chunk candidates\n",
      " 5m 59s CLIQUES (F 20 SET M>50 S>60): inspecting the similarity matrix\n",
      " 5m 59s CLIQUES (F 20 SET M>50 S>60): 1437 relevant similarities between 1828 passages\n",
      " 5m 59s CLIQUES (F 20 SET M>50 S>60): Loaded:   732 cliques out of   1828 chunks from 1437 comparisons\n",
      " 5m 59s CLIQUES (F 20 SET M>50 S>60): 1828 members in 732 cliques\n",
      " 5m 59s PRINT (F 20 SET M>50 S>60): sorting out cliques\n",
      " 5m 59s PRINT (F 20 SET M>50 S>60): formatting 732 cliques skipping 211 binary chapter diffs\n",
      " 6m 01s PRINT (F 20 SET M>50 S>60): formatted 732 cliques skipping 211 binary chapter diffs\n",
      " 6m 01s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 01s PREPARING (F 20 LCS)\n",
      " 6m 03s PREPARING (F 20 LCS): Done 21311 chunks.\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): Loaded:   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>100): inspecting the similarity matrix\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>100): 3 relevant similarities between 6 passages\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>100): Loaded:     3 cliques out of      6 chunks from 3 comparisons\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>100): 6 members in 3 cliques\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>100): sorting out cliques\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>100): formatting 3 cliques skipping 3 binary chapter diffs\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>100): formatted 3 cliques skipping 3 binary chapter diffs\n",
      " 6m 03s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 03s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>95): inspecting the similarity matrix\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>95): 25 relevant similarities between 47 passages\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>95): Loaded:    22 cliques out of     47 chunks from 25 comparisons\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>95): 47 members in 22 cliques\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>95): sorting out cliques\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>95): formatting 22 cliques skipping 12 binary chapter diffs\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>95): formatted 22 cliques skipping 12 binary chapter diffs\n",
      " 6m 03s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 03s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>90): inspecting the similarity matrix\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>90): 95 relevant similarities between 149 passages\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>90): Loaded:    61 cliques out of    149 chunks from 95 comparisons\n",
      " 6m 03s CLIQUES (F 20 LCS M>60 S>90): 149 members in 61 cliques\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>90): sorting out cliques\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>90): formatting 61 cliques skipping 31 binary chapter diffs\n",
      " 6m 03s PRINT (F 20 LCS M>60 S>90): formatted 61 cliques skipping 31 binary chapter diffs\n",
      " 6m 03s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 03s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 03s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 04s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>85): inspecting the similarity matrix\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>85): 212 relevant similarities between 311 passages\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>85): Loaded:   136 cliques out of    311 chunks from 212 comparisons\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>85): 311 members in 136 cliques\n",
      " 6m 04s PRINT (F 20 LCS M>60 S>85): sorting out cliques\n",
      " 6m 04s PRINT (F 20 LCS M>60 S>85): formatting 136 cliques skipping 56 binary chapter diffs\n",
      " 6m 04s PRINT (F 20 LCS M>60 S>85): formatted 136 cliques skipping 56 binary chapter diffs\n",
      " 6m 04s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 04s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 04s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 04s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>80): inspecting the similarity matrix\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>80): 468 relevant similarities between 684 passages\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>80): Loaded:   300 cliques out of    684 chunks from 468 comparisons\n",
      " 6m 04s CLIQUES (F 20 LCS M>60 S>80): 684 members in 300 cliques\n",
      " 6m 04s PRINT (F 20 LCS M>60 S>80): sorting out cliques\n",
      " 6m 04s PRINT (F 20 LCS M>60 S>80): formatting 300 cliques skipping 117 binary chapter diffs\n",
      " 6m 05s PRINT (F 20 LCS M>60 S>80): formatted 300 cliques skipping 117 binary chapter diffs\n",
      " 6m 05s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 05s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 05s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 05s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 05s CLIQUES (F 20 LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 6m 05s CLIQUES (F 20 LCS M>60 S>75): inspecting the similarity matrix\n",
      " 6m 05s CLIQUES (F 20 LCS M>60 S>75): 872 relevant similarities between 1137 passages\n",
      " 6m 05s CLIQUES (F 20 LCS M>60 S>75): Loaded:   471 cliques out of   1137 chunks from 872 comparisons\n",
      " 6m 05s CLIQUES (F 20 LCS M>60 S>75): 1137 members in 471 cliques\n",
      " 6m 05s PRINT (F 20 LCS M>60 S>75): sorting out cliques\n",
      " 6m 05s PRINT (F 20 LCS M>60 S>75): formatting 471 cliques skipping 162 binary chapter diffs\n",
      " 6m 06s PRINT (F 20 LCS M>60 S>75): formatted 471 cliques skipping 162 binary chapter diffs\n",
      " 6m 06s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 06s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 06s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 06s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 06s CLIQUES (F 20 LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 6m 06s CLIQUES (F 20 LCS M>60 S>70): inspecting the similarity matrix\n",
      " 6m 06s CLIQUES (F 20 LCS M>60 S>70): 1945 relevant similarities between 2219 passages\n",
      " 6m 06s CLIQUES (F 20 LCS M>60 S>70): Loaded:   841 cliques out of   2219 chunks from 1945 comparisons\n",
      " 6m 06s CLIQUES (F 20 LCS M>60 S>70): 2219 members in 841 cliques\n",
      " 6m 06s PRINT (F 20 LCS M>60 S>70): sorting out cliques\n",
      " 6m 06s PRINT (F 20 LCS M>60 S>70): formatting 841 cliques skipping 317 binary chapter diffs\n",
      " 6m 09s PRINT (F 20 LCS M>60 S>70): formatted 841 cliques skipping 317 binary chapter diffs\n",
      " 6m 09s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 09s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 09s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 09s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 09s CLIQUES (F 20 LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 6m 09s CLIQUES (F 20 LCS M>60 S>65): inspecting the similarity matrix\n",
      " 6m 09s CLIQUES (F 20 LCS M>60 S>65): 7002 relevant similarities between 5994 passages\n",
      " 6m 09s CLIQUES (F 20 LCS M>60 S>65): Loaded:  1234 cliques out of   5994 chunks from 7002 comparisons\n",
      " 6m 09s CLIQUES (F 20 LCS M>60 S>65): 5994 members in 1234 cliques\n",
      " 6m 09s PRINT (F 20 LCS M>60 S>65): sorting out cliques\n",
      " 6m 09s PRINT (F 20 LCS M>60 S>65): formatting 1234 cliques skipping 555 binary chapter diffs\n",
      " 6m 13s PRINT (F 20 LCS M>60 S>65): formatted 1234 cliques skipping 555 binary chapter diffs\n",
      " 6m 13s CHUNKING (F 20): already chunked into 21311 chunks\n",
      " 6m 13s PREPARING (F 20 LCS): Already prepared\n",
      " 6m 13s SIMILARITY (F 20 LCS M>60): Using   227 M (227068705) comparisons with 122544 entries in matrix\n",
      " 6m 13s SIMILARITY (F 20 LCS M>60): similarities between 60.0 and 100.0. 3 are 100%\n",
      " 6m 13s CLIQUES (F 20 LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 6m 13s CLIQUES (F 20 LCS M>60 S>60): inspecting the similarity matrix\n",
      " 6m 13s CLIQUES (F 20 LCS M>60 S>60): 122544 relevant similarities between 17680 passages\n",
      " 6m 13s CLIQUES (F 20 LCS M>60 S>60): Loaded:   154 cliques out of  17680 chunks from 122544 comparisons\n",
      " 6m 13s CLIQUES (F 20 LCS M>60 S>60): 17680 members in 154 cliques\n",
      " 6m 13s PRINT (F 20 LCS M>60 S>60): sorting out cliques\n",
      " 6m 13s PRINT (F 20 LCS M>60 S>60): formatting 154 cliques skipping 93 binary chapter diffs\n",
      " 6m 14s PRINT (F 20 LCS M>60 S>60): formatted 154 cliques skipping 93 binary chapter diffs\n",
      " 6m 14s CHUNKING (F 10)\n",
      " 6m 16s CHUNKING (F 10): Made 42639 chunks\n",
      " 6m 16s PREPARING (F 10 SET)\n",
      " 6m 18s PREPARING (F 10 SET): Done 42639 chunks.\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): Loaded:   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>100): fetching similars and chunk candidates\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>100): inspecting the similarity matrix\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>100): 274 relevant similarities between 446 passages\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>100): Loaded:   208 cliques out of    446 chunks from 274 comparisons\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>100): 446 members in 208 cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>100): sorting out cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>100): formatting 208 cliques skipping 79 binary chapter diffs\n",
      " 6m 18s PRINT (F 10 SET M>50 S>100): formatted 208 cliques skipping 79 binary chapter diffs\n",
      " 6m 18s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 18s PREPARING (F 10 SET): Already prepared\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>95): fetching similars and chunk candidates\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>95): inspecting the similarity matrix\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>95): 274 relevant similarities between 446 passages\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>95): Loaded:   208 cliques out of    446 chunks from 274 comparisons\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>95): 446 members in 208 cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>95): sorting out cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>95): formatting 208 cliques skipping 79 binary chapter diffs\n",
      " 6m 18s PRINT (F 10 SET M>50 S>95): formatted 208 cliques skipping 79 binary chapter diffs\n",
      " 6m 18s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 18s PREPARING (F 10 SET): Already prepared\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>90): fetching similars and chunk candidates\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>90): inspecting the similarity matrix\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>90): 314 relevant similarities between 480 passages\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>90): Loaded:   219 cliques out of    480 chunks from 314 comparisons\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>90): 480 members in 219 cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>90): sorting out cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>90): formatting 219 cliques skipping 84 binary chapter diffs\n",
      " 6m 18s PRINT (F 10 SET M>50 S>90): formatted 219 cliques skipping 84 binary chapter diffs\n",
      " 6m 18s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 18s PREPARING (F 10 SET): Already prepared\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 18s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>85): fetching similars and chunk candidates\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>85): inspecting the similarity matrix\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>85): 750 relevant similarities between 1120 passages\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>85): Loaded:   495 cliques out of   1120 chunks from 750 comparisons\n",
      " 6m 18s CLIQUES (F 10 SET M>50 S>85): 1120 members in 495 cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>85): sorting out cliques\n",
      " 6m 18s PRINT (F 10 SET M>50 S>85): formatting 495 cliques skipping 197 binary chapter diffs\n",
      " 6m 19s PRINT (F 10 SET M>50 S>85): formatted 495 cliques skipping 197 binary chapter diffs\n",
      " 6m 19s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 19s PREPARING (F 10 SET): Already prepared\n",
      " 6m 19s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 19s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 19s CLIQUES (F 10 SET M>50 S>80): fetching similars and chunk candidates\n",
      " 6m 19s CLIQUES (F 10 SET M>50 S>80): inspecting the similarity matrix\n",
      " 6m 19s CLIQUES (F 10 SET M>50 S>80): 1156 relevant similarities between 1546 passages\n",
      " 6m 19s CLIQUES (F 10 SET M>50 S>80): Loaded:   632 cliques out of   1546 chunks from 1156 comparisons\n",
      " 6m 19s CLIQUES (F 10 SET M>50 S>80): 1546 members in 632 cliques\n",
      " 6m 19s PRINT (F 10 SET M>50 S>80): sorting out cliques\n",
      " 6m 19s PRINT (F 10 SET M>50 S>80): formatting 632 cliques skipping 237 binary chapter diffs\n",
      " 6m 19s PRINT (F 10 SET M>50 S>80): formatted 632 cliques skipping 237 binary chapter diffs\n",
      " 6m 19s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 19s PREPARING (F 10 SET): Already prepared\n",
      " 6m 19s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 20s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 20s CLIQUES (F 10 SET M>50 S>75): fetching similars and chunk candidates\n",
      " 6m 20s CLIQUES (F 10 SET M>50 S>75): inspecting the similarity matrix\n",
      " 6m 20s CLIQUES (F 10 SET M>50 S>75): 2127 relevant similarities between 2772 passages\n",
      " 6m 20s CLIQUES (F 10 SET M>50 S>75): Loaded:  1100 cliques out of   2772 chunks from 2127 comparisons\n",
      " 6m 20s CLIQUES (F 10 SET M>50 S>75): 2772 members in 1100 cliques\n",
      " 6m 20s PRINT (F 10 SET M>50 S>75): sorting out cliques\n",
      " 6m 20s PRINT (F 10 SET M>50 S>75): formatting 1100 cliques skipping 409 binary chapter diffs\n",
      " 6m 21s PRINT (F 10 SET M>50 S>75): formatted 1100 cliques skipping 409 binary chapter diffs\n",
      " 6m 21s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 21s PREPARING (F 10 SET): Already prepared\n",
      " 6m 21s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 21s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 21s CLIQUES (F 10 SET M>50 S>70): fetching similars and chunk candidates\n",
      " 6m 21s CLIQUES (F 10 SET M>50 S>70): inspecting the similarity matrix\n",
      " 6m 21s CLIQUES (F 10 SET M>50 S>70): 3582 relevant similarities between 4050 passages\n",
      " 6m 21s CLIQUES (F 10 SET M>50 S>70): Loaded:  1485 cliques out of   4050 chunks from 3582 comparisons\n",
      " 6m 21s CLIQUES (F 10 SET M>50 S>70): 4050 members in 1485 cliques\n",
      " 6m 21s PRINT (F 10 SET M>50 S>70): sorting out cliques\n",
      " 6m 21s PRINT (F 10 SET M>50 S>70): formatting 1485 cliques skipping 563 binary chapter diffs\n",
      " 6m 23s PRINT (F 10 SET M>50 S>70): formatted 1485 cliques skipping 563 binary chapter diffs\n",
      " 6m 23s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 23s PREPARING (F 10 SET): Already prepared\n",
      " 6m 23s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 23s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 23s CLIQUES (F 10 SET M>50 S>65): fetching similars and chunk candidates\n",
      " 6m 23s CLIQUES (F 10 SET M>50 S>65): inspecting the similarity matrix\n",
      " 6m 23s CLIQUES (F 10 SET M>50 S>65): 5509 relevant similarities between 5789 passages\n",
      " 6m 23s CLIQUES (F 10 SET M>50 S>65): Loaded:  1849 cliques out of   5789 chunks from 5509 comparisons\n",
      " 6m 23s CLIQUES (F 10 SET M>50 S>65): 5789 members in 1849 cliques\n",
      " 6m 23s PRINT (F 10 SET M>50 S>65): sorting out cliques\n",
      " 6m 23s PRINT (F 10 SET M>50 S>65): formatting 1849 cliques skipping 688 binary chapter diffs\n",
      " 6m 25s PRINT (F 10 SET M>50 S>65): formatted 1849 cliques skipping 688 binary chapter diffs\n",
      " 6m 25s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 25s PREPARING (F 10 SET): Already prepared\n",
      " 6m 25s SIMILARITY (F 10 SET M>50): Using   909 M (909020841) comparisons with 89103 entries in matrix\n",
      " 6m 25s SIMILARITY (F 10 SET M>50): similarities between 50.0 and 100.0. 274 are 100%\n",
      " 6m 25s CLIQUES (F 10 SET M>50 S>60): fetching similars and chunk candidates\n",
      " 6m 25s CLIQUES (F 10 SET M>50 S>60): inspecting the similarity matrix\n",
      " 6m 25s CLIQUES (F 10 SET M>50 S>60): 13304 relevant similarities between 10213 passages\n",
      " 6m 25s CLIQUES (F 10 SET M>50 S>60): Loaded:  2205 cliques out of  10213 chunks from 13304 comparisons\n",
      " 6m 25s CLIQUES (F 10 SET M>50 S>60): 10213 members in 2205 cliques\n",
      " 6m 25s PRINT (F 10 SET M>50 S>60): sorting out cliques\n",
      " 6m 25s PRINT (F 10 SET M>50 S>60): formatting 2205 cliques skipping 837 binary chapter diffs\n",
      " 6m 28s PRINT (F 10 SET M>50 S>60): formatted 2205 cliques skipping 837 binary chapter diffs\n",
      " 6m 28s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 28s PREPARING (F 10 LCS)\n",
      " 6m 29s PREPARING (F 10 LCS): Done 42639 chunks.\n",
      " 6m 32s SIMILARITY (F 10 LCS M>60): Loaded:   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 33s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 33s CLIQUES (F 10 LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 6m 33s CLIQUES (F 10 LCS M>60 S>100): inspecting the similarity matrix\n",
      " 6m 34s CLIQUES (F 10 LCS M>60 S>100): 139 relevant similarities between 236 passages\n",
      " 6m 34s CLIQUES (F 10 LCS M>60 S>100): Loaded:   112 cliques out of    236 chunks from 139 comparisons\n",
      " 6m 34s CLIQUES (F 10 LCS M>60 S>100): 236 members in 112 cliques\n",
      " 6m 34s PRINT (F 10 LCS M>60 S>100): sorting out cliques\n",
      " 6m 34s PRINT (F 10 LCS M>60 S>100): formatting 112 cliques skipping 47 binary chapter diffs\n",
      " 6m 34s PRINT (F 10 LCS M>60 S>100): formatted 112 cliques skipping 47 binary chapter diffs\n",
      " 6m 34s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 34s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 34s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 36s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 36s CLIQUES (F 10 LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 6m 36s CLIQUES (F 10 LCS M>60 S>95): inspecting the similarity matrix\n",
      " 6m 37s CLIQUES (F 10 LCS M>60 S>95): 213 relevant similarities between 374 passages\n",
      " 6m 37s CLIQUES (F 10 LCS M>60 S>95): Loaded:   179 cliques out of    374 chunks from 213 comparisons\n",
      " 6m 37s CLIQUES (F 10 LCS M>60 S>95): 374 members in 179 cliques\n",
      " 6m 37s PRINT (F 10 LCS M>60 S>95): sorting out cliques\n",
      " 6m 37s PRINT (F 10 LCS M>60 S>95): formatting 179 cliques skipping 75 binary chapter diffs\n",
      " 6m 37s PRINT (F 10 LCS M>60 S>95): formatted 179 cliques skipping 75 binary chapter diffs\n",
      " 6m 37s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 37s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 37s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 38s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 38s CLIQUES (F 10 LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 6m 38s CLIQUES (F 10 LCS M>60 S>90): inspecting the similarity matrix\n",
      " 6m 39s CLIQUES (F 10 LCS M>60 S>90): 604 relevant similarities between 903 passages\n",
      " 6m 39s CLIQUES (F 10 LCS M>60 S>90): Loaded:   398 cliques out of    903 chunks from 604 comparisons\n",
      " 6m 39s CLIQUES (F 10 LCS M>60 S>90): 903 members in 398 cliques\n",
      " 6m 39s PRINT (F 10 LCS M>60 S>90): sorting out cliques\n",
      " 6m 39s PRINT (F 10 LCS M>60 S>90): formatting 398 cliques skipping 160 binary chapter diffs\n",
      " 6m 40s PRINT (F 10 LCS M>60 S>90): formatted 398 cliques skipping 160 binary chapter diffs\n",
      " 6m 40s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 40s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 40s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 41s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 41s CLIQUES (F 10 LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 6m 41s CLIQUES (F 10 LCS M>60 S>85): inspecting the similarity matrix\n",
      " 6m 42s CLIQUES (F 10 LCS M>60 S>85): 1401 relevant similarities between 1909 passages\n",
      " 6m 42s CLIQUES (F 10 LCS M>60 S>85): Loaded:   788 cliques out of   1909 chunks from 1401 comparisons\n",
      " 6m 42s CLIQUES (F 10 LCS M>60 S>85): 1909 members in 788 cliques\n",
      " 6m 42s PRINT (F 10 LCS M>60 S>85): sorting out cliques\n",
      " 6m 42s PRINT (F 10 LCS M>60 S>85): formatting 788 cliques skipping 295 binary chapter diffs\n",
      " 6m 43s PRINT (F 10 LCS M>60 S>85): formatted 788 cliques skipping 295 binary chapter diffs\n",
      " 6m 43s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 43s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 43s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 44s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 44s CLIQUES (F 10 LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 6m 44s CLIQUES (F 10 LCS M>60 S>80): inspecting the similarity matrix\n",
      " 6m 45s CLIQUES (F 10 LCS M>60 S>80): 3306 relevant similarities between 3852 passages\n",
      " 6m 45s CLIQUES (F 10 LCS M>60 S>80): Loaded:  1418 cliques out of   3852 chunks from 3306 comparisons\n",
      " 6m 45s CLIQUES (F 10 LCS M>60 S>80): 3852 members in 1418 cliques\n",
      " 6m 45s PRINT (F 10 LCS M>60 S>80): sorting out cliques\n",
      " 6m 45s PRINT (F 10 LCS M>60 S>80): formatting 1418 cliques skipping 544 binary chapter diffs\n",
      " 6m 46s PRINT (F 10 LCS M>60 S>80): formatted 1418 cliques skipping 544 binary chapter diffs\n",
      " 6m 46s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 46s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 46s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 48s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 48s CLIQUES (F 10 LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 6m 48s CLIQUES (F 10 LCS M>60 S>75): inspecting the similarity matrix\n",
      " 6m 49s CLIQUES (F 10 LCS M>60 S>75): 9217 relevant similarities between 8562 passages\n",
      " 6m 49s CLIQUES (F 10 LCS M>60 S>75): Loaded:  2341 cliques out of   8562 chunks from 9217 comparisons\n",
      " 6m 49s CLIQUES (F 10 LCS M>60 S>75): 8562 members in 2341 cliques\n",
      " 6m 49s PRINT (F 10 LCS M>60 S>75): sorting out cliques\n",
      " 6m 49s PRINT (F 10 LCS M>60 S>75): formatting 2341 cliques skipping 991 binary chapter diffs\n",
      " 6m 53s PRINT (F 10 LCS M>60 S>75): formatted 2341 cliques skipping 991 binary chapter diffs\n",
      " 6m 53s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 53s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 53s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 6m 55s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 6m 55s CLIQUES (F 10 LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 6m 55s CLIQUES (F 10 LCS M>60 S>70): inspecting the similarity matrix\n",
      " 6m 56s CLIQUES (F 10 LCS M>60 S>70): 38701 relevant similarities between 20423 passages\n",
      " 6m 56s CLIQUES (F 10 LCS M>60 S>70): Loaded:  1919 cliques out of  20423 chunks from 38701 comparisons\n",
      " 6m 56s CLIQUES (F 10 LCS M>60 S>70): 20423 members in 1919 cliques\n",
      " 6m 56s PRINT (F 10 LCS M>60 S>70): sorting out cliques\n",
      " 6m 56s PRINT (F 10 LCS M>60 S>70): formatting 1919 cliques skipping 994 binary chapter diffs\n",
      " 6m 58s PRINT (F 10 LCS M>60 S>70): formatted 1919 cliques skipping 994 binary chapter diffs\n",
      " 6m 58s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 6m 58s PREPARING (F 10 LCS): Already prepared\n",
      " 6m 58s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 7m 00s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 7m 00s CLIQUES (F 10 LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 7m 00s CLIQUES (F 10 LCS M>60 S>65): inspecting the similarity matrix\n",
      " 7m 02s CLIQUES (F 10 LCS M>60 S>65): 347270 relevant similarities between 37712 passages\n",
      " 7m 02s CLIQUES (F 10 LCS M>60 S>65): Loaded:   227 cliques out of  37712 chunks from 347270 comparisons\n",
      " 7m 02s CLIQUES (F 10 LCS M>60 S>65): 37712 members in 227 cliques\n",
      " 7m 02s PRINT (F 10 LCS M>60 S>65): sorting out cliques\n",
      " 7m 02s PRINT (F 10 LCS M>60 S>65): formatting 227 cliques skipping 146 binary chapter diffs\n",
      " 7m 02s PRINT (F 10 LCS M>60 S>65): formatted 227 cliques skipping 146 binary chapter diffs\n",
      " 7m 02s CHUNKING (F 10): already chunked into 42639 chunks\n",
      " 7m 02s PREPARING (F 10 LCS): Already prepared\n",
      " 7m 02s SIMILARITY (F 10 LCS M>60): Using   909 M (909020841) comparisons with 2924000 entries in matrix\n",
      " 7m 03s SIMILARITY (F 10 LCS M>60): similarities between 60.0 and 100.0. 139 are 100%\n",
      " 7m 03s CLIQUES (F 10 LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 7m 03s CLIQUES (F 10 LCS M>60 S>60): inspecting the similarity matrix\n",
      " 7m 08s CLIQUES (F 10 LCS M>60 S>60): 2924000 relevant similarities between 42451 passages\n",
      " 7m 08s CLIQUES (F 10 LCS M>60 S>60): Loaded:     2 cliques out of  42451 chunks from 2924000 comparisons\n",
      " 7m 08s CLIQUES (F 10 LCS M>60 S>60): 42451 members in 2 cliques\n",
      " 7m 08s PRINT (F 10 LCS M>60 S>60): sorting out cliques\n",
      " 7m 08s PRINT (F 10 LCS M>60 S>60): formatting 2 cliques skipping 1 binary chapter diffs\n",
      " 7m 08s PRINT (F 10 LCS M>60 S>60): formatted 2 cliques skipping 1 binary chapter diffs\n",
      " 7m 08s CHUNKING (O verse)\n",
      " 7m 10s CHUNKING (O verse): Made 23213 chunks\n",
      " 7m 10s PREPARING (O verse SET)\n",
      " 7m 11s PREPARING (O verse SET): Done 23213 chunks.\n",
      " 7m 12s SIMILARITY (O verse SET M>50): Loaded:   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 12s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 12s CLIQUES (O verse SET M>50 S>100): fetching similars and chunk candidates\n",
      " 7m 12s CLIQUES (O verse SET M>50 S>100): inspecting the similarity matrix\n",
      " 7m 12s CLIQUES (O verse SET M>50 S>100): 4507 relevant similarities between 995 passages\n",
      " 7m 12s CLIQUES (O verse SET M>50 S>100): Loaded:   389 cliques out of    995 chunks from 4507 comparisons\n",
      " 7m 12s CLIQUES (O verse SET M>50 S>100): 995 members in 389 cliques\n",
      " 7m 12s PRINT (O verse SET M>50 S>100): sorting out cliques\n",
      " 7m 12s PRINT (O verse SET M>50 S>100): formatting 389 cliques skipping 100 binary chapter diffs\n",
      " 7m 12s PRINT (O verse SET M>50 S>100): formatted 389 cliques skipping 100 binary chapter diffs\n",
      " 7m 12s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 12s PREPARING (O verse SET): Already prepared\n",
      " 7m 12s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 13s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>95): fetching similars and chunk candidates\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>95): inspecting the similarity matrix\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>95): 4525 relevant similarities between 1031 passages\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>95): Loaded:   407 cliques out of   1031 chunks from 4525 comparisons\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>95): 1031 members in 407 cliques\n",
      " 7m 13s PRINT (O verse SET M>50 S>95): sorting out cliques\n",
      " 7m 13s PRINT (O verse SET M>50 S>95): formatting 407 cliques skipping 103 binary chapter diffs\n",
      " 7m 13s PRINT (O verse SET M>50 S>95): formatted 407 cliques skipping 103 binary chapter diffs\n",
      " 7m 13s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 13s PREPARING (O verse SET): Already prepared\n",
      " 7m 13s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 13s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>90): fetching similars and chunk candidates\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>90): inspecting the similarity matrix\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>90): 4702 relevant similarities between 1290 passages\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>90): Loaded:   528 cliques out of   1290 chunks from 4702 comparisons\n",
      " 7m 13s CLIQUES (O verse SET M>50 S>90): 1290 members in 528 cliques\n",
      " 7m 13s PRINT (O verse SET M>50 S>90): sorting out cliques\n",
      " 7m 13s PRINT (O verse SET M>50 S>90): formatting 528 cliques involving 132 binary chapter diffs\n",
      " 7m 13s PRINT (O verse SET M>50 S>90): Chapter diffs needed: 132\n",
      " 7m 13s PRINT (O verse SET M>50 S>90): Chapter diffs: 0 newly created and 132 already existing\n",
      " 7m 14s PRINT (O verse SET M>50 S>90): formatted 528 cliques involving 132 binary chapter diffs\n",
      " 7m 14s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 14s PREPARING (O verse SET): Already prepared\n",
      " 7m 14s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 14s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 14s CLIQUES (O verse SET M>50 S>85): fetching similars and chunk candidates\n",
      " 7m 14s CLIQUES (O verse SET M>50 S>85): inspecting the similarity matrix\n",
      " 7m 14s CLIQUES (O verse SET M>50 S>85): 4934 relevant similarities between 1577 passages\n",
      " 7m 14s CLIQUES (O verse SET M>50 S>85): Loaded:   653 cliques out of   1577 chunks from 4934 comparisons\n",
      " 7m 14s CLIQUES (O verse SET M>50 S>85): 1577 members in 653 cliques\n",
      " 7m 14s PRINT (O verse SET M>50 S>85): sorting out cliques\n",
      " 7m 14s PRINT (O verse SET M>50 S>85): formatting 653 cliques involving 150 binary chapter diffs\n",
      " 7m 14s PRINT (O verse SET M>50 S>85): Chapter diffs needed: 150\n",
      " 7m 14s PRINT (O verse SET M>50 S>85): Chapter diffs: 0 newly created and 150 already existing\n",
      " 7m 15s PRINT (O verse SET M>50 S>85): formatted 653 cliques involving 150 binary chapter diffs\n",
      " 7m 15s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 15s PREPARING (O verse SET): Already prepared\n",
      " 7m 15s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 15s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 15s CLIQUES (O verse SET M>50 S>80): fetching similars and chunk candidates\n",
      " 7m 15s CLIQUES (O verse SET M>50 S>80): inspecting the similarity matrix\n",
      " 7m 15s CLIQUES (O verse SET M>50 S>80): 10656 relevant similarities between 1964 passages\n",
      " 7m 15s CLIQUES (O verse SET M>50 S>80): Loaded:   803 cliques out of   1964 chunks from 10656 comparisons\n",
      " 7m 15s CLIQUES (O verse SET M>50 S>80): 1964 members in 803 cliques\n",
      " 7m 15s PRINT (O verse SET M>50 S>80): sorting out cliques\n",
      " 7m 15s PRINT (O verse SET M>50 S>80): formatting 803 cliques skipping 174 binary chapter diffs\n",
      " 7m 16s PRINT (O verse SET M>50 S>80): formatted 803 cliques skipping 174 binary chapter diffs\n",
      " 7m 16s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 16s PREPARING (O verse SET): Already prepared\n",
      " 7m 16s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 16s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 16s CLIQUES (O verse SET M>50 S>75): fetching similars and chunk candidates\n",
      " 7m 16s CLIQUES (O verse SET M>50 S>75): inspecting the similarity matrix\n",
      " 7m 16s CLIQUES (O verse SET M>50 S>75): 11184 relevant similarities between 2365 passages\n",
      " 7m 16s CLIQUES (O verse SET M>50 S>75): Loaded:   964 cliques out of   2365 chunks from 11184 comparisons\n",
      " 7m 16s CLIQUES (O verse SET M>50 S>75): 2365 members in 964 cliques\n",
      " 7m 16s PRINT (O verse SET M>50 S>75): sorting out cliques\n",
      " 7m 16s PRINT (O verse SET M>50 S>75): formatting 964 cliques skipping 210 binary chapter diffs\n",
      " 7m 19s PRINT (O verse SET M>50 S>75): formatted 964 cliques skipping 210 binary chapter diffs\n",
      " 7m 19s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 19s PREPARING (O verse SET): Already prepared\n",
      " 7m 19s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 19s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 19s CLIQUES (O verse SET M>50 S>70): fetching similars and chunk candidates\n",
      " 7m 19s CLIQUES (O verse SET M>50 S>70): inspecting the similarity matrix\n",
      " 7m 19s CLIQUES (O verse SET M>50 S>70): 11708 relevant similarities between 2723 passages\n",
      " 7m 19s CLIQUES (O verse SET M>50 S>70): Loaded:  1095 cliques out of   2723 chunks from 11708 comparisons\n",
      " 7m 19s CLIQUES (O verse SET M>50 S>70): 2723 members in 1095 cliques\n",
      " 7m 19s PRINT (O verse SET M>50 S>70): sorting out cliques\n",
      " 7m 19s PRINT (O verse SET M>50 S>70): formatting 1095 cliques skipping 237 binary chapter diffs\n",
      " 7m 22s PRINT (O verse SET M>50 S>70): formatted 1095 cliques skipping 237 binary chapter diffs\n",
      " 7m 22s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 22s PREPARING (O verse SET): Already prepared\n",
      " 7m 22s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 22s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 22s CLIQUES (O verse SET M>50 S>65): fetching similars and chunk candidates\n",
      " 7m 22s CLIQUES (O verse SET M>50 S>65): inspecting the similarity matrix\n",
      " 7m 22s CLIQUES (O verse SET M>50 S>65): 14357 relevant similarities between 3141 passages\n",
      " 7m 22s CLIQUES (O verse SET M>50 S>65): Loaded:  1235 cliques out of   3141 chunks from 14357 comparisons\n",
      " 7m 22s CLIQUES (O verse SET M>50 S>65): 3141 members in 1235 cliques\n",
      " 7m 22s PRINT (O verse SET M>50 S>65): sorting out cliques\n",
      " 7m 22s PRINT (O verse SET M>50 S>65): formatting 1235 cliques involving 284 binary chapter diffs\n",
      " 7m 22s PRINT (O verse SET M>50 S>65): Chapter diffs needed: 284\n",
      " 7m 22s PRINT (O verse SET M>50 S>65): Chapter diffs: 0 newly created and 284 already existing\n",
      " 7m 25s PRINT (O verse SET M>50 S>65): formatted 1235 cliques involving 284 binary chapter diffs\n",
      " 7m 25s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 25s PREPARING (O verse SET): Already prepared\n",
      " 7m 25s SIMILARITY (O verse SET M>50): Using   269 M (269410078) comparisons with 24867 entries in matrix\n",
      " 7m 25s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      " 7m 25s CLIQUES (O verse SET M>50 S>60): fetching similars and chunk candidates\n",
      " 7m 25s CLIQUES (O verse SET M>50 S>60): inspecting the similarity matrix\n",
      " 7m 25s CLIQUES (O verse SET M>50 S>60): 16071 relevant similarities between 3893 passages\n",
      " 7m 25s CLIQUES (O verse SET M>50 S>60): Loaded:  1443 cliques out of   3893 chunks from 16071 comparisons\n",
      " 7m 25s CLIQUES (O verse SET M>50 S>60): 3893 members in 1443 cliques\n",
      " 7m 25s PRINT (O verse SET M>50 S>60): sorting out cliques\n",
      " 7m 25s PRINT (O verse SET M>50 S>60): formatting 1443 cliques involving 360 binary chapter diffs\n",
      " 7m 25s PRINT (O verse SET M>50 S>60): Chapter diffs needed: 360\n",
      " 7m 25s PRINT (O verse SET M>50 S>60): Chapter diffs: 0 newly created and 360 already existing\n",
      " 7m 30s PRINT (O verse SET M>50 S>60): formatted 1443 cliques involving 360 binary chapter diffs\n",
      " 7m 30s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 30s PREPARING (O verse LCS)\n",
      " 7m 31s PREPARING (O verse LCS): Done 23213 chunks.\n",
      " 7m 31s SIMILARITY (O verse LCS M>60): Loaded:   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 32s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>100): inspecting the similarity matrix\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>100): 4205 relevant similarities between 795 passages\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>100): Loaded:   296 cliques out of    795 chunks from 4205 comparisons\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>100): 795 members in 296 cliques\n",
      " 7m 32s PRINT (O verse LCS M>60 S>100): sorting out cliques\n",
      " 7m 32s PRINT (O verse LCS M>60 S>100): formatting 296 cliques skipping 80 binary chapter diffs\n",
      " 7m 32s PRINT (O verse LCS M>60 S>100): formatted 296 cliques skipping 80 binary chapter diffs\n",
      " 7m 32s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 32s PREPARING (O verse LCS): Already prepared\n",
      " 7m 32s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 32s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>95): inspecting the similarity matrix\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>95): 4489 relevant similarities between 1235 passages\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>95): Loaded:   504 cliques out of   1235 chunks from 4489 comparisons\n",
      " 7m 32s CLIQUES (O verse LCS M>60 S>95): 1235 members in 504 cliques\n",
      " 7m 32s PRINT (O verse LCS M>60 S>95): sorting out cliques\n",
      " 7m 32s PRINT (O verse LCS M>60 S>95): formatting 504 cliques involving 119 binary chapter diffs\n",
      " 7m 32s PRINT (O verse LCS M>60 S>95): Chapter diffs needed: 119\n",
      " 7m 32s PRINT (O verse LCS M>60 S>95): Chapter diffs: 0 newly created and 119 already existing\n",
      " 7m 33s PRINT (O verse LCS M>60 S>95): formatted 504 cliques involving 119 binary chapter diffs\n",
      " 7m 33s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 33s PREPARING (O verse LCS): Already prepared\n",
      " 7m 33s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 33s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 33s CLIQUES (O verse LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 7m 33s CLIQUES (O verse LCS M>60 S>90): inspecting the similarity matrix\n",
      " 7m 33s CLIQUES (O verse LCS M>60 S>90): 5538 relevant similarities between 1754 passages\n",
      " 7m 33s CLIQUES (O verse LCS M>60 S>90): Loaded:   724 cliques out of   1754 chunks from 5538 comparisons\n",
      " 7m 33s CLIQUES (O verse LCS M>60 S>90): 1754 members in 724 cliques\n",
      " 7m 33s PRINT (O verse LCS M>60 S>90): sorting out cliques\n",
      " 7m 33s PRINT (O verse LCS M>60 S>90): formatting 724 cliques involving 151 binary chapter diffs\n",
      " 7m 33s PRINT (O verse LCS M>60 S>90): Chapter diffs needed: 151\n",
      " 7m 33s PRINT (O verse LCS M>60 S>90): Chapter diffs: 0 newly created and 151 already existing\n",
      " 7m 34s PRINT (O verse LCS M>60 S>90): formatted 724 cliques involving 151 binary chapter diffs\n",
      " 7m 34s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 34s PREPARING (O verse LCS): Already prepared\n",
      " 7m 34s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 34s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 34s CLIQUES (O verse LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 7m 34s CLIQUES (O verse LCS M>60 S>85): inspecting the similarity matrix\n",
      " 7m 34s CLIQUES (O verse LCS M>60 S>85): 7873 relevant similarities between 2298 passages\n",
      " 7m 34s CLIQUES (O verse LCS M>60 S>85): Loaded:   939 cliques out of   2298 chunks from 7873 comparisons\n",
      " 7m 34s CLIQUES (O verse LCS M>60 S>85): 2298 members in 939 cliques\n",
      " 7m 34s PRINT (O verse LCS M>60 S>85): sorting out cliques\n",
      " 7m 34s PRINT (O verse LCS M>60 S>85): formatting 939 cliques skipping 179 binary chapter diffs\n",
      " 7m 35s PRINT (O verse LCS M>60 S>85): formatted 939 cliques skipping 179 binary chapter diffs\n",
      " 7m 35s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 35s PREPARING (O verse LCS): Already prepared\n",
      " 7m 35s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 36s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 36s CLIQUES (O verse LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 7m 36s CLIQUES (O verse LCS M>60 S>80): inspecting the similarity matrix\n",
      " 7m 36s CLIQUES (O verse LCS M>60 S>80): 9459 relevant similarities between 2925 passages\n",
      " 7m 36s CLIQUES (O verse LCS M>60 S>80): Loaded:  1141 cliques out of   2925 chunks from 9459 comparisons\n",
      " 7m 36s CLIQUES (O verse LCS M>60 S>80): 2925 members in 1141 cliques\n",
      " 7m 36s PRINT (O verse LCS M>60 S>80): sorting out cliques\n",
      " 7m 36s PRINT (O verse LCS M>60 S>80): formatting 1141 cliques skipping 251 binary chapter diffs\n",
      " 7m 38s PRINT (O verse LCS M>60 S>80): formatted 1141 cliques skipping 251 binary chapter diffs\n",
      " 7m 38s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 38s PREPARING (O verse LCS): Already prepared\n",
      " 7m 38s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 38s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 38s CLIQUES (O verse LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 7m 38s CLIQUES (O verse LCS M>60 S>75): inspecting the similarity matrix\n",
      " 7m 38s CLIQUES (O verse LCS M>60 S>75): 15542 relevant similarities between 3683 passages\n",
      " 7m 38s CLIQUES (O verse LCS M>60 S>75): Loaded:  1339 cliques out of   3683 chunks from 15542 comparisons\n",
      " 7m 38s CLIQUES (O verse LCS M>60 S>75): 3683 members in 1339 cliques\n",
      " 7m 38s PRINT (O verse LCS M>60 S>75): sorting out cliques\n",
      " 7m 38s PRINT (O verse LCS M>60 S>75): formatting 1339 cliques involving 346 binary chapter diffs\n",
      " 7m 38s PRINT (O verse LCS M>60 S>75): Chapter diffs needed: 346\n",
      " 7m 38s PRINT (O verse LCS M>60 S>75): Chapter diffs: 0 newly created and 346 already existing\n",
      " 7m 42s PRINT (O verse LCS M>60 S>75): formatted 1339 cliques involving 346 binary chapter diffs\n",
      " 7m 42s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 42s PREPARING (O verse LCS): Already prepared\n",
      " 7m 42s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 42s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 42s CLIQUES (O verse LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 7m 42s CLIQUES (O verse LCS M>60 S>70): inspecting the similarity matrix\n",
      " 7m 42s CLIQUES (O verse LCS M>60 S>70): 19839 relevant similarities between 4964 passages\n",
      " 7m 42s CLIQUES (O verse LCS M>60 S>70): Loaded:  1646 cliques out of   4964 chunks from 19839 comparisons\n",
      " 7m 42s CLIQUES (O verse LCS M>60 S>70): 4964 members in 1646 cliques\n",
      " 7m 42s PRINT (O verse LCS M>60 S>70): sorting out cliques\n",
      " 7m 42s PRINT (O verse LCS M>60 S>70): formatting 1646 cliques skipping 505 binary chapter diffs\n",
      " 7m 47s PRINT (O verse LCS M>60 S>70): formatted 1646 cliques skipping 505 binary chapter diffs\n",
      " 7m 47s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 47s PREPARING (O verse LCS): Already prepared\n",
      " 7m 47s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 48s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 48s CLIQUES (O verse LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 7m 48s CLIQUES (O verse LCS M>60 S>65): inspecting the similarity matrix\n",
      " 7m 48s CLIQUES (O verse LCS M>60 S>65): 31885 relevant similarities between 9052 passages\n",
      " 7m 48s CLIQUES (O verse LCS M>60 S>65): Loaded:  1820 cliques out of   9052 chunks from 31885 comparisons\n",
      " 7m 48s CLIQUES (O verse LCS M>60 S>65): 9052 members in 1820 cliques\n",
      " 7m 48s PRINT (O verse LCS M>60 S>65): sorting out cliques\n",
      " 7m 48s PRINT (O verse LCS M>60 S>65): formatting 1820 cliques skipping 702 binary chapter diffs\n",
      " 7m 53s PRINT (O verse LCS M>60 S>65): formatted 1820 cliques skipping 702 binary chapter diffs\n",
      " 7m 53s CHUNKING (O verse): already chunked into 23213 chunks\n",
      " 7m 53s PREPARING (O verse LCS): Already prepared\n",
      " 7m 53s SIMILARITY (O verse LCS M>60): Using   269 M (269410078) comparisons with 113877 entries in matrix\n",
      " 7m 53s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      " 7m 53s CLIQUES (O verse LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 7m 53s CLIQUES (O verse LCS M>60 S>60): inspecting the similarity matrix\n",
      " 7m 53s CLIQUES (O verse LCS M>60 S>60): 113877 relevant similarities between 18937 passages\n",
      " 7m 53s CLIQUES (O verse LCS M>60 S>60): Loaded:   378 cliques out of  18937 chunks from 113877 comparisons\n",
      " 7m 53s CLIQUES (O verse LCS M>60 S>60): 18937 members in 378 cliques\n",
      " 7m 53s PRINT (O verse LCS M>60 S>60): sorting out cliques\n",
      " 7m 53s PRINT (O verse LCS M>60 S>60): formatting 378 cliques skipping 190 binary chapter diffs\n",
      " 7m 54s PRINT (O verse LCS M>60 S>60): formatted 378 cliques skipping 190 binary chapter diffs\n",
      " 7m 54s CHUNKING (O half_verse)\n",
      " 7m 56s CHUNKING (O half_verse): Made 45087 chunks\n",
      " 7m 56s PREPARING (O half_verse SET)\n",
      " 7m 59s PREPARING (O half_verse SET): Done 45087 chunks.\n",
      " 7m 59s SIMILARITY (O half_verse SET M>50): Loaded:  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 7m 59s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 7m 59s CLIQUES (O half_verse SET M>50 S>100): fetching similars and chunk candidates\n",
      " 7m 59s CLIQUES (O half_verse SET M>50 S>100): inspecting the similarity matrix\n",
      " 7m 59s CLIQUES (O half_verse SET M>50 S>100): 10190 relevant similarities between 4308 passages\n",
      " 7m 59s CLIQUES (O half_verse SET M>50 S>100): Loaded:  1717 cliques out of   4308 chunks from 10190 comparisons\n",
      " 7m 59s CLIQUES (O half_verse SET M>50 S>100): 4308 members in 1717 cliques\n",
      " 7m 59s PRINT (O half_verse SET M>50 S>100): sorting out cliques\n",
      " 7m 59s PRINT (O half_verse SET M>50 S>100): formatting 1717 cliques involving 569 binary chapter diffs\n",
      " 7m 59s PRINT (O half_verse SET M>50 S>100): Chapter diffs needed: 569\n",
      " 8m 00s PRINT (O half_verse SET M>50 S>100): Chapter diffs: 0 newly created and 569 already existing\n",
      " 8m 00s PRINT (O half_verse SET M>50 S>100): formatted 1717 cliques involving 569 binary chapter diffs\n",
      " 8m 00s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 00s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 00s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 00s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 00s CLIQUES (O half_verse SET M>50 S>95): fetching similars and chunk candidates\n",
      " 8m 00s CLIQUES (O half_verse SET M>50 S>95): inspecting the similarity matrix\n",
      " 8m 00s CLIQUES (O half_verse SET M>50 S>95): 10193 relevant similarities between 4314 passages\n",
      " 8m 00s CLIQUES (O half_verse SET M>50 S>95): Loaded:  1720 cliques out of   4314 chunks from 10193 comparisons\n",
      " 8m 00s CLIQUES (O half_verse SET M>50 S>95): 4314 members in 1720 cliques\n",
      " 8m 00s PRINT (O half_verse SET M>50 S>95): sorting out cliques\n",
      " 8m 00s PRINT (O half_verse SET M>50 S>95): formatting 1720 cliques involving 569 binary chapter diffs\n",
      " 8m 00s PRINT (O half_verse SET M>50 S>95): Chapter diffs needed: 569\n",
      " 8m 00s PRINT (O half_verse SET M>50 S>95): Chapter diffs: 0 newly created and 569 already existing\n",
      " 8m 01s PRINT (O half_verse SET M>50 S>95): formatted 1720 cliques involving 569 binary chapter diffs\n",
      " 8m 01s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 01s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 01s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 01s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 01s CLIQUES (O half_verse SET M>50 S>90): fetching similars and chunk candidates\n",
      " 8m 01s CLIQUES (O half_verse SET M>50 S>90): inspecting the similarity matrix\n",
      " 8m 01s CLIQUES (O half_verse SET M>50 S>90): 10363 relevant similarities between 4603 passages\n",
      " 8m 01s CLIQUES (O half_verse SET M>50 S>90): Loaded:  1857 cliques out of   4603 chunks from 10363 comparisons\n",
      " 8m 01s CLIQUES (O half_verse SET M>50 S>90): 4603 members in 1857 cliques\n",
      " 8m 01s PRINT (O half_verse SET M>50 S>90): sorting out cliques\n",
      " 8m 01s PRINT (O half_verse SET M>50 S>90): formatting 1857 cliques involving 583 binary chapter diffs\n",
      " 8m 01s PRINT (O half_verse SET M>50 S>90): Chapter diffs needed: 583\n",
      " 8m 01s PRINT (O half_verse SET M>50 S>90): Chapter diffs: 0 newly created and 583 already existing\n",
      " 8m 02s PRINT (O half_verse SET M>50 S>90): formatted 1857 cliques involving 583 binary chapter diffs\n",
      " 8m 02s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 02s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 02s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 02s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 02s CLIQUES (O half_verse SET M>50 S>85): fetching similars and chunk candidates\n",
      " 8m 02s CLIQUES (O half_verse SET M>50 S>85): inspecting the similarity matrix\n",
      " 8m 03s CLIQUES (O half_verse SET M>50 S>85): 11066 relevant similarities between 5131 passages\n",
      " 8m 03s CLIQUES (O half_verse SET M>50 S>85): Loaded:  2066 cliques out of   5131 chunks from 11066 comparisons\n",
      " 8m 03s CLIQUES (O half_verse SET M>50 S>85): 5131 members in 2066 cliques\n",
      " 8m 03s PRINT (O half_verse SET M>50 S>85): sorting out cliques\n",
      " 8m 03s PRINT (O half_verse SET M>50 S>85): formatting 2066 cliques involving 636 binary chapter diffs\n",
      " 8m 03s PRINT (O half_verse SET M>50 S>85): Chapter diffs needed: 636\n",
      " 8m 03s PRINT (O half_verse SET M>50 S>85): Chapter diffs: 0 newly created and 636 already existing\n",
      " 8m 04s PRINT (O half_verse SET M>50 S>85): formatted 2066 cliques involving 636 binary chapter diffs\n",
      " 8m 04s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 04s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 04s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 04s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 04s CLIQUES (O half_verse SET M>50 S>80): fetching similars and chunk candidates\n",
      " 8m 04s CLIQUES (O half_verse SET M>50 S>80): inspecting the similarity matrix\n",
      " 8m 04s CLIQUES (O half_verse SET M>50 S>80): 20136 relevant similarities between 6407 passages\n",
      " 8m 04s CLIQUES (O half_verse SET M>50 S>80): Loaded:  2466 cliques out of   6407 chunks from 20136 comparisons\n",
      " 8m 04s CLIQUES (O half_verse SET M>50 S>80): 6407 members in 2466 cliques\n",
      " 8m 04s PRINT (O half_verse SET M>50 S>80): sorting out cliques\n",
      " 8m 04s PRINT (O half_verse SET M>50 S>80): formatting 2466 cliques involving 764 binary chapter diffs\n",
      " 8m 04s PRINT (O half_verse SET M>50 S>80): Chapter diffs needed: 764\n",
      " 8m 04s PRINT (O half_verse SET M>50 S>80): Chapter diffs: 0 newly created and 764 already existing\n",
      " 8m 06s PRINT (O half_verse SET M>50 S>80): formatted 2466 cliques involving 764 binary chapter diffs\n",
      " 8m 06s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 06s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 06s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 06s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 06s CLIQUES (O half_verse SET M>50 S>75): fetching similars and chunk candidates\n",
      " 8m 06s CLIQUES (O half_verse SET M>50 S>75): inspecting the similarity matrix\n",
      " 8m 06s CLIQUES (O half_verse SET M>50 S>75): 23668 relevant similarities between 8242 passages\n",
      " 8m 06s CLIQUES (O half_verse SET M>50 S>75): Loaded:  2878 cliques out of   8242 chunks from 23668 comparisons\n",
      " 8m 06s CLIQUES (O half_verse SET M>50 S>75): 8242 members in 2878 cliques\n",
      " 8m 06s PRINT (O half_verse SET M>50 S>75): sorting out cliques\n",
      " 8m 06s PRINT (O half_verse SET M>50 S>75): formatting 2878 cliques skipping 914 binary chapter diffs\n",
      " 8m 09s PRINT (O half_verse SET M>50 S>75): formatted 2878 cliques skipping 914 binary chapter diffs\n",
      " 8m 09s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 09s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 09s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 09s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 09s CLIQUES (O half_verse SET M>50 S>70): fetching similars and chunk candidates\n",
      " 8m 09s CLIQUES (O half_verse SET M>50 S>70): inspecting the similarity matrix\n",
      " 8m 09s CLIQUES (O half_verse SET M>50 S>70): 25510 relevant similarities between 9363 passages\n",
      " 8m 09s CLIQUES (O half_verse SET M>50 S>70): Loaded:  3181 cliques out of   9363 chunks from 25510 comparisons\n",
      " 8m 09s CLIQUES (O half_verse SET M>50 S>70): 9363 members in 3181 cliques\n",
      " 8m 09s PRINT (O half_verse SET M>50 S>70): sorting out cliques\n",
      " 8m 09s PRINT (O half_verse SET M>50 S>70): formatting 3181 cliques skipping 1011 binary chapter diffs\n",
      " 8m 12s PRINT (O half_verse SET M>50 S>70): formatted 3181 cliques skipping 1011 binary chapter diffs\n",
      " 8m 12s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 12s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 12s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 12s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 12s CLIQUES (O half_verse SET M>50 S>65): fetching similars and chunk candidates\n",
      " 8m 12s CLIQUES (O half_verse SET M>50 S>65): inspecting the similarity matrix\n",
      " 8m 13s CLIQUES (O half_verse SET M>50 S>65): 37377 relevant similarities between 12139 passages\n",
      " 8m 13s CLIQUES (O half_verse SET M>50 S>65): Loaded:  3337 cliques out of  12139 chunks from 37377 comparisons\n",
      " 8m 13s CLIQUES (O half_verse SET M>50 S>65): 12139 members in 3337 cliques\n",
      " 8m 13s PRINT (O half_verse SET M>50 S>65): sorting out cliques\n",
      " 8m 13s PRINT (O half_verse SET M>50 S>65): formatting 3337 cliques skipping 1074 binary chapter diffs\n",
      " 8m 18s PRINT (O half_verse SET M>50 S>65): formatted 3337 cliques skipping 1074 binary chapter diffs\n",
      " 8m 18s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 18s PREPARING (O half_verse SET): Already prepared\n",
      " 8m 18s SIMILARITY (O half_verse SET M>50): Using  1016 M (1016396241) comparisons with 179326 entries in matrix\n",
      " 8m 18s SIMILARITY (O half_verse SET M>50): similarities between 50.0 and 100.0. 10190 are 100%\n",
      " 8m 18s CLIQUES (O half_verse SET M>50 S>60): fetching similars and chunk candidates\n",
      " 8m 18s CLIQUES (O half_verse SET M>50 S>60): inspecting the similarity matrix\n",
      " 8m 18s CLIQUES (O half_verse SET M>50 S>60): 55241 relevant similarities between 16431 passages\n",
      " 8m 18s CLIQUES (O half_verse SET M>50 S>60): Loaded:  3414 cliques out of  16431 chunks from 55241 comparisons\n",
      " 8m 18s CLIQUES (O half_verse SET M>50 S>60): 16431 members in 3414 cliques\n",
      " 8m 18s PRINT (O half_verse SET M>50 S>60): sorting out cliques\n",
      " 8m 18s PRINT (O half_verse SET M>50 S>60): formatting 3414 cliques skipping 1178 binary chapter diffs\n",
      " 8m 23s PRINT (O half_verse SET M>50 S>60): formatted 3414 cliques skipping 1178 binary chapter diffs\n",
      " 8m 23s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 23s PREPARING (O half_verse LCS)\n",
      " 8m 25s PREPARING (O half_verse LCS): Done 45087 chunks.\n",
      " 8m 27s SIMILARITY (O half_verse LCS M>60): Loaded:  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 28s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 28s CLIQUES (O half_verse LCS M>60 S>100): fetching similars and chunk candidates\n",
      " 8m 28s CLIQUES (O half_verse LCS M>60 S>100): inspecting the similarity matrix\n",
      " 8m 28s CLIQUES (O half_verse LCS M>60 S>100): 9222 relevant similarities between 3779 passages\n",
      " 8m 28s CLIQUES (O half_verse LCS M>60 S>100): Loaded:  1505 cliques out of   3779 chunks from 9222 comparisons\n",
      " 8m 28s CLIQUES (O half_verse LCS M>60 S>100): 3779 members in 1505 cliques\n",
      " 8m 28s PRINT (O half_verse LCS M>60 S>100): sorting out cliques\n",
      " 8m 28s PRINT (O half_verse LCS M>60 S>100): formatting 1505 cliques involving 489 binary chapter diffs\n",
      " 8m 28s PRINT (O half_verse LCS M>60 S>100): Chapter diffs needed: 489\n",
      " 8m 28s PRINT (O half_verse LCS M>60 S>100): Chapter diffs: 0 newly created and 489 already existing\n",
      " 8m 29s PRINT (O half_verse LCS M>60 S>100): formatted 1505 cliques involving 489 binary chapter diffs\n",
      " 8m 29s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 29s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 29s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 30s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 30s CLIQUES (O half_verse LCS M>60 S>95): fetching similars and chunk candidates\n",
      " 8m 30s CLIQUES (O half_verse LCS M>60 S>95): inspecting the similarity matrix\n",
      " 8m 31s CLIQUES (O half_verse LCS M>60 S>95): 9616 relevant similarities between 4324 passages\n",
      " 8m 31s CLIQUES (O half_verse LCS M>60 S>95): Loaded:  1763 cliques out of   4324 chunks from 9616 comparisons\n",
      " 8m 31s CLIQUES (O half_verse LCS M>60 S>95): 4324 members in 1763 cliques\n",
      " 8m 31s PRINT (O half_verse LCS M>60 S>95): sorting out cliques\n",
      " 8m 31s PRINT (O half_verse LCS M>60 S>95): formatting 1763 cliques involving 540 binary chapter diffs\n",
      " 8m 31s PRINT (O half_verse LCS M>60 S>95): Chapter diffs needed: 540\n",
      " 8m 31s PRINT (O half_verse LCS M>60 S>95): Chapter diffs: 0 newly created and 540 already existing\n",
      " 8m 32s PRINT (O half_verse LCS M>60 S>95): formatted 1763 cliques involving 540 binary chapter diffs\n",
      " 8m 32s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 32s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 32s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 34s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 34s CLIQUES (O half_verse LCS M>60 S>90): fetching similars and chunk candidates\n",
      " 8m 34s CLIQUES (O half_verse LCS M>60 S>90): inspecting the similarity matrix\n",
      " 8m 35s CLIQUES (O half_verse LCS M>60 S>90): 12075 relevant similarities between 5752 passages\n",
      " 8m 35s CLIQUES (O half_verse LCS M>60 S>90): Loaded:  2325 cliques out of   5752 chunks from 12075 comparisons\n",
      " 8m 35s CLIQUES (O half_verse LCS M>60 S>90): 5752 members in 2325 cliques\n",
      " 8m 35s PRINT (O half_verse LCS M>60 S>90): sorting out cliques\n",
      " 8m 35s PRINT (O half_verse LCS M>60 S>90): formatting 2325 cliques involving 730 binary chapter diffs\n",
      " 8m 35s PRINT (O half_verse LCS M>60 S>90): Chapter diffs needed: 730\n",
      " 8m 35s PRINT (O half_verse LCS M>60 S>90): Chapter diffs: 0 newly created and 730 already existing\n",
      " 8m 36s PRINT (O half_verse LCS M>60 S>90): formatted 2325 cliques involving 730 binary chapter diffs\n",
      " 8m 36s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 36s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 36s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 38s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 38s CLIQUES (O half_verse LCS M>60 S>85): fetching similars and chunk candidates\n",
      " 8m 38s CLIQUES (O half_verse LCS M>60 S>85): inspecting the similarity matrix\n",
      " 8m 39s CLIQUES (O half_verse LCS M>60 S>85): 17494 relevant similarities between 7944 passages\n",
      " 8m 39s CLIQUES (O half_verse LCS M>60 S>85): Loaded:  2973 cliques out of   7944 chunks from 17494 comparisons\n",
      " 8m 39s CLIQUES (O half_verse LCS M>60 S>85): 7944 members in 2973 cliques\n",
      " 8m 39s PRINT (O half_verse LCS M>60 S>85): sorting out cliques\n",
      " 8m 39s PRINT (O half_verse LCS M>60 S>85): formatting 2973 cliques involving 973 binary chapter diffs\n",
      " 8m 39s PRINT (O half_verse LCS M>60 S>85): Chapter diffs needed: 973\n",
      " 8m 39s PRINT (O half_verse LCS M>60 S>85): Chapter diffs: 0 newly created and 973 already existing\n",
      " 8m 41s PRINT (O half_verse LCS M>60 S>85): formatted 2973 cliques involving 973 binary chapter diffs\n",
      " 8m 41s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 41s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 41s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 42s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 42s CLIQUES (O half_verse LCS M>60 S>80): fetching similars and chunk candidates\n",
      " 8m 42s CLIQUES (O half_verse LCS M>60 S>80): inspecting the similarity matrix\n",
      " 8m 43s CLIQUES (O half_verse LCS M>60 S>80): 27186 relevant similarities between 12463 passages\n",
      " 8m 43s CLIQUES (O half_verse LCS M>60 S>80): Loaded:  3528 cliques out of  12463 chunks from 27186 comparisons\n",
      " 8m 43s CLIQUES (O half_verse LCS M>60 S>80): 12463 members in 3528 cliques\n",
      " 8m 43s PRINT (O half_verse LCS M>60 S>80): sorting out cliques\n",
      " 8m 43s PRINT (O half_verse LCS M>60 S>80): formatting 3528 cliques skipping 1225 binary chapter diffs\n",
      " 8m 47s PRINT (O half_verse LCS M>60 S>80): formatted 3528 cliques skipping 1225 binary chapter diffs\n",
      " 8m 47s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 47s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 47s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 48s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 48s CLIQUES (O half_verse LCS M>60 S>75): fetching similars and chunk candidates\n",
      " 8m 48s CLIQUES (O half_verse LCS M>60 S>75): inspecting the similarity matrix\n",
      " 8m 49s CLIQUES (O half_verse LCS M>60 S>75): 53833 relevant similarities between 19071 passages\n",
      " 8m 49s CLIQUES (O half_verse LCS M>60 S>75): Loaded:  3074 cliques out of  19071 chunks from 53833 comparisons\n",
      " 8m 49s CLIQUES (O half_verse LCS M>60 S>75): 19071 members in 3074 cliques\n",
      " 8m 49s PRINT (O half_verse LCS M>60 S>75): sorting out cliques\n",
      " 8m 49s PRINT (O half_verse LCS M>60 S>75): formatting 3074 cliques skipping 1130 binary chapter diffs\n",
      " 8m 54s PRINT (O half_verse LCS M>60 S>75): formatted 3074 cliques skipping 1130 binary chapter diffs\n",
      " 8m 54s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 54s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 54s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 8m 55s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 8m 55s CLIQUES (O half_verse LCS M>60 S>70): fetching similars and chunk candidates\n",
      " 8m 55s CLIQUES (O half_verse LCS M>60 S>70): inspecting the similarity matrix\n",
      " 8m 56s CLIQUES (O half_verse LCS M>60 S>70): 125786 relevant similarities between 28373 passages\n",
      " 8m 56s CLIQUES (O half_verse LCS M>60 S>70): Loaded:  1890 cliques out of  28373 chunks from 125786 comparisons\n",
      " 8m 56s CLIQUES (O half_verse LCS M>60 S>70): 28373 members in 1890 cliques\n",
      " 8m 56s PRINT (O half_verse LCS M>60 S>70): sorting out cliques\n",
      " 8m 56s PRINT (O half_verse LCS M>60 S>70): formatting 1890 cliques skipping 748 binary chapter diffs\n",
      " 8m 59s PRINT (O half_verse LCS M>60 S>70): formatted 1890 cliques skipping 748 binary chapter diffs\n",
      " 8m 59s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 8m 59s PREPARING (O half_verse LCS): Already prepared\n",
      " 8m 59s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 9m 00s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 9m 00s CLIQUES (O half_verse LCS M>60 S>65): fetching similars and chunk candidates\n",
      " 9m 00s CLIQUES (O half_verse LCS M>60 S>65): inspecting the similarity matrix\n",
      " 9m 01s CLIQUES (O half_verse LCS M>60 S>65): 392024 relevant similarities between 38059 passages\n",
      " 9m 01s CLIQUES (O half_verse LCS M>60 S>65): Loaded:   668 cliques out of  38059 chunks from 392024 comparisons\n",
      " 9m 01s CLIQUES (O half_verse LCS M>60 S>65): 38059 members in 668 cliques\n",
      " 9m 01s PRINT (O half_verse LCS M>60 S>65): sorting out cliques\n",
      " 9m 02s PRINT (O half_verse LCS M>60 S>65): formatting 668 cliques skipping 291 binary chapter diffs\n",
      " 9m 03s PRINT (O half_verse LCS M>60 S>65): formatted 668 cliques skipping 291 binary chapter diffs\n",
      " 9m 03s CHUNKING (O half_verse): already chunked into 45087 chunks\n",
      " 9m 03s PREPARING (O half_verse LCS): Already prepared\n",
      " 9m 03s SIMILARITY (O half_verse LCS M>60): Using  1016 M (1016396241) comparisons with 2009728 entries in matrix\n",
      " 9m 05s SIMILARITY (O half_verse LCS M>60): similarities between 60.0 and 100.0. 9222 are 100%\n",
      " 9m 05s CLIQUES (O half_verse LCS M>60 S>60): fetching similars and chunk candidates\n",
      " 9m 05s CLIQUES (O half_verse LCS M>60 S>60): inspecting the similarity matrix\n",
      " 9m 08s CLIQUES (O half_verse LCS M>60 S>60): 2009728 relevant similarities between 43903 passages\n",
      " 9m 08s CLIQUES (O half_verse LCS M>60 S>60): Loaded:    92 cliques out of  43903 chunks from 2009728 comparisons\n",
      " 9m 08s CLIQUES (O half_verse LCS M>60 S>60): 43903 members in 92 cliques\n",
      " 9m 08s PRINT (O half_verse LCS M>60 S>60): sorting out cliques\n",
      " 9m 08s PRINT (O half_verse LCS M>60 S>60): formatting 92 cliques skipping 58 binary chapter diffs\n",
      " 9m 09s PRINT (O half_verse LCS M>60 S>60): formatted 92 cliques skipping 58 binary chapter diffs\n",
      " 9m 09s CHUNKING (O sentence)\n",
      " 9m 10s CHUNKING (O sentence): Made 64125 chunks\n",
      " 9m 10s PREPARING (O sentence SET)\n",
      " 9m 12s PREPARING (O sentence SET): Done 64125 chunks.\n",
      " 9m 17s SIMILARITY (O sentence SET M>50): Loaded:  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      " 9m 20s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      " 9m 20s CLIQUES (O sentence SET M>50 S>100): fetching similars and chunk candidates\n",
      " 9m 20s CLIQUES (O sentence SET M>50 S>100): inspecting the similarity matrix\n",
      " 9m 23s CLIQUES (O sentence SET M>50 S>100): 958139 relevant similarities between 19247 passages\n",
      " 9m 23s CLIQUES (O sentence SET M>50 S>100): Loaded:  4351 cliques out of  19247 chunks from 958139 comparisons\n",
      " 9m 23s CLIQUES (O sentence SET M>50 S>100): 19247 members in 4351 cliques\n",
      " 9m 23s PRINT (O sentence SET M>50 S>100): sorting out cliques\n",
      " 9m 23s PRINT (O sentence SET M>50 S>100): formatting 4351 cliques skipping 1555 binary chapter diffs\n",
      " 9m 26s PRINT (O sentence SET M>50 S>100): formatted 4351 cliques skipping 1555 binary chapter diffs\n",
      " 9m 26s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      " 9m 26s PREPARING (O sentence SET): Already prepared\n",
      " 9m 26s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      " 9m 28s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      " 9m 28s CLIQUES (O sentence SET M>50 S>95): fetching similars and chunk candidates\n",
      " 9m 28s CLIQUES (O sentence SET M>50 S>95): inspecting the similarity matrix\n",
      " 9m 31s CLIQUES (O sentence SET M>50 S>95): 958143 relevant similarities between 19255 passages\n",
      " 9m 31s CLIQUES (O sentence SET M>50 S>95): Loaded:  4355 cliques out of  19255 chunks from 958143 comparisons\n",
      " 9m 31s CLIQUES (O sentence SET M>50 S>95): 19255 members in 4355 cliques\n",
      " 9m 31s PRINT (O sentence SET M>50 S>95): sorting out cliques\n",
      " 9m 32s PRINT (O sentence SET M>50 S>95): formatting 4355 cliques skipping 1556 binary chapter diffs\n",
      " 9m 35s PRINT (O sentence SET M>50 S>95): formatted 4355 cliques skipping 1556 binary chapter diffs\n",
      " 9m 35s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      " 9m 35s PREPARING (O sentence SET): Already prepared\n",
      " 9m 35s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      " 9m 38s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      " 9m 38s CLIQUES (O sentence SET M>50 S>90): fetching similars and chunk candidates\n",
      " 9m 38s CLIQUES (O sentence SET M>50 S>90): inspecting the similarity matrix\n",
      " 9m 41s CLIQUES (O sentence SET M>50 S>90): 958274 relevant similarities between 19415 passages\n",
      " 9m 41s CLIQUES (O sentence SET M>50 S>90): Loaded:  4425 cliques out of  19415 chunks from 958274 comparisons\n",
      " 9m 41s CLIQUES (O sentence SET M>50 S>90): 19415 members in 4425 cliques\n",
      " 9m 41s PRINT (O sentence SET M>50 S>90): sorting out cliques\n",
      " 9m 41s PRINT (O sentence SET M>50 S>90): formatting 4425 cliques skipping 1562 binary chapter diffs\n",
      " 9m 44s PRINT (O sentence SET M>50 S>90): formatted 4425 cliques skipping 1562 binary chapter diffs\n",
      " 9m 44s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      " 9m 44s PREPARING (O sentence SET): Already prepared\n",
      " 9m 44s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      " 9m 48s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      " 9m 48s CLIQUES (O sentence SET M>50 S>85): fetching similars and chunk candidates\n",
      " 9m 48s CLIQUES (O sentence SET M>50 S>85): inspecting the similarity matrix\n",
      " 9m 51s CLIQUES (O sentence SET M>50 S>85): 959071 relevant similarities between 19976 passages\n",
      " 9m 51s CLIQUES (O sentence SET M>50 S>85): Loaded:  4628 cliques out of  19976 chunks from 959071 comparisons\n",
      " 9m 51s CLIQUES (O sentence SET M>50 S>85): 19976 members in 4628 cliques\n",
      " 9m 51s PRINT (O sentence SET M>50 S>85): sorting out cliques\n",
      " 9m 52s PRINT (O sentence SET M>50 S>85): formatting 4628 cliques skipping 1612 binary chapter diffs\n",
      " 9m 55s PRINT (O sentence SET M>50 S>85): formatted 4628 cliques skipping 1612 binary chapter diffs\n",
      " 9m 55s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      " 9m 55s PREPARING (O sentence SET): Already prepared\n",
      " 9m 55s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      " 9m 58s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      " 9m 58s CLIQUES (O sentence SET M>50 S>80): fetching similars and chunk candidates\n",
      " 9m 58s CLIQUES (O sentence SET M>50 S>80): inspecting the similarity matrix\n",
      "10m 01s CLIQUES (O sentence SET M>50 S>80): 981392 relevant similarities between 22348 passages\n",
      "10m 01s CLIQUES (O sentence SET M>50 S>80): Loaded:  5100 cliques out of  22348 chunks from 981392 comparisons\n",
      "10m 01s CLIQUES (O sentence SET M>50 S>80): 22348 members in 5100 cliques\n",
      "10m 01s PRINT (O sentence SET M>50 S>80): sorting out cliques\n",
      "10m 01s PRINT (O sentence SET M>50 S>80): formatting 5100 cliques skipping 1780 binary chapter diffs\n",
      "10m 06s PRINT (O sentence SET M>50 S>80): formatted 5100 cliques skipping 1780 binary chapter diffs\n",
      "10m 06s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "10m 06s PREPARING (O sentence SET): Already prepared\n",
      "10m 06s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      "10m 09s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      "10m 09s CLIQUES (O sentence SET M>50 S>75): fetching similars and chunk candidates\n",
      "10m 09s CLIQUES (O sentence SET M>50 S>75): inspecting the similarity matrix\n",
      "10m 13s CLIQUES (O sentence SET M>50 S>75): 1030178 relevant similarities between 26090 passages\n",
      "10m 13s CLIQUES (O sentence SET M>50 S>75): Loaded:  5003 cliques out of  26090 chunks from 1030178 comparisons\n",
      "10m 13s CLIQUES (O sentence SET M>50 S>75): 26090 members in 5003 cliques\n",
      "10m 13s PRINT (O sentence SET M>50 S>75): sorting out cliques\n",
      "10m 13s PRINT (O sentence SET M>50 S>75): formatting 5003 cliques skipping 1778 binary chapter diffs\n",
      "10m 17s PRINT (O sentence SET M>50 S>75): formatted 5003 cliques skipping 1778 binary chapter diffs\n",
      "10m 17s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "10m 17s PREPARING (O sentence SET): Already prepared\n",
      "10m 17s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      "10m 20s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      "10m 20s CLIQUES (O sentence SET M>50 S>70): fetching similars and chunk candidates\n",
      "10m 20s CLIQUES (O sentence SET M>50 S>70): inspecting the similarity matrix\n",
      "10m 23s CLIQUES (O sentence SET M>50 S>70): 1032912 relevant similarities between 27265 passages\n",
      "10m 23s CLIQUES (O sentence SET M>50 S>70): Loaded:  5237 cliques out of  27265 chunks from 1032912 comparisons\n",
      "10m 23s CLIQUES (O sentence SET M>50 S>70): 27265 members in 5237 cliques\n",
      "10m 23s PRINT (O sentence SET M>50 S>70): sorting out cliques\n",
      "10m 23s PRINT (O sentence SET M>50 S>70): formatting 5237 cliques skipping 1857 binary chapter diffs\n",
      "10m 28s PRINT (O sentence SET M>50 S>70): formatted 5237 cliques skipping 1857 binary chapter diffs\n",
      "10m 28s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "10m 28s PREPARING (O sentence SET): Already prepared\n",
      "10m 28s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      "10m 31s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      "10m 31s CLIQUES (O sentence SET M>50 S>65): fetching similars and chunk candidates\n",
      "10m 31s CLIQUES (O sentence SET M>50 S>65): inspecting the similarity matrix\n",
      "10m 34s CLIQUES (O sentence SET M>50 S>65): 1364817 relevant similarities between 33892 passages\n",
      "10m 34s CLIQUES (O sentence SET M>50 S>65): Loaded:  4053 cliques out of  33892 chunks from 1364817 comparisons\n",
      "10m 34s CLIQUES (O sentence SET M>50 S>65): 33892 members in 4053 cliques\n",
      "10m 34s PRINT (O sentence SET M>50 S>65): sorting out cliques\n",
      "10m 35s PRINT (O sentence SET M>50 S>65): formatting 4053 cliques skipping 1477 binary chapter diffs\n",
      "10m 39s PRINT (O sentence SET M>50 S>65): formatted 4053 cliques skipping 1477 binary chapter diffs\n",
      "10m 39s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "10m 39s PREPARING (O sentence SET): Already prepared\n",
      "10m 39s SIMILARITY (O sentence SET M>50): Using  2055 M (2055975750) comparisons with 4090939 entries in matrix\n",
      "10m 42s SIMILARITY (O sentence SET M>50): similarities between 50.0 and 100.0. 958139 are 100%\n",
      "10m 42s CLIQUES (O sentence SET M>50 S>60): fetching similars and chunk candidates\n",
      "10m 42s CLIQUES (O sentence SET M>50 S>60): inspecting the similarity matrix\n",
      "10m 45s CLIQUES (O sentence SET M>50 S>60): 1465957 relevant similarities between 39418 passages\n",
      "10m 45s CLIQUES (O sentence SET M>50 S>60): Loaded:  3697 cliques out of  39418 chunks from 1465957 comparisons\n",
      "10m 45s CLIQUES (O sentence SET M>50 S>60): 39418 members in 3697 cliques\n",
      "10m 45s PRINT (O sentence SET M>50 S>60): sorting out cliques\n",
      "10m 46s PRINT (O sentence SET M>50 S>60): formatting 3697 cliques skipping 1375 binary chapter diffs\n",
      "10m 49s PRINT (O sentence SET M>50 S>60): formatted 3697 cliques skipping 1375 binary chapter diffs\n",
      "10m 49s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "10m 49s PREPARING (O sentence LCS)\n",
      "10m 51s PREPARING (O sentence LCS): Done 64125 chunks.\n",
      "11m 06s SIMILARITY (O sentence LCS M>60): Loaded:  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "11m 13s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "11m 13s CLIQUES (O sentence LCS M>60 S>100): fetching similars and chunk candidates\n",
      "11m 13s CLIQUES (O sentence LCS M>60 S>100): inspecting the similarity matrix\n",
      "11m 20s CLIQUES (O sentence LCS M>60 S>100): 912742 relevant similarities between 17698 passages\n",
      "11m 20s CLIQUES (O sentence LCS M>60 S>100): Loaded:  3992 cliques out of  17698 chunks from 912742 comparisons\n",
      "11m 20s CLIQUES (O sentence LCS M>60 S>100): 17698 members in 3992 cliques\n",
      "11m 20s PRINT (O sentence LCS M>60 S>100): sorting out cliques\n",
      "11m 20s PRINT (O sentence LCS M>60 S>100): formatting 3992 cliques skipping 1383 binary chapter diffs\n",
      "11m 22s PRINT (O sentence LCS M>60 S>100): formatted 3992 cliques skipping 1383 binary chapter diffs\n",
      "11m 22s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "11m 22s PREPARING (O sentence LCS): Already prepared\n",
      "11m 22s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "11m 29s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "11m 29s CLIQUES (O sentence LCS M>60 S>95): fetching similars and chunk candidates\n",
      "11m 29s CLIQUES (O sentence LCS M>60 S>95): inspecting the similarity matrix\n",
      "11m 35s CLIQUES (O sentence LCS M>60 S>95): 913433 relevant similarities between 18239 passages\n",
      "11m 35s CLIQUES (O sentence LCS M>60 S>95): Loaded:  4224 cliques out of  18239 chunks from 913433 comparisons\n",
      "11m 35s CLIQUES (O sentence LCS M>60 S>95): 18239 members in 4224 cliques\n",
      "11m 35s PRINT (O sentence LCS M>60 S>95): sorting out cliques\n",
      "11m 35s PRINT (O sentence LCS M>60 S>95): formatting 4224 cliques skipping 1440 binary chapter diffs\n",
      "11m 38s PRINT (O sentence LCS M>60 S>95): formatted 4224 cliques skipping 1440 binary chapter diffs\n",
      "11m 38s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "11m 38s PREPARING (O sentence LCS): Already prepared\n",
      "11m 38s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "11m 45s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "11m 45s CLIQUES (O sentence LCS M>60 S>90): fetching similars and chunk candidates\n",
      "11m 45s CLIQUES (O sentence LCS M>60 S>90): inspecting the similarity matrix\n",
      "11m 52s CLIQUES (O sentence LCS M>60 S>90): 924729 relevant similarities between 21484 passages\n",
      "11m 52s CLIQUES (O sentence LCS M>60 S>90): Loaded:  5005 cliques out of  21484 chunks from 924729 comparisons\n",
      "11m 52s CLIQUES (O sentence LCS M>60 S>90): 21484 members in 5005 cliques\n",
      "11m 52s PRINT (O sentence LCS M>60 S>90): sorting out cliques\n",
      "11m 52s PRINT (O sentence LCS M>60 S>90): formatting 5005 cliques skipping 1730 binary chapter diffs\n",
      "11m 56s PRINT (O sentence LCS M>60 S>90): formatted 5005 cliques skipping 1730 binary chapter diffs\n",
      "11m 56s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "11m 56s PREPARING (O sentence LCS): Already prepared\n",
      "11m 56s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "12m 03s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "12m 03s CLIQUES (O sentence LCS M>60 S>85): fetching similars and chunk candidates\n",
      "12m 03s CLIQUES (O sentence LCS M>60 S>85): inspecting the similarity matrix\n",
      "12m 10s CLIQUES (O sentence LCS M>60 S>85): 992823 relevant similarities between 26842 passages\n",
      "12m 10s CLIQUES (O sentence LCS M>60 S>85): Loaded:  4832 cliques out of  26842 chunks from 992823 comparisons\n",
      "12m 10s CLIQUES (O sentence LCS M>60 S>85): 26842 members in 4832 cliques\n",
      "12m 10s PRINT (O sentence LCS M>60 S>85): sorting out cliques\n",
      "12m 10s PRINT (O sentence LCS M>60 S>85): formatting 4832 cliques skipping 1719 binary chapter diffs\n",
      "12m 14s PRINT (O sentence LCS M>60 S>85): formatted 4832 cliques skipping 1719 binary chapter diffs\n",
      "12m 14s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "12m 14s PREPARING (O sentence LCS): Already prepared\n",
      "12m 14s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "12m 22s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "12m 22s CLIQUES (O sentence LCS M>60 S>80): fetching similars and chunk candidates\n",
      "12m 22s CLIQUES (O sentence LCS M>60 S>80): inspecting the similarity matrix\n",
      "12m 29s CLIQUES (O sentence LCS M>60 S>80): 1321971 relevant similarities between 36154 passages\n",
      "12m 29s CLIQUES (O sentence LCS M>60 S>80): Loaded:  3428 cliques out of  36154 chunks from 1321971 comparisons\n",
      "12m 29s CLIQUES (O sentence LCS M>60 S>80): 36154 members in 3428 cliques\n",
      "12m 29s PRINT (O sentence LCS M>60 S>80): sorting out cliques\n",
      "12m 29s PRINT (O sentence LCS M>60 S>80): formatting 3428 cliques skipping 1305 binary chapter diffs\n",
      "12m 32s PRINT (O sentence LCS M>60 S>80): formatted 3428 cliques skipping 1305 binary chapter diffs\n",
      "12m 32s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "12m 32s PREPARING (O sentence LCS): Already prepared\n",
      "12m 32s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "12m 39s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "12m 39s CLIQUES (O sentence LCS M>60 S>75): fetching similars and chunk candidates\n",
      "12m 39s CLIQUES (O sentence LCS M>60 S>75): inspecting the similarity matrix\n",
      "12m 46s CLIQUES (O sentence LCS M>60 S>75): 1655321 relevant similarities between 44920 passages\n",
      "12m 46s CLIQUES (O sentence LCS M>60 S>75): Loaded:  2245 cliques out of  44920 chunks from 1655321 comparisons\n",
      "12m 46s CLIQUES (O sentence LCS M>60 S>75): 44920 members in 2245 cliques\n",
      "12m 46s PRINT (O sentence LCS M>60 S>75): sorting out cliques\n",
      "12m 47s PRINT (O sentence LCS M>60 S>75): formatting 2245 cliques skipping 884 binary chapter diffs\n",
      "12m 49s PRINT (O sentence LCS M>60 S>75): formatted 2245 cliques skipping 884 binary chapter diffs\n",
      "12m 49s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "12m 49s PREPARING (O sentence LCS): Already prepared\n",
      "12m 49s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "12m 56s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "12m 56s CLIQUES (O sentence LCS M>60 S>70): fetching similars and chunk candidates\n",
      "12m 56s CLIQUES (O sentence LCS M>60 S>70): inspecting the similarity matrix\n",
      "13m 04s CLIQUES (O sentence LCS M>60 S>70): 2234732 relevant similarities between 53180 passages\n",
      "13m 04s CLIQUES (O sentence LCS M>60 S>70): Loaded:  1167 cliques out of  53180 chunks from 2234732 comparisons\n",
      "13m 04s CLIQUES (O sentence LCS M>60 S>70): 53180 members in 1167 cliques\n",
      "13m 04s PRINT (O sentence LCS M>60 S>70): sorting out cliques\n",
      "13m 05s PRINT (O sentence LCS M>60 S>70): formatting 1167 cliques skipping 447 binary chapter diffs\n",
      "13m 07s PRINT (O sentence LCS M>60 S>70): formatted 1167 cliques skipping 447 binary chapter diffs\n",
      "13m 07s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "13m 07s PREPARING (O sentence LCS): Already prepared\n",
      "13m 07s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "13m 14s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "13m 14s CLIQUES (O sentence LCS M>60 S>65): fetching similars and chunk candidates\n",
      "13m 14s CLIQUES (O sentence LCS M>60 S>65): inspecting the similarity matrix\n",
      "13m 24s CLIQUES (O sentence LCS M>60 S>65): 4978613 relevant similarities between 59474 passages\n",
      "13m 25s CLIQUES (O sentence LCS M>60 S>65): Loaded:   449 cliques out of  59474 chunks from 4978613 comparisons\n",
      "13m 25s CLIQUES (O sentence LCS M>60 S>65): 59474 members in 449 cliques\n",
      "13m 25s PRINT (O sentence LCS M>60 S>65): sorting out cliques\n",
      "13m 25s PRINT (O sentence LCS M>60 S>65): formatting 449 cliques skipping 202 binary chapter diffs\n",
      "13m 27s PRINT (O sentence LCS M>60 S>65): formatted 449 cliques skipping 202 binary chapter diffs\n",
      "13m 27s CHUNKING (O sentence): already chunked into 64125 chunks\n",
      "13m 27s PREPARING (O sentence LCS): Already prepared\n",
      "13m 27s SIMILARITY (O sentence LCS M>60): Using  2055 M (2055975750) comparisons with 10602703 entries in matrix\n",
      "13m 34s SIMILARITY (O sentence LCS M>60): similarities between 60.0 and 100.0. 912742 are 100%\n",
      "13m 34s CLIQUES (O sentence LCS M>60 S>60): fetching similars and chunk candidates\n",
      "13m 34s CLIQUES (O sentence LCS M>60 S>60): inspecting the similarity matrix\n",
      "13m 50s CLIQUES (O sentence LCS M>60 S>60): 10602703 relevant similarities between 62942 passages\n",
      "13m 50s CLIQUES (O sentence LCS M>60 S>60): Loaded:   105 cliques out of  62942 chunks from 10602703 comparisons\n",
      "13m 50s CLIQUES (O sentence LCS M>60 S>60): 62942 members in 105 cliques\n",
      "13m 50s PRINT (O sentence LCS M>60 S>60): sorting out cliques\n",
      "13m 51s PRINT (O sentence LCS M>60 S>60): formatting 105 cliques skipping 56 binary chapter diffs\n",
      "13m 51s PRINT (O sentence LCS M>60 S>60): formatted 105 cliques skipping 56 binary chapter diffs\n",
      "13m 51s EXPERIMENT: Generating html report\n",
      "13m 51s EXPERIMENT:  21 messy results: deprecated\n",
      "13m 51s EXPERIMENT:  17 mixed quality: take care\n",
      "13m 51s EXPERIMENT:   7 unassessed quality: inspection needed\n",
      "13m 51s EXPERIMENT:  72 method deprecated\n",
      "13m 51s EXPERIMENT:   9 promising results: recommended\n",
      "13m 51s EXPERIMENT: Generated html report\n",
      "13m 51s EXPERIMENT: Generating html report(standalone)\n",
      "13m 51s EXPERIMENT:  21 messy results: deprecated\n",
      "13m 51s EXPERIMENT:  17 mixed quality: take care\n",
      "13m 51s EXPERIMENT:   7 unassessed quality: inspection needed\n",
      "13m 51s EXPERIMENT:  72 method deprecated\n",
      "13m 51s EXPERIMENT:   9 promising results: recommended\n",
      "13m 51s EXPERIMENT: Generated html report\n",
      "13m 51s CROSSREFS: Fetching crossrefs\n",
      "13m 51s CROSSREFS (O verse SET S>85)\n",
      "13m 51s CHUNKING (O verse)\n",
      "13m 54s CHUNKING (O verse): Made 23213 chunks\n",
      "13m 54s PREPARING (O verse SET)\n",
      "13m 55s PREPARING (O verse SET): Done 23213 chunks.\n",
      "13m 56s SIMILARITY (O verse SET M>50): Loaded:   269 M (269410078) comparisons with 24867 entries in matrix\n",
      "13m 56s SIMILARITY (O verse SET M>50): similarities between 50.0 and 100.0. 4507 are 100%\n",
      "13m 56s CROSSREFS (O verse SET S>85): found 4934 pairs\n",
      "13m 56s CROSSREFS (O verse LCS S>90)\n",
      "13m 56s CHUNKING (O verse): already chunked into 23213 chunks\n",
      "13m 56s PREPARING (O verse LCS)\n",
      "13m 58s PREPARING (O verse LCS): Done 23213 chunks.\n",
      "13m 58s SIMILARITY (O verse LCS M>60): Loaded:   269 M (269410078) comparisons with 113877 entries in matrix\n",
      "13m 58s SIMILARITY (O verse LCS M>60): similarities between 60.0 and 100.0. 4205 are 100%\n",
      "13m 58s CROSSREFS (O verse LCS S>90): found 5538 pairs\n",
      "13m 58s CROSSREFS: Found 11726 crossreferences\n",
      "13m 59s CROSSREFS: Compiled crossreferences into 7840 notes\n",
      "13m 59s CROSSREFS: Generated 7840 notes\n"
     ]
    }
   ],
   "source": [
    "#reset_params()\n",
    "#do_experiment(False, 'sentence', 'LCS', 60, False)\n",
    "do_all_experiments()\n",
    "crossrefs2shebanq()\n",
    "#show_all_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       ".mis {background-color: #cccccc;}\n",
       ".rec {background-color: #aaffaa;}\n",
       ".dep {background-color: #ffaaaa;}\n",
       ".dub {background-color: #ffddaa;}\n",
       ".out {background-color: #ffddff;}\n",
       ".nor {background-color: #fcfcff;}\n",
       ".ps  {font-weight: normal;}\n",
       ".mx  {font-style: italic;}\n",
       ".cl  {font-weight: bold;}\n",
       ".lr  {font-weight: bold; background-color: #ffffaa;}\n",
       "p,td {font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: small;}\n",
       "td   {border: 1pt solid #000000; padding: 4pt;}\n",
       "table {border: 1pt solid #000000; border-collapse: collapse;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(ecss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "This is sample code for plotting characteristics of the similarity matrix.\n",
    "It does not have a role in the experiments or the assessments of the results.\n",
    "\n",
    "# Overview of the similarities\n",
    "\n",
    "Here is a plot of the similarity matrix.\n",
    "Horizontally you see the degree of similarity from 0 to 100%, vertically the number of pairs that have that (rounded) similarity. This axis is logarithmic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell after the cells below\n",
    "distances = collections.Counter()\n",
    "for (x, d) in chunk_dist.items():\n",
    "    distances[int(round(d))] += 1\n",
    "\n",
    "x = range(MATRIX_THRESHOLD, 101)\n",
    "fig = plt.figure(figsize=[15, 4])\n",
    "plt.plot(x, [math.log(max((1, distances[y]))) for y in x], 'b-')\n",
    "plt.axis([MATRIX_THRESHOLD, 101, 0, 15])\n",
    "plt.xlabel('similarity as %')\n",
    "plt.ylabel('log # similarities')\n",
    "plt.xticks(x, x, rotation='vertical')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15);\n",
    "plt.title('distances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
